{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "    \n",
    "import missingno as msno\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import folium\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "from textwrap import wrap\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor, RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, LogisticRegression, Ridge, Lasso, LassoCV, RidgeCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score,  median_absolute_error, mean_absolute_error\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import dummy, preprocessing, utils\n",
    "\n",
    "\n",
    "import xgboost as xg\n",
    "import shap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('df_pour_explo.csv')\n",
    "df2= pd.read_csv('df_encoder_pour_explo.csv')\n",
    "\n",
    "dfNRJ= pd.read_csv('df_pour_explo.csv')\n",
    "dfNRJ2= pd.read_csv('df_encoder_pour_explo.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>age_building</th>\n",
       "      <th>part_park</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SiteEUIWN(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUIWN(kBtu/sf)</th>\n",
       "      <th>SiteEnergyUse(kBtu)</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>GHGEmissionsIntensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7.456910e+06</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>84.300003</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>7.226362e+06</td>\n",
       "      <td>88434</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.664479e+06</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>20</td>\n",
       "      <td>14.545314</td>\n",
       "      <td>94.800003</td>\n",
       "      <td>97.900002</td>\n",
       "      <td>176.100006</td>\n",
       "      <td>179.399994</td>\n",
       "      <td>8.387933e+06</td>\n",
       "      <td>88502</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7.393711e+07</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>47</td>\n",
       "      <td>20.574829</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>241.899994</td>\n",
       "      <td>244.100006</td>\n",
       "      <td>7.258702e+07</td>\n",
       "      <td>759392</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.946800e+06</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.800003</td>\n",
       "      <td>113.300003</td>\n",
       "      <td>216.199997</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>6.794584e+06</td>\n",
       "      <td>61320</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.465650e+07</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>36</td>\n",
       "      <td>35.311539</td>\n",
       "      <td>114.800003</td>\n",
       "      <td>118.699997</td>\n",
       "      <td>211.399994</td>\n",
       "      <td>215.600006</td>\n",
       "      <td>1.417261e+07</td>\n",
       "      <td>113580</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>18261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.025432e+06</td>\n",
       "      <td>20.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678440</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>136.600006</td>\n",
       "      <td>9.320821e+05</td>\n",
       "      <td>18261</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.053706e+06</td>\n",
       "      <td>32.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417296</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.400002</td>\n",
       "      <td>65.900002</td>\n",
       "      <td>114.199997</td>\n",
       "      <td>118.900002</td>\n",
       "      <td>9.502762e+05</td>\n",
       "      <td>16000</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>13157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.053764e+06</td>\n",
       "      <td>223.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310820</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>438.200012</td>\n",
       "      <td>460.100006</td>\n",
       "      <td>744.799988</td>\n",
       "      <td>767.799988</td>\n",
       "      <td>5.765898e+06</td>\n",
       "      <td>13157</td>\n",
       "      <td>16.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>14101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.828413e+05</td>\n",
       "      <td>22.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>105.300003</td>\n",
       "      <td>110.800003</td>\n",
       "      <td>7.194712e+05</td>\n",
       "      <td>14101</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>18258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.293722e+06</td>\n",
       "      <td>41.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375189</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.099998</td>\n",
       "      <td>70.900002</td>\n",
       "      <td>115.800003</td>\n",
       "      <td>123.900002</td>\n",
       "      <td>1.152896e+06</td>\n",
       "      <td>18258</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PrimaryPropertyType LargestPropertyUseType  PropertyGFATotal  \\\n",
       "0                  Hotel                  Hotel             88434   \n",
       "1                  Hotel                  Hotel            103566   \n",
       "2                  Hotel                  Hotel            956110   \n",
       "3                  Hotel                  Hotel             61320   \n",
       "4                  Hotel                  Hotel            175580   \n",
       "...                  ...                    ...               ...   \n",
       "1509               Other                Culture             18261   \n",
       "1510               Other                Culture             16000   \n",
       "1511               Other                Culture             13157   \n",
       "1512               Other                Culture             14101   \n",
       "1513               Other                Culture             18258   \n",
       "\n",
       "      NumberofBuildings  NumberofFloors  SiteEnergyUseWN(kBtu)  \\\n",
       "0                   1.0              12           7.456910e+06   \n",
       "1                   1.0              11           8.664479e+06   \n",
       "2                   1.0              41           7.393711e+07   \n",
       "3                   1.0              10           6.946800e+06   \n",
       "4                   1.0              18           1.465650e+07   \n",
       "...                 ...             ...                    ...   \n",
       "1509                1.0               1           1.025432e+06   \n",
       "1510                1.0               1           1.053706e+06   \n",
       "1511                1.0               1           6.053764e+06   \n",
       "1512                1.0               1           7.828413e+05   \n",
       "1513                1.0               1           1.293722e+06   \n",
       "\n",
       "      TotalGHGEmissions  Electricity_Use  Electricity_Part  SteamUse_Use  ...  \\\n",
       "0                249.98                1          0.546060             1  ...   \n",
       "1                295.86                1          0.386609             0  ...   \n",
       "2               2089.28                1          0.682307             1  ...   \n",
       "3                286.43                1          0.407519             1  ...   \n",
       "4                505.01                1          0.378802             0  ...   \n",
       "...                 ...              ...               ...           ...  ...   \n",
       "1509              20.33                1          0.678440             0  ...   \n",
       "1510              32.17                1          0.417296             0  ...   \n",
       "1511             223.54                1          0.310820             0  ...   \n",
       "1512              22.11                1          0.484898             0  ...   \n",
       "1513              41.27                1          0.375189             0  ...   \n",
       "\n",
       "      ENERGYSTARScore  age_building  part_park  SiteEUI(kBtu/sf)  \\\n",
       "0                60.0            89   0.000000         81.699997   \n",
       "1                61.0            20  14.545314         94.800003   \n",
       "2                43.0            47  20.574829         96.000000   \n",
       "3                56.0            90   0.000000        110.800003   \n",
       "4                75.0            36  35.311539        114.800003   \n",
       "...               ...           ...        ...               ...   \n",
       "1509              NaN            34   0.000000         51.000000   \n",
       "1510              NaN            12   0.000000         59.400002   \n",
       "1511              NaN            42   0.000000        438.200012   \n",
       "1512              NaN            27   0.000000         51.000000   \n",
       "1513              NaN            78   0.000000         63.099998   \n",
       "\n",
       "      SiteEUIWN(kBtu/sf)  SourceEUI(kBtu/sf)  SourceEUIWN(kBtu/sf)  \\\n",
       "0              84.300003          182.500000            189.000000   \n",
       "1              97.900002          176.100006            179.399994   \n",
       "2              97.699997          241.899994            244.100006   \n",
       "3             113.300003          216.199997            224.000000   \n",
       "4             118.699997          211.399994            215.600006   \n",
       "...                  ...                 ...                   ...   \n",
       "1509           56.200001          126.000000            136.600006   \n",
       "1510           65.900002          114.199997            118.900002   \n",
       "1511          460.100006          744.799988            767.799988   \n",
       "1512           55.500000          105.300003            110.800003   \n",
       "1513           70.900002          115.800003            123.900002   \n",
       "\n",
       "      SiteEnergyUse(kBtu)  PropertyGFABuilding(s)  GHGEmissionsIntensity  \n",
       "0            7.226362e+06                   88434                   2.83  \n",
       "1            8.387933e+06                   88502                   2.86  \n",
       "2            7.258702e+07                  759392                   2.19  \n",
       "3            6.794584e+06                   61320                   4.67  \n",
       "4            1.417261e+07                  113580                   2.88  \n",
       "...                   ...                     ...                    ...  \n",
       "1509         9.320821e+05                   18261                   1.11  \n",
       "1510         9.502762e+05                   16000                   2.01  \n",
       "1511         5.765898e+06                   13157                  16.99  \n",
       "1512         7.194712e+05                   14101                   1.57  \n",
       "1513         1.152896e+06                   18258                   2.26  \n",
       "\n",
       "[1514 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([\"ENERGYSTARScore\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(axis=0,how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>NaturalGas_Part</th>\n",
       "      <th>age_building</th>\n",
       "      <th>part_park</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SiteEUIWN(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUIWN(kBtu/sf)</th>\n",
       "      <th>SiteEnergyUse(kBtu)</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>GHGEmissionsIntensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7456910.0</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176638</td>\n",
       "      <td>89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>84.300003</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>7226362.5</td>\n",
       "      <td>88434</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8664479.0</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613391</td>\n",
       "      <td>20</td>\n",
       "      <td>14.545314</td>\n",
       "      <td>94.800003</td>\n",
       "      <td>97.900002</td>\n",
       "      <td>176.100006</td>\n",
       "      <td>179.399994</td>\n",
       "      <td>8387933.0</td>\n",
       "      <td>88502</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>73937112.0</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020579</td>\n",
       "      <td>47</td>\n",
       "      <td>20.574829</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>241.899994</td>\n",
       "      <td>244.100006</td>\n",
       "      <td>72587024.0</td>\n",
       "      <td>759392</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6946800.5</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266567</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.800003</td>\n",
       "      <td>113.300003</td>\n",
       "      <td>216.199997</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>6794584.0</td>\n",
       "      <td>61320</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>14656503.0</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621198</td>\n",
       "      <td>36</td>\n",
       "      <td>35.311539</td>\n",
       "      <td>114.800003</td>\n",
       "      <td>118.699997</td>\n",
       "      <td>211.399994</td>\n",
       "      <td>215.600006</td>\n",
       "      <td>14172606.0</td>\n",
       "      <td>113580</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PrimaryPropertyType LargestPropertyUseType  PropertyGFATotal  \\\n",
       "0               Hotel                  Hotel             88434   \n",
       "1               Hotel                  Hotel            103566   \n",
       "2               Hotel                  Hotel            956110   \n",
       "3               Hotel                  Hotel             61320   \n",
       "4               Hotel                  Hotel            175580   \n",
       "\n",
       "   NumberofBuildings  NumberofFloors  SiteEnergyUseWN(kBtu)  \\\n",
       "0                1.0              12              7456910.0   \n",
       "1                1.0              11              8664479.0   \n",
       "2                1.0              41             73937112.0   \n",
       "3                1.0              10              6946800.5   \n",
       "4                1.0              18             14656503.0   \n",
       "\n",
       "   TotalGHGEmissions  Electricity_Use  Electricity_Part  SteamUse_Use  ...  \\\n",
       "0             249.98                1          0.546060             1  ...   \n",
       "1             295.86                1          0.386609             0  ...   \n",
       "2            2089.28                1          0.682307             1  ...   \n",
       "3             286.43                1          0.407519             1  ...   \n",
       "4             505.01                1          0.378802             0  ...   \n",
       "\n",
       "   NaturalGas_Part  age_building  part_park  SiteEUI(kBtu/sf)  \\\n",
       "0         0.176638            89   0.000000         81.699997   \n",
       "1         0.613391            20  14.545314         94.800003   \n",
       "2         0.020579            47  20.574829         96.000000   \n",
       "3         0.266567            90   0.000000        110.800003   \n",
       "4         0.621198            36  35.311539        114.800003   \n",
       "\n",
       "   SiteEUIWN(kBtu/sf)  SourceEUI(kBtu/sf)  SourceEUIWN(kBtu/sf)  \\\n",
       "0           84.300003          182.500000            189.000000   \n",
       "1           97.900002          176.100006            179.399994   \n",
       "2           97.699997          241.899994            244.100006   \n",
       "3          113.300003          216.199997            224.000000   \n",
       "4          118.699997          211.399994            215.600006   \n",
       "\n",
       "   SiteEnergyUse(kBtu)  PropertyGFABuilding(s)  GHGEmissionsIntensity  \n",
       "0            7226362.5                   88434                   2.83  \n",
       "1            8387933.0                   88502                   2.86  \n",
       "2           72587024.0                  759392                   2.19  \n",
       "3            6794584.0                   61320                   4.67  \n",
       "4           14172606.0                  113580                   2.88  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1509 entries, 0 to 1513\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   PrimaryPropertyType     1509 non-null   object \n",
      " 1   LargestPropertyUseType  1509 non-null   object \n",
      " 2   PropertyGFATotal        1509 non-null   int64  \n",
      " 3   NumberofBuildings       1509 non-null   float64\n",
      " 4   NumberofFloors          1509 non-null   int64  \n",
      " 5   SiteEnergyUseWN(kBtu)   1509 non-null   float64\n",
      " 6   TotalGHGEmissions       1509 non-null   float64\n",
      " 7   Electricity_Use         1509 non-null   int64  \n",
      " 8   Electricity_Part        1509 non-null   float64\n",
      " 9   SteamUse_Use            1509 non-null   int64  \n",
      " 10  SteamUse_Part           1509 non-null   float64\n",
      " 11  NaturalGas_Use          1509 non-null   int64  \n",
      " 12  NaturalGas_Part         1509 non-null   float64\n",
      " 13  age_building            1509 non-null   int64  \n",
      " 14  part_park               1509 non-null   float64\n",
      " 15  SiteEUI(kBtu/sf)        1509 non-null   float64\n",
      " 16  SiteEUIWN(kBtu/sf)      1509 non-null   float64\n",
      " 17  SourceEUI(kBtu/sf)      1509 non-null   float64\n",
      " 18  SourceEUIWN(kBtu/sf)    1509 non-null   float64\n",
      " 19  SiteEnergyUse(kBtu)     1509 non-null   float64\n",
      " 20  PropertyGFABuilding(s)  1509 non-null   int64  \n",
      " 21  GHGEmissionsIntensity   1509 non-null   float64\n",
      "dtypes: float64(13), int64(7), object(2)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>SteamUse_Part</th>\n",
       "      <th>NaturalGas_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>LargestPropertyUseType_Distribution</th>\n",
       "      <th>LargestPropertyUseType_Food</th>\n",
       "      <th>LargestPropertyUseType_Hotel</th>\n",
       "      <th>LargestPropertyUseType_Legal</th>\n",
       "      <th>LargestPropertyUseType_Medical</th>\n",
       "      <th>LargestPropertyUseType_Office</th>\n",
       "      <th>LargestPropertyUseType_Other</th>\n",
       "      <th>LargestPropertyUseType_Parking</th>\n",
       "      <th>LargestPropertyUseType_School</th>\n",
       "      <th>LargestPropertyUseType_Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7.456910e+06</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277302</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.664479e+06</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7.393711e+07</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.946800e+06</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.465650e+07</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>18261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.025432e+06</td>\n",
       "      <td>20.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.053706e+06</td>\n",
       "      <td>32.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>13157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.053764e+06</td>\n",
       "      <td>223.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310820</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>14101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.828413e+05</td>\n",
       "      <td>22.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>18258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.293722e+06</td>\n",
       "      <td>41.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PropertyGFATotal  NumberofBuildings  NumberofFloors  \\\n",
       "0                88434                1.0              12   \n",
       "1               103566                1.0              11   \n",
       "2               956110                1.0              41   \n",
       "3                61320                1.0              10   \n",
       "4               175580                1.0              18   \n",
       "...                ...                ...             ...   \n",
       "1509             18261                1.0               1   \n",
       "1510             16000                1.0               1   \n",
       "1511             13157                1.0               1   \n",
       "1512             14101                1.0               1   \n",
       "1513             18258                1.0               1   \n",
       "\n",
       "      SiteEnergyUseWN(kBtu)  TotalGHGEmissions  Electricity_Use  \\\n",
       "0              7.456910e+06             249.98                1   \n",
       "1              8.664479e+06             295.86                1   \n",
       "2              7.393711e+07            2089.28                1   \n",
       "3              6.946800e+06             286.43                1   \n",
       "4              1.465650e+07             505.01                1   \n",
       "...                     ...                ...              ...   \n",
       "1509           1.025432e+06              20.33                1   \n",
       "1510           1.053706e+06              32.17                1   \n",
       "1511           6.053764e+06             223.54                1   \n",
       "1512           7.828413e+05              22.11                1   \n",
       "1513           1.293722e+06              41.27                1   \n",
       "\n",
       "      Electricity_Part  SteamUse_Use  SteamUse_Part  NaturalGas_Use  ...  \\\n",
       "0             0.546060             1       0.277302               1  ...   \n",
       "1             0.386609             0       0.000000               1  ...   \n",
       "2             0.682307             1       0.297113               1  ...   \n",
       "3             0.407519             1       0.325913               1  ...   \n",
       "4             0.378802             0       0.000000               1  ...   \n",
       "...                ...           ...            ...             ...  ...   \n",
       "1509          0.678440             0       0.000000               1  ...   \n",
       "1510          0.417296             0       0.000000               1  ...   \n",
       "1511          0.310820             0       0.000000               1  ...   \n",
       "1512          0.484898             0       0.000000               1  ...   \n",
       "1513          0.375189             0       0.000000               1  ...   \n",
       "\n",
       "      LargestPropertyUseType_Distribution  LargestPropertyUseType_Food  \\\n",
       "0                                       0                            0   \n",
       "1                                       0                            0   \n",
       "2                                       0                            0   \n",
       "3                                       0                            0   \n",
       "4                                       0                            0   \n",
       "...                                   ...                          ...   \n",
       "1509                                    0                            0   \n",
       "1510                                    0                            0   \n",
       "1511                                    0                            0   \n",
       "1512                                    0                            0   \n",
       "1513                                    0                            0   \n",
       "\n",
       "      LargestPropertyUseType_Hotel  LargestPropertyUseType_Legal  \\\n",
       "0                                1                             0   \n",
       "1                                1                             0   \n",
       "2                                1                             0   \n",
       "3                                1                             0   \n",
       "4                                1                             0   \n",
       "...                            ...                           ...   \n",
       "1509                             0                             0   \n",
       "1510                             0                             0   \n",
       "1511                             0                             0   \n",
       "1512                             0                             0   \n",
       "1513                             0                             0   \n",
       "\n",
       "      LargestPropertyUseType_Medical  LargestPropertyUseType_Office  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "...                              ...                            ...   \n",
       "1509                               0                              0   \n",
       "1510                               0                              0   \n",
       "1511                               0                              0   \n",
       "1512                               0                              0   \n",
       "1513                               0                              0   \n",
       "\n",
       "      LargestPropertyUseType_Other  LargestPropertyUseType_Parking  \\\n",
       "0                                0                               0   \n",
       "1                                0                               0   \n",
       "2                                0                               0   \n",
       "3                                0                               0   \n",
       "4                                0                               0   \n",
       "...                            ...                             ...   \n",
       "1509                             0                               0   \n",
       "1510                             0                               0   \n",
       "1511                             0                               0   \n",
       "1512                             0                               0   \n",
       "1513                             0                               0   \n",
       "\n",
       "      LargestPropertyUseType_School  LargestPropertyUseType_Sport  \n",
       "0                                 0                             0  \n",
       "1                                 0                             0  \n",
       "2                                 0                             0  \n",
       "3                                 0                             0  \n",
       "4                                 0                             0  \n",
       "...                             ...                           ...  \n",
       "1509                              0                             0  \n",
       "1510                              0                             0  \n",
       "1511                              0                             0  \n",
       "1512                              0                             0  \n",
       "1513                              0                             0  \n",
       "\n",
       "[1514 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= df2.drop([\"ENERGYSTARScore\"], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.dropna(axis=0,how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>SteamUse_Part</th>\n",
       "      <th>NaturalGas_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>LargestPropertyUseType_Distribution</th>\n",
       "      <th>LargestPropertyUseType_Food</th>\n",
       "      <th>LargestPropertyUseType_Hotel</th>\n",
       "      <th>LargestPropertyUseType_Legal</th>\n",
       "      <th>LargestPropertyUseType_Medical</th>\n",
       "      <th>LargestPropertyUseType_Office</th>\n",
       "      <th>LargestPropertyUseType_Other</th>\n",
       "      <th>LargestPropertyUseType_Parking</th>\n",
       "      <th>LargestPropertyUseType_School</th>\n",
       "      <th>LargestPropertyUseType_Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7456910.0</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277302</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8664479.0</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>73937112.0</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6946800.5</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>14656503.0</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PropertyGFATotal  NumberofBuildings  NumberofFloors  SiteEnergyUseWN(kBtu)  \\\n",
       "0             88434                1.0              12              7456910.0   \n",
       "1            103566                1.0              11              8664479.0   \n",
       "2            956110                1.0              41             73937112.0   \n",
       "3             61320                1.0              10              6946800.5   \n",
       "4            175580                1.0              18             14656503.0   \n",
       "\n",
       "   TotalGHGEmissions  Electricity_Use  Electricity_Part  SteamUse_Use  \\\n",
       "0             249.98                1          0.546060             1   \n",
       "1             295.86                1          0.386609             0   \n",
       "2            2089.28                1          0.682307             1   \n",
       "3             286.43                1          0.407519             1   \n",
       "4             505.01                1          0.378802             0   \n",
       "\n",
       "   SteamUse_Part  NaturalGas_Use  ...  LargestPropertyUseType_Distribution  \\\n",
       "0       0.277302               1  ...                                    0   \n",
       "1       0.000000               1  ...                                    0   \n",
       "2       0.297113               1  ...                                    0   \n",
       "3       0.325913               1  ...                                    0   \n",
       "4       0.000000               1  ...                                    0   \n",
       "\n",
       "   LargestPropertyUseType_Food  LargestPropertyUseType_Hotel  \\\n",
       "0                            0                             1   \n",
       "1                            0                             1   \n",
       "2                            0                             1   \n",
       "3                            0                             1   \n",
       "4                            0                             1   \n",
       "\n",
       "   LargestPropertyUseType_Legal  LargestPropertyUseType_Medical  \\\n",
       "0                             0                               0   \n",
       "1                             0                               0   \n",
       "2                             0                               0   \n",
       "3                             0                               0   \n",
       "4                             0                               0   \n",
       "\n",
       "   LargestPropertyUseType_Office  LargestPropertyUseType_Other  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              0                             0   \n",
       "4                              0                             0   \n",
       "\n",
       "   LargestPropertyUseType_Parking  LargestPropertyUseType_School  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "\n",
       "   LargestPropertyUseType_Sport  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1513 entries, 0 to 1513\n",
      "Data columns (total 36 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   PropertyGFATotal                     1513 non-null   int64  \n",
      " 1   NumberofBuildings                    1513 non-null   float64\n",
      " 2   NumberofFloors                       1513 non-null   int64  \n",
      " 3   SiteEnergyUseWN(kBtu)                1513 non-null   float64\n",
      " 4   TotalGHGEmissions                    1513 non-null   float64\n",
      " 5   Electricity_Use                      1513 non-null   int64  \n",
      " 6   Electricity_Part                     1513 non-null   float64\n",
      " 7   SteamUse_Use                         1513 non-null   int64  \n",
      " 8   SteamUse_Part                        1513 non-null   float64\n",
      " 9   NaturalGas_Use                       1513 non-null   int64  \n",
      " 10  NaturalGas_Part                      1513 non-null   float64\n",
      " 11  age_building                         1513 non-null   int64  \n",
      " 12  part_park                            1513 non-null   float64\n",
      " 13  SiteEUI(kBtu/sf)                     1513 non-null   float64\n",
      " 14  SiteEUIWN(kBtu/sf)                   1513 non-null   float64\n",
      " 15  SourceEUI(kBtu/sf)                   1513 non-null   float64\n",
      " 16  SourceEUIWN(kBtu/sf)                 1513 non-null   float64\n",
      " 17  SiteEnergyUse(kBtu)                  1513 non-null   float64\n",
      " 18  PropertyGFABuilding(s)               1513 non-null   int64  \n",
      " 19  GHGEmissionsIntensity                1513 non-null   float64\n",
      " 20  PrimaryPropertyType_Hotel            1513 non-null   int64  \n",
      " 21  PrimaryPropertyType_Medical          1513 non-null   int64  \n",
      " 22  PrimaryPropertyType_Office           1513 non-null   int64  \n",
      " 23  PrimaryPropertyType_Other            1513 non-null   int64  \n",
      " 24  PrimaryPropertyType_School           1513 non-null   int64  \n",
      " 25  LargestPropertyUseType_Culture       1513 non-null   int64  \n",
      " 26  LargestPropertyUseType_Distribution  1513 non-null   int64  \n",
      " 27  LargestPropertyUseType_Food          1513 non-null   int64  \n",
      " 28  LargestPropertyUseType_Hotel         1513 non-null   int64  \n",
      " 29  LargestPropertyUseType_Legal         1513 non-null   int64  \n",
      " 30  LargestPropertyUseType_Medical       1513 non-null   int64  \n",
      " 31  LargestPropertyUseType_Office        1513 non-null   int64  \n",
      " 32  LargestPropertyUseType_Other         1513 non-null   int64  \n",
      " 33  LargestPropertyUseType_Parking       1513 non-null   int64  \n",
      " 34  LargestPropertyUseType_School        1513 non-null   int64  \n",
      " 35  LargestPropertyUseType_Sport         1513 non-null   int64  \n",
      "dtypes: float64(13), int64(23)\n",
      "memory usage: 437.4 KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARATION DES VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[['NumberofBuildings', 'NumberofFloors', \n",
    "       'age_building', 'part_park', 'Electricity_Use' , 'SteamUse_Use', 'NaturalGas_Use',\n",
    "         'PropertyGFABuilding(s)','PropertyGFATotal',\n",
    "        'PrimaryPropertyType_Hotel', 'PrimaryPropertyType_Medical', 'PrimaryPropertyType_Office', 'PrimaryPropertyType_Other', 'PrimaryPropertyType_School',\n",
    "        'LargestPropertyUseType_Culture', 'LargestPropertyUseType_Distribution',   'LargestPropertyUseType_Food', 'LargestPropertyUseType_Hotel', 'LargestPropertyUseType_Legal', 'LargestPropertyUseType_Medical', 'LargestPropertyUseType_Office', 'LargestPropertyUseType_Other', 'LargestPropertyUseType_Parking', 'LargestPropertyUseType_School', 'LargestPropertyUseType_Sport']]\n",
    "\n",
    "y = df2[['SiteEnergyUseWN(kBtu)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "std_scale = StandardScaler().fit(X_train)\n",
    "X_train_std =  std_scale.transform(X_train)\n",
    "X_test_std =  std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "\n",
    "scoring = {'R2': 'r2',\n",
    "           'MAE': 'neg_mean_squared_error',\n",
    "           'RMSE': 'neg_mean_absolute_error'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DUMMY REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01571207, 0.01470189, 0.00794373, 0.01205788]),\n",
       " 'std_fit_time': array([0.00023629, 0.00184944, 0.00660055, 0.00705828]),\n",
       " 'mean_score_time': array([0.        , 0.        , 0.00725937, 0.00376406]),\n",
       " 'std_score_time': array([0.        , 0.        , 0.00690074, 0.00630181]),\n",
       " 'param_n_features_to_select': masked_array(data=[1, 2, 3, 4],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_features_to_select': 1},\n",
       "  {'n_features_to_select': 2},\n",
       "  {'n_features_to_select': 3},\n",
       "  {'n_features_to_select': 4}],\n",
       " 'split0_test_R2': array([0.26210998, 0.18810145, 0.19054217, 0.19372901]),\n",
       " 'split1_test_R2': array([0.27423317, 0.23832515, 0.22636013, 0.14833163]),\n",
       " 'split2_test_R2': array([0.43169227, 0.4405816 , 0.45335191, 0.54959666]),\n",
       " 'split3_test_R2': array([0.54846499, 0.02566095, 0.003256  , 0.06692631]),\n",
       " 'split4_test_R2': array([0.63823182, 0.74758494, 0.74984362, 0.78331937]),\n",
       " 'mean_test_R2': array([0.43094645, 0.32805082, 0.32467076, 0.34838059]),\n",
       " 'std_test_R2': array([0.14821821, 0.248092  , 0.25623962, 0.27306148]),\n",
       " 'rank_test_R2': array([1, 3, 4, 2]),\n",
       " 'split0_train_R2': array([0.52430126, 0.63380055, 0.6639681 , 0.66418441]),\n",
       " 'split1_train_R2': array([0.48328899, 0.56714715, 0.56910492, 0.59925101]),\n",
       " 'split2_train_R2': array([0.48951628, 0.49114939, 0.50660163, 0.52539239]),\n",
       " 'split3_train_R2': array([0.46768755, 0.56925514, 0.57130931, 0.59468967]),\n",
       " 'split4_train_R2': array([0.40329815, 0.46365708, 0.46421414, 0.4852982 ]),\n",
       " 'mean_train_R2': array([0.47361845, 0.54500186, 0.55503962, 0.57376313]),\n",
       " 'std_train_R2': array([0.03973695, 0.06079623, 0.06771035, 0.06233672]),\n",
       " 'split0_test_MAE': array([-3.09345561e+14, -3.40372151e+14, -3.39348929e+14, -3.38012911e+14]),\n",
       " 'split1_test_MAE': array([-9.80105699e+13, -1.02859738e+14, -1.04475545e+14, -1.15012837e+14]),\n",
       " 'split2_test_MAE': array([-4.75448215e+14, -4.68011373e+14, -4.57327689e+14, -3.76808996e+14]),\n",
       " 'split3_test_MAE': array([-4.66151131e+13, -1.00587825e+14, -1.02900845e+14, -9.63277144e+13]),\n",
       " 'split4_test_MAE': array([-2.22823119e+14, -1.55469479e+14, -1.54078296e+14, -1.33459650e+14]),\n",
       " 'mean_test_MAE': array([-2.30448516e+14, -2.33460113e+14, -2.31626261e+14, -2.11924422e+14]),\n",
       " 'std_test_MAE': array([1.53389877e+14, 1.46450346e+14, 1.42335190e+14, 1.19997004e+14]),\n",
       " 'rank_test_MAE': array([2, 4, 3, 1]),\n",
       " 'split0_train_MAE': array([-2.01855945e+14, -1.55391490e+14, -1.42590320e+14, -1.42498536e+14]),\n",
       " 'split1_train_MAE': array([-2.55969767e+14, -2.14427874e+14, -2.13458029e+14, -1.98524175e+14]),\n",
       " 'split2_train_MAE': array([-1.63157858e+14, -1.62635893e+14, -1.57697137e+14, -1.51691344e+14]),\n",
       " 'split3_train_MAE': array([-2.67459778e+14, -2.16427257e+14, -2.15395141e+14, -2.03647705e+14]),\n",
       " 'split4_train_MAE': array([-2.23456755e+14, -2.00853156e+14, -2.00644543e+14, -1.92748850e+14]),\n",
       " 'mean_train_MAE': array([-2.22380020e+14, -1.89947134e+14, -1.85957034e+14, -1.77822122e+14]),\n",
       " 'std_train_MAE': array([3.76566520e+13, 2.59208072e+13, 3.00596854e+13, 2.54908462e+13]),\n",
       " 'split0_test_RMSE': array([-4903564.73755849, -5497542.32123641, -5262798.91073972,\n",
       "        -5275029.85727913]),\n",
       " 'split1_test_RMSE': array([-4827561.18368885, -5343614.81872675, -5408928.36640485,\n",
       "        -5938301.25660849]),\n",
       " 'split2_test_RMSE': array([-5663513.56739102, -5767879.49746228, -5917194.49823298,\n",
       "        -5820093.19746856]),\n",
       " 'split3_test_RMSE': array([-3658116.54101663, -4572022.86139244, -4675767.9905698 ,\n",
       "        -4634456.28096663]),\n",
       " 'split4_test_RMSE': array([-5450670.37934361, -5185702.17984084, -5221661.15868784,\n",
       "        -4968588.02946864]),\n",
       " 'mean_test_RMSE': array([-4900685.28179972, -5273352.33573174, -5297270.18492704,\n",
       "        -5327293.72435829]),\n",
       " 'std_test_RMSE': array([697670.85382432, 399825.12707713, 397477.96791837, 495501.06669473]),\n",
       " 'rank_test_RMSE': array([1, 2, 3, 4]),\n",
       " 'split0_train_RMSE': array([-4900578.81390582, -5244910.43735689, -5222633.84127256,\n",
       "        -5240123.09185898]),\n",
       " 'split1_train_RMSE': array([-5029417.5293151 , -5208297.14419218, -5294138.17058487,\n",
       "        -5231638.06248099]),\n",
       " 'split2_train_RMSE': array([-4529795.39958364, -4599798.28979255, -4594513.61063802,\n",
       "        -4672051.14987836]),\n",
       " 'split3_train_RMSE': array([-5211848.92472565, -5449044.95991879, -5537328.97974675,\n",
       "        -5493781.39264225]),\n",
       " 'split4_train_RMSE': array([-4624343.91655114, -4987836.66981544, -5028376.53606346,\n",
       "        -5054433.57260685]),\n",
       " 'mean_train_RMSE': array([-4859196.91681627, -5097977.50021517, -5135398.22766113,\n",
       "        -5138405.45389349]),\n",
       " 'std_train_RMSE': array([252472.67111409, 288901.9215393 , 315710.8052121 , 271981.05402367])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Dummyparams = [{'n_features_to_select': list(range(1, 5))}]\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_std, y_train)\n",
    "rfe = RFE(lm)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "\n",
    "MyDummy = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = Dummyparams, \n",
    "                        scoring= scoring,\n",
    "                        refit= False,  \n",
    "                        cv = CV, \n",
    "                        verbose = 2,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "MyDummy.fit(X_train_std, y_train)  \n",
    "\n",
    "MyDummy.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_features_to_select</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "      <th>split0_train_RMSE</th>\n",
       "      <th>split1_train_RMSE</th>\n",
       "      <th>split2_train_RMSE</th>\n",
       "      <th>split3_train_RMSE</th>\n",
       "      <th>split4_train_RMSE</th>\n",
       "      <th>mean_train_RMSE</th>\n",
       "      <th>std_train_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_features_to_select': 1}</td>\n",
       "      <td>0.262110</td>\n",
       "      <td>0.274233</td>\n",
       "      <td>0.431692</td>\n",
       "      <td>0.548465</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.900685e+06</td>\n",
       "      <td>697670.853824</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.900579e+06</td>\n",
       "      <td>-5.029418e+06</td>\n",
       "      <td>-4.529795e+06</td>\n",
       "      <td>-5.211849e+06</td>\n",
       "      <td>-4.624344e+06</td>\n",
       "      <td>-4.859197e+06</td>\n",
       "      <td>252472.671114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_features_to_select': 2}</td>\n",
       "      <td>0.188101</td>\n",
       "      <td>0.238325</td>\n",
       "      <td>0.440582</td>\n",
       "      <td>0.025661</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.273352e+06</td>\n",
       "      <td>399825.127077</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.244910e+06</td>\n",
       "      <td>-5.208297e+06</td>\n",
       "      <td>-4.599798e+06</td>\n",
       "      <td>-5.449045e+06</td>\n",
       "      <td>-4.987837e+06</td>\n",
       "      <td>-5.097978e+06</td>\n",
       "      <td>288901.921539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007944</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_features_to_select': 3}</td>\n",
       "      <td>0.190542</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>0.453352</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.297270e+06</td>\n",
       "      <td>397477.967918</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.222634e+06</td>\n",
       "      <td>-5.294138e+06</td>\n",
       "      <td>-4.594514e+06</td>\n",
       "      <td>-5.537329e+06</td>\n",
       "      <td>-5.028377e+06</td>\n",
       "      <td>-5.135398e+06</td>\n",
       "      <td>315710.805212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012058</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_features_to_select': 4}</td>\n",
       "      <td>0.193729</td>\n",
       "      <td>0.148332</td>\n",
       "      <td>0.549597</td>\n",
       "      <td>0.066926</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.327294e+06</td>\n",
       "      <td>495501.066695</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.240123e+06</td>\n",
       "      <td>-5.231638e+06</td>\n",
       "      <td>-4.672051e+06</td>\n",
       "      <td>-5.493781e+06</td>\n",
       "      <td>-5.054434e+06</td>\n",
       "      <td>-5.138405e+06</td>\n",
       "      <td>271981.054024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.015712      0.000236         0.000000        0.000000   \n",
       "1       0.014702      0.001849         0.000000        0.000000   \n",
       "2       0.007944      0.006601         0.007259        0.006901   \n",
       "3       0.012058      0.007058         0.003764        0.006302   \n",
       "\n",
       "  param_n_features_to_select                       params  split0_test_R2  \\\n",
       "0                          1  {'n_features_to_select': 1}        0.262110   \n",
       "1                          2  {'n_features_to_select': 2}        0.188101   \n",
       "2                          3  {'n_features_to_select': 3}        0.190542   \n",
       "3                          4  {'n_features_to_select': 4}        0.193729   \n",
       "\n",
       "   split1_test_R2  split2_test_R2  split3_test_R2  ...  mean_test_RMSE  \\\n",
       "0        0.274233        0.431692        0.548465  ...   -4.900685e+06   \n",
       "1        0.238325        0.440582        0.025661  ...   -5.273352e+06   \n",
       "2        0.226360        0.453352        0.003256  ...   -5.297270e+06   \n",
       "3        0.148332        0.549597        0.066926  ...   -5.327294e+06   \n",
       "\n",
       "   std_test_RMSE  rank_test_RMSE  split0_train_RMSE  split1_train_RMSE  \\\n",
       "0  697670.853824               1      -4.900579e+06      -5.029418e+06   \n",
       "1  399825.127077               2      -5.244910e+06      -5.208297e+06   \n",
       "2  397477.967918               3      -5.222634e+06      -5.294138e+06   \n",
       "3  495501.066695               4      -5.240123e+06      -5.231638e+06   \n",
       "\n",
       "   split2_train_RMSE  split3_train_RMSE  split4_train_RMSE  mean_train_RMSE  \\\n",
       "0      -4.529795e+06      -5.211849e+06      -4.624344e+06    -4.859197e+06   \n",
       "1      -4.599798e+06      -5.449045e+06      -4.987837e+06    -5.097978e+06   \n",
       "2      -4.594514e+06      -5.537329e+06      -5.028377e+06    -5.135398e+06   \n",
       "3      -4.672051e+06      -5.493781e+06      -5.054434e+06    -5.138405e+06   \n",
       "\n",
       "   std_train_RMSE  \n",
       "0   252472.671114  \n",
       "1   288901.921539  \n",
       "2   315710.805212  \n",
       "3   271981.054024  \n",
       "\n",
       "[4 rows x 51 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyDummybest=pd.concat([pd.DataFrame(MyDummy.cv_results_)])\n",
    "MyDummybest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.430946\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyDummybestR2=MyDummybest[MyDummybest['rank_test_R2'].isin([1])]\n",
    "print(MyDummybestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ELASTICNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 280 candidates, totalling 1400 fits\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.014e+16, tolerance: 3.849e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e+16, tolerance: 4.493e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.239e+16, tolerance: 2.899e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.658e+16, tolerance: 4.557e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.376e+16, tolerance: 3.400e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.014e+16, tolerance: 3.849e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e+16, tolerance: 4.493e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.239e+16, tolerance: 2.899e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.658e+16, tolerance: 4.557e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.376e+16, tolerance: 3.400e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.014e+16, tolerance: 3.849e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e+16, tolerance: 4.493e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.239e+16, tolerance: 2.899e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.658e+16, tolerance: 4.557e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.376e+16, tolerance: 3.400e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.014e+16, tolerance: 3.849e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e+16, tolerance: 4.493e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.239e+16, tolerance: 2.899e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.658e+16, tolerance: 4.557e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.376e+16, tolerance: 3.400e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.945e+16, tolerance: 3.849e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.566e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e+16, tolerance: 2.899e+16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.653e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.945e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.566e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.653e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.945e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.566e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.653e+16, tolerance: 4.557e+14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.945e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.566e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.653e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.879e+16, tolerance: 3.849e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.560e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.205e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.879e+16, tolerance: 3.849e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.560e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.205e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.879e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.560e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.205e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.879e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.560e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.205e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e+16, tolerance: 4.557e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+16, tolerance: 3.849e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.188e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.645e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.188e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.645e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.188e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.645e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.817e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.188e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.645e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.375e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.758e+16, tolerance: 3.849e+16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.173e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.641e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.758e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.173e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.641e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.758e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e+16, tolerance: 4.493e+14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.173e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.641e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.758e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.173e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.641e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.703e+16, tolerance: 3.849e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.542e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.158e+16, tolerance: 2.899e+16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.637e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.703e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.542e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.158e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.637e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.703e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.542e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.158e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.637e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.703e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.542e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.158e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.637e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.650e+16, tolerance: 3.849e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.537e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.144e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.633e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.650e+16, tolerance: 3.849e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.537e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.144e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.633e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.650e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.537e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.144e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.633e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.650e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.537e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.144e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.633e+16, tolerance: 4.557e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.601e+16, tolerance: 3.849e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.532e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.130e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.630e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.601e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.532e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.130e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.630e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.601e+16, tolerance: 3.849e+14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.532e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.130e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.630e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.601e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.532e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.130e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.630e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.554e+16, tolerance: 3.849e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.527e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.117e+16, tolerance: 2.899e+16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.626e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.554e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.527e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.117e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.626e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.554e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.527e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.117e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.626e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e+16, tolerance: 3.400e+14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.554e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.527e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.117e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.626e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.373e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.510e+16, tolerance: 3.849e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.522e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.105e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.623e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.372e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.510e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.522e+16, tolerance: 4.493e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.105e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.623e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.372e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.510e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.522e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.105e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.623e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.372e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.510e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.522e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.105e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.623e+16, tolerance: 4.557e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.372e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.037e+16, tolerance: 3.849e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.613e+16, tolerance: 4.493e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.276e+16, tolerance: 2.899e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.695e+16, tolerance: 4.557e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.403e+16, tolerance: 3.400e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.037e+16, tolerance: 3.849e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.613e+16, tolerance: 4.493e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.276e+16, tolerance: 2.899e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.695e+16, tolerance: 4.557e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.403e+16, tolerance: 3.400e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.037e+16, tolerance: 3.849e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.613e+16, tolerance: 4.493e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.276e+16, tolerance: 2.899e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.695e+16, tolerance: 4.557e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.403e+16, tolerance: 3.400e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.037e+16, tolerance: 3.849e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.613e+16, tolerance: 4.493e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.276e+16, tolerance: 2.899e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.695e+16, tolerance: 4.557e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.403e+16, tolerance: 3.400e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.297e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.423e+16, tolerance: 2.899e+16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.471e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.399e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.297e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.423e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.471e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.399e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.297e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.423e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.471e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.399e+16, tolerance: 3.400e+14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.297e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.423e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.471e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.399e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.105e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.975e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.335e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.396e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.725e+16, tolerance: 3.849e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.105e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.975e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.335e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.396e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.725e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.105e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.975e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.335e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.396e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.725e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.105e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.975e+16, tolerance: 2.899e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.335e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.396e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.995e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.744e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.258e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.392e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.362e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.995e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.744e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.258e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.392e+16, tolerance: 3.400e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.362e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.995e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.744e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.258e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.392e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.362e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.995e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.744e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.258e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.392e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.941e+16, tolerance: 4.493e+16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.642e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.220e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.389e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.941e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.642e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.220e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.389e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.941e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.642e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.220e+16, tolerance: 4.557e+14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.389e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.941e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.642e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.220e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.389e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.925e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.210e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.386e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+16, tolerance: 3.849e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.925e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.210e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.386e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.925e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.210e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.386e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.925e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e+16, tolerance: 2.899e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.210e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.386e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.934e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.651e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.218e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.383e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.934e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.651e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.218e+16, tolerance: 4.557e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.383e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.934e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.651e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.218e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.383e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.934e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.651e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.218e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.383e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.959e+16, tolerance: 4.493e+16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.717e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.380e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.287e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.959e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.717e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.380e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.287e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.959e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.717e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e+16, tolerance: 4.557e+14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.380e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.287e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.959e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.717e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.237e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.380e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.995e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.804e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.263e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.377e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e+16, tolerance: 3.849e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.995e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.804e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.263e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.377e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.995e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.804e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.263e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.377e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.995e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.804e+16, tolerance: 2.899e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.263e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.377e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.036e+16, tolerance: 4.493e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.905e+16, tolerance: 2.899e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.293e+16, tolerance: 4.557e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e+16, tolerance: 3.849e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.036e+16, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.905e+16, tolerance: 2.899e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.293e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e+16, tolerance: 3.849e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.036e+16, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.905e+16, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.293e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.036e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.905e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.293e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.177e+16, tolerance: 3.849e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.827e+16, tolerance: 4.493e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.471e+16, tolerance: 2.899e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+16, tolerance: 4.557e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.547e+16, tolerance: 3.400e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.177e+16, tolerance: 3.849e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.827e+16, tolerance: 4.493e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.471e+16, tolerance: 2.899e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+16, tolerance: 4.557e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.547e+16, tolerance: 3.400e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.177e+16, tolerance: 3.849e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.827e+16, tolerance: 4.493e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.471e+16, tolerance: 2.899e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+16, tolerance: 4.557e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.547e+16, tolerance: 3.400e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.177e+16, tolerance: 3.849e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.827e+16, tolerance: 4.493e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.471e+16, tolerance: 2.899e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e+16, tolerance: 4.557e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.547e+16, tolerance: 3.400e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.708e+14, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.234e+15, tolerance: 3.400e+15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.234e+15, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.234e+15, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.177e+16, tolerance: 3.400e+16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.177e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.177e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.177e+16, tolerance: 3.400e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.523e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.523e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.728e+14, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.523e+16, tolerance: 3.400e+14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.828e+14, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.728e+14, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.523e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.269e+16, tolerance: 3.400e+16\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.220e+15, tolerance: 4.493e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e+16, tolerance: 4.557e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.269e+16, tolerance: 3.400e+15\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.220e+15, tolerance: 4.493e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.145e+14, tolerance: 2.899e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e+16, tolerance: 4.557e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.269e+16, tolerance: 3.400e+14\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.260e+13, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.220e+15, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.145e+14, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.269e+16, tolerance: 3.400e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.784e+16, tolerance: 3.849e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.486e+16, tolerance: 4.493e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.931e+16, tolerance: 2.899e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+16, tolerance: 4.557e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.025e+16, tolerance: 3.400e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.784e+16, tolerance: 3.849e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.486e+16, tolerance: 4.493e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.931e+16, tolerance: 2.899e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+16, tolerance: 4.557e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.025e+16, tolerance: 3.400e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.784e+16, tolerance: 3.849e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.486e+16, tolerance: 4.493e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.931e+16, tolerance: 2.899e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+16, tolerance: 4.557e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.025e+16, tolerance: 3.400e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.784e+16, tolerance: 3.849e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.486e+16, tolerance: 4.493e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.931e+16, tolerance: 2.899e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+16, tolerance: 4.557e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.025e+16, tolerance: 3.400e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+17, tolerance: 3.849e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+17, tolerance: 4.493e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.961e+16, tolerance: 2.899e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+17, tolerance: 4.557e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+17, tolerance: 3.400e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+17, tolerance: 3.849e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+17, tolerance: 4.493e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.961e+16, tolerance: 2.899e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+17, tolerance: 4.557e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+17, tolerance: 3.400e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+17, tolerance: 3.849e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+17, tolerance: 4.493e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.961e+16, tolerance: 2.899e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+17, tolerance: 4.557e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+17, tolerance: 3.400e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+17, tolerance: 3.849e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+17, tolerance: 4.493e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.961e+16, tolerance: 2.899e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e+17, tolerance: 4.557e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+17, tolerance: 3.400e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+17, tolerance: 3.849e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+17, tolerance: 4.493e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+17, tolerance: 2.899e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+17, tolerance: 4.557e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.553e+17, tolerance: 3.400e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+17, tolerance: 3.849e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+17, tolerance: 4.493e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+17, tolerance: 2.899e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+17, tolerance: 4.557e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.553e+17, tolerance: 3.400e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+17, tolerance: 3.849e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+17, tolerance: 4.493e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+17, tolerance: 2.899e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+17, tolerance: 4.557e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.553e+17, tolerance: 3.400e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+17, tolerance: 3.849e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+17, tolerance: 4.493e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+17, tolerance: 2.899e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+17, tolerance: 4.557e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.553e+17, tolerance: 3.400e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+17, tolerance: 3.849e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+17, tolerance: 4.493e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+17, tolerance: 2.899e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+17, tolerance: 4.557e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+17, tolerance: 3.400e+16 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+17, tolerance: 3.849e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+17, tolerance: 4.493e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+17, tolerance: 2.899e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+17, tolerance: 4.557e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+17, tolerance: 3.400e+15 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+17, tolerance: 3.849e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+17, tolerance: 4.493e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+17, tolerance: 2.899e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+17, tolerance: 4.557e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+17, tolerance: 3.400e+14 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+17, tolerance: 3.849e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+17, tolerance: 4.493e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+17, tolerance: 2.899e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+17, tolerance: 4.557e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+17, tolerance: 3.400e+13 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01882806, 0.01895161, 0.01639872, 0.01561441, 0.01729527,\n",
       "        0.01700606, 0.01658602, 0.01601601, 0.015973  , 0.01722898,\n",
       "        0.01696901, 0.01512856, 0.01690021, 0.01552062, 0.0186532 ,\n",
       "        0.01305747, 0.01970601, 0.01441693, 0.01750212, 0.01486573,\n",
       "        0.01313219, 0.01520581, 0.01666708, 0.01598477, 0.01540151,\n",
       "        0.01999288, 0.01571088, 0.01390147, 0.01467009, 0.01966372,\n",
       "        0.01785946, 0.01069369, 0.01697202, 0.01642914, 0.01335144,\n",
       "        0.01543665, 0.01280527, 0.0174758 , 0.01823287, 0.01643806,\n",
       "        0.01557512, 0.01600032, 0.01831264, 0.01626563, 0.01582122,\n",
       "        0.01589522, 0.01571651, 0.01712499, 0.01372418, 0.01669855,\n",
       "        0.01519861, 0.01352921, 0.01475706, 0.01643014, 0.01677303,\n",
       "        0.01570692, 0.01425166, 0.01578336, 0.01570921, 0.01381917,\n",
       "        0.01684155, 0.018119  , 0.01892562, 0.01425796, 0.01569571,\n",
       "        0.01675863, 0.01632109, 0.0157052 , 0.01951294, 0.01391053,\n",
       "        0.0171761 , 0.014814  , 0.01892238, 0.01664348, 0.01675577,\n",
       "        0.0180994 , 0.01563315, 0.01351604, 0.01598721, 0.01803393,\n",
       "        0.01372666, 0.01489253, 0.01722894, 0.01482177, 0.00825825,\n",
       "        0.01113553, 0.0091815 , 0.0130331 , 0.00920534, 0.0098671 ,\n",
       "        0.0116107 , 0.00968065, 0.01348119, 0.00588045, 0.01527987,\n",
       "        0.00762548, 0.00967503, 0.01303201, 0.01301274, 0.01616278,\n",
       "        0.0090498 , 0.01330538, 0.01337914, 0.00633774, 0.01271663,\n",
       "        0.01338229, 0.01727996, 0.01213117, 0.01251082, 0.01543074,\n",
       "        0.01592016, 0.01541562, 0.01376772, 0.01483078, 0.01537137,\n",
       "        0.01630106, 0.0142952 , 0.01619878, 0.01565962, 0.01283398,\n",
       "        0.01614971, 0.02059193, 0.02216372, 0.01594791, 0.0020112 ,\n",
       "        0.00312552, 0.0013289 , 0.00369015, 0.00232   , 0.00344968,\n",
       "        0.        , 0.00634489, 0.00060096, 0.00260096, 0.00319395,\n",
       "        0.00165105, 0.00245204, 0.00352726, 0.00318313, 0.00640965,\n",
       "        0.        , 0.00581169, 0.        , 0.00314188, 0.00484719,\n",
       "        0.00396576, 0.00243397, 0.        , 0.00625038, 0.00280085,\n",
       "        0.00315208, 0.00630984, 0.0073081 , 0.00475912, 0.0063005 ,\n",
       "        0.00632806, 0.00629425, 0.00953817, 0.0074007 , 0.00632834,\n",
       "        0.01898804, 0.0108151 , 0.01736808, 0.01833901, 0.00252223,\n",
       "        0.00188675, 0.00141735, 0.00100927, 0.        , 0.00040278,\n",
       "        0.00312881, 0.        , 0.00306702, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00313292, 0.00313659,\n",
       "        0.00313277, 0.00312519, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00320096, 0.00313563,\n",
       "        0.00312996, 0.00313153, 0.        , 0.        , 0.00433183,\n",
       "        0.00200076, 0.        , 0.00316434, 0.        , 0.        ,\n",
       "        0.0166429 , 0.01570868, 0.01431451, 0.01572399, 0.00312495,\n",
       "        0.        , 0.00364442, 0.        , 0.00312753, 0.        ,\n",
       "        0.00311708, 0.00020432, 0.00040321, 0.        , 0.        ,\n",
       "        0.00312748, 0.00080066, 0.00039992, 0.        , 0.        ,\n",
       "        0.00240293, 0.        , 0.00312409, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00362749, 0.        , 0.00312777,\n",
       "        0.        , 0.00312514, 0.        , 0.00312543, 0.        ,\n",
       "        0.        , 0.00312514, 0.        , 0.        , 0.        ,\n",
       "        0.01864452, 0.01666756, 0.01578102, 0.01534081, 0.        ,\n",
       "        0.        , 0.        , 0.00313406, 0.        , 0.        ,\n",
       "        0.00312529, 0.        , 0.        , 0.        , 0.0053278 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00050092, 0.00105562, 0.00312514, 0.        ,\n",
       "        0.        , 0.00040507, 0.        , 0.00312576, 0.00115848,\n",
       "        0.        , 0.00312529, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00312638, 0.        , 0.        , 0.00312514]),\n",
       " 'std_fit_time': array([3.43524196e-03, 3.85274205e-03, 3.22657201e-03, 4.40187077e-05,\n",
       "        5.20138349e-03, 3.31286728e-03, 2.82536676e-03, 5.08959253e-03,\n",
       "        1.56253129e-03, 2.66628248e-03, 5.53725731e-03, 8.43323377e-03,\n",
       "        2.65705840e-03, 7.23005236e-03, 7.98740238e-03, 5.45513927e-03,\n",
       "        5.73875519e-03, 2.55946343e-03, 2.07911682e-03, 1.94087152e-03,\n",
       "        4.78502437e-03, 1.04808434e-03, 2.05938993e-03, 5.44214710e-04,\n",
       "        3.06839375e-03, 9.00920451e-03, 5.22457451e-04, 7.46137946e-03,\n",
       "        8.74702807e-03, 6.07497754e-03, 6.80483065e-03, 6.39274382e-03,\n",
       "        4.87193104e-03, 1.76597207e-03, 6.64763690e-03, 4.03427683e-03,\n",
       "        6.42931729e-03, 2.48532236e-03, 4.55815505e-03, 3.72756889e-04,\n",
       "        5.59014957e-03, 2.46106279e-03, 3.36481894e-03, 7.26388191e-04,\n",
       "        2.67614984e-03, 8.26517006e-03, 1.14988245e-03, 4.31693850e-03,\n",
       "        6.20357778e-03, 2.06819001e-03, 8.47386255e-03, 6.64985722e-03,\n",
       "        2.73563562e-03, 1.60229907e-03, 4.18693105e-03, 2.41101445e-03,\n",
       "        4.57673917e-03, 1.46869006e-03, 1.60151948e-04, 7.43378294e-03,\n",
       "        2.42476817e-03, 5.85208182e-03, 6.16806225e-03, 6.47058016e-03,\n",
       "        1.61481282e-04, 2.25892564e-03, 6.27330537e-03, 3.67616398e-03,\n",
       "        5.37216721e-03, 3.45816337e-03, 5.09588546e-03, 3.14835519e-03,\n",
       "        4.28969093e-03, 6.14098292e-04, 5.25951481e-04, 5.53794746e-03,\n",
       "        4.00288523e-03, 5.91426487e-03, 1.47483092e-03, 4.67153527e-03,\n",
       "        4.85707825e-03, 1.94958738e-03, 3.00605249e-03, 2.07098484e-03,\n",
       "        7.05050805e-03, 5.91443577e-03, 4.95361322e-03, 4.08392181e-03,\n",
       "        6.95687930e-03, 6.85817049e-03, 6.77309762e-03, 7.92324796e-03,\n",
       "        7.00297326e-03, 4.87288971e-03, 2.88322585e-03, 6.42379065e-03,\n",
       "        8.12760601e-03, 6.65785158e-03, 6.62363160e-03, 3.54746769e-03,\n",
       "        5.08544537e-03, 6.82948779e-03, 7.84352893e-03, 7.78027961e-03,\n",
       "        7.38142057e-03, 3.51246693e-03, 2.28225956e-03, 4.91448965e-03,\n",
       "        2.52958101e-03, 1.51979508e-03, 1.54582624e-03, 1.21968008e-03,\n",
       "        1.87366990e-03, 9.48712380e-04, 1.04118995e-03, 5.35018979e-03,\n",
       "        8.32756045e-04, 2.13897910e-03, 4.13378350e-03, 6.42731585e-03,\n",
       "        5.08010866e-03, 5.96881759e-03, 6.73833130e-03, 8.61496358e-04,\n",
       "        1.09629694e-03, 6.25104904e-03, 1.68366870e-03, 4.82059390e-03,\n",
       "        2.37608745e-04, 6.06474638e-03, 0.00000000e+00, 7.77089190e-03,\n",
       "        1.20191574e-03, 5.20191193e-03, 6.38790131e-03, 1.40862787e-03,\n",
       "        4.78201740e-04, 6.09839611e-03, 6.36625290e-03, 7.85018008e-03,\n",
       "        0.00000000e+00, 7.18282116e-03, 0.00000000e+00, 6.28376007e-03,\n",
       "        6.39893077e-03, 1.86746607e-03, 1.48769929e-03, 0.00000000e+00,\n",
       "        7.65512265e-03, 5.60169220e-03, 6.30416870e-03, 7.72851615e-03,\n",
       "        5.25025165e-03, 5.50167185e-03, 7.71689296e-03, 6.82239082e-03,\n",
       "        7.71157823e-03, 5.34035699e-03, 4.75985704e-03, 7.79471579e-03,\n",
       "        7.64355579e-03, 6.85274137e-03, 1.79692223e-03, 1.86207601e-03,\n",
       "        2.87669775e-03, 8.82779200e-04, 8.23659906e-04, 1.42863468e-05,\n",
       "        0.00000000e+00, 8.05568695e-04, 6.25762939e-03, 0.00000000e+00,\n",
       "        6.13403320e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.26583099e-03, 6.27317429e-03,\n",
       "        6.26554489e-03, 6.25038147e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.40192032e-03, 6.27126694e-03, 6.25991821e-03, 6.26306534e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.12062787e-03, 4.00152206e-03,\n",
       "        0.00000000e+00, 6.32867813e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        8.56461066e-03, 5.23237457e-04, 2.65413141e-03, 1.57067902e-04,\n",
       "        6.24990463e-03, 0.00000000e+00, 6.07466287e-03, 0.00000000e+00,\n",
       "        6.25505447e-03, 0.00000000e+00, 6.23416901e-03, 4.08649445e-04,\n",
       "        4.93833759e-04, 0.00000000e+00, 0.00000000e+00, 6.25495911e-03,\n",
       "        4.00329641e-04, 4.89804325e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.80585098e-03, 0.00000000e+00, 6.24818802e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.07736959e-03,\n",
       "        0.00000000e+00, 6.25553131e-03, 0.00000000e+00, 6.25028610e-03,\n",
       "        0.00000000e+00, 6.25085831e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.25028610e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        5.74460383e-03, 1.75977344e-03, 5.89175314e-03, 3.62187700e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.26811981e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.25057220e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.68622434e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.33880710e-04, 6.42041474e-04, 6.25028610e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.96147035e-04, 0.00000000e+00,\n",
       "        6.25152588e-03, 2.31695175e-03, 0.00000000e+00, 6.25057220e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.25276566e-03, 0.00000000e+00, 0.00000000e+00, 6.25028610e-03]),\n",
       " 'mean_score_time': array([0.00019941, 0.00222607, 0.00170274, 0.        , 0.00115218,\n",
       "        0.00263429, 0.        , 0.00387383, 0.        , 0.00338945,\n",
       "        0.00080013, 0.00060005, 0.00111256, 0.0012002 , 0.00143266,\n",
       "        0.00373111, 0.00163565, 0.        , 0.0010736 , 0.00040007,\n",
       "        0.00440159, 0.0004004 , 0.00337796, 0.00072117, 0.00040841,\n",
       "        0.00126262, 0.        , 0.00492659, 0.00070319, 0.        ,\n",
       "        0.00100017, 0.00625043, 0.0005785 , 0.        , 0.00587406,\n",
       "        0.00080142, 0.00603027, 0.00040197, 0.00060015, 0.00069084,\n",
       "        0.00060015, 0.00290256, 0.00040426, 0.        , 0.00382686,\n",
       "        0.00059991, 0.00312676, 0.00080004, 0.00613194, 0.00050502,\n",
       "        0.00379963, 0.0038682 , 0.00060043, 0.00240288, 0.00130649,\n",
       "        0.        , 0.00392709, 0.00026827, 0.00375571, 0.00060019,\n",
       "        0.00200248, 0.00306201, 0.        , 0.0035903 , 0.00019851,\n",
       "        0.00268044, 0.00087605, 0.        , 0.00079994, 0.00392761,\n",
       "        0.        , 0.00080009, 0.        , 0.00192451, 0.        ,\n",
       "        0.00159855, 0.00100164, 0.00600452, 0.0009428 , 0.0006    ,\n",
       "        0.00463896, 0.00020018, 0.00352588, 0.00080204, 0.00427446,\n",
       "        0.00059986, 0.00080113, 0.00080142, 0.00348396, 0.00040054,\n",
       "        0.00099864, 0.00290308, 0.00045357, 0.00397034, 0.00061436,\n",
       "        0.00369158, 0.00313592, 0.00037146, 0.00040102, 0.00040379,\n",
       "        0.00348706, 0.00250101, 0.00080209, 0.00947905, 0.        ,\n",
       "        0.00121689, 0.00040069, 0.00335011, 0.00100026, 0.00128279,\n",
       "        0.00035982, 0.00209236, 0.00196791, 0.00205917, 0.00185585,\n",
       "        0.00137925, 0.00194931, 0.00046134, 0.00075355, 0.00320683,\n",
       "        0.00121818, 0.00105281, 0.00229321, 0.0032351 , 0.00100045,\n",
       "        0.0031251 , 0.00305586, 0.00100846, 0.0019279 , 0.        ,\n",
       "        0.00317583, 0.        , 0.00316682, 0.00313272, 0.        ,\n",
       "        0.00105023, 0.00155644, 0.00027132, 0.        , 0.        ,\n",
       "        0.00320711, 0.00060091, 0.00313439, 0.00313215, 0.00120978,\n",
       "        0.00111403, 0.00120358, 0.00632038, 0.00040135, 0.0031261 ,\n",
       "        0.        , 0.        , 0.0018085 , 0.00040607, 0.00312471,\n",
       "        0.        , 0.00308132, 0.00020008, 0.00079889, 0.00312586,\n",
       "        0.00312772, 0.00713062, 0.00180173, 0.00161519, 0.00152225,\n",
       "        0.00130067, 0.00186868, 0.00150442, 0.00280867, 0.        ,\n",
       "        0.        , 0.00318203, 0.        , 0.00313993, 0.00312524,\n",
       "        0.00392475, 0.00240097, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00200272, 0.00120082, 0.003126  , 0.00312529,\n",
       "        0.00313573, 0.00315399, 0.00312505, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00313463, 0.00312519, 0.        ,\n",
       "        0.00312991, 0.        , 0.        , 0.00313292, 0.00542741,\n",
       "        0.        , 0.00312529, 0.00456481, 0.        , 0.        ,\n",
       "        0.00312519, 0.        , 0.002703  , 0.        , 0.00313168,\n",
       "        0.        , 0.00396128, 0.00170503, 0.00321064, 0.        ,\n",
       "        0.        , 0.00458546, 0.00061078, 0.        , 0.003124  ,\n",
       "        0.00080247, 0.00312753, 0.        , 0.00312643, 0.00312514,\n",
       "        0.00312538, 0.        , 0.        , 0.00270309, 0.        ,\n",
       "        0.0031251 , 0.        , 0.00312533, 0.        , 0.00150266,\n",
       "        0.00312762, 0.        , 0.00312514, 0.        , 0.        ,\n",
       "        0.00030074, 0.0023006 , 0.00313206, 0.00354738, 0.        ,\n",
       "        0.        , 0.00318885, 0.        , 0.        , 0.00312753,\n",
       "        0.        , 0.00312519, 0.00312514, 0.        , 0.        ,\n",
       "        0.00100255, 0.00312748, 0.00312343, 0.00312676, 0.00312381,\n",
       "        0.00312686, 0.00321064, 0.00100021, 0.        , 0.00312533,\n",
       "        0.00302906, 0.00102224, 0.0015008 , 0.        , 0.        ,\n",
       "        0.00312757, 0.        , 0.00312476, 0.        , 0.00312543,\n",
       "        0.        , 0.00010066, 0.00310259, 0.00312767, 0.        ]),\n",
       " 'std_score_time': array([0.00039883, 0.00043799, 0.00087355, 0.        , 0.00094521,\n",
       "        0.00449302, 0.        , 0.00529662, 0.        , 0.00433807,\n",
       "        0.00097996, 0.00080017, 0.00144815, 0.00097996, 0.00124446,\n",
       "        0.00606781, 0.00082107, 0.        , 0.00098372, 0.00080013,\n",
       "        0.00653131, 0.0008008 , 0.00614955, 0.00102141, 0.00081682,\n",
       "        0.00103751, 0.        , 0.00638714, 0.00087511, 0.        ,\n",
       "        0.00089463, 0.00765518, 0.00079703, 0.        , 0.00687751,\n",
       "        0.0007495 , 0.00739411, 0.00080395, 0.00080016, 0.00091989,\n",
       "        0.0008001 , 0.00580511, 0.00049512, 0.        , 0.00572077,\n",
       "        0.00080028, 0.00625353, 0.00097984, 0.00751006, 0.00101004,\n",
       "        0.00567333, 0.00593917, 0.00080036, 0.00480576, 0.00108356,\n",
       "        0.        , 0.00591785, 0.00053654, 0.00605951, 0.0008003 ,\n",
       "        0.00400496, 0.00308683, 0.        , 0.00539896, 0.00039701,\n",
       "        0.00407312, 0.00107966, 0.        , 0.00097972, 0.0060537 ,\n",
       "        0.        , 0.0009799 , 0.        , 0.00315055, 0.        ,\n",
       "        0.0012334 , 0.00089618, 0.00735497, 0.00117635, 0.00080009,\n",
       "        0.00562519, 0.00040035, 0.0060997 , 0.0009823 , 0.00601414,\n",
       "        0.00080001, 0.00098119, 0.00098154, 0.00601571, 0.00080109,\n",
       "        0.00089287, 0.00580616, 0.00090714, 0.00600743, 0.00082532,\n",
       "        0.00554229, 0.00433373, 0.00074291, 0.00080204, 0.00080757,\n",
       "        0.00552379, 0.00500202, 0.00098235, 0.00774142, 0.        ,\n",
       "        0.00099386, 0.00080137, 0.00481512, 0.00089468, 0.00067926,\n",
       "        0.00071964, 0.00017517, 0.00039664, 0.00050322, 0.00045105,\n",
       "        0.00082594, 0.00045102, 0.00092268, 0.00095401, 0.00641365,\n",
       "        0.00119318, 0.00210562, 0.00123992, 0.00517032, 0.00089463,\n",
       "        0.00625019, 0.00517034, 0.00090396, 0.00051952, 0.        ,\n",
       "        0.00635166, 0.        , 0.00633364, 0.00626545, 0.        ,\n",
       "        0.00090541, 0.00060218, 0.00054264, 0.        , 0.        ,\n",
       "        0.00641422, 0.00120182, 0.00626879, 0.00626431, 0.00098779,\n",
       "        0.00065684, 0.00110269, 0.00774167, 0.00080271, 0.00625219,\n",
       "        0.        , 0.        , 0.00040352, 0.00081215, 0.00624943,\n",
       "        0.        , 0.00616264, 0.00040016, 0.00074826, 0.00625172,\n",
       "        0.00625544, 0.00713839, 0.00040067, 0.00080766, 0.0008776 ,\n",
       "        0.00051003, 0.00028716, 0.00061553, 0.00561733, 0.        ,\n",
       "        0.        , 0.00636406, 0.        , 0.00627985, 0.00625048,\n",
       "        0.00604881, 0.00480194, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00400543, 0.00240164, 0.006252  , 0.00625057,\n",
       "        0.00627146, 0.00630798, 0.0062501 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00626926, 0.00625038, 0.        ,\n",
       "        0.00625982, 0.        , 0.        , 0.00626583, 0.00677402,\n",
       "        0.        , 0.00625057, 0.0062466 , 0.        , 0.        ,\n",
       "        0.00625038, 0.        , 0.005406  , 0.        , 0.00626335,\n",
       "        0.        , 0.00695739, 0.00244342, 0.00393473, 0.        ,\n",
       "        0.        , 0.00618626, 0.00080591, 0.        , 0.006248  ,\n",
       "        0.00160494, 0.00625505, 0.        , 0.00625286, 0.00625029,\n",
       "        0.00625076, 0.        , 0.        , 0.00540619, 0.        ,\n",
       "        0.00625019, 0.        , 0.00625067, 0.        , 0.00300531,\n",
       "        0.00625525, 0.        , 0.00625029, 0.        , 0.        ,\n",
       "        0.00060148, 0.00460119, 0.00626411, 0.00612788, 0.        ,\n",
       "        0.        , 0.0063777 , 0.        , 0.        , 0.00625505,\n",
       "        0.        , 0.00625038, 0.00625029, 0.        , 0.        ,\n",
       "        0.0020051 , 0.00625496, 0.00624685, 0.00625353, 0.00624762,\n",
       "        0.00625372, 0.00497601, 0.00089452, 0.        , 0.00625067,\n",
       "        0.00605812, 0.00091409, 0.00300159, 0.        , 0.        ,\n",
       "        0.00625515, 0.        , 0.00624952, 0.        , 0.00625086,\n",
       "        0.        , 0.00020132, 0.00620518, 0.00625534, 0.        ]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_l1_ratio': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tol': masked_array(data=[0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.0001}],\n",
       " 'split0_test_R2': array([0.19626218, 0.19626218, 0.19626218, 0.19626218, 0.19629085,\n",
       "        0.19629085, 0.19629085, 0.19629085, 0.19631957, 0.19631957,\n",
       "        0.19631957, 0.19631957, 0.19634834, 0.19634834, 0.19634834,\n",
       "        0.19634834, 0.19637715, 0.19637715, 0.19637715, 0.19637715,\n",
       "        0.19640601, 0.19640601, 0.19640601, 0.19640601, 0.19643492,\n",
       "        0.19643492, 0.19643492, 0.19643492, 0.19646388, 0.19646388,\n",
       "        0.19646388, 0.19646388, 0.19649289, 0.19649289, 0.19649289,\n",
       "        0.19649289, 0.19652194, 0.19652194, 0.19652194, 0.19652194,\n",
       "        0.19386624, 0.19386624, 0.19386624, 0.19386624, 0.19411538,\n",
       "        0.19411538, 0.19411538, 0.19411538, 0.1943686 , 0.1943686 ,\n",
       "        0.1943686 , 0.1943686 , 0.19462597, 0.19462597, 0.19462597,\n",
       "        0.19462597, 0.19488758, 0.19488758, 0.19488758, 0.19488758,\n",
       "        0.19515351, 0.19515351, 0.19515351, 0.19515351, 0.19542384,\n",
       "        0.19542384, 0.19542384, 0.19542384, 0.19569867, 0.19569867,\n",
       "        0.19569867, 0.19569867, 0.19597809, 0.19597809, 0.19597809,\n",
       "        0.19597809, 0.19626218, 0.19626218, 0.19626218, 0.19626218,\n",
       "        0.1815625 , 0.1815625 , 0.1815625 , 0.1815625 , 0.1823089 ,\n",
       "        0.1823089 , 0.1823089 , 0.1823089 , 0.18315698, 0.18315698,\n",
       "        0.18315698, 0.18315698, 0.18412284, 0.18412284, 0.18412284,\n",
       "        0.18412284, 0.18522602, 0.18522602, 0.18522602, 0.18522602,\n",
       "        0.18649039, 0.18649039, 0.18649039, 0.18649039, 0.18794537,\n",
       "        0.18794537, 0.18794537, 0.18794537, 0.18962741, 0.18962742,\n",
       "        0.18962742, 0.18962742, 0.19158205, 0.19158205, 0.19158205,\n",
       "        0.19158205, 0.19386623, 0.19386624, 0.19386624, 0.19386624,\n",
       "        0.18451647, 0.18451647, 0.18451647, 0.18451647, 0.18307545,\n",
       "        0.18307545, 0.18307545, 0.18307545, 0.18164551, 0.18164551,\n",
       "        0.18164551, 0.18164551, 0.18025304, 0.18025304, 0.18025304,\n",
       "        0.18025304, 0.17894157, 0.17894157, 0.17894157, 0.17894157,\n",
       "        0.17778616, 0.17778616, 0.17778616, 0.17778616, 0.17692492,\n",
       "        0.17692491, 0.17692491, 0.17692491, 0.1766364 , 0.17663639,\n",
       "        0.17663639, 0.17663639, 0.17756461, 0.1775646 , 0.1775646 ,\n",
       "        0.1775646 , 0.18156246, 0.18156249, 0.18156249, 0.18156249,\n",
       "        0.23276459, 0.23276459, 0.23276459, 0.23276459, 0.23190635,\n",
       "        0.23190635, 0.23190635, 0.23190635, 0.23046434, 0.23046434,\n",
       "        0.23046434, 0.23046434, 0.22830118, 0.22830118, 0.22830118,\n",
       "        0.22830118, 0.22523785, 0.22523785, 0.22523785, 0.22523785,\n",
       "        0.22103619, 0.22103619, 0.22103619, 0.22103619, 0.21537213,\n",
       "        0.21537213, 0.21537213, 0.21537213, 0.2077956 , 0.2077956 ,\n",
       "        0.2077956 , 0.2077956 , 0.1976901 , 0.19769009, 0.19769008,\n",
       "        0.19769008, 0.18451657, 0.18451654, 0.18451653, 0.18451652,\n",
       "        0.12088987, 0.12088987, 0.12088987, 0.12088987, 0.12902373,\n",
       "        0.12902373, 0.12902373, 0.12902373, 0.13825552, 0.1382555 ,\n",
       "        0.1382555 , 0.1382555 , 0.14879062, 0.14879057, 0.14879057,\n",
       "        0.14879057, 0.16086409, 0.16086409, 0.16086409, 0.16086409,\n",
       "        0.17471465, 0.17471465, 0.17471466, 0.17471466, 0.19048694,\n",
       "        0.19048689, 0.19048689, 0.19048689, 0.20789991, 0.20789991,\n",
       "        0.20789992, 0.20789992, 0.22503394, 0.22503394, 0.22503394,\n",
       "        0.22503394, 0.23276477, 0.2327646 , 0.2327646 , 0.2327646 ,\n",
       "        0.01742959, 0.01742959, 0.01742959, 0.01742959, 0.01929663,\n",
       "        0.01929663, 0.01929663, 0.01929662, 0.02160183, 0.02160183,\n",
       "        0.02160183, 0.02160182, 0.02451983, 0.02451983, 0.02451983,\n",
       "        0.02451982, 0.02833215, 0.02833215, 0.02833215, 0.02833213,\n",
       "        0.03352365, 0.03352365, 0.03352365, 0.03352361, 0.04100597,\n",
       "        0.04100597, 0.04100597, 0.0410059 , 0.0527169 , 0.0527169 ,\n",
       "        0.05271676, 0.05271676, 0.07360917, 0.07360888, 0.07360888,\n",
       "        0.07360888, 0.1208895 , 0.1208895 , 0.12088916, 0.12088916]),\n",
       " 'split1_test_R2': array([0.21880022, 0.21880022, 0.21880022, 0.21880022, 0.218706  ,\n",
       "        0.218706  , 0.218706  , 0.218706  , 0.21861123, 0.21861123,\n",
       "        0.21861123, 0.21861123, 0.21851592, 0.21851592, 0.21851592,\n",
       "        0.21851592, 0.21842005, 0.21842005, 0.21842005, 0.21842005,\n",
       "        0.21832362, 0.21832362, 0.21832362, 0.21832362, 0.21822663,\n",
       "        0.21822663, 0.21822663, 0.21822663, 0.21812908, 0.21812908,\n",
       "        0.21812908, 0.21812908, 0.21803096, 0.21803096, 0.21803096,\n",
       "        0.21803096, 0.21793227, 0.21793227, 0.21793227, 0.21793227,\n",
       "        0.22538984, 0.22538984, 0.22538984, 0.22538984, 0.22481578,\n",
       "        0.22481578, 0.22481578, 0.22481578, 0.22420728, 0.22420728,\n",
       "        0.22420728, 0.22420728, 0.22356237, 0.22356237, 0.22356237,\n",
       "        0.22356237, 0.22287895, 0.22287895, 0.22287895, 0.22287895,\n",
       "        0.22215477, 0.22215477, 0.22215477, 0.22215477, 0.22138745,\n",
       "        0.22138745, 0.22138745, 0.22138745, 0.22057443, 0.22057443,\n",
       "        0.22057443, 0.22057443, 0.21971299, 0.21971299, 0.21971299,\n",
       "        0.21971299, 0.21880022, 0.21880022, 0.21880022, 0.21880022,\n",
       "        0.23154627, 0.23154627, 0.23154627, 0.23154627, 0.23207105,\n",
       "        0.23207105, 0.23207105, 0.23207105, 0.23257014, 0.23257014,\n",
       "        0.23257014, 0.23257014, 0.23299858, 0.23299858, 0.23299858,\n",
       "        0.23299858, 0.23328638, 0.23328638, 0.23328638, 0.23328638,\n",
       "        0.23332404, 0.23332404, 0.23332404, 0.23332404, 0.23293814,\n",
       "        0.23293814, 0.23293814, 0.23293814, 0.23184919, 0.23184919,\n",
       "        0.23184919, 0.23184919, 0.22959552, 0.22959551, 0.22959551,\n",
       "        0.22959551, 0.22538986, 0.22538985, 0.22538985, 0.22538985,\n",
       "        0.25478693, 0.25478693, 0.25478693, 0.25478693, 0.25050864,\n",
       "        0.25050864, 0.25050864, 0.25050864, 0.24619287, 0.24619287,\n",
       "        0.24619287, 0.24619287, 0.24189193, 0.24189193, 0.24189193,\n",
       "        0.24189193, 0.23769643, 0.23769643, 0.23769643, 0.23769643,\n",
       "        0.23376573, 0.23376573, 0.23376572, 0.23376572, 0.23038857,\n",
       "        0.23038856, 0.23038856, 0.23038856, 0.22810939, 0.22810938,\n",
       "        0.22810938, 0.22810938, 0.22797936, 0.22797935, 0.22797935,\n",
       "        0.22797935, 0.23154628, 0.23154628, 0.23154628, 0.23154628,\n",
       "        0.43067384, 0.43067384, 0.43067384, 0.43067384, 0.42169084,\n",
       "        0.42169084, 0.42169084, 0.42169084, 0.41112042, 0.41112042,\n",
       "        0.41112042, 0.41112042, 0.39871294, 0.39871294, 0.39871294,\n",
       "        0.39871294, 0.38415622, 0.38415622, 0.38415622, 0.38415622,\n",
       "        0.36704168, 0.36704168, 0.36704168, 0.36704168, 0.34679635,\n",
       "        0.34679635, 0.34679635, 0.34679636, 0.32253376, 0.32253377,\n",
       "        0.32253377, 0.32253377, 0.29271544, 0.29271546, 0.29271547,\n",
       "        0.29271547, 0.254787  , 0.25478702, 0.25478703, 0.25478703,\n",
       "        0.29606607, 0.29606607, 0.29606607, 0.29606607, 0.31416592,\n",
       "        0.31416592, 0.31416592, 0.31416592, 0.33422216, 0.33422208,\n",
       "        0.33422208, 0.33422208, 0.35639137, 0.3563912 , 0.3563912 ,\n",
       "        0.3563912 , 0.38069138, 0.38069138, 0.38069138, 0.38069138,\n",
       "        0.4067716 , 0.40677157, 0.40677157, 0.40677157, 0.43334362,\n",
       "        0.43334343, 0.43334343, 0.43334343, 0.45669138, 0.45669131,\n",
       "        0.45669132, 0.45669132, 0.46636538, 0.46636525, 0.46636525,\n",
       "        0.46636525, 0.43067441, 0.43067429, 0.43067429, 0.4306743 ,\n",
       "        0.0425591 , 0.0425591 , 0.0425591 , 0.0425591 , 0.04740581,\n",
       "        0.04740581, 0.04740581, 0.0474058 , 0.05337963, 0.05337963,\n",
       "        0.05337963, 0.05337962, 0.06092481, 0.06092481, 0.06092481,\n",
       "        0.0609248 , 0.0707538 , 0.0707538 , 0.0707538 , 0.07075377,\n",
       "        0.08408477, 0.08408477, 0.08408477, 0.08408472, 0.10318438,\n",
       "        0.10318438, 0.10318429, 0.10318429, 0.1327906 , 0.1327906 ,\n",
       "        0.13279043, 0.13279043, 0.18463557, 0.18463567, 0.18463567,\n",
       "        0.18463567, 0.29606466, 0.29606466, 0.29606399, 0.29606399]),\n",
       " 'split2_test_R2': array([0.57398029, 0.57398029, 0.57398029, 0.57398029, 0.57397918,\n",
       "        0.57397918, 0.57397918, 0.57397918, 0.57397804, 0.57397804,\n",
       "        0.57397804, 0.57397804, 0.57397687, 0.57397687, 0.57397687,\n",
       "        0.57397687, 0.57397567, 0.57397567, 0.57397567, 0.57397567,\n",
       "        0.57397444, 0.57397444, 0.57397444, 0.57397444, 0.57397318,\n",
       "        0.57397318, 0.57397318, 0.57397318, 0.57397188, 0.57397188,\n",
       "        0.57397188, 0.57397188, 0.57397056, 0.57397056, 0.57397056,\n",
       "        0.57397056, 0.57396921, 0.57396921, 0.57396921, 0.57396921,\n",
       "        0.57397785, 0.57397785, 0.57397785, 0.57397785, 0.57398669,\n",
       "        0.57398669, 0.57398669, 0.57398669, 0.57399367, 0.57399367,\n",
       "        0.57399367, 0.57399367, 0.57399868, 0.57399868, 0.57399868,\n",
       "        0.57399868, 0.57400159, 0.57400159, 0.57400159, 0.57400159,\n",
       "        0.5740023 , 0.5740023 , 0.5740023 , 0.5740023 , 0.57400066,\n",
       "        0.57400066, 0.57400066, 0.57400066, 0.57399655, 0.57399655,\n",
       "        0.57399655, 0.57399655, 0.57398981, 0.57398981, 0.57398981,\n",
       "        0.57398981, 0.57398029, 0.57398029, 0.57398029, 0.57398029,\n",
       "        0.57091229, 0.57091229, 0.57091229, 0.57091229, 0.5712914 ,\n",
       "        0.5712914 , 0.5712914 , 0.5712914 , 0.57167613, 0.57167613,\n",
       "        0.57167613, 0.57167613, 0.57206427, 0.57206427, 0.57206427,\n",
       "        0.57206427, 0.57245213, 0.57245213, 0.57245213, 0.57245213,\n",
       "        0.57283365, 0.57283365, 0.57283365, 0.57283365, 0.57319902,\n",
       "        0.57319902, 0.57319902, 0.57319902, 0.57353221, 0.57353221,\n",
       "        0.57353221, 0.57353221, 0.57380672, 0.57380672, 0.57380672,\n",
       "        0.57380672, 0.57397785, 0.57397785, 0.57397785, 0.57397785,\n",
       "        0.54987651, 0.54987651, 0.54987651, 0.54987651, 0.55178402,\n",
       "        0.55178401, 0.55178401, 0.55178401, 0.5537333 , 0.5537333 ,\n",
       "        0.5537333 , 0.5537333 , 0.55573392, 0.55573392, 0.55573392,\n",
       "        0.55573392, 0.55780027, 0.55780027, 0.55780027, 0.55780027,\n",
       "        0.55995525, 0.55995525, 0.55995525, 0.55995525, 0.56223737,\n",
       "        0.56223737, 0.56223737, 0.56223737, 0.56471608, 0.56471608,\n",
       "        0.56471608, 0.56471608, 0.56752547, 0.56752547, 0.56752547,\n",
       "        0.56752547, 0.57091229, 0.57091229, 0.57091229, 0.57091229,\n",
       "        0.43011917, 0.43011917, 0.43011917, 0.43011917, 0.44042011,\n",
       "        0.44042011, 0.44042011, 0.44042011, 0.45127351, 0.45127351,\n",
       "        0.45127351, 0.45127351, 0.46273531, 0.46273531, 0.46273531,\n",
       "        0.46273531, 0.47487235, 0.47487236, 0.47487236, 0.47487236,\n",
       "        0.48776635, 0.48776635, 0.48776635, 0.48776635, 0.50152067,\n",
       "        0.50152067, 0.50152067, 0.50152067, 0.51627391, 0.51627391,\n",
       "        0.51627391, 0.51627391, 0.53223649, 0.53223647, 0.53223646,\n",
       "        0.53223646, 0.54987651, 0.54987649, 0.54987648, 0.54987648,\n",
       "        0.140634  , 0.140634  , 0.140634  , 0.140634  , 0.15202864,\n",
       "        0.15202863, 0.15202863, 0.15202863, 0.16541017, 0.16541015,\n",
       "        0.16541015, 0.16541015, 0.18134971, 0.18134971, 0.18134971,\n",
       "        0.18134971, 0.20066187, 0.20066187, 0.20066187, 0.20066187,\n",
       "        0.22455086, 0.22455085, 0.22455085, 0.22455085, 0.25487899,\n",
       "        0.25487893, 0.25487893, 0.25487893, 0.29469903, 0.29469901,\n",
       "        0.29469902, 0.29469902, 0.34943981, 0.34943978, 0.34943978,\n",
       "        0.34943979, 0.43011876, 0.43011876, 0.43011876, 0.43011876,\n",
       "        0.01684413, 0.01684413, 0.01684413, 0.01684413, 0.01883127,\n",
       "        0.01883127, 0.01883127, 0.01883127, 0.02129423, 0.02129423,\n",
       "        0.02129423, 0.02129423, 0.02442718, 0.02442718, 0.02442718,\n",
       "        0.02442718, 0.02854656, 0.02854656, 0.02854656, 0.02854656,\n",
       "        0.03420532, 0.03420532, 0.03420531, 0.03420531, 0.0424647 ,\n",
       "        0.0424647 , 0.0424647 , 0.0424647 , 0.05565279, 0.05565281,\n",
       "        0.05565281, 0.05565281, 0.08005976, 0.08006001, 0.08006001,\n",
       "        0.08006001, 0.14063236, 0.14063236, 0.14063224, 0.14063224]),\n",
       " 'split3_test_R2': array([0.01200922, 0.01200922, 0.01200922, 0.01200922, 0.01195654,\n",
       "        0.01195654, 0.01195654, 0.01195654, 0.0119037 , 0.0119037 ,\n",
       "        0.0119037 , 0.0119037 , 0.0118507 , 0.0118507 , 0.0118507 ,\n",
       "        0.0118507 , 0.01179753, 0.01179753, 0.01179753, 0.01179753,\n",
       "        0.01174419, 0.01174419, 0.01174419, 0.01174419, 0.01169068,\n",
       "        0.01169068, 0.01169068, 0.01169068, 0.011637  , 0.011637  ,\n",
       "        0.011637  , 0.011637  , 0.01158315, 0.01158315, 0.01158315,\n",
       "        0.01158315, 0.01152913, 0.01152913, 0.01152913, 0.01152913,\n",
       "        0.01615112, 0.01615112, 0.01615112, 0.01615112, 0.01574312,\n",
       "        0.01574312, 0.01574312, 0.01574312, 0.0153233 , 0.0153233 ,\n",
       "        0.0153233 , 0.0153233 , 0.01489118, 0.01489118, 0.01489118,\n",
       "        0.01489118, 0.01444624, 0.01444624, 0.01444624, 0.01444624,\n",
       "        0.01398794, 0.01398794, 0.01398794, 0.01398794, 0.01351569,\n",
       "        0.01351569, 0.01351569, 0.01351569, 0.01302892, 0.01302892,\n",
       "        0.01302892, 0.01302892, 0.01252698, 0.01252698, 0.01252698,\n",
       "        0.01252698, 0.01200922, 0.01200922, 0.01200922, 0.01200922,\n",
       "        0.03290015, 0.03290015, 0.03290015, 0.03290015, 0.0318317 ,\n",
       "        0.0318317 , 0.0318317 , 0.0318317 , 0.03068809, 0.03068809,\n",
       "        0.03068809, 0.03068809, 0.02944249, 0.02944249, 0.02944249,\n",
       "        0.02944249, 0.02805775, 0.02805775, 0.02805775, 0.02805775,\n",
       "        0.02648165, 0.02648165, 0.02648165, 0.02648165, 0.02463982,\n",
       "        0.02463982, 0.02463982, 0.02463982, 0.02242432, 0.02242433,\n",
       "        0.02242433, 0.02242433, 0.01967542, 0.01967542, 0.01967542,\n",
       "        0.01967542, 0.01615112, 0.01615112, 0.01615112, 0.01615112,\n",
       "        0.11059658, 0.11059658, 0.11059658, 0.11059658, 0.10249137,\n",
       "        0.10249137, 0.10249137, 0.10249137, 0.09420243, 0.09420243,\n",
       "        0.09420243, 0.09420243, 0.08573802, 0.08573802, 0.08573802,\n",
       "        0.08573802, 0.07711537, 0.07711537, 0.07711537, 0.07711537,\n",
       "        0.06836655, 0.06836655, 0.06836655, 0.06836655, 0.05954726,\n",
       "        0.05954725, 0.05954725, 0.05954725, 0.05074477, 0.05074477,\n",
       "        0.05074477, 0.05074477, 0.04203749, 0.04203749, 0.04203749,\n",
       "        0.04203749, 0.03290019, 0.03290019, 0.03290019, 0.03290019,\n",
       "        0.43423142, 0.43423142, 0.43423142, 0.43423142, 0.41894038,\n",
       "        0.41894038, 0.41894038, 0.41894038, 0.40072144, 0.40072144,\n",
       "        0.40072144, 0.40072144, 0.37900199, 0.37900199, 0.37900199,\n",
       "        0.37900199, 0.35305204, 0.35305205, 0.35305205, 0.35305205,\n",
       "        0.3219203 , 0.3219203 , 0.3219203 , 0.3219203 , 0.28433162,\n",
       "        0.28433161, 0.28433161, 0.28433161, 0.23851292, 0.23851287,\n",
       "        0.23851287, 0.23851287, 0.18188129, 0.18188126, 0.18188125,\n",
       "        0.18188124, 0.1105969 , 0.11059688, 0.11059685, 0.11059685,\n",
       "        0.30038314, 0.30038314, 0.30038314, 0.30038314, 0.32154568,\n",
       "        0.32154565, 0.32154565, 0.32154565, 0.34502067, 0.3450206 ,\n",
       "        0.3450206 , 0.3450206 , 0.37099916, 0.37099917, 0.37099917,\n",
       "        0.37099917, 0.39950612, 0.39950613, 0.39950613, 0.39950613,\n",
       "        0.43011085, 0.43011083, 0.43011084, 0.43011084, 0.46118977,\n",
       "        0.46118961, 0.46118961, 0.46118961, 0.48788625, 0.48788622,\n",
       "        0.48788623, 0.48788623, 0.49565672, 0.49565666, 0.49565666,\n",
       "        0.49565666, 0.43423204, 0.43423199, 0.434232  , 0.434232  ,\n",
       "        0.00549852, 0.00549852, 0.00549852, 0.00549852, 0.01112148,\n",
       "        0.01112148, 0.01112148, 0.01112147, 0.01805238, 0.01805238,\n",
       "        0.01805238, 0.01805237, 0.02680696, 0.02680696, 0.02680696,\n",
       "        0.02680693, 0.03821241, 0.03821241, 0.03821241, 0.03821238,\n",
       "        0.05368366, 0.05368366, 0.05368366, 0.0536836 , 0.07585461,\n",
       "        0.07585461, 0.0758545 , 0.0758545 , 0.11023572, 0.11023572,\n",
       "        0.11023552, 0.11023552, 0.17049674, 0.17049687, 0.17049687,\n",
       "        0.17049687, 0.30038121, 0.30038121, 0.30038043, 0.30038043]),\n",
       " 'split4_test_R2': array([0.80080444, 0.80080444, 0.80080444, 0.80080444, 0.80081132,\n",
       "        0.80081132, 0.80081132, 0.80081132, 0.8008181 , 0.8008181 ,\n",
       "        0.8008181 , 0.8008181 , 0.80082481, 0.80082481, 0.80082481,\n",
       "        0.80082481, 0.80083142, 0.80083142, 0.80083142, 0.80083142,\n",
       "        0.80083794, 0.80083794, 0.80083794, 0.80083794, 0.80084437,\n",
       "        0.80084437, 0.80084437, 0.80084437, 0.80085071, 0.80085071,\n",
       "        0.80085071, 0.80085071, 0.80085696, 0.80085696, 0.80085696,\n",
       "        0.80085696, 0.80086311, 0.80086311, 0.80086311, 0.80086311,\n",
       "        0.79993338, 0.79993338, 0.79993338, 0.79993338, 0.80004781,\n",
       "        0.80004781, 0.80004781, 0.80004781, 0.80015907, 0.80015907,\n",
       "        0.80015907, 0.80015907, 0.80026669, 0.80026669, 0.80026669,\n",
       "        0.80026669, 0.80037021, 0.80037021, 0.80037021, 0.80037021,\n",
       "        0.80046906, 0.80046906, 0.80046906, 0.80046906, 0.80056264,\n",
       "        0.80056264, 0.80056264, 0.80056264, 0.80065026, 0.80065026,\n",
       "        0.80065026, 0.80065026, 0.80073114, 0.80073114, 0.80073114,\n",
       "        0.80073114, 0.80080444, 0.80080444, 0.80080444, 0.80080444,\n",
       "        0.79010723, 0.79010723, 0.79010723, 0.79010723, 0.79092969,\n",
       "        0.79092969, 0.79092969, 0.79092969, 0.7918155 , 0.7918155 ,\n",
       "        0.7918155 , 0.7918155 , 0.79277131, 0.79277131, 0.79277131,\n",
       "        0.79277131, 0.79380347, 0.79380347, 0.79380347, 0.79380347,\n",
       "        0.7949168 , 0.7949168 , 0.7949168 , 0.7949168 , 0.79611189,\n",
       "        0.79611189, 0.79611189, 0.79611189, 0.79737904, 0.79737904,\n",
       "        0.79737904, 0.79737904, 0.79868423, 0.79868423, 0.79868423,\n",
       "        0.79868423, 0.79993338, 0.79993338, 0.79993338, 0.79993338,\n",
       "        0.76695933, 0.76695933, 0.76695933, 0.76695933, 0.7685425 ,\n",
       "        0.7685425 , 0.7685425 , 0.7685425 , 0.77017259, 0.77017259,\n",
       "        0.77017259, 0.77017259, 0.77187147, 0.77187147, 0.77187147,\n",
       "        0.77187147, 0.77367396, 0.77367396, 0.77367396, 0.77367396,\n",
       "        0.77563847, 0.77563846, 0.77563846, 0.77563846, 0.77787006,\n",
       "        0.77787005, 0.77787005, 0.77787005, 0.78057663, 0.78057663,\n",
       "        0.78057663, 0.78057663, 0.78422831, 0.7842283 , 0.7842283 ,\n",
       "        0.7842283 , 0.79010722, 0.79010722, 0.79010722, 0.79010722,\n",
       "        0.63803118, 0.63803118, 0.63803118, 0.63803118, 0.6512235 ,\n",
       "        0.6512235 , 0.6512235 , 0.6512235 , 0.6647998 , 0.6647998 ,\n",
       "        0.6647998 , 0.6647998 , 0.67874108, 0.67874108, 0.67874108,\n",
       "        0.67874108, 0.69301415, 0.69301415, 0.69301415, 0.69301415,\n",
       "        0.70756602, 0.70756602, 0.70756602, 0.70756602, 0.72231699,\n",
       "        0.72231699, 0.72231699, 0.72231699, 0.73715624, 0.73715624,\n",
       "        0.73715624, 0.73715624, 0.75196762, 0.75196763, 0.75196763,\n",
       "        0.75196763, 0.7669593 , 0.7669593 , 0.7669593 , 0.7669593 ,\n",
       "        0.2110769 , 0.2110769 , 0.2110769 , 0.2110769 , 0.22864279,\n",
       "        0.22864279, 0.22864279, 0.22864279, 0.24926503, 0.24926501,\n",
       "        0.24926501, 0.24926501, 0.2738106 , 0.27381056, 0.27381056,\n",
       "        0.27381056, 0.30350391, 0.30350381, 0.30350381, 0.30350381,\n",
       "        0.34012666, 0.34012666, 0.34012666, 0.34012666, 0.38636196,\n",
       "        0.38636192, 0.38636193, 0.38636193, 0.44639498, 0.44639498,\n",
       "        0.44639498, 0.44639498, 0.52692173, 0.52692172, 0.52692173,\n",
       "        0.52692173, 0.63803079, 0.63803071, 0.63803072, 0.63803072,\n",
       "        0.02088197, 0.02088197, 0.02088197, 0.02088197, 0.02391573,\n",
       "        0.02391573, 0.02391573, 0.02391573, 0.02767716, 0.02767716,\n",
       "        0.02767716, 0.02767716, 0.0324637 , 0.0324637 , 0.0324637 ,\n",
       "        0.0324637 , 0.03876049, 0.03876049, 0.03876049, 0.03876049,\n",
       "        0.04741609, 0.04741609, 0.04741609, 0.04741607, 0.06006106,\n",
       "        0.06006106, 0.06006106, 0.06006104, 0.08027819, 0.08027819,\n",
       "        0.08027816, 0.08027816, 0.11776856, 0.11776857, 0.11776857,\n",
       "        0.11776857, 0.21107463, 0.21107463, 0.21107443, 0.21107443]),\n",
       " 'mean_test_R2': array([0.36037127, 0.36037127, 0.36037127, 0.36037127, 0.36034878,\n",
       "        0.36034878, 0.36034878, 0.36034878, 0.36032613, 0.36032613,\n",
       "        0.36032613, 0.36032613, 0.36030333, 0.36030333, 0.36030333,\n",
       "        0.36030333, 0.36028036, 0.36028036, 0.36028036, 0.36028036,\n",
       "        0.36025724, 0.36025724, 0.36025724, 0.36025724, 0.36023396,\n",
       "        0.36023396, 0.36023396, 0.36023396, 0.36021051, 0.36021051,\n",
       "        0.36021051, 0.36021051, 0.3601869 , 0.3601869 , 0.3601869 ,\n",
       "        0.3601869 , 0.36016313, 0.36016313, 0.36016313, 0.36016313,\n",
       "        0.36186369, 0.36186369, 0.36186369, 0.36186369, 0.36174176,\n",
       "        0.36174176, 0.36174176, 0.36174176, 0.36161038, 0.36161038,\n",
       "        0.36161038, 0.36161038, 0.36146898, 0.36146898, 0.36146898,\n",
       "        0.36146898, 0.36131691, 0.36131691, 0.36131691, 0.36131691,\n",
       "        0.36115351, 0.36115351, 0.36115351, 0.36115351, 0.36097806,\n",
       "        0.36097806, 0.36097806, 0.36097806, 0.36078976, 0.36078976,\n",
       "        0.36078976, 0.36078976, 0.3605878 , 0.3605878 , 0.3605878 ,\n",
       "        0.3605878 , 0.36037127, 0.36037127, 0.36037127, 0.36037127,\n",
       "        0.36140569, 0.36140569, 0.36140569, 0.36140569, 0.36168655,\n",
       "        0.36168655, 0.36168655, 0.36168655, 0.36198137, 0.36198137,\n",
       "        0.36198137, 0.36198137, 0.3622799 , 0.3622799 , 0.3622799 ,\n",
       "        0.3622799 , 0.36256515, 0.36256515, 0.36256515, 0.36256515,\n",
       "        0.36280931, 0.36280931, 0.36280931, 0.36280931, 0.36296685,\n",
       "        0.36296685, 0.36296685, 0.36296685, 0.36296243, 0.36296244,\n",
       "        0.36296244, 0.36296244, 0.36266878, 0.36266879, 0.36266879,\n",
       "        0.36266879, 0.36186369, 0.36186369, 0.36186369, 0.36186369,\n",
       "        0.37334717, 0.37334717, 0.37334717, 0.37334717, 0.3712804 ,\n",
       "        0.3712804 , 0.3712804 , 0.3712804 , 0.36918934, 0.36918934,\n",
       "        0.36918934, 0.36918934, 0.36709768, 0.36709767, 0.36709767,\n",
       "        0.36709767, 0.36504552, 0.36504552, 0.36504552, 0.36504552,\n",
       "        0.36310243, 0.36310243, 0.36310243, 0.36310243, 0.36139363,\n",
       "        0.36139363, 0.36139363, 0.36139363, 0.36015666, 0.36015665,\n",
       "        0.36015665, 0.36015665, 0.35986705, 0.35986705, 0.35986704,\n",
       "        0.35986704, 0.36140569, 0.36140569, 0.36140569, 0.36140569,\n",
       "        0.43316404, 0.43316404, 0.43316404, 0.43316404, 0.43283624,\n",
       "        0.43283624, 0.43283624, 0.43283624, 0.4316759 , 0.4316759 ,\n",
       "        0.4316759 , 0.4316759 , 0.4294985 , 0.4294985 , 0.4294985 ,\n",
       "        0.4294985 , 0.42606652, 0.42606652, 0.42606652, 0.42606652,\n",
       "        0.42106611, 0.42106611, 0.42106611, 0.42106611, 0.41406755,\n",
       "        0.41406755, 0.41406755, 0.41406755, 0.40445449, 0.40445448,\n",
       "        0.40445448, 0.40445448, 0.39129819, 0.39129818, 0.39129818,\n",
       "        0.39129818, 0.37334726, 0.37334725, 0.37334724, 0.37334724,\n",
       "        0.21381   , 0.21381   , 0.21381   , 0.21381   , 0.22908135,\n",
       "        0.22908134, 0.22908134, 0.22908134, 0.24643471, 0.24643467,\n",
       "        0.24643467, 0.24643467, 0.26626829, 0.26626824, 0.26626824,\n",
       "        0.26626824, 0.28904547, 0.28904546, 0.28904546, 0.28904546,\n",
       "        0.31525492, 0.31525491, 0.31525492, 0.31525492, 0.34525226,\n",
       "        0.34525216, 0.34525216, 0.34525216, 0.37871431, 0.37871428,\n",
       "        0.37871429, 0.37871429, 0.41268352, 0.41268347, 0.41268347,\n",
       "        0.41268347, 0.43316416, 0.43316407, 0.43316408, 0.43316408,\n",
       "        0.02064266, 0.02064266, 0.02064266, 0.02064266, 0.02411418,\n",
       "        0.02411418, 0.02411418, 0.02411418, 0.02840105, 0.02840105,\n",
       "        0.02840105, 0.02840104, 0.0338285 , 0.0338285 , 0.0338285 ,\n",
       "        0.03382848, 0.04092108, 0.04092108, 0.04092108, 0.04092106,\n",
       "        0.0505827 , 0.0505827 , 0.0505827 , 0.05058266, 0.06451414,\n",
       "        0.06451414, 0.0645141 , 0.06451409, 0.08633484, 0.08633484,\n",
       "        0.08633473, 0.08633473, 0.12531396, 0.125314  , 0.125314  ,\n",
       "        0.125314  , 0.21380847, 0.21380847, 0.21380805, 0.21380805]),\n",
       " 'std_test_R2': array([0.2856363 , 0.2856363 , 0.2856363 , 0.2856363 , 0.28565715,\n",
       "        0.28565715, 0.28565715, 0.28565715, 0.28567806, 0.28567806,\n",
       "        0.28567806, 0.28567806, 0.28569904, 0.28569904, 0.28569904,\n",
       "        0.28569904, 0.28572008, 0.28572008, 0.28572008, 0.28572008,\n",
       "        0.28574118, 0.28574118, 0.28574118, 0.28574118, 0.28576235,\n",
       "        0.28576235, 0.28576235, 0.28576235, 0.28578359, 0.28578359,\n",
       "        0.28578359, 0.28578359, 0.28580489, 0.28580489, 0.28580489,\n",
       "        0.28580489, 0.28582625, 0.28582625, 0.28582625, 0.28582625,\n",
       "        0.28399398, 0.28399398, 0.28399398, 0.28399398, 0.28415577,\n",
       "        0.28415577, 0.28415577, 0.28415577, 0.28432227, 0.28432227,\n",
       "        0.28432227, 0.28432227, 0.28449369, 0.28449369, 0.28449369,\n",
       "        0.28449369, 0.2846702 , 0.2846702 , 0.2846702 , 0.2846702 ,\n",
       "        0.28485201, 0.28485201, 0.28485201, 0.28485201, 0.28503932,\n",
       "        0.28503932, 0.28503932, 0.28503932, 0.28523233, 0.28523233,\n",
       "        0.28523233, 0.28523233, 0.28543125, 0.28543125, 0.28543125,\n",
       "        0.28543125, 0.2856363 , 0.2856363 , 0.2856363 , 0.2856363 ,\n",
       "        0.277417  , 0.277417  , 0.277417  , 0.277417  , 0.27783614,\n",
       "        0.27783614, 0.27783614, 0.27783614, 0.27828401, 0.27828401,\n",
       "        0.27828401, 0.27828401, 0.27877112, 0.27877112, 0.27877112,\n",
       "        0.27877112, 0.27931216, 0.27931216, 0.27931216, 0.27931216,\n",
       "        0.27992792, 0.27992792, 0.27992792, 0.27992792, 0.2806483 ,\n",
       "        0.2806483 , 0.2806483 , 0.2806483 , 0.28151708, 0.28151708,\n",
       "        0.28151708, 0.28151708, 0.28259947, 0.28259947, 0.28259947,\n",
       "        0.28259947, 0.28399398, 0.28399398, 0.28399398, 0.28399398,\n",
       "        0.24691884, 0.24691884, 0.24691884, 0.24691884, 0.25006127,\n",
       "        0.25006127, 0.25006127, 0.25006127, 0.2532835 , 0.2532835 ,\n",
       "        0.2532835 , 0.2532835 , 0.25658375, 0.25658375, 0.25658375,\n",
       "        0.25658375, 0.25995686, 0.25995686, 0.25995686, 0.25995686,\n",
       "        0.26339186, 0.26339186, 0.26339186, 0.26339186, 0.26686816,\n",
       "        0.26686816, 0.26686817, 0.26686817, 0.2703514 , 0.2703514 ,\n",
       "        0.2703514 , 0.2703514 , 0.27380601, 0.27380601, 0.27380602,\n",
       "        0.27380602, 0.27741699, 0.27741699, 0.27741699, 0.27741699,\n",
       "        0.1281773 , 0.1281773 , 0.1281773 , 0.1281773 , 0.13299673,\n",
       "        0.13299673, 0.13299673, 0.13299673, 0.13899469, 0.13899469,\n",
       "        0.13899469, 0.13899469, 0.14642715, 0.14642715, 0.14642715,\n",
       "        0.14642715, 0.15560385, 0.15560385, 0.15560385, 0.15560385,\n",
       "        0.16690813, 0.16690813, 0.16690813, 0.16690813, 0.18083277,\n",
       "        0.18083278, 0.18083278, 0.18083278, 0.19804866, 0.19804867,\n",
       "        0.19804867, 0.19804867, 0.21954686, 0.21954687, 0.21954687,\n",
       "        0.21954687, 0.24691874, 0.24691875, 0.24691875, 0.24691875,\n",
       "        0.07517622, 0.07517622, 0.07517622, 0.07517622, 0.07967167,\n",
       "        0.07967167, 0.07967167, 0.07967167, 0.08450036, 0.08450034,\n",
       "        0.08450033, 0.08450033, 0.08962118, 0.08962116, 0.08962116,\n",
       "        0.08962116, 0.09492281, 0.09492281, 0.09492281, 0.09492281,\n",
       "        0.10016445, 0.10016444, 0.10016444, 0.10016444, 0.1048916 ,\n",
       "        0.10489155, 0.10489155, 0.10489155, 0.10845804, 0.10845803,\n",
       "        0.10845803, 0.10845803, 0.11138114, 0.11138112, 0.11138112,\n",
       "        0.11138112, 0.12817712, 0.12817715, 0.12817715, 0.12817715,\n",
       "        0.01212011, 0.01212011, 0.01212011, 0.01212011, 0.01234883,\n",
       "        0.01234883, 0.01234883, 0.01234883, 0.01287078, 0.01287078,\n",
       "        0.01287078, 0.01287078, 0.01385937, 0.01385937, 0.01385937,\n",
       "        0.01385937, 0.01557951, 0.01557951, 0.01557951, 0.0155795 ,\n",
       "        0.01844593, 0.01844593, 0.01844593, 0.01844592, 0.02316306,\n",
       "        0.02316306, 0.02316301, 0.02316303, 0.03110507, 0.03110507,\n",
       "        0.03110502, 0.03110502, 0.04547262, 0.04547269, 0.04547269,\n",
       "        0.04547269, 0.07517589, 0.07517589, 0.07517567, 0.07517567]),\n",
       " 'rank_test_R2': array([165, 165, 165, 165, 169, 169, 169, 169, 173, 173, 173, 173, 177,\n",
       "        177, 177, 177, 181, 181, 181, 181, 185, 185, 185, 185, 189, 189,\n",
       "        189, 189, 193, 193, 193, 193, 197, 197, 197, 197, 201, 201, 201,\n",
       "        201, 109, 109, 109, 109, 116, 113, 113, 113, 124, 121, 121, 121,\n",
       "        128, 125, 125, 125, 144, 141, 141, 141, 148, 145, 145, 145, 152,\n",
       "        149, 149, 149, 156, 153, 153, 153, 160, 157, 157, 157, 164, 161,\n",
       "        161, 161, 132, 132, 132, 132, 120, 119, 118, 117, 104, 103, 102,\n",
       "        101, 100,  99,  98,  97,  96,  95,  94,  93,  88,  87,  86,  85,\n",
       "         80,  79,  78,  77,  84,  83,  82,  81,  92,  91,  90,  89, 108,\n",
       "        107, 106, 105,  53,  53,  53,  53,  57,  58,  59,  60,  61,  62,\n",
       "         63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
       "         76, 137, 138, 139, 140, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "        136, 131, 130, 129,   5,   5,   5,   5,  12,  11,  10,   9,  16,\n",
       "         15,  14,  13,  20,  19,  18,  17,  24,  23,  22,  21,  28,  27,\n",
       "         26,  25,  32,  31,  30,  29,  37,  38,  39,  40,  41,  42,  43,\n",
       "         44,  49,  50,  51,  52, 237, 237, 237, 237, 233, 236, 234, 234,\n",
       "        229, 232, 230, 230, 225, 228, 226, 226, 221, 223, 223, 222, 217,\n",
       "        220, 219, 218, 213, 216, 215, 214,  45,  48,  47,  46,  33,  36,\n",
       "         35,  34,   1,   4,   3,   2, 277, 277, 277, 277, 273, 273, 273,\n",
       "        276, 269, 269, 269, 272, 265, 265, 265, 268, 261, 261, 261, 264,\n",
       "        257, 257, 259, 260, 253, 253, 255, 256, 250, 249, 251, 251, 248,\n",
       "        245, 245, 245, 241, 241, 243, 243]),\n",
       " 'split0_test_MAE': array([-3.36950928e+14, -3.36950928e+14, -3.36950928e+14, -3.36950928e+14,\n",
       "        -3.36938908e+14, -3.36938908e+14, -3.36938908e+14, -3.36938908e+14,\n",
       "        -3.36926869e+14, -3.36926869e+14, -3.36926869e+14, -3.36926869e+14,\n",
       "        -3.36914810e+14, -3.36914810e+14, -3.36914810e+14, -3.36914810e+14,\n",
       "        -3.36902730e+14, -3.36902730e+14, -3.36902730e+14, -3.36902730e+14,\n",
       "        -3.36890630e+14, -3.36890630e+14, -3.36890630e+14, -3.36890630e+14,\n",
       "        -3.36878510e+14, -3.36878510e+14, -3.36878510e+14, -3.36878510e+14,\n",
       "        -3.36866370e+14, -3.36866370e+14, -3.36866370e+14, -3.36866370e+14,\n",
       "        -3.36854210e+14, -3.36854210e+14, -3.36854210e+14, -3.36854210e+14,\n",
       "        -3.36842029e+14, -3.36842029e+14, -3.36842029e+14, -3.36842029e+14,\n",
       "        -3.37955380e+14, -3.37955380e+14, -3.37955380e+14, -3.37955380e+14,\n",
       "        -3.37850931e+14, -3.37850931e+14, -3.37850931e+14, -3.37850931e+14,\n",
       "        -3.37744775e+14, -3.37744775e+14, -3.37744775e+14, -3.37744775e+14,\n",
       "        -3.37636877e+14, -3.37636877e+14, -3.37636877e+14, -3.37636877e+14,\n",
       "        -3.37527204e+14, -3.37527204e+14, -3.37527204e+14, -3.37527204e+14,\n",
       "        -3.37415718e+14, -3.37415718e+14, -3.37415718e+14, -3.37415718e+14,\n",
       "        -3.37302385e+14, -3.37302385e+14, -3.37302385e+14, -3.37302385e+14,\n",
       "        -3.37187168e+14, -3.37187168e+14, -3.37187168e+14, -3.37187168e+14,\n",
       "        -3.37070028e+14, -3.37070028e+14, -3.37070028e+14, -3.37070028e+14,\n",
       "        -3.36950928e+14, -3.36950928e+14, -3.36950928e+14, -3.36950928e+14,\n",
       "        -3.43113477e+14, -3.43113477e+14, -3.43113477e+14, -3.43113477e+14,\n",
       "        -3.42800561e+14, -3.42800561e+14, -3.42800561e+14, -3.42800561e+14,\n",
       "        -3.42445022e+14, -3.42445021e+14, -3.42445021e+14, -3.42445021e+14,\n",
       "        -3.42040105e+14, -3.42040104e+14, -3.42040104e+14, -3.42040104e+14,\n",
       "        -3.41577619e+14, -3.41577618e+14, -3.41577618e+14, -3.41577618e+14,\n",
       "        -3.41047555e+14, -3.41047554e+14, -3.41047554e+14, -3.41047554e+14,\n",
       "        -3.40437586e+14, -3.40437585e+14, -3.40437585e+14, -3.40437585e+14,\n",
       "        -3.39732421e+14, -3.39732420e+14, -3.39732420e+14, -3.39732420e+14,\n",
       "        -3.38912981e+14, -3.38912980e+14, -3.38912980e+14, -3.38912980e+14,\n",
       "        -3.37955382e+14, -3.37955381e+14, -3.37955381e+14, -3.37955381e+14,\n",
       "        -3.41875080e+14, -3.41875080e+14, -3.41875080e+14, -3.41875080e+14,\n",
       "        -3.42479200e+14, -3.42479200e+14, -3.42479200e+14, -3.42479200e+14,\n",
       "        -3.43078676e+14, -3.43078676e+14, -3.43078676e+14, -3.43078676e+14,\n",
       "        -3.43662439e+14, -3.43662439e+14, -3.43662440e+14, -3.43662440e+14,\n",
       "        -3.44212246e+14, -3.44212247e+14, -3.44212248e+14, -3.44212248e+14,\n",
       "        -3.44696629e+14, -3.44696630e+14, -3.44696631e+14, -3.44696631e+14,\n",
       "        -3.45057687e+14, -3.45057689e+14, -3.45057690e+14, -3.45057691e+14,\n",
       "        -3.45178643e+14, -3.45178646e+14, -3.45178647e+14, -3.45178648e+14,\n",
       "        -3.44789508e+14, -3.44789512e+14, -3.44789514e+14, -3.44789515e+14,\n",
       "        -3.43113490e+14, -3.43113480e+14, -3.43113479e+14, -3.43113479e+14,\n",
       "        -3.21648028e+14, -3.21648028e+14, -3.21648028e+14, -3.21648028e+14,\n",
       "        -3.22007827e+14, -3.22007827e+14, -3.22007827e+14, -3.22007827e+14,\n",
       "        -3.22612361e+14, -3.22612361e+14, -3.22612361e+14, -3.22612361e+14,\n",
       "        -3.23519221e+14, -3.23519221e+14, -3.23519221e+14, -3.23519221e+14,\n",
       "        -3.24803463e+14, -3.24803462e+14, -3.24803461e+14, -3.24803461e+14,\n",
       "        -3.26564923e+14, -3.26564922e+14, -3.26564922e+14, -3.26564922e+14,\n",
       "        -3.28939468e+14, -3.28939467e+14, -3.28939467e+14, -3.28939467e+14,\n",
       "        -3.32115776e+14, -3.32115776e+14, -3.32115776e+14, -3.32115776e+14,\n",
       "        -3.36352304e+14, -3.36352308e+14, -3.36352310e+14, -3.36352310e+14,\n",
       "        -3.41875041e+14, -3.41875052e+14, -3.41875058e+14, -3.41875060e+14,\n",
       "        -3.68549257e+14, -3.68549257e+14, -3.68549257e+14, -3.68549257e+14,\n",
       "        -3.65139297e+14, -3.65139299e+14, -3.65139299e+14, -3.65139299e+14,\n",
       "        -3.61269058e+14, -3.61269065e+14, -3.61269065e+14, -3.61269065e+14,\n",
       "        -3.56852427e+14, -3.56852449e+14, -3.56852449e+14, -3.56852449e+14,\n",
       "        -3.51790868e+14, -3.51790866e+14, -3.51790866e+14, -3.51790866e+14,\n",
       "        -3.45984297e+14, -3.45984296e+14, -3.45984295e+14, -3.45984295e+14,\n",
       "        -3.39372084e+14, -3.39372104e+14, -3.39372104e+14, -3.39372103e+14,\n",
       "        -3.32072045e+14, -3.32072045e+14, -3.32072043e+14, -3.32072043e+14,\n",
       "        -3.24888947e+14, -3.24888949e+14, -3.24888949e+14, -3.24888948e+14,\n",
       "        -3.21647952e+14, -3.21648025e+14, -3.21648023e+14, -3.21648022e+14,\n",
       "        -4.11922900e+14, -4.11922900e+14, -4.11922900e+14, -4.11922900e+14,\n",
       "        -4.11140182e+14, -4.11140182e+14, -4.11140182e+14, -4.11140184e+14,\n",
       "        -4.10173772e+14, -4.10173772e+14, -4.10173772e+14, -4.10173775e+14,\n",
       "        -4.08950460e+14, -4.08950460e+14, -4.08950460e+14, -4.08950464e+14,\n",
       "        -4.07352221e+14, -4.07352221e+14, -4.07352221e+14, -4.07352229e+14,\n",
       "        -4.05175789e+14, -4.05175789e+14, -4.05175789e+14, -4.05175802e+14,\n",
       "        -4.02038976e+14, -4.02038976e+14, -4.02038976e+14, -4.02039003e+14,\n",
       "        -3.97129402e+14, -3.97129402e+14, -3.97129464e+14, -3.97129464e+14,\n",
       "        -3.88370739e+14, -3.88370861e+14, -3.88370861e+14, -3.88370861e+14,\n",
       "        -3.68549412e+14, -3.68549412e+14, -3.68549554e+14, -3.68549554e+14]),\n",
       " 'split1_test_MAE': array([-1.05496466e+14, -1.05496466e+14, -1.05496466e+14, -1.05496466e+14,\n",
       "        -1.05509189e+14, -1.05509189e+14, -1.05509189e+14, -1.05509189e+14,\n",
       "        -1.05521987e+14, -1.05521987e+14, -1.05521987e+14, -1.05521987e+14,\n",
       "        -1.05534859e+14, -1.05534859e+14, -1.05534859e+14, -1.05534859e+14,\n",
       "        -1.05547806e+14, -1.05547806e+14, -1.05547806e+14, -1.05547806e+14,\n",
       "        -1.05560827e+14, -1.05560827e+14, -1.05560827e+14, -1.05560827e+14,\n",
       "        -1.05573925e+14, -1.05573925e+14, -1.05573925e+14, -1.05573925e+14,\n",
       "        -1.05587099e+14, -1.05587099e+14, -1.05587099e+14, -1.05587099e+14,\n",
       "        -1.05600349e+14, -1.05600349e+14, -1.05600349e+14, -1.05600349e+14,\n",
       "        -1.05613677e+14, -1.05613677e+14, -1.05613677e+14, -1.05613677e+14,\n",
       "        -1.04606576e+14, -1.04606576e+14, -1.04606576e+14, -1.04606576e+14,\n",
       "        -1.04684099e+14, -1.04684099e+14, -1.04684099e+14, -1.04684099e+14,\n",
       "        -1.04766274e+14, -1.04766274e+14, -1.04766274e+14, -1.04766274e+14,\n",
       "        -1.04853365e+14, -1.04853365e+14, -1.04853365e+14, -1.04853365e+14,\n",
       "        -1.04945657e+14, -1.04945657e+14, -1.04945657e+14, -1.04945657e+14,\n",
       "        -1.05043453e+14, -1.05043453e+14, -1.05043453e+14, -1.05043453e+14,\n",
       "        -1.05147075e+14, -1.05147075e+14, -1.05147075e+14, -1.05147075e+14,\n",
       "        -1.05256869e+14, -1.05256869e+14, -1.05256869e+14, -1.05256869e+14,\n",
       "        -1.05373202e+14, -1.05373202e+14, -1.05373202e+14, -1.05373202e+14,\n",
       "        -1.05496466e+14, -1.05496466e+14, -1.05496466e+14, -1.05496466e+14,\n",
       "        -1.03775186e+14, -1.03775186e+14, -1.03775186e+14, -1.03775186e+14,\n",
       "        -1.03704318e+14, -1.03704318e+14, -1.03704318e+14, -1.03704318e+14,\n",
       "        -1.03636918e+14, -1.03636918e+14, -1.03636918e+14, -1.03636918e+14,\n",
       "        -1.03579060e+14, -1.03579060e+14, -1.03579060e+14, -1.03579060e+14,\n",
       "        -1.03540194e+14, -1.03540194e+14, -1.03540194e+14, -1.03540194e+14,\n",
       "        -1.03535109e+14, -1.03535109e+14, -1.03535109e+14, -1.03535109e+14,\n",
       "        -1.03587221e+14, -1.03587222e+14, -1.03587222e+14, -1.03587222e+14,\n",
       "        -1.03734279e+14, -1.03734279e+14, -1.03734279e+14, -1.03734279e+14,\n",
       "        -1.04038624e+14, -1.04038625e+14, -1.04038625e+14, -1.04038625e+14,\n",
       "        -1.04606574e+14, -1.04606574e+14, -1.04606574e+14, -1.04606574e+14,\n",
       "        -1.00636670e+14, -1.00636670e+14, -1.00636670e+14, -1.00636670e+14,\n",
       "        -1.01214429e+14, -1.01214429e+14, -1.01214429e+14, -1.01214429e+14,\n",
       "        -1.01797248e+14, -1.01797248e+14, -1.01797248e+14, -1.01797248e+14,\n",
       "        -1.02378065e+14, -1.02378065e+14, -1.02378065e+14, -1.02378065e+14,\n",
       "        -1.02944643e+14, -1.02944643e+14, -1.02944643e+14, -1.02944643e+14,\n",
       "        -1.03475461e+14, -1.03475462e+14, -1.03475462e+14, -1.03475462e+14,\n",
       "        -1.03931527e+14, -1.03931527e+14, -1.03931527e+14, -1.03931528e+14,\n",
       "        -1.04239317e+14, -1.04239318e+14, -1.04239318e+14, -1.04239318e+14,\n",
       "        -1.04256876e+14, -1.04256877e+14, -1.04256877e+14, -1.04256877e+14,\n",
       "        -1.03775184e+14, -1.03775184e+14, -1.03775184e+14, -1.03775184e+14,\n",
       "        -7.68841716e+13, -7.68841716e+13, -7.68841716e+13, -7.68841716e+13,\n",
       "        -7.80972726e+13, -7.80972725e+13, -7.80972725e+13, -7.80972725e+13,\n",
       "        -7.95247466e+13, -7.95247465e+13, -7.95247465e+13, -7.95247464e+13,\n",
       "        -8.12003046e+13, -8.12003045e+13, -8.12003044e+13, -8.12003044e+13,\n",
       "        -8.31661045e+13, -8.31661042e+13, -8.31661042e+13, -8.31661042e+13,\n",
       "        -8.54773228e+13, -8.54773225e+13, -8.54773224e+13, -8.54773224e+13,\n",
       "        -8.82113362e+13, -8.82113356e+13, -8.82113355e+13, -8.82113355e+13,\n",
       "        -9.14878576e+13, -9.14878564e+13, -9.14878563e+13, -9.14878562e+13,\n",
       "        -9.55146466e+13, -9.55146438e+13, -9.55146433e+13, -9.55146432e+13,\n",
       "        -1.00636661e+14, -1.00636659e+14, -1.00636657e+14, -1.00636657e+14,\n",
       "        -9.50621644e+13, -9.50621644e+13, -9.50621644e+13, -9.50621644e+13,\n",
       "        -9.26178853e+13, -9.26178850e+13, -9.26178850e+13, -9.26178850e+13,\n",
       "        -8.99094076e+13, -8.99094172e+13, -8.99094172e+13, -8.99094172e+13,\n",
       "        -8.69155852e+13, -8.69156078e+13, -8.69156078e+13, -8.69156078e+13,\n",
       "        -8.36340104e+13, -8.36340102e+13, -8.36340102e+13, -8.36340100e+13,\n",
       "        -8.01120295e+13, -8.01120333e+13, -8.01120327e+13, -8.01120327e+13,\n",
       "        -7.65236328e+13, -7.65236584e+13, -7.65236584e+13, -7.65236581e+13,\n",
       "        -7.33706551e+13, -7.33706641e+13, -7.33706630e+13, -7.33706630e+13,\n",
       "        -7.20642370e+13, -7.20642552e+13, -7.20642552e+13, -7.20642546e+13,\n",
       "        -7.68840939e+13, -7.68841100e+13, -7.68841099e+13, -7.68841096e+13,\n",
       "        -1.29296800e+14, -1.29296800e+14, -1.29296800e+14, -1.29296800e+14,\n",
       "        -1.28642279e+14, -1.28642279e+14, -1.28642279e+14, -1.28642280e+14,\n",
       "        -1.27835549e+14, -1.27835549e+14, -1.27835549e+14, -1.27835551e+14,\n",
       "        -1.26816617e+14, -1.26816617e+14, -1.26816617e+14, -1.26816619e+14,\n",
       "        -1.25489270e+14, -1.25489270e+14, -1.25489270e+14, -1.25489274e+14,\n",
       "        -1.23689000e+14, -1.23689000e+14, -1.23689000e+14, -1.23689007e+14,\n",
       "        -1.21109709e+14, -1.21109709e+14, -1.21109722e+14, -1.21109722e+14,\n",
       "        -1.17111562e+14, -1.17111562e+14, -1.17111585e+14, -1.17111585e+14,\n",
       "        -1.10110202e+14, -1.10110188e+14, -1.10110188e+14, -1.10110188e+14,\n",
       "        -9.50623548e+13, -9.50623548e+13, -9.50624443e+13, -9.50624443e+13]),\n",
       " 'split2_test_MAE': array([-3.56409565e+14, -3.56409565e+14, -3.56409565e+14, -3.56409565e+14,\n",
       "        -3.56410494e+14, -3.56410494e+14, -3.56410494e+14, -3.56410494e+14,\n",
       "        -3.56411449e+14, -3.56411449e+14, -3.56411449e+14, -3.56411449e+14,\n",
       "        -3.56412428e+14, -3.56412428e+14, -3.56412428e+14, -3.56412428e+14,\n",
       "        -3.56413432e+14, -3.56413432e+14, -3.56413432e+14, -3.56413432e+14,\n",
       "        -3.56414462e+14, -3.56414462e+14, -3.56414462e+14, -3.56414462e+14,\n",
       "        -3.56415517e+14, -3.56415517e+14, -3.56415517e+14, -3.56415517e+14,\n",
       "        -3.56416597e+14, -3.56416597e+14, -3.56416597e+14, -3.56416597e+14,\n",
       "        -3.56417703e+14, -3.56417703e+14, -3.56417703e+14, -3.56417703e+14,\n",
       "        -3.56418835e+14, -3.56418835e+14, -3.56418835e+14, -3.56418835e+14,\n",
       "        -3.56411603e+14, -3.56411603e+14, -3.56411603e+14, -3.56411603e+14,\n",
       "        -3.56404206e+14, -3.56404206e+14, -3.56404206e+14, -3.56404206e+14,\n",
       "        -3.56398369e+14, -3.56398369e+14, -3.56398369e+14, -3.56398369e+14,\n",
       "        -3.56394183e+14, -3.56394183e+14, -3.56394183e+14, -3.56394183e+14,\n",
       "        -3.56391744e+14, -3.56391744e+14, -3.56391744e+14, -3.56391744e+14,\n",
       "        -3.56391155e+14, -3.56391155e+14, -3.56391155e+14, -3.56391155e+14,\n",
       "        -3.56392523e+14, -3.56392523e+14, -3.56392523e+14, -3.56392523e+14,\n",
       "        -3.56395964e+14, -3.56395964e+14, -3.56395964e+14, -3.56395964e+14,\n",
       "        -3.56401601e+14, -3.56401601e+14, -3.56401601e+14, -3.56401601e+14,\n",
       "        -3.56409565e+14, -3.56409565e+14, -3.56409565e+14, -3.56409565e+14,\n",
       "        -3.58976262e+14, -3.58976262e+14, -3.58976262e+14, -3.58976262e+14,\n",
       "        -3.58659099e+14, -3.58659099e+14, -3.58659099e+14, -3.58659099e+14,\n",
       "        -3.58337232e+14, -3.58337232e+14, -3.58337232e+14, -3.58337232e+14,\n",
       "        -3.58012512e+14, -3.58012512e+14, -3.58012512e+14, -3.58012512e+14,\n",
       "        -3.57688031e+14, -3.57688031e+14, -3.57688031e+14, -3.57688031e+14,\n",
       "        -3.57368846e+14, -3.57368846e+14, -3.57368846e+14, -3.57368846e+14,\n",
       "        -3.57063177e+14, -3.57063177e+14, -3.57063177e+14, -3.57063177e+14,\n",
       "        -3.56784433e+14, -3.56784433e+14, -3.56784433e+14, -3.56784433e+14,\n",
       "        -3.56554774e+14, -3.56554774e+14, -3.56554774e+14, -3.56554774e+14,\n",
       "        -3.56411603e+14, -3.56411603e+14, -3.56411603e+14, -3.56411603e+14,\n",
       "        -3.76574867e+14, -3.76574867e+14, -3.76574867e+14, -3.76574867e+14,\n",
       "        -3.74979045e+14, -3.74979045e+14, -3.74979045e+14, -3.74979045e+14,\n",
       "        -3.73348263e+14, -3.73348263e+14, -3.73348263e+14, -3.73348263e+14,\n",
       "        -3.71674542e+14, -3.71674542e+14, -3.71674542e+14, -3.71674543e+14,\n",
       "        -3.69945822e+14, -3.69945823e+14, -3.69945823e+14, -3.69945824e+14,\n",
       "        -3.68142960e+14, -3.68142961e+14, -3.68142962e+14, -3.68142962e+14,\n",
       "        -3.66233731e+14, -3.66233732e+14, -3.66233733e+14, -3.66233734e+14,\n",
       "        -3.64160035e+14, -3.64160038e+14, -3.64160039e+14, -3.64160039e+14,\n",
       "        -3.61809686e+14, -3.61809685e+14, -3.61809685e+14, -3.61809685e+14,\n",
       "        -3.58976267e+14, -3.58976266e+14, -3.58976266e+14, -3.58976266e+14,\n",
       "        -4.76764279e+14, -4.76764279e+14, -4.76764279e+14, -4.76764279e+14,\n",
       "        -4.68146474e+14, -4.68146474e+14, -4.68146474e+14, -4.68146474e+14,\n",
       "        -4.59066485e+14, -4.59066485e+14, -4.59066485e+14, -4.59066485e+14,\n",
       "        -4.49477498e+14, -4.49477498e+14, -4.49477498e+14, -4.49477498e+14,\n",
       "        -4.39323606e+14, -4.39323606e+14, -4.39323606e+14, -4.39323606e+14,\n",
       "        -4.28536448e+14, -4.28536447e+14, -4.28536447e+14, -4.28536447e+14,\n",
       "        -4.17029533e+14, -4.17029529e+14, -4.17029529e+14, -4.17029530e+14,\n",
       "        -4.04686922e+14, -4.04686922e+14, -4.04686923e+14, -4.04686923e+14,\n",
       "        -3.91332575e+14, -3.91332590e+14, -3.91332593e+14, -3.91332594e+14,\n",
       "        -3.76574870e+14, -3.76574885e+14, -3.76574895e+14, -3.76574899e+14,\n",
       "        -7.18948570e+14, -7.18948570e+14, -7.18948570e+14, -7.18948570e+14,\n",
       "        -7.09415773e+14, -7.09415782e+14, -7.09415782e+14, -7.09415782e+14,\n",
       "        -6.98220742e+14, -6.98220760e+14, -6.98220760e+14, -6.98220760e+14,\n",
       "        -6.84885664e+14, -6.84885664e+14, -6.84885664e+14, -6.84885664e+14,\n",
       "        -6.68729050e+14, -6.68729050e+14, -6.68729050e+14, -6.68729050e+14,\n",
       "        -6.48743436e+14, -6.48743444e+14, -6.48743443e+14, -6.48743443e+14,\n",
       "        -6.23370820e+14, -6.23370867e+14, -6.23370867e+14, -6.23370867e+14,\n",
       "        -5.90057232e+14, -5.90057247e+14, -5.90057244e+14, -5.90057244e+14,\n",
       "        -5.44260907e+14, -5.44260933e+14, -5.44260929e+14, -5.44260928e+14,\n",
       "        -4.76764616e+14, -4.76764617e+14, -4.76764615e+14, -4.76764615e+14,\n",
       "        -8.22511606e+14, -8.22511606e+14, -8.22511606e+14, -8.22511606e+14,\n",
       "        -8.20849160e+14, -8.20849160e+14, -8.20849160e+14, -8.20849160e+14,\n",
       "        -8.18788636e+14, -8.18788636e+14, -8.18788636e+14, -8.18788636e+14,\n",
       "        -8.16167595e+14, -8.16167595e+14, -8.16167595e+14, -8.16167596e+14,\n",
       "        -8.12721309e+14, -8.12721309e+14, -8.12721309e+14, -8.12721310e+14,\n",
       "        -8.07987177e+14, -8.07987177e+14, -8.07987179e+14, -8.07987179e+14,\n",
       "        -8.01077347e+14, -8.01077347e+14, -8.01077348e+14, -8.01077348e+14,\n",
       "        -7.90044148e+14, -7.90044132e+14, -7.90044132e+14, -7.90044132e+14,\n",
       "        -7.69625187e+14, -7.69624985e+14, -7.69624985e+14, -7.69624985e+14,\n",
       "        -7.18949940e+14, -7.18949940e+14, -7.18950040e+14, -7.18950040e+14]),\n",
       " 'split3_test_MAE': array([-1.01997189e+14, -1.01997189e+14, -1.01997189e+14, -1.01997189e+14,\n",
       "        -1.02002627e+14, -1.02002627e+14, -1.02002627e+14, -1.02002627e+14,\n",
       "        -1.02008082e+14, -1.02008082e+14, -1.02008082e+14, -1.02008082e+14,\n",
       "        -1.02013554e+14, -1.02013554e+14, -1.02013554e+14, -1.02013554e+14,\n",
       "        -1.02019043e+14, -1.02019043e+14, -1.02019043e+14, -1.02019043e+14,\n",
       "        -1.02024550e+14, -1.02024550e+14, -1.02024550e+14, -1.02024550e+14,\n",
       "        -1.02030074e+14, -1.02030074e+14, -1.02030074e+14, -1.02030074e+14,\n",
       "        -1.02035616e+14, -1.02035616e+14, -1.02035616e+14, -1.02035616e+14,\n",
       "        -1.02041175e+14, -1.02041175e+14, -1.02041175e+14, -1.02041175e+14,\n",
       "        -1.02046752e+14, -1.02046752e+14, -1.02046752e+14, -1.02046752e+14,\n",
       "        -1.01569591e+14, -1.01569591e+14, -1.01569591e+14, -1.01569591e+14,\n",
       "        -1.01611712e+14, -1.01611712e+14, -1.01611712e+14, -1.01611712e+14,\n",
       "        -1.01655053e+14, -1.01655053e+14, -1.01655053e+14, -1.01655053e+14,\n",
       "        -1.01699663e+14, -1.01699663e+14, -1.01699663e+14, -1.01699663e+14,\n",
       "        -1.01745598e+14, -1.01745598e+14, -1.01745598e+14, -1.01745598e+14,\n",
       "        -1.01792912e+14, -1.01792912e+14, -1.01792912e+14, -1.01792912e+14,\n",
       "        -1.01841665e+14, -1.01841665e+14, -1.01841665e+14, -1.01841665e+14,\n",
       "        -1.01891918e+14, -1.01891918e+14, -1.01891918e+14, -1.01891918e+14,\n",
       "        -1.01943737e+14, -1.01943737e+14, -1.01943737e+14, -1.01943737e+14,\n",
       "        -1.01997189e+14, -1.01997189e+14, -1.01997189e+14, -1.01997189e+14,\n",
       "        -9.98404720e+13, -9.98404720e+13, -9.98404720e+13, -9.98404720e+13,\n",
       "        -9.99507754e+13, -9.99507754e+13, -9.99507754e+13, -9.99507754e+13,\n",
       "        -1.00068838e+14, -1.00068838e+14, -1.00068838e+14, -1.00068838e+14,\n",
       "        -1.00197430e+14, -1.00197430e+14, -1.00197430e+14, -1.00197430e+14,\n",
       "        -1.00340387e+14, -1.00340387e+14, -1.00340387e+14, -1.00340387e+14,\n",
       "        -1.00503098e+14, -1.00503098e+14, -1.00503098e+14, -1.00503098e+14,\n",
       "        -1.00693244e+14, -1.00693243e+14, -1.00693243e+14, -1.00693243e+14,\n",
       "        -1.00921965e+14, -1.00921965e+14, -1.00921965e+14, -1.00921965e+14,\n",
       "        -1.01205754e+14, -1.01205753e+14, -1.01205753e+14, -1.01205753e+14,\n",
       "        -1.01569592e+14, -1.01569591e+14, -1.01569591e+14, -1.01569591e+14,\n",
       "        -9.18193265e+13, -9.18193265e+13, -9.18193265e+13, -9.18193265e+13,\n",
       "        -9.26560840e+13, -9.26560841e+13, -9.26560841e+13, -9.26560841e+13,\n",
       "        -9.35118091e+13, -9.35118092e+13, -9.35118093e+13, -9.35118093e+13,\n",
       "        -9.43856499e+13, -9.43856501e+13, -9.43856502e+13, -9.43856502e+13,\n",
       "        -9.52758259e+13, -9.52758261e+13, -9.52758262e+13, -9.52758263e+13,\n",
       "        -9.61790278e+13, -9.61790280e+13, -9.61790282e+13, -9.61790283e+13,\n",
       "        -9.70895051e+13, -9.70895054e+13, -9.70895057e+13, -9.70895057e+13,\n",
       "        -9.79982468e+13, -9.79982472e+13, -9.79982473e+13, -9.79982476e+13,\n",
       "        -9.88971604e+13, -9.88971603e+13, -9.88971603e+13, -9.88971603e+13,\n",
       "        -9.98404684e+13, -9.98404680e+13, -9.98404679e+13, -9.98404679e+13,\n",
       "        -5.84082423e+13, -5.84082423e+13, -5.84082423e+13, -5.84082423e+13,\n",
       "        -5.99868426e+13, -5.99868425e+13, -5.99868425e+13, -5.99868425e+13,\n",
       "        -6.18677117e+13, -6.18677114e+13, -6.18677114e+13, -6.18677114e+13,\n",
       "        -6.41099623e+13, -6.41099621e+13, -6.41099620e+13, -6.41099620e+13,\n",
       "        -6.67889561e+13, -6.67889558e+13, -6.67889557e+13, -6.67889557e+13,\n",
       "        -7.00029038e+13, -7.00029037e+13, -7.00029037e+13, -7.00029037e+13,\n",
       "        -7.38834449e+13, -7.38834462e+13, -7.38834462e+13, -7.38834462e+13,\n",
       "        -7.86136294e+13, -7.86136348e+13, -7.86136350e+13, -7.86136351e+13,\n",
       "        -8.44601083e+13, -8.44601118e+13, -8.44601129e+13, -8.44601133e+13,\n",
       "        -9.18192934e+13, -9.18192963e+13, -9.18192987e+13, -9.18192995e+13,\n",
       "        -7.22263348e+13, -7.22263348e+13, -7.22263348e+13, -7.22263348e+13,\n",
       "        -7.00415779e+13, -7.00415810e+13, -7.00415810e+13, -7.00415810e+13,\n",
       "        -6.76180904e+13, -6.76180981e+13, -6.76180981e+13, -6.76180981e+13,\n",
       "        -6.49361499e+13, -6.49361493e+13, -6.49361493e+13, -6.49361493e+13,\n",
       "        -6.19931768e+13, -6.19931762e+13, -6.19931762e+13, -6.19931760e+13,\n",
       "        -5.88336372e+13, -5.88336390e+13, -5.88336384e+13, -5.88336384e+13,\n",
       "        -5.56251435e+13, -5.56251600e+13, -5.56251600e+13, -5.56251598e+13,\n",
       "        -5.28690791e+13, -5.28690828e+13, -5.28690817e+13, -5.28690815e+13,\n",
       "        -5.20668793e+13, -5.20668855e+13, -5.20668855e+13, -5.20668852e+13,\n",
       "        -5.84081777e+13, -5.84081827e+13, -5.84081826e+13, -5.84081824e+13,\n",
       "        -1.02669333e+14, -1.02669333e+14, -1.02669333e+14, -1.02669333e+14,\n",
       "        -1.02088836e+14, -1.02088836e+14, -1.02088836e+14, -1.02088837e+14,\n",
       "        -1.01373311e+14, -1.01373311e+14, -1.01373311e+14, -1.01373312e+14,\n",
       "        -1.00469515e+14, -1.00469515e+14, -1.00469515e+14, -1.00469517e+14,\n",
       "        -9.92920499e+13, -9.92920499e+13, -9.92920499e+13, -9.92920535e+13,\n",
       "        -9.76948452e+13, -9.76948452e+13, -9.76948452e+13, -9.76948515e+13,\n",
       "        -9.54059830e+13, -9.54059830e+13, -9.54059946e+13, -9.54059946e+13,\n",
       "        -9.18565815e+13, -9.18565815e+13, -9.18566016e+13, -9.18566016e+13,\n",
       "        -8.56354153e+13, -8.56354016e+13, -8.56354016e+13, -8.56354016e+13,\n",
       "        -7.22265336e+13, -7.22265336e+13, -7.22266150e+13, -7.22266150e+13]),\n",
       " 'split4_test_MAE': array([-1.22690105e+14, -1.22690105e+14, -1.22690105e+14, -1.22690105e+14,\n",
       "        -1.22685870e+14, -1.22685870e+14, -1.22685870e+14, -1.22685870e+14,\n",
       "        -1.22681688e+14, -1.22681688e+14, -1.22681688e+14, -1.22681688e+14,\n",
       "        -1.22677561e+14, -1.22677561e+14, -1.22677561e+14, -1.22677561e+14,\n",
       "        -1.22673488e+14, -1.22673488e+14, -1.22673488e+14, -1.22673488e+14,\n",
       "        -1.22669471e+14, -1.22669471e+14, -1.22669471e+14, -1.22669471e+14,\n",
       "        -1.22665509e+14, -1.22665509e+14, -1.22665509e+14, -1.22665509e+14,\n",
       "        -1.22661604e+14, -1.22661604e+14, -1.22661604e+14, -1.22661604e+14,\n",
       "        -1.22657757e+14, -1.22657757e+14, -1.22657757e+14, -1.22657757e+14,\n",
       "        -1.22653967e+14, -1.22653967e+14, -1.22653967e+14, -1.22653967e+14,\n",
       "        -1.23226617e+14, -1.23226617e+14, -1.23226617e+14, -1.23226617e+14,\n",
       "        -1.23156132e+14, -1.23156132e+14, -1.23156132e+14, -1.23156132e+14,\n",
       "        -1.23087609e+14, -1.23087609e+14, -1.23087609e+14, -1.23087609e+14,\n",
       "        -1.23021317e+14, -1.23021317e+14, -1.23021317e+14, -1.23021317e+14,\n",
       "        -1.22957560e+14, -1.22957560e+14, -1.22957560e+14, -1.22957560e+14,\n",
       "        -1.22896675e+14, -1.22896675e+14, -1.22896675e+14, -1.22896675e+14,\n",
       "        -1.22839038e+14, -1.22839038e+14, -1.22839038e+14, -1.22839038e+14,\n",
       "        -1.22785071e+14, -1.22785071e+14, -1.22785071e+14, -1.22785071e+14,\n",
       "        -1.22735249e+14, -1.22735249e+14, -1.22735249e+14, -1.22735249e+14,\n",
       "        -1.22690105e+14, -1.22690105e+14, -1.22690105e+14, -1.22690105e+14,\n",
       "        -1.29278815e+14, -1.29278815e+14, -1.29278815e+14, -1.29278815e+14,\n",
       "        -1.28772240e+14, -1.28772240e+14, -1.28772240e+14, -1.28772240e+14,\n",
       "        -1.28226643e+14, -1.28226643e+14, -1.28226643e+14, -1.28226643e+14,\n",
       "        -1.27637934e+14, -1.27637934e+14, -1.27637934e+14, -1.27637934e+14,\n",
       "        -1.27002198e+14, -1.27002198e+14, -1.27002198e+14, -1.27002198e+14,\n",
       "        -1.26316465e+14, -1.26316465e+14, -1.26316465e+14, -1.26316465e+14,\n",
       "        -1.25580377e+14, -1.25580377e+14, -1.25580377e+14, -1.25580377e+14,\n",
       "        -1.24799904e+14, -1.24799904e+14, -1.24799904e+14, -1.24799904e+14,\n",
       "        -1.23996003e+14, -1.23996003e+14, -1.23996003e+14, -1.23996003e+14,\n",
       "        -1.23226617e+14, -1.23226617e+14, -1.23226617e+14, -1.23226617e+14,\n",
       "        -1.43536255e+14, -1.43536255e+14, -1.43536255e+14, -1.43536255e+14,\n",
       "        -1.42561133e+14, -1.42561133e+14, -1.42561133e+14, -1.42561133e+14,\n",
       "        -1.41557119e+14, -1.41557119e+14, -1.41557119e+14, -1.41557119e+14,\n",
       "        -1.40510730e+14, -1.40510730e+14, -1.40510730e+14, -1.40510730e+14,\n",
       "        -1.39400525e+14, -1.39400525e+14, -1.39400525e+14, -1.39400525e+14,\n",
       "        -1.38190531e+14, -1.38190532e+14, -1.38190532e+14, -1.38190532e+14,\n",
       "        -1.36816033e+14, -1.36816035e+14, -1.36816035e+14, -1.36816035e+14,\n",
       "        -1.35148975e+14, -1.35148978e+14, -1.35148978e+14, -1.35148978e+14,\n",
       "        -1.32899807e+14, -1.32899810e+14, -1.32899811e+14, -1.32899811e+14,\n",
       "        -1.29278822e+14, -1.29278822e+14, -1.29278822e+14, -1.29278822e+14,\n",
       "        -2.22946698e+14, -2.22946698e+14, -2.22946698e+14, -2.22946698e+14,\n",
       "        -2.14821180e+14, -2.14821180e+14, -2.14821180e+14, -2.14821180e+14,\n",
       "        -2.06459159e+14, -2.06459159e+14, -2.06459159e+14, -2.06459159e+14,\n",
       "        -1.97872336e+14, -1.97872336e+14, -1.97872336e+14, -1.97872336e+14,\n",
       "        -1.89081154e+14, -1.89081153e+14, -1.89081153e+14, -1.89081153e+14,\n",
       "        -1.80118251e+14, -1.80118250e+14, -1.80118250e+14, -1.80118250e+14,\n",
       "        -1.71032717e+14, -1.71032715e+14, -1.71032715e+14, -1.71032715e+14,\n",
       "        -1.61892809e+14, -1.61892805e+14, -1.61892805e+14, -1.61892805e+14,\n",
       "        -1.52770066e+14, -1.52770061e+14, -1.52770061e+14, -1.52770061e+14,\n",
       "        -1.43536272e+14, -1.43536272e+14, -1.43536271e+14, -1.43536271e+14,\n",
       "        -4.85919755e+14, -4.85919755e+14, -4.85919755e+14, -4.85919755e+14,\n",
       "        -4.75100431e+14, -4.75100436e+14, -4.75100435e+14, -4.75100435e+14,\n",
       "        -4.62398622e+14, -4.62398633e+14, -4.62398632e+14, -4.62398632e+14,\n",
       "        -4.47280318e+14, -4.47280343e+14, -4.47280342e+14, -4.47280342e+14,\n",
       "        -4.28991378e+14, -4.28991442e+14, -4.28991442e+14, -4.28991442e+14,\n",
       "        -4.06434404e+14, -4.06434406e+14, -4.06434406e+14, -4.06434405e+14,\n",
       "        -3.77956792e+14, -3.77956817e+14, -3.77956815e+14, -3.77956815e+14,\n",
       "        -3.40980783e+14, -3.40980785e+14, -3.40980785e+14, -3.40980782e+14,\n",
       "        -2.91382109e+14, -2.91382116e+14, -2.91382112e+14, -2.91382112e+14,\n",
       "        -2.22946937e+14, -2.22946986e+14, -2.22946981e+14, -2.22946981e+14,\n",
       "        -6.03066124e+14, -6.03066124e+14, -6.03066124e+14, -6.03066124e+14,\n",
       "        -6.01197541e+14, -6.01197541e+14, -6.01197541e+14, -6.01197541e+14,\n",
       "        -5.98880774e+14, -5.98880774e+14, -5.98880774e+14, -5.98880775e+14,\n",
       "        -5.95932611e+14, -5.95932611e+14, -5.95932611e+14, -5.95932613e+14,\n",
       "        -5.92054241e+14, -5.92054241e+14, -5.92054241e+14, -5.92054245e+14,\n",
       "        -5.86723019e+14, -5.86723019e+14, -5.86723019e+14, -5.86723026e+14,\n",
       "        -5.78934626e+14, -5.78934626e+14, -5.78934626e+14, -5.78934639e+14,\n",
       "        -5.66482329e+14, -5.66482329e+14, -5.66482353e+14, -5.66482353e+14,\n",
       "        -5.43390968e+14, -5.43390958e+14, -5.43390958e+14, -5.43390958e+14,\n",
       "        -4.85921153e+14, -4.85921153e+14, -4.85921274e+14, -4.85921274e+14]),\n",
       " 'mean_test_MAE': array([-2.04708850e+14, -2.04708850e+14, -2.04708850e+14, -2.04708850e+14,\n",
       "        -2.04709418e+14, -2.04709418e+14, -2.04709418e+14, -2.04709418e+14,\n",
       "        -2.04710015e+14, -2.04710015e+14, -2.04710015e+14, -2.04710015e+14,\n",
       "        -2.04710642e+14, -2.04710642e+14, -2.04710642e+14, -2.04710642e+14,\n",
       "        -2.04711300e+14, -2.04711300e+14, -2.04711300e+14, -2.04711300e+14,\n",
       "        -2.04711988e+14, -2.04711988e+14, -2.04711988e+14, -2.04711988e+14,\n",
       "        -2.04712707e+14, -2.04712707e+14, -2.04712707e+14, -2.04712707e+14,\n",
       "        -2.04713457e+14, -2.04713457e+14, -2.04713457e+14, -2.04713457e+14,\n",
       "        -2.04714239e+14, -2.04714239e+14, -2.04714239e+14, -2.04714239e+14,\n",
       "        -2.04715052e+14, -2.04715052e+14, -2.04715052e+14, -2.04715052e+14,\n",
       "        -2.04753953e+14, -2.04753953e+14, -2.04753953e+14, -2.04753953e+14,\n",
       "        -2.04741416e+14, -2.04741416e+14, -2.04741416e+14, -2.04741416e+14,\n",
       "        -2.04730416e+14, -2.04730416e+14, -2.04730416e+14, -2.04730416e+14,\n",
       "        -2.04721081e+14, -2.04721081e+14, -2.04721081e+14, -2.04721081e+14,\n",
       "        -2.04713553e+14, -2.04713553e+14, -2.04713553e+14, -2.04713553e+14,\n",
       "        -2.04707983e+14, -2.04707983e+14, -2.04707983e+14, -2.04707983e+14,\n",
       "        -2.04704537e+14, -2.04704537e+14, -2.04704537e+14, -2.04704537e+14,\n",
       "        -2.04703398e+14, -2.04703398e+14, -2.04703398e+14, -2.04703398e+14,\n",
       "        -2.04704763e+14, -2.04704763e+14, -2.04704763e+14, -2.04704763e+14,\n",
       "        -2.04708850e+14, -2.04708850e+14, -2.04708850e+14, -2.04708850e+14,\n",
       "        -2.06996843e+14, -2.06996843e+14, -2.06996843e+14, -2.06996843e+14,\n",
       "        -2.06777399e+14, -2.06777399e+14, -2.06777399e+14, -2.06777399e+14,\n",
       "        -2.06542931e+14, -2.06542931e+14, -2.06542931e+14, -2.06542931e+14,\n",
       "        -2.06293408e+14, -2.06293408e+14, -2.06293408e+14, -2.06293408e+14,\n",
       "        -2.06029686e+14, -2.06029686e+14, -2.06029686e+14, -2.06029686e+14,\n",
       "        -2.05754215e+14, -2.05754214e+14, -2.05754214e+14, -2.05754214e+14,\n",
       "        -2.05472321e+14, -2.05472321e+14, -2.05472321e+14, -2.05472321e+14,\n",
       "        -2.05194600e+14, -2.05194600e+14, -2.05194600e+14, -2.05194600e+14,\n",
       "        -2.04941627e+14, -2.04941627e+14, -2.04941627e+14, -2.04941627e+14,\n",
       "        -2.04753953e+14, -2.04753953e+14, -2.04753953e+14, -2.04753953e+14,\n",
       "        -2.10888440e+14, -2.10888440e+14, -2.10888440e+14, -2.10888440e+14,\n",
       "        -2.10777978e+14, -2.10777978e+14, -2.10777978e+14, -2.10777978e+14,\n",
       "        -2.10658623e+14, -2.10658623e+14, -2.10658623e+14, -2.10658623e+14,\n",
       "        -2.10522285e+14, -2.10522285e+14, -2.10522285e+14, -2.10522286e+14,\n",
       "        -2.10355812e+14, -2.10355813e+14, -2.10355813e+14, -2.10355813e+14,\n",
       "        -2.10136922e+14, -2.10136923e+14, -2.10136923e+14, -2.10136923e+14,\n",
       "        -2.09825697e+14, -2.09825698e+14, -2.09825698e+14, -2.09825698e+14,\n",
       "        -2.09345043e+14, -2.09345045e+14, -2.09345046e+14, -2.09345046e+14,\n",
       "        -2.08530608e+14, -2.08530609e+14, -2.08530610e+14, -2.08530610e+14,\n",
       "        -2.06996847e+14, -2.06996844e+14, -2.06996844e+14, -2.06996844e+14,\n",
       "        -2.31330284e+14, -2.31330284e+14, -2.31330284e+14, -2.31330284e+14,\n",
       "        -2.28611919e+14, -2.28611919e+14, -2.28611919e+14, -2.28611919e+14,\n",
       "        -2.25906093e+14, -2.25906092e+14, -2.25906092e+14, -2.25906092e+14,\n",
       "        -2.23235865e+14, -2.23235864e+14, -2.23235864e+14, -2.23235864e+14,\n",
       "        -2.20632657e+14, -2.20632656e+14, -2.20632656e+14, -2.20632656e+14,\n",
       "        -2.18139970e+14, -2.18139969e+14, -2.18139969e+14, -2.18139969e+14,\n",
       "        -2.15819300e+14, -2.15819299e+14, -2.15819299e+14, -2.15819299e+14,\n",
       "        -2.13759399e+14, -2.13759399e+14, -2.13759399e+14, -2.13759399e+14,\n",
       "        -2.12085940e+14, -2.12085943e+14, -2.12085944e+14, -2.12085944e+14,\n",
       "        -2.10888428e+14, -2.10888433e+14, -2.10888436e+14, -2.10888437e+14,\n",
       "        -3.48141216e+14, -3.48141216e+14, -3.48141216e+14, -3.48141216e+14,\n",
       "        -3.42462993e+14, -3.42462997e+14, -3.42462996e+14, -3.42462996e+14,\n",
       "        -3.35883184e+14, -3.35883195e+14, -3.35883195e+14, -3.35883195e+14,\n",
       "        -3.28174029e+14, -3.28174043e+14, -3.28174042e+14, -3.28174042e+14,\n",
       "        -3.19027697e+14, -3.19027709e+14, -3.19027709e+14, -3.19027709e+14,\n",
       "        -3.08021561e+14, -3.08021564e+14, -3.08021563e+14, -3.08021563e+14,\n",
       "        -2.94569694e+14, -2.94569721e+14, -2.94569721e+14, -2.94569721e+14,\n",
       "        -2.77869959e+14, -2.77869965e+14, -2.77869963e+14, -2.77869963e+14,\n",
       "        -2.56932616e+14, -2.56932628e+14, -2.56932626e+14, -2.56932625e+14,\n",
       "        -2.31330355e+14, -2.31330384e+14, -2.31330382e+14, -2.31330382e+14,\n",
       "        -4.13893352e+14, -4.13893352e+14, -4.13893352e+14, -4.13893352e+14,\n",
       "        -4.12783600e+14, -4.12783600e+14, -4.12783600e+14, -4.12783601e+14,\n",
       "        -4.11410408e+14, -4.11410408e+14, -4.11410408e+14, -4.11410410e+14,\n",
       "        -4.09667359e+14, -4.09667359e+14, -4.09667359e+14, -4.09667362e+14,\n",
       "        -4.07381818e+14, -4.07381818e+14, -4.07381818e+14, -4.07381822e+14,\n",
       "        -4.04253966e+14, -4.04253966e+14, -4.04253966e+14, -4.04253973e+14,\n",
       "        -3.99713328e+14, -3.99713328e+14, -3.99713333e+14, -3.99713341e+14,\n",
       "        -3.92524805e+14, -3.92524801e+14, -3.92524827e+14, -3.92524827e+14,\n",
       "        -3.79426503e+14, -3.79426479e+14, -3.79426479e+14, -3.79426479e+14,\n",
       "        -3.48141879e+14, -3.48141879e+14, -3.48141985e+14, -3.48141985e+14]),\n",
       " 'std_test_MAE': array([1.16293535e+14, 1.16293535e+14, 1.16293535e+14, 1.16293535e+14,\n",
       "        1.16288510e+14, 1.16288510e+14, 1.16288510e+14, 1.16288510e+14,\n",
       "        1.16283464e+14, 1.16283464e+14, 1.16283464e+14, 1.16283464e+14,\n",
       "        1.16278397e+14, 1.16278397e+14, 1.16278397e+14, 1.16278397e+14,\n",
       "        1.16273309e+14, 1.16273309e+14, 1.16273309e+14, 1.16273309e+14,\n",
       "        1.16268200e+14, 1.16268200e+14, 1.16268200e+14, 1.16268200e+14,\n",
       "        1.16263069e+14, 1.16263069e+14, 1.16263069e+14, 1.16263069e+14,\n",
       "        1.16257917e+14, 1.16257917e+14, 1.16257917e+14, 1.16257917e+14,\n",
       "        1.16252742e+14, 1.16252742e+14, 1.16252742e+14, 1.16252742e+14,\n",
       "        1.16247546e+14, 1.16247546e+14, 1.16247546e+14, 1.16247546e+14,\n",
       "        1.16675515e+14, 1.16675515e+14, 1.16675515e+14, 1.16675515e+14,\n",
       "        1.16638849e+14, 1.16638849e+14, 1.16638849e+14, 1.16638849e+14,\n",
       "        1.16600940e+14, 1.16600940e+14, 1.16600940e+14, 1.16600940e+14,\n",
       "        1.16561712e+14, 1.16561712e+14, 1.16561712e+14, 1.16561712e+14,\n",
       "        1.16521084e+14, 1.16521084e+14, 1.16521084e+14, 1.16521084e+14,\n",
       "        1.16478966e+14, 1.16478966e+14, 1.16478966e+14, 1.16478966e+14,\n",
       "        1.16435264e+14, 1.16435264e+14, 1.16435264e+14, 1.16435264e+14,\n",
       "        1.16389869e+14, 1.16389869e+14, 1.16389869e+14, 1.16389869e+14,\n",
       "        1.16342669e+14, 1.16342669e+14, 1.16342669e+14, 1.16342669e+14,\n",
       "        1.16293535e+14, 1.16293535e+14, 1.16293535e+14, 1.16293535e+14,\n",
       "        1.18154790e+14, 1.18154790e+14, 1.18154790e+14, 1.18154790e+14,\n",
       "        1.18060276e+14, 1.18060276e+14, 1.18060276e+14, 1.18060276e+14,\n",
       "        1.17958220e+14, 1.17958220e+14, 1.17958220e+14, 1.17958220e+14,\n",
       "        1.17846620e+14, 1.17846620e+14, 1.17846620e+14, 1.17846620e+14,\n",
       "        1.17722694e+14, 1.17722694e+14, 1.17722694e+14, 1.17722694e+14,\n",
       "        1.17582468e+14, 1.17582468e+14, 1.17582468e+14, 1.17582468e+14,\n",
       "        1.17420068e+14, 1.17420068e+14, 1.17420067e+14, 1.17420067e+14,\n",
       "        1.17226438e+14, 1.17226438e+14, 1.17226438e+14, 1.17226438e+14,\n",
       "        1.16986847e+14, 1.16986847e+14, 1.16986847e+14, 1.16986847e+14,\n",
       "        1.16675516e+14, 1.16675516e+14, 1.16675516e+14, 1.16675516e+14,\n",
       "        1.22864735e+14, 1.22864735e+14, 1.22864735e+14, 1.22864735e+14,\n",
       "        1.22407266e+14, 1.22407266e+14, 1.22407266e+14, 1.22407266e+14,\n",
       "        1.21944399e+14, 1.21944399e+14, 1.21944399e+14, 1.21944399e+14,\n",
       "        1.21474984e+14, 1.21474984e+14, 1.21474984e+14, 1.21474984e+14,\n",
       "        1.20997299e+14, 1.20997299e+14, 1.20997299e+14, 1.20997299e+14,\n",
       "        1.20508568e+14, 1.20508568e+14, 1.20508569e+14, 1.20508569e+14,\n",
       "        1.20003833e+14, 1.20003833e+14, 1.20003834e+14, 1.20003834e+14,\n",
       "        1.19472865e+14, 1.19472866e+14, 1.19472866e+14, 1.19472867e+14,\n",
       "        1.18889432e+14, 1.18889433e+14, 1.18889433e+14, 1.18889433e+14,\n",
       "        1.18154794e+14, 1.18154792e+14, 1.18154792e+14, 1.18154792e+14,\n",
       "        1.56346448e+14, 1.56346448e+14, 1.56346448e+14, 1.56346448e+14,\n",
       "        1.53218053e+14, 1.53218053e+14, 1.53218053e+14, 1.53218053e+14,\n",
       "        1.49953421e+14, 1.49953421e+14, 1.49953421e+14, 1.49953421e+14,\n",
       "        1.46547255e+14, 1.46547255e+14, 1.46547255e+14, 1.46547255e+14,\n",
       "        1.42994911e+14, 1.42994911e+14, 1.42994911e+14, 1.42994911e+14,\n",
       "        1.39292690e+14, 1.39292690e+14, 1.39292690e+14, 1.39292690e+14,\n",
       "        1.35437918e+14, 1.35437916e+14, 1.35437916e+14, 1.35437916e+14,\n",
       "        1.31427853e+14, 1.31427853e+14, 1.31427853e+14, 1.31427853e+14,\n",
       "        1.27253352e+14, 1.27253357e+14, 1.27253358e+14, 1.27253358e+14,\n",
       "        1.22864733e+14, 1.22864740e+14, 1.22864744e+14, 1.22864745e+14,\n",
       "        2.43752143e+14, 2.43752143e+14, 2.43752143e+14, 2.43752143e+14,\n",
       "        2.40581484e+14, 2.40581487e+14, 2.40581487e+14, 2.40581487e+14,\n",
       "        2.36815694e+14, 2.36815697e+14, 2.36815697e+14, 2.36815697e+14,\n",
       "        2.32272154e+14, 2.32272152e+14, 2.32272152e+14, 2.32272152e+14,\n",
       "        2.26686305e+14, 2.26686312e+14, 2.26686312e+14, 2.26686312e+14,\n",
       "        2.19661116e+14, 2.19661117e+14, 2.19661117e+14, 2.19661117e+14,\n",
       "        2.10575129e+14, 2.10575138e+14, 2.10575138e+14, 2.10575138e+14,\n",
       "        1.98407206e+14, 1.98407208e+14, 1.98407208e+14, 1.98407207e+14,\n",
       "        1.81388349e+14, 1.81388352e+14, 1.81388351e+14, 1.81388350e+14,\n",
       "        1.56346572e+14, 1.56346576e+14, 1.56346576e+14, 1.56346575e+14,\n",
       "        2.75903855e+14, 2.75903855e+14, 2.75903855e+14, 2.75903855e+14,\n",
       "        2.75422418e+14, 2.75422418e+14, 2.75422418e+14, 2.75422418e+14,\n",
       "        2.74824086e+14, 2.74824086e+14, 2.74824086e+14, 2.74824085e+14,\n",
       "        2.74060413e+14, 2.74060413e+14, 2.74060413e+14, 2.74060412e+14,\n",
       "        2.73051908e+14, 2.73051908e+14, 2.73051908e+14, 2.73051907e+14,\n",
       "        2.71658427e+14, 2.71658427e+14, 2.71658428e+14, 2.71658426e+14,\n",
       "        2.69607750e+14, 2.69607750e+14, 2.69607745e+14, 2.69607747e+14,\n",
       "        2.66292278e+14, 2.66292273e+14, 2.66292267e+14, 2.66292267e+14,\n",
       "        2.60024549e+14, 2.60024494e+14, 2.60024494e+14, 2.60024494e+14,\n",
       "        2.43752636e+14, 2.43752636e+14, 2.43752645e+14, 2.43752645e+14]),\n",
       " 'rank_test_MAE': array([ 21,  21,  21,  21,  25,  25,  25,  25,  29,  29,  29,  29,  33,\n",
       "         33,  33,  33,  37,  37,  37,  37,  41,  41,  41,  41,  45,  45,\n",
       "         45,  45,  49,  49,  49,  49,  57,  57,  57,  57,  61,  61,  61,\n",
       "         61,  81,  81,  81,  81,  76,  73,  73,  73,  72,  69,  69,  69,\n",
       "         68,  65,  65,  65,  56,  53,  53,  53,  16,  13,  13,  13,   8,\n",
       "          5,   5,   5,   4,   1,   1,   1,  12,   9,   9,   9,  20,  17,\n",
       "         17,  17, 117, 117, 117, 117, 116, 115, 114, 113, 112, 111, 110,\n",
       "        109, 108, 107, 106, 105, 104, 103, 102, 101, 100,  99,  98,  97,\n",
       "         96,  95,  94,  93,  92,  91,  90,  89,  88,  87,  86,  85,  80,\n",
       "         79,  78,  77, 161, 161, 161, 161, 153, 154, 155, 156, 149, 150,\n",
       "        151, 152, 145, 146, 147, 148, 141, 142, 143, 144, 137, 138, 139,\n",
       "        140, 133, 134, 135, 136, 129, 130, 131, 132, 125, 126, 127, 128,\n",
       "        124, 123, 122, 121, 197, 197, 197, 197, 196, 195, 193, 194, 192,\n",
       "        191, 190, 189, 188, 187, 186, 185, 184, 183, 182, 181, 180, 179,\n",
       "        178, 177, 176, 175, 174, 173, 169, 170, 171, 172, 165, 166, 167,\n",
       "        168, 157, 158, 159, 160, 237, 237, 237, 237, 233, 236, 234, 234,\n",
       "        229, 232, 230, 230, 225, 228, 226, 226, 221, 223, 223, 222, 217,\n",
       "        220, 219, 218, 213, 216, 215, 214, 209, 212, 211, 210, 205, 208,\n",
       "        207, 206, 201, 204, 203, 202, 277, 277, 277, 277, 273, 273, 273,\n",
       "        276, 269, 269, 269, 272, 265, 265, 265, 268, 261, 261, 261, 264,\n",
       "        257, 257, 259, 260, 253, 253, 255, 256, 250, 249, 251, 251, 248,\n",
       "        245, 245, 245, 241, 241, 243, 243]),\n",
       " 'split0_test_RMSE': array([-5779316.73982873, -5779316.73982873, -5779316.73982873,\n",
       "        -5779316.73982873, -5779532.07099663, -5779532.07099663,\n",
       "        -5779532.07099663, -5779532.07099663, -5779747.77730402,\n",
       "        -5779747.77730402, -5779747.77730402, -5779747.77730402,\n",
       "        -5779963.85987771, -5779963.85987771, -5779963.85987771,\n",
       "        -5779963.85987771, -5780180.31984911, -5780180.31984911,\n",
       "        -5780180.31984911, -5780180.31984911, -5780397.15835416,\n",
       "        -5780397.15835416, -5780397.15835416, -5780397.15835416,\n",
       "        -5780614.37653335, -5780614.37653335, -5780614.37653335,\n",
       "        -5780614.37653335, -5780831.97553179, -5780831.97553179,\n",
       "        -5780831.97553179, -5780831.97553179, -5781049.95649923,\n",
       "        -5781049.95649923, -5781049.95649923, -5781049.95649923,\n",
       "        -5781268.32059003, -5781268.32059003, -5781268.32059003,\n",
       "        -5781268.32059003, -5762132.12052274, -5762132.12052274,\n",
       "        -5762132.12052274, -5762132.12052274, -5763772.99012403,\n",
       "        -5763772.99014961, -5763772.99014961, -5763772.99014961,\n",
       "        -5765549.12081528, -5765549.12098236, -5765549.12098236,\n",
       "        -5765549.12098236, -5767393.92135237, -5767393.92166784,\n",
       "        -5767393.92166784, -5767393.92166784, -5769276.89493524,\n",
       "        -5769276.89538485, -5769276.89538485, -5769276.89538485,\n",
       "        -5771190.59745877, -5771190.59803744, -5771190.59803744,\n",
       "        -5771190.59803744, -5773135.92007783, -5773135.92077733,\n",
       "        -5773135.92077733, -5773135.92077733, -5775113.78900716,\n",
       "        -5775113.78980192, -5775113.78980192, -5775113.78980192,\n",
       "        -5777183.81352226, -5777183.81444127, -5777183.81444127,\n",
       "        -5777183.81444127, -5779316.73721696, -5779316.73815713,\n",
       "        -5779316.73815713, -5779316.73815713, -5679462.49102441,\n",
       "        -5679462.49102441, -5679462.49102441, -5679462.49102441,\n",
       "        -5685053.7877248 , -5685053.78830118, -5685053.78834286,\n",
       "        -5685053.78835327, -5690942.3458672 , -5690942.34712625,\n",
       "        -5690942.34721965, -5690942.34724193, -5697244.96067934,\n",
       "        -5697244.96293995, -5697244.96310114, -5697244.96314006,\n",
       "        -5704298.00963399, -5704298.01329146, -5704298.01354783,\n",
       "        -5704298.01361185, -5713179.24634224, -5713179.25245297,\n",
       "        -5713179.25289373, -5713179.25300037, -5723118.49472133,\n",
       "        -5723118.50254624, -5723118.50308137, -5723118.50321315,\n",
       "        -5734279.96503379, -5734279.97510836, -5734279.97579298,\n",
       "        -5734279.97595726, -5747238.87402714, -5747238.88597517,\n",
       "        -5747238.88678396, -5747238.88697852, -5762132.08986073,\n",
       "        -5762132.1038336 , -5762132.1047498 , -5762132.10495084,\n",
       "        -5453503.33991265, -5453503.33991265, -5453503.33991265,\n",
       "        -5453503.33991265, -5470227.93811624, -5470227.93776787,\n",
       "        -5470227.9375582 , -5470227.93748525, -5488548.69687739,\n",
       "        -5488548.69639757, -5488548.69603031, -5488548.69594248,\n",
       "        -5511416.68017024, -5511416.67479394, -5511416.67150765,\n",
       "        -5511416.67054815, -5535341.18902483, -5535341.1813411 ,\n",
       "        -5535341.17676578, -5535341.17563583, -5560134.46236221,\n",
       "        -5560134.45270377, -5560134.44711894, -5560134.44555058,\n",
       "        -5585321.31737831, -5585321.30571578, -5585321.29967702,\n",
       "        -5585321.29794967, -5611991.43839835, -5611991.41626828,\n",
       "        -5611991.41186342, -5611991.40320654, -5641982.42617969,\n",
       "        -5641982.39066788, -5641982.37708797, -5641982.36925385,\n",
       "        -5679462.33708361, -5679462.37231802, -5679462.37516321,\n",
       "        -5679462.37586552, -4997025.09094997, -4997025.09094997,\n",
       "        -4997025.09094997, -4997025.09094997, -4993431.86971145,\n",
       "        -4993431.86604465, -4993431.86604465, -4993431.86504587,\n",
       "        -4999067.22579141, -4999067.22017464, -4999067.21765325,\n",
       "        -4999067.21679184, -5012986.67807679, -5012986.66489081,\n",
       "        -5012986.66489081, -5012986.66308694, -5035535.62170814,\n",
       "        -5035535.6165254 , -5035535.61496646, -5035535.61419359,\n",
       "        -5074590.71932821, -5074590.73114743, -5074590.73212573,\n",
       "        -5074590.73201465, -5126319.00074472, -5126319.05048045,\n",
       "        -5126319.05594755, -5126319.05664115, -5199922.44598642,\n",
       "        -5199922.57483693, -5199922.5847632 , -5199922.58568713,\n",
       "        -5309150.31741181, -5309150.36408601, -5309150.38782245,\n",
       "        -5309150.39069243, -5453502.76040844, -5453502.73548363,\n",
       "        -5453502.72244779, -5453502.71910859, -6783153.80958923,\n",
       "        -6783153.80958923, -6783153.80958923, -6783153.80958923,\n",
       "        -6668388.14036943, -6668388.22650637, -6668388.22650637,\n",
       "        -6668388.22650637, -6537008.83423722, -6537009.08755545,\n",
       "        -6537009.08755545, -6537009.08755545, -6383979.63758872,\n",
       "        -6383980.33601798, -6383980.33601798, -6383980.33601798,\n",
       "        -6197467.72968214, -6197467.68496343, -6197467.68496343,\n",
       "        -6197467.67666028, -5967284.83989038, -5967284.87907303,\n",
       "        -5967284.84914097, -5967284.84914097, -5701685.50057718,\n",
       "        -5701686.21664405, -5701686.21664405, -5701686.20682503,\n",
       "        -5420218.01790387, -5420218.19089847, -5420218.1320449 ,\n",
       "        -5420218.1320449 , -5152850.58774332, -5152850.89227074,\n",
       "        -5152850.89227074, -5152850.87275113, -4997024.90454411,\n",
       "        -4997025.96898982, -4997025.94636391, -4997025.93290703,\n",
       "        -8044298.11779464, -8044298.11779464, -8044298.11779464,\n",
       "        -8044298.11779464, -8022995.29039927, -8022995.29039927,\n",
       "        -8022995.29039927, -8022995.32755129, -7996566.5493683 ,\n",
       "        -7996566.5493683 , -7996566.5493683 , -7996566.60619004,\n",
       "        -7962908.64680928, -7962908.64680928, -7962908.64680928,\n",
       "        -7962908.73803685, -7918585.3718216 , -7918585.3718216 ,\n",
       "        -7918585.3718216 , -7918585.52732572, -7857572.59658765,\n",
       "        -7857572.59658765, -7857572.59658765, -7857572.88208575,\n",
       "        -7768256.61882286, -7768256.61882286, -7768256.61882286,\n",
       "        -7768257.19177203, -7632250.90184688, -7632250.90184688,\n",
       "        -7632252.07046537, -7632252.07046537, -7388086.04854959,\n",
       "        -7388087.76096178, -7388087.76096178, -7388087.76096178,\n",
       "        -6783163.23361609, -6783163.23361609, -6783166.6147105 ,\n",
       "        -6783166.6147105 ]),\n",
       " 'split1_test_RMSE': array([-6265008.60561198, -6265008.60561198, -6265008.60561198,\n",
       "        -6265008.60561198, -6265564.18273409, -6265564.18273409,\n",
       "        -6265564.18273409, -6265564.18273409, -6266121.1086297 ,\n",
       "        -6266121.1086297 , -6266121.1086297 , -6266121.1086297 ,\n",
       "        -6266679.38837225, -6266679.38837225, -6266679.38837225,\n",
       "        -6266679.38837225, -6267239.02706077, -6267239.02706077,\n",
       "        -6267239.02706077, -6267239.02706077, -6267800.02982013,\n",
       "        -6267800.02982013, -6267800.02982013, -6267800.02982013,\n",
       "        -6268362.40180104, -6268362.40180104, -6268362.40180104,\n",
       "        -6268362.40180104, -6268926.14818044, -6268926.14818044,\n",
       "        -6268926.14818044, -6268926.14818044, -6269491.27416146,\n",
       "        -6269491.27416146, -6269491.27416146, -6269491.27416146,\n",
       "        -6270057.78497369, -6270057.78497369, -6270057.78497369,\n",
       "        -6270057.78497369, -6220304.59236006, -6220304.59236006,\n",
       "        -6220304.59236006, -6220304.59236006, -6224801.79644658,\n",
       "        -6224801.79644658, -6224801.79644658, -6224801.79644658,\n",
       "        -6229398.46547123, -6229398.46547123, -6229398.46547123,\n",
       "        -6229398.46547123, -6234098.06389572, -6234098.06389572,\n",
       "        -6234098.06389572, -6234098.06389572, -6238904.21975788,\n",
       "        -6238904.21975788, -6238904.21975788, -6238904.21975788,\n",
       "        -6243836.26128491, -6243836.26128491, -6243836.26128491,\n",
       "        -6243836.26128491, -6248944.30720826, -6248944.30720826,\n",
       "        -6248944.30720826, -6248944.30720826, -6254172.70744707,\n",
       "        -6254172.70744707, -6254172.70744707, -6254172.70744707,\n",
       "        -6259525.91346339, -6259525.91346339, -6259525.91346339,\n",
       "        -6259525.91346339, -6265008.60020037, -6265008.60020037,\n",
       "        -6265008.60020037, -6265008.60020037, -6082960.76242938,\n",
       "        -6082960.76242938, -6082960.76242938, -6082960.76242938,\n",
       "        -6084203.60557159, -6084203.60657057, -6084203.60667177,\n",
       "        -6084203.60669991, -6085999.35417507, -6085999.35628772,\n",
       "        -6085999.35651203, -6085999.35657283, -6088703.58977483,\n",
       "        -6088703.59338397, -6088703.59377855, -6088703.59387981,\n",
       "        -6092029.60775945, -6092029.61305984, -6092029.61362751,\n",
       "        -6092029.6137738 , -6099931.27962954, -6099931.29171665,\n",
       "        -6099931.29296749, -6099931.2933034 , -6119227.54461229,\n",
       "        -6119227.5639128 , -6119227.56587583, -6119227.56637951,\n",
       "        -6147040.54910555, -6147040.57463448, -6147040.57721298,\n",
       "        -6147040.57783141, -6180141.16946001, -6180141.20403726,\n",
       "        -6180141.20718155, -6180141.20725902, -6220304.50519626,\n",
       "        -6220304.54391067, -6220304.54391067, -6220304.54391067,\n",
       "        -5958109.78997006, -5958109.78997006, -5958109.78997006,\n",
       "        -5958109.78997006, -5974651.59367512, -5974651.5942544 ,\n",
       "        -5974651.59470176, -5974651.59481592, -5990976.21608381,\n",
       "        -5990976.21745909, -5990976.21850988, -5990976.21879411,\n",
       "        -6006836.35831485, -6006836.36155933, -6006836.3636234 ,\n",
       "        -6006836.36411526, -6026183.49444178, -6026183.49540512,\n",
       "        -6026183.49584163, -6026183.4959587 , -6047243.12380143,\n",
       "        -6047243.12948952, -6047243.13177628, -6047243.13229471,\n",
       "        -6066300.45197108, -6066300.46800995, -6066300.47273606,\n",
       "        -6066300.47391688, -6081464.31841089, -6081464.35910266,\n",
       "        -6081464.36598362, -6081464.36761411, -6086536.00984533,\n",
       "        -6086536.07344015, -6086536.07946279, -6086536.08085224,\n",
       "        -6082960.61342764, -6082960.66125978, -6082960.66651655,\n",
       "        -6082960.66788829, -5118807.25926001, -5118807.25926001,\n",
       "        -5118807.25926001, -5118807.25926001, -5162975.08562625,\n",
       "        -5162975.08631826, -5162975.08585569, -5162975.08558241,\n",
       "        -5219099.83098849, -5219099.8336575 , -5219099.83389584,\n",
       "        -5219099.83376181, -5282765.89668677, -5282765.90268053,\n",
       "        -5282765.90420665, -5282765.90443335, -5354656.94196033,\n",
       "        -5354656.96179217, -5354656.96410445, -5354656.96487268,\n",
       "        -5441219.81145387, -5441219.83467206, -5441219.83910588,\n",
       "        -5441219.84204534, -5543542.30592021, -5543542.33025218,\n",
       "        -5543542.33917461, -5543542.34108093, -5662857.58058947,\n",
       "        -5662857.50502856, -5662857.50768155, -5662857.50920583,\n",
       "        -5798348.05993109, -5798347.95483186, -5798347.94625657,\n",
       "        -5798347.9462605 , -5958108.3504126 , -5958108.39914842,\n",
       "        -5958108.41746271, -5958108.42060305, -6258616.80823897,\n",
       "        -6258616.80823897, -6258616.80823897, -6258616.80823897,\n",
       "        -6170677.72330062, -6170677.71462856, -6170677.71462856,\n",
       "        -6170677.71462856, -6069269.24620521, -6069269.61360422,\n",
       "        -6069269.61360422, -6069269.61360422, -5948947.18061462,\n",
       "        -5948948.0734224 , -5948948.0734224 , -5948948.0734224 ,\n",
       "        -5806552.01188506, -5806552.00356773, -5806552.00356773,\n",
       "        -5806551.99486715, -5645956.63247804, -5645956.7916164 ,\n",
       "        -5645956.76588857, -5645956.76588857, -5456787.07909328,\n",
       "        -5456788.19895825, -5456788.19895825, -5456788.18667736,\n",
       "        -5268964.89757245, -5268965.30855572, -5268965.25785379,\n",
       "        -5268965.25785379, -5100048.12042117, -5100048.9363092 ,\n",
       "        -5100048.9363092 , -5100048.9060642 , -5118801.44234735,\n",
       "        -5118802.07974503, -5118802.15795548, -5118802.17345935,\n",
       "        -7368497.94395704, -7368497.94395704, -7368497.94395704,\n",
       "        -7368497.94395704, -7349016.78708602, -7349016.78708602,\n",
       "        -7349016.78708602, -7349016.81596959, -7324856.36298547,\n",
       "        -7324856.36298547, -7324856.36298547, -7324856.4066307 ,\n",
       "        -7294100.5844083 , -7294100.5844083 , -7294100.5844083 ,\n",
       "        -7294100.65331273, -7253621.87498458, -7253621.87498458,\n",
       "        -7253621.87498458, -7253621.98953541, -7198322.47348377,\n",
       "        -7198322.47348377, -7198322.47348377, -7198322.67526577,\n",
       "        -7117658.09778617, -7117658.09778617, -7117658.47059335,\n",
       "        -7117658.47059335, -6989508.86959711, -6989508.86959711,\n",
       "        -6989509.49510349, -6989509.49510349, -6763708.12060851,\n",
       "        -6763707.12566904, -6763707.12566904, -6763707.12566904,\n",
       "        -6258621.70602579, -6258621.70602579, -6258624.7101587 ,\n",
       "        -6258624.7101587 ]),\n",
       " 'split2_test_RMSE': array([-6300497.37882849, -6300497.37882849, -6300497.37882849,\n",
       "        -6300497.37882849, -6301043.37701257, -6301043.37701257,\n",
       "        -6301043.37701257, -6301043.37701257, -6301590.5464473 ,\n",
       "        -6301590.5464473 , -6301590.5464473 , -6301590.5464473 ,\n",
       "        -6302138.8910047 , -6302138.8910047 , -6302138.8910047 ,\n",
       "        -6302138.8910047 , -6302688.41457411, -6302688.41457411,\n",
       "        -6302688.41457411, -6302688.41457411, -6303239.12106224,\n",
       "        -6303239.12106224, -6303239.12106224, -6303239.12106224,\n",
       "        -6303791.01439325, -6303791.01439325, -6303791.01439325,\n",
       "        -6303791.01439325, -6304344.0985089 , -6304344.0985089 ,\n",
       "        -6304344.0985089 , -6304344.0985089 , -6304898.37736859,\n",
       "        -6304898.37736859, -6304898.37736859, -6304898.37736859,\n",
       "        -6305453.85494952, -6305453.85494952, -6305453.85494952,\n",
       "        -6305453.85494952, -6257926.54103094, -6257926.54103094,\n",
       "        -6257926.54103094, -6257926.54103094, -6262076.83958657,\n",
       "        -6262076.83958657, -6262076.83958657, -6262076.83958657,\n",
       "        -6266309.1212862 , -6266309.1212862 , -6266309.1212862 ,\n",
       "        -6266309.1212862 , -6270687.69584235, -6270687.69584235,\n",
       "        -6270687.69584235, -6270687.69584235, -6275353.48896784,\n",
       "        -6275353.48896784, -6275353.48896784, -6275353.48896784,\n",
       "        -6280129.0949154 , -6280129.0949154 , -6280129.0949154 ,\n",
       "        -6280129.0949154 , -6285003.51299006, -6285003.51299006,\n",
       "        -6285003.51299006, -6285003.51299006, -6289979.93122637,\n",
       "        -6289979.93122637, -6289979.93122637, -6289979.93122637,\n",
       "        -6295100.97133502, -6295100.97133502, -6295100.97133502,\n",
       "        -6295100.97133502, -6300497.37403201, -6300497.37403201,\n",
       "        -6300497.37403201, -6300497.37403201, -6110788.23047624,\n",
       "        -6110788.23047624, -6110788.23047624, -6110788.23047624,\n",
       "        -6116668.74244177, -6116668.74318737, -6116668.74327126,\n",
       "        -6116668.74329338, -6123968.71093664, -6123968.7126982 ,\n",
       "        -6123968.71289355, -6123968.7129432 , -6132965.34648671,\n",
       "        -6132965.34989537, -6132965.35026338, -6132965.35035524,\n",
       "        -6143433.28253329, -6143433.28732228, -6143433.28783436,\n",
       "        -6143433.28796297, -6157202.96794426, -6157202.97519426,\n",
       "        -6157202.9759841 , -6157202.97617873, -6173918.56812937,\n",
       "        -6173918.57780042, -6173918.57883292, -6173918.57908963,\n",
       "        -6194482.6276763 , -6194482.63943307, -6194482.64066844,\n",
       "        -6194482.64098682, -6221684.3916955 , -6221684.40852904,\n",
       "        -6221684.4103213 , -6221684.41076715, -6257926.47612199,\n",
       "        -6257926.49785495, -6257926.49964708, -6257926.49964708,\n",
       "        -5995496.09959051, -5995496.09959051, -5995496.09959051,\n",
       "        -5995496.09959051, -6003850.14527347, -6003850.1459084 ,\n",
       "        -6003850.14673207, -6003850.14707101, -6013596.48440908,\n",
       "        -6013596.48552789, -6013596.4863397 , -6013596.48690011,\n",
       "        -6023446.33878727, -6023446.34014749, -6023446.34119836,\n",
       "        -6023446.34205349, -6033313.88604644, -6033313.88810266,\n",
       "        -6033313.88928079, -6033313.89041032, -6043621.55509655,\n",
       "        -6043621.5566636 , -6043621.55774842, -6043621.55832611,\n",
       "        -6054652.6527195 , -6054652.65476744, -6054652.65597687,\n",
       "        -6054652.65629204, -6065719.16242922, -6065719.16309701,\n",
       "        -6065719.16316735, -6065719.16318558, -6080386.03680811,\n",
       "        -6080386.06402139, -6080386.06723611, -6080386.06802091,\n",
       "        -6110788.05395193, -6110788.11116184, -6110788.11771306,\n",
       "        -6110788.11949143, -5957549.77343092, -5957549.77343092,\n",
       "        -5957549.77343092, -5957549.77343092, -5917499.17545996,\n",
       "        -5917499.17478536, -5917499.17434865, -5917499.1742076 ,\n",
       "        -5879685.51050375, -5879685.51230414, -5879685.51230414,\n",
       "        -5879685.5117368 , -5844901.49524832, -5844901.50114821,\n",
       "        -5844901.50086054, -5844901.50061215, -5823783.38912818,\n",
       "        -5823783.41850431, -5823783.42129347, -5823783.4220264 ,\n",
       "        -5820469.02143028, -5820469.05610425, -5820469.06382142,\n",
       "        -5820469.06463319, -5829055.98233363, -5829056.08162465,\n",
       "        -5829056.09232955, -5829056.09491634, -5860883.45974867,\n",
       "        -5860883.55018725, -5860883.56503872, -5860883.56772589,\n",
       "        -5917936.26516129, -5917936.38831513, -5917936.42084945,\n",
       "        -5917936.42896915, -5995494.63941196, -5995494.72567378,\n",
       "        -5995494.78809503, -5995494.80942894, -7998962.46552207,\n",
       "        -7998962.46552207, -7998962.46552207, -7998962.46552207,\n",
       "        -7887510.95993771, -7887511.12407082, -7887511.11745473,\n",
       "        -7887511.11745473, -7756105.48540018, -7756105.84642685,\n",
       "        -7756105.83559834, -7756105.83559834, -7606328.03412681,\n",
       "        -7606328.02013758, -7606328.02013758, -7606328.02013758,\n",
       "        -7430961.83219766, -7430961.835465  , -7430961.835465  ,\n",
       "        -7430961.82940776, -7243739.76677048, -7243739.88792611,\n",
       "        -7243739.86994141, -7243739.86994141, -7005866.90542179,\n",
       "        -7005867.71172629, -7005867.71172629, -7005867.71172629,\n",
       "        -6722372.95610875, -6722373.18928915, -6722373.15139367,\n",
       "        -6722373.15139367, -6373914.97381123, -6373915.42435005,\n",
       "        -6373915.41659065, -6373915.40185105, -5957547.77242637,\n",
       "        -5957548.16067639, -5957548.17585747, -5957548.17430306,\n",
       "        -9213108.94060145, -9213108.94060145, -9213108.94060145,\n",
       "        -9213108.94060145, -9193801.57590999, -9193801.57590999,\n",
       "        -9193801.57590999, -9193801.58632973, -9169843.57043714,\n",
       "        -9169843.57043714, -9169843.57043714, -9169843.58551026,\n",
       "        -9139324.49183968, -9139324.49183968, -9139324.49183968,\n",
       "        -9139324.51413723, -9099121.27874011, -9099121.27874011,\n",
       "        -9099121.27874011, -9099121.31201976, -9043754.79329128,\n",
       "        -9043754.79329128, -9043754.84054347, -9043754.84054347,\n",
       "        -8962651.04844273, -8962651.04844273, -8962651.09185322,\n",
       "        -8962651.09185322, -8832919.89796497, -8832919.70739326,\n",
       "        -8832919.70739326, -8832919.70739326, -8592827.03757902,\n",
       "        -8592823.76775398, -8592823.76775398, -8592823.76775398,\n",
       "        -7998972.47397947, -7998972.47397947, -7998974.62188775,\n",
       "        -7998974.62188775]),\n",
       " 'split3_test_RMSE': array([-5365621.69423786, -5365621.69423786, -5365621.69423786,\n",
       "        -5365621.69423786, -5365976.87687178, -5365976.87687178,\n",
       "        -5365976.87687178, -5365976.87687178, -5366332.69984714,\n",
       "        -5366332.69984714, -5366332.69984714, -5366332.69984714,\n",
       "        -5366689.16503215, -5366689.16503215, -5366689.16503215,\n",
       "        -5366689.16503215, -5367046.27430226, -5367046.27430226,\n",
       "        -5367046.27430226, -5367046.27430226, -5367404.02954021,\n",
       "        -5367404.02954021, -5367404.02954021, -5367404.02954021,\n",
       "        -5367762.43263601, -5367762.43263601, -5367762.43263601,\n",
       "        -5367762.43263601, -5368121.48548707, -5368121.48548707,\n",
       "        -5368121.48548707, -5368121.48548707, -5368481.18999813,\n",
       "        -5368481.18999813, -5368481.18999813, -5368481.18999813,\n",
       "        -5368841.54808137, -5368841.54808137, -5368841.54808137,\n",
       "        -5368841.54808137, -5337264.82426942, -5337264.82426942,\n",
       "        -5337264.82426942, -5337264.82426942, -5340202.03257666,\n",
       "        -5340202.03257666, -5340202.03257666, -5340202.03257666,\n",
       "        -5343187.80762621, -5343187.80762621, -5343187.80762621,\n",
       "        -5343187.80762621, -5346223.48280169, -5346223.48280169,\n",
       "        -5346223.48280169, -5346223.48280169, -5349310.4405515 ,\n",
       "        -5349310.4405515 , -5349310.4405515 , -5349310.4405515 ,\n",
       "        -5352450.11464508, -5352450.11464508, -5352450.11464508,\n",
       "        -5352450.11464508, -5355643.99255301, -5355643.99255301,\n",
       "        -5355643.99255301, -5355643.99255301, -5358893.61795843,\n",
       "        -5358893.61795843, -5358893.61795843, -5358893.61795843,\n",
       "        -5362200.59340826, -5362200.59340826, -5362200.59340826,\n",
       "        -5362200.59340826, -5365621.69094175, -5365621.69094175,\n",
       "        -5365621.69094175, -5365621.69094175, -5248829.08937938,\n",
       "        -5248829.08937938, -5248829.08937938, -5248829.08937938,\n",
       "        -5250780.21276794, -5250780.2127292 , -5250780.21272528,\n",
       "        -5250780.21272427, -5252654.29656405, -5252654.29646714,\n",
       "        -5252654.29645681, -5252654.29645418, -5254419.2941151 ,\n",
       "        -5254419.29392448, -5254419.29390458, -5254419.29389901,\n",
       "        -5256854.82888665, -5256854.83113185, -5256854.83134757,\n",
       "        -5256854.83140008, -5266268.7032428 , -5266268.70614304,\n",
       "        -5266268.70641935, -5266268.70649152, -5276612.03905486,\n",
       "        -5276612.04270405, -5276612.04300732, -5276612.04306034,\n",
       "        -5289726.10037262, -5289726.10639487, -5289726.10670631,\n",
       "        -5289726.10675849, -5310301.63534464, -5310301.63962408,\n",
       "        -5310301.6397894 , -5310301.6397894 , -5337264.79127697,\n",
       "        -5337264.79267132, -5337264.79267132, -5337264.79267132,\n",
       "        -5083926.95806515, -5083926.95806515, -5083926.95806515,\n",
       "        -5083926.95806515, -5103911.75633079, -5103911.75740388,\n",
       "        -5103911.7581312 , -5103911.75833616, -5123835.27556945,\n",
       "        -5123835.27777552, -5123835.27953554, -5123835.28001633,\n",
       "        -5143544.63758976, -5143544.64162634, -5143544.64441528,\n",
       "        -5143544.64513468, -5162986.10377791, -5162986.10996046,\n",
       "        -5162986.11389373, -5162986.11501216, -5181878.77764785,\n",
       "        -5181878.78473418, -5181878.7903972 , -5181878.79195148,\n",
       "        -5200027.11481774, -5200027.12225941, -5200027.12733373,\n",
       "        -5200027.12877809, -5217211.62435006, -5217211.63382732,\n",
       "        -5217211.63585128, -5217211.64179138, -5233886.80072312,\n",
       "        -5233886.79068041, -5233886.78965156, -5233886.78940146,\n",
       "        -5248828.9071185 , -5248828.90195386, -5248828.90147957,\n",
       "        -5248828.90136531, -4258649.77190193, -4258649.77190193,\n",
       "        -4258649.77190193, -4258649.77190193, -4284535.84270482,\n",
       "        -4284535.83997568, -4284535.83870754, -4284535.83830572,\n",
       "        -4320936.32193407, -4320936.32677506, -4320936.32677506,\n",
       "        -4320936.32550705, -4369432.13130931, -4369432.14766662,\n",
       "        -4369432.14780239, -4369432.14747625, -4438973.93674602,\n",
       "        -4438973.97615912, -4438973.97700419, -4438973.97700419,\n",
       "        -4525741.26946415, -4525741.32486497, -4525741.32767258,\n",
       "        -4525741.32865073, -4628035.84952611, -4628035.99316694,\n",
       "        -4628036.00237261, -4628036.00373431, -4755270.34868108,\n",
       "        -4755270.59097162, -4755270.60827352, -4755270.61443214,\n",
       "        -4902506.32016176, -4902506.43820899, -4902506.4814352 ,\n",
       "        -4902506.49881858, -5083925.50896763, -5083925.57409405,\n",
       "        -5083925.63175468, -5083925.64994292, -5604014.60128218,\n",
       "        -5604014.60128218, -5604014.60128218, -5604014.60128218,\n",
       "        -5499569.81025223, -5499569.94822107, -5499569.94822107,\n",
       "        -5499569.94822107, -5377961.73665229, -5377962.0540834 ,\n",
       "        -5377962.0540834 , -5377962.0540834 , -5239412.26124766,\n",
       "        -5239412.22922742, -5239412.22922742, -5239412.22922742,\n",
       "        -5075197.31249883, -5075197.27716613, -5075197.27716613,\n",
       "        -5075197.26778104, -4894484.50624099, -4894484.58070182,\n",
       "        -4894484.54947661, -4894484.54947661, -4676314.44006653,\n",
       "        -4676315.17342313, -4676315.17342313, -4676315.16296113,\n",
       "        -4485996.66819208, -4485996.83722026, -4485996.77607019,\n",
       "        -4485996.76817408, -4307717.99910782, -4307718.39534545,\n",
       "        -4307718.39534545, -4307718.37152452, -4258646.66669095,\n",
       "        -4258647.22347293, -4258647.24308962, -4258647.23853869,\n",
       "        -6896722.47904976, -6896722.47904976, -6896722.47904976,\n",
       "        -6896722.47904976, -6874860.68941872, -6874860.68941872,\n",
       "        -6874860.68941872, -6874860.72107514, -6847743.51325213,\n",
       "        -6847743.51325213, -6847743.51325213, -6847743.561143  ,\n",
       "        -6813209.72421369, -6813209.72421369, -6813209.72421369,\n",
       "        -6813209.79994509, -6767734.39655706, -6767734.39655706,\n",
       "        -6767734.39655706, -6767734.52277142, -6706028.44702611,\n",
       "        -6706028.44702611, -6706028.44702611, -6706028.66984771,\n",
       "        -6617580.92423494, -6617580.92423494, -6617581.34169224,\n",
       "        -6617581.34169224, -6475696.9794923 , -6475696.9794923 ,\n",
       "        -6475697.72446229, -6475697.72446229, -6217323.55145831,\n",
       "        -6217322.97697035, -6217322.97697035, -6217322.97697035,\n",
       "        -5604024.65903271, -5604024.65903271, -5604028.06225885,\n",
       "        -5604028.06225885]),\n",
       " 'split4_test_RMSE': array([-5322975.92001694, -5322975.92001694, -5322975.92001694,\n",
       "        -5322975.92001694, -5323513.58433859, -5323513.58433859,\n",
       "        -5323513.58433859, -5323513.58433859, -5324052.81395492,\n",
       "        -5324052.81395492, -5324052.81395492, -5324052.81395492,\n",
       "        -5324593.61686612, -5324593.61686612, -5324593.61686612,\n",
       "        -5324593.61686612, -5325136.00113208, -5325136.00113208,\n",
       "        -5325136.00113208, -5325136.00113208, -5325679.97487296,\n",
       "        -5325679.97487296, -5325679.97487296, -5325679.97487296,\n",
       "        -5326225.54626985, -5326225.54626985, -5326225.54626985,\n",
       "        -5326225.54626985, -5326772.72356529, -5326772.72356529,\n",
       "        -5326772.72356529, -5326772.72356529, -5327321.51506388,\n",
       "        -5327321.51506388, -5327321.51506388, -5327321.51506388,\n",
       "        -5327871.92913295, -5327871.92913295, -5327871.92913295,\n",
       "        -5327871.92913295, -5292881.91727403, -5292881.91727403,\n",
       "        -5292881.91727403, -5292881.91727403, -5294667.08893699,\n",
       "        -5294667.08893699, -5294667.08893699, -5294667.08893699,\n",
       "        -5296500.56241358, -5296500.56241358, -5296500.56241358,\n",
       "        -5296500.56241358, -5298384.95244896, -5298384.95244896,\n",
       "        -5298384.95244896, -5298384.95244896, -5300323.07799382,\n",
       "        -5300323.07799382, -5300323.07799382, -5300323.07799382,\n",
       "        -5302667.82617006, -5302667.82617006, -5302667.82617006,\n",
       "        -5302667.82617006, -5307536.45557989, -5307536.45557989,\n",
       "        -5307536.45557989, -5307536.45557989, -5312539.52281812,\n",
       "        -5312539.52281812, -5312539.52281812, -5312539.52281812,\n",
       "        -5317683.64194639, -5317683.64194639, -5317683.64194639,\n",
       "        -5317683.64194639, -5322975.91231443, -5322975.91231443,\n",
       "        -5322975.91231443, -5322975.91231443, -5249560.19548179,\n",
       "        -5249560.19548179, -5249560.19548179, -5249560.19548179,\n",
       "        -5250002.81759184, -5250002.81891421, -5250002.81907895,\n",
       "        -5250002.81912151, -5250188.57014667, -5250188.57293418,\n",
       "        -5250188.57327269, -5250188.57335995, -5250101.91145183,\n",
       "        -5250101.91579059, -5250101.91632299, -5250101.91646071,\n",
       "        -5249704.12841177, -5249704.13447026, -5249704.13521067,\n",
       "        -5249704.13540116, -5253342.4587739 , -5253342.46706925,\n",
       "        -5253342.46810539, -5253342.46821636, -5259531.15238549,\n",
       "        -5259531.16242772, -5259531.16242772, -5259531.16242772,\n",
       "        -5266668.83701251, -5266668.83701251, -5266668.83701251,\n",
       "        -5266668.83701251, -5277225.85635885, -5277225.85635885,\n",
       "        -5277225.85635885, -5277225.85635885, -5292881.86672447,\n",
       "        -5292881.86672447, -5292881.86672447, -5292881.86672447,\n",
       "        -5121837.30492378, -5121837.30492378, -5121837.30492378,\n",
       "        -5121837.30492378, -5137087.38995897, -5137087.39207768,\n",
       "        -5137087.39276251, -5137087.39291262, -5153036.0193773 ,\n",
       "        -5153036.01348318, -5153036.01416196, -5153036.01468816,\n",
       "        -5169434.19431294, -5169434.15997268, -5169434.15864228,\n",
       "        -5169434.1588218 , -5185906.76280934, -5185906.70928004,\n",
       "        -5185906.70287795, -5185906.70123573, -5202267.5717298 ,\n",
       "        -5202267.47859113, -5202267.4685118 , -5202267.46563772,\n",
       "        -5218449.87840862, -5218449.75375287, -5218449.73385464,\n",
       "        -5218449.72882262, -5233953.35294158, -5233953.27028219,\n",
       "        -5233953.24965925, -5233953.2444404 , -5245825.24318604,\n",
       "        -5245825.33109011, -5245825.34262691, -5245825.34551603,\n",
       "        -5249559.86887341, -5249559.98514867, -5249559.99938329,\n",
       "        -5249560.00308286, -5185740.56764075, -5185740.56764075,\n",
       "        -5185740.56764075, -5185740.56764075, -5107674.40654557,\n",
       "        -5107674.40524638, -5107674.4049575 , -5107674.40491617,\n",
       "        -5037708.99268688, -5037708.99449499, -5037708.99449499,\n",
       "        -5037708.99454979, -4997264.30451367, -4997264.31169323,\n",
       "        -4997264.31219452, -4997264.31219452, -4966390.76558513,\n",
       "        -4966390.78398952, -4966390.78626725, -4966390.78706124,\n",
       "        -4946346.77732611, -4946346.81447624, -4946346.81751562,\n",
       "        -4946346.81884871, -4956940.06624621, -4956940.12451568,\n",
       "        -4956940.13146023, -4956940.13268646, -4983176.20427418,\n",
       "        -4983176.21980971, -4983176.23580357, -4983176.2392881 ,\n",
       "        -5030705.42808251, -5030705.40835992, -5030705.43836354,\n",
       "        -5030705.44460631, -5121837.05007088, -5121836.25420423,\n",
       "        -5121836.20236549, -5121836.2020851 , -8318757.53264856,\n",
       "        -8318757.53264856, -8318757.53264856, -8318757.53264856,\n",
       "        -8190597.99431908, -8190598.06124394, -8190598.0560175 ,\n",
       "        -8190598.0560175 , -8039198.8580166 , -8039199.03510425,\n",
       "        -8039199.02489681, -8039199.02489681, -7857572.29961685,\n",
       "        -7857572.75790301, -7857572.739672  , -7857572.739672  ,\n",
       "        -7637257.32397396, -7637258.53665563, -7637258.53665563,\n",
       "        -7637258.53665563, -7358754.88737964, -7358754.8954541 ,\n",
       "        -7358754.8954541 , -7358754.87915068, -7008203.59381488,\n",
       "        -7008204.01198999, -7008203.95839547, -7008203.95839547,\n",
       "        -6566888.37080231, -6566888.34495468, -6566888.34495468,\n",
       "        -6566888.2967983 , -5972643.908931  , -5972643.96080246,\n",
       "        -5972643.86122149, -5972643.86122149, -5185741.83868318,\n",
       "        -5185743.4008957 , -5185743.36257002, -5185743.35528883,\n",
       "        -9668713.41037426, -9668713.41037426, -9668713.41037426,\n",
       "        -9668713.41037426, -9647813.70120476, -9647813.70120476,\n",
       "        -9647813.70120476, -9647813.70120476, -9621854.27621141,\n",
       "        -9621854.27621141, -9621854.27621141, -9621854.30016441,\n",
       "        -9588744.55668133, -9588744.55668133, -9588744.55668133,\n",
       "        -9588744.59476786, -9545058.31078113, -9545058.31078113,\n",
       "        -9545058.31078113, -9545058.37465302, -9484763.52449111,\n",
       "        -9484763.52449111, -9484763.52449111, -9484763.63878092,\n",
       "        -9396164.2239035 , -9396164.2239035 , -9396164.2239035 ,\n",
       "        -9396164.44164923, -9253983.87163865, -9253983.87163865,\n",
       "        -9253984.26357414, -9253984.26357414, -8987550.59432411,\n",
       "        -8987550.33196083, -8987550.33196083, -8987550.33196083,\n",
       "        -8318777.45218709, -8318777.45218709, -8318779.70064557,\n",
       "        -8318779.70064557]),\n",
       " 'mean_test_RMSE': array([-5806684.0677048 , -5806684.0677048 , -5806684.0677048 ,\n",
       "        -5806684.0677048 , -5807126.01839073, -5807126.01839073,\n",
       "        -5807126.01839073, -5807126.01839073, -5807568.98923661,\n",
       "        -5807568.98923661, -5807568.98923661, -5807568.98923661,\n",
       "        -5808012.98423059, -5808012.98423059, -5808012.98423059,\n",
       "        -5808012.98423059, -5808458.00738367, -5808458.00738367,\n",
       "        -5808458.00738367, -5808458.00738367, -5808904.06272994,\n",
       "        -5808904.06272994, -5808904.06272994, -5808904.06272994,\n",
       "        -5809351.1543267 , -5809351.1543267 , -5809351.1543267 ,\n",
       "        -5809351.1543267 , -5809799.28625469, -5809799.28625469,\n",
       "        -5809799.28625469, -5809799.28625469, -5810248.46261826,\n",
       "        -5810248.46261826, -5810248.46261826, -5810248.46261826,\n",
       "        -5810698.68754551, -5810698.68754551, -5810698.68754551,\n",
       "        -5810698.68754551, -5774101.99909144, -5774101.99909144,\n",
       "        -5774101.99909144, -5774101.99909144, -5777104.14953417,\n",
       "        -5777104.14953928, -5777104.14953928, -5777104.14953928,\n",
       "        -5780189.0155225 , -5780189.01555592, -5780189.01555592,\n",
       "        -5780189.01555592, -5783357.62326822, -5783357.62333131,\n",
       "        -5783357.62333131, -5783357.62333131, -5786633.62444126,\n",
       "        -5786633.62453118, -5786633.62453118, -5786633.62453118,\n",
       "        -5790054.77889485, -5790054.77901058, -5790054.77901058,\n",
       "        -5790054.77901058, -5794052.83768181, -5794052.83782171,\n",
       "        -5794052.83782171, -5794052.83782171, -5798139.91369143,\n",
       "        -5798139.91385038, -5798139.91385038, -5798139.91385038,\n",
       "        -5802338.98673506, -5802338.98691887, -5802338.98691887,\n",
       "        -5802338.98691887, -5806684.0629411 , -5806684.06312914,\n",
       "        -5806684.06312914, -5806684.06312914, -5674320.15375824,\n",
       "        -5674320.15375824, -5674320.15375824, -5674320.15375824,\n",
       "        -5677341.83321959, -5677341.83394051, -5677341.83401802,\n",
       "        -5677341.83403847, -5680750.65553792, -5680750.6571027 ,\n",
       "        -5680750.65727095, -5680750.65731442, -5684687.02050156,\n",
       "        -5684687.02318687, -5684687.02347413, -5684687.02354697,\n",
       "        -5689263.97144503, -5689263.97585514, -5689263.97631359,\n",
       "        -5689263.97642997, -5697984.93118655, -5697984.93851523,\n",
       "        -5697984.93927401, -5697984.93943808, -5710481.55978067,\n",
       "        -5710481.56987824, -5710481.57064503, -5710481.57083407,\n",
       "        -5726439.61584015, -5726439.62651666, -5726439.62747864,\n",
       "        -5726439.6277093 , -5747318.38537723, -5747318.39890488,\n",
       "        -5747318.40008701, -5747318.40023059, -5774101.94583608,\n",
       "        -5774101.960999  , -5774101.96154067, -5774101.96158088,\n",
       "        -5522574.69849243, -5522574.69849243, -5522574.69849243,\n",
       "        -5522574.69849243, -5537945.76467092, -5537945.76548245,\n",
       "        -5537945.76597715, -5537945.76612419, -5553998.53846341,\n",
       "        -5553998.53812865, -5553998.53891548, -5553998.53926824,\n",
       "        -5570935.64183501, -5570935.63561996, -5570935.63587739,\n",
       "        -5570935.63613467, -5588746.28722006, -5588746.27681788,\n",
       "        -5588746.27573198, -5588746.27565055, -5607029.09812757,\n",
       "        -5607029.08043644, -5607029.07911053, -5607029.07875212,\n",
       "        -5624950.28305905, -5624950.26090109, -5624950.25791566,\n",
       "        -5624950.25715186, -5642067.97930602, -5642067.96851549,\n",
       "        -5642067.96530498, -5642067.9640476 , -5657723.30334846,\n",
       "        -5657723.32997999, -5657723.33121307, -5657723.3306089 ,\n",
       "        -5674319.95609102, -5674320.00636843, -5674320.01205114,\n",
       "        -5674320.01353868, -5103554.49263672, -5103554.49263672,\n",
       "        -5103554.49263672, -5103554.49263672, -5093223.27600961,\n",
       "        -5093223.27447407, -5093223.27398281, -5093223.27361155,\n",
       "        -5091299.57638092, -5091299.57748127, -5091299.57702466,\n",
       "        -5091299.57646946, -5101470.10116697, -5101470.10561588,\n",
       "        -5101470.10599098, -5101470.10556064, -5123868.13102556,\n",
       "        -5123868.1513941 , -5123868.15272716, -5123868.15303162,\n",
       "        -5161673.51980052, -5161673.55225299, -5161673.55604825,\n",
       "        -5161673.55723852, -5216778.64095418, -5216778.71600798,\n",
       "        -5216778.72425691, -5216778.72581184, -5292422.00785596,\n",
       "        -5292422.08816682, -5292422.10031211, -5292422.10326782,\n",
       "        -5391729.27814969, -5391729.31076038, -5391729.33494544,\n",
       "        -5391729.3418694 , -5522573.6618543 , -5522573.53772082,\n",
       "        -5522573.55242514, -5522573.56023372, -6992701.0434562 ,\n",
       "        -6992701.0434562 , -6992701.0434562 , -6992701.0434562 ,\n",
       "        -6883348.92563581, -6883349.01493415, -6883349.01256565,\n",
       "        -6883349.01256565, -6755908.8321023 , -6755909.12735484,\n",
       "        -6755909.12314764, -6755909.12314764, -6607247.88263893,\n",
       "        -6607248.28334168, -6607248.27969548, -6607248.27969548,\n",
       "        -6429487.24204753, -6429487.46756358, -6429487.46756358,\n",
       "        -6429487.46107437, -6222044.12655191, -6222044.20695429,\n",
       "        -6222044.18598033, -6222044.18271965, -5969771.50379473,\n",
       "        -5969772.26254834, -5969772.25182944, -5969772.24531705,\n",
       "        -5692888.18211589, -5692888.37418366, -5692888.33246344,\n",
       "        -5692888.32125295, -5381435.11800291, -5381435.52181558,\n",
       "        -5381435.5003475 , -5381435.48268248, -5103552.52493839,\n",
       "        -5103553.36675597, -5103553.3771673 , -5103553.37489939,\n",
       "        -8238268.17835543, -8238268.17835543, -8238268.17835543,\n",
       "        -8238268.17835543, -8217697.60880375, -8217697.60880375,\n",
       "        -8217697.60880375, -8217697.6304261 , -8192172.85445089,\n",
       "        -8192172.85445089, -8192172.85445089, -8192172.89192768,\n",
       "        -8159657.60079045, -8159657.60079045, -8159657.60079045,\n",
       "        -8159657.66003995, -8116824.2465769 , -8116824.2465769 ,\n",
       "        -8116824.2465769 , -8116824.34526107, -8058088.36697598,\n",
       "        -8058088.36697598, -8058088.37642642, -8058088.54130472,\n",
       "        -7972462.18263804, -7972462.18263804, -7972462.34937303,\n",
       "        -7972462.50751201, -7836872.10410798, -7836872.06599364,\n",
       "        -7836872.65219971, -7836872.65219971, -7589899.07050391,\n",
       "        -7589898.3926632 , -7589898.3926632 , -7589898.3926632 ,\n",
       "        -6992711.90496823, -6992711.90496823, -6992714.74193228,\n",
       "        -6992714.74193228]),\n",
       " 'std_test_RMSE': array([ 420278.84275889,  420278.84275889,  420278.84275889,\n",
       "         420278.84275889,  420327.22610843,  420327.22610843,\n",
       "         420327.22610843,  420327.22610843,  420375.71762779,\n",
       "         420375.71762779,  420375.71762779,  420375.71762779,\n",
       "         420424.3174569 ,  420424.3174569 ,  420424.3174569 ,\n",
       "         420424.3174569 ,  420473.02573385,  420473.02573385,\n",
       "         420473.02573385,  420473.02573385,  420521.84259486,\n",
       "         420521.84259486,  420521.84259486,  420521.84259486,\n",
       "         420570.76817421,  420570.76817421,  420570.76817421,\n",
       "         420570.76817421,  420619.80260428,  420619.80260428,\n",
       "         420619.80260428,  420619.80260428,  420668.94601542,\n",
       "         420668.94601542,  420668.94601542,  420668.94601542,\n",
       "         420718.19853596,  420718.19853596,  420718.19853596,\n",
       "         420718.19853596,  413696.91902802,  413696.91902802,\n",
       "         413696.91902802,  413696.91902802,  414593.38880363,\n",
       "         414593.38880346,  414593.38880346,  414593.38880346,\n",
       "         415509.51590588,  415509.51590471,  415509.51590471,\n",
       "         415509.51590471,  416460.59415844,  416460.59415602,\n",
       "         416460.59415602,  416460.59415602,  417479.71643747,\n",
       "         417479.71643373,  417479.71643373,  417479.71643373,\n",
       "         418447.1795063 ,  418447.17950108,  418447.17950108,\n",
       "         418447.17950108,  418878.70263749,  418878.7026305 ,\n",
       "         418878.7026305 ,  418878.7026305 ,  419320.34584045,\n",
       "         419320.34583172,  419320.34583172,  419320.34583172,\n",
       "         419780.81201743,  419780.81200642,  419780.81200642,\n",
       "         419780.81200642,  420278.84295029,  420278.84293804,\n",
       "         420278.84293804,  420278.84293804,  379204.86302337,\n",
       "         379204.86302337,  379204.86302337,  379204.86302337,\n",
       "         380309.75783707,  380309.75793692,  380309.75794198,\n",
       "         380309.75794382,  381948.37998699,  381948.38024411,\n",
       "         381948.38026354,  381948.380269  ,  384274.66245758,\n",
       "         384274.66308787,  384274.66314179,  384274.66315487,\n",
       "         387015.88220896,  387015.88258667,  387015.88261061,\n",
       "         387015.88261674,  389039.52736619,  389039.52908324,\n",
       "         389039.52923344,  389039.52930825,  393346.12338056,\n",
       "         393346.12661333,  393346.12720114,  393346.12735546,\n",
       "         399534.41421826,  399534.42107081,  399534.42183775,\n",
       "         399534.42203179,  406036.77231047,  406036.78269374,\n",
       "         406036.78374723,  406036.78386792,  413696.90394817,\n",
       "         413696.91700751,  413696.9174214 ,  413696.91742023,\n",
       "         392713.28444228,  392713.28444228,  392713.28444228,\n",
       "         392713.28444228,  390240.31927946,  390240.31889884,\n",
       "         390240.31890043,  390240.31893302,  387885.24562687,\n",
       "         387885.24694733,  387885.24685815,  387885.24684253,\n",
       "         385275.05892637,  385275.0664079 ,  385275.06688188,\n",
       "         385275.06702667,  383508.847599  ,  383508.85838223,\n",
       "         383508.85935401,  383508.85977073,  382409.50746591,\n",
       "         382409.52751106,  382409.52929672,  382409.52984927,\n",
       "         381262.85706861,  381262.88640869,  381262.89101303,\n",
       "         381262.89214444,  379608.88732812,  379608.91289989,\n",
       "         379608.9185596 ,  379608.91887083,  377377.60708501,\n",
       "         377377.61099634,  377377.61091111,  377377.61089352,\n",
       "         379204.90392661,  379204.90261126,  379204.90217755,\n",
       "         379204.90208132,  540649.17238014,  540649.17238014,\n",
       "         540649.17238014,  540649.17238014,  519314.66339577,\n",
       "         519314.66418387,  519314.66442616,  519314.66453734,\n",
       "         498542.59339767,  498542.59277679,  498542.5928823 ,\n",
       "         498542.59311857,  477519.87533717,  477519.87278952,\n",
       "         477519.87275232,  477519.87285903,  457127.25885988,\n",
       "         457127.25698009,  457127.25771777,  457127.25799494,\n",
       "         440571.55816629,  440571.55139045,  440571.55311475,\n",
       "         440571.55332225,  425199.98621363,  425199.9695331 ,\n",
       "         425199.97035677,  425199.97083828,  413059.79634133,\n",
       "         413059.73656826,  413059.73379253,  413059.73264066,\n",
       "         404655.21980411,  404655.20378243,  404655.19374598,\n",
       "         404655.1904242 ,  392713.0095713 ,  392713.18991077,\n",
       "         392713.20716419,  392713.20911053, 1027835.3568895 ,\n",
       "        1027835.3568895 , 1027835.3568895 , 1027835.3568895 ,\n",
       "        1018449.2663573 , 1018449.27598951, 1018449.27334315,\n",
       "        1018449.27334315, 1006514.37781333, 1006514.3466617 ,\n",
       "        1006514.34190672, 1006514.34190672,  991529.63722408,\n",
       "         991529.60881458,  991529.6042167 ,  991529.6042167 ,\n",
       "         973410.75542505,  973411.07005495,  973411.07005495,\n",
       "         973411.07292945,  948173.71567365,  948173.70142553,\n",
       "         948173.71102829,  948173.70711924,  912128.19139331,\n",
       "         912128.09374231,  912128.08153915,  912128.08646486,\n",
       "         840757.07855692,  840757.02909444,  840757.04630037,\n",
       "         840757.03855522,  723718.46459053,  723718.3963817 ,\n",
       "         723718.37798389,  723718.38459437,  540649.52394611,\n",
       "         540649.4817227 ,  540649.48055493,  540649.48188264,\n",
       "        1057389.00901293, 1057389.00901293, 1057389.00901293,\n",
       "        1057389.00901293, 1057708.59382163, 1057708.59382163,\n",
       "        1057708.59382163, 1057708.58159466, 1058094.41668089,\n",
       "        1058094.41668089, 1058094.41668089, 1058094.40451314,\n",
       "        1058570.51997065, 1058570.51997065, 1058570.51997065,\n",
       "        1058570.50045662, 1059171.41301712, 1059171.41301712,\n",
       "        1059171.41301712, 1059171.37977084, 1059661.29512762,\n",
       "        1059661.29512762, 1059661.30391815, 1059661.23428347,\n",
       "        1059763.62009757, 1059763.62009757, 1059763.46132677,\n",
       "        1059763.49775105, 1059529.04413322, 1059529.00830249,\n",
       "        1059528.77654421, 1059528.77654421, 1055137.6996564 ,\n",
       "        1055137.2483154 , 1055137.2483154 , 1055137.2483154 ,\n",
       "        1027838.6547645 , 1027838.6547645 , 1027838.1689166 ,\n",
       "        1027838.1689166 ]),\n",
       " 'rank_test_RMSE': array([173, 173, 173, 173, 177, 177, 177, 177, 181, 181, 181, 181, 185,\n",
       "        185, 185, 185, 189, 189, 189, 189, 193, 193, 193, 193, 197, 197,\n",
       "        197, 197, 201, 201, 201, 201, 205, 205, 205, 205, 209, 209, 209,\n",
       "        209, 133, 133, 133, 133, 137, 138, 138, 138, 141, 142, 142, 142,\n",
       "        145, 146, 146, 146, 149, 150, 150, 150, 153, 154, 154, 154, 157,\n",
       "        158, 158, 158, 161, 162, 162, 162, 165, 166, 166, 166, 169, 170,\n",
       "        170, 170,  89,  89,  89,  89,  93,  94,  95,  96,  97,  98,  99,\n",
       "        100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132,  49,  49,  49,  49,  53,  54,  55,  56,  58,  57,\n",
       "         59,  60,  64,  61,  62,  63,  68,  67,  66,  65,  72,  71,  70,\n",
       "         69,  76,  75,  74,  73,  80,  79,  78,  77,  81,  82,  84,  83,\n",
       "         85,  86,  87,  88,  17,  17,  17,  17,   8,   7,   6,   5,   1,\n",
       "          4,   3,   2,   9,  11,  12,  10,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  41,  42,  43,\n",
       "         44,  48,  45,  46,  47, 237, 237, 237, 237, 233, 236, 234, 234,\n",
       "        229, 232, 230, 230, 225, 228, 226, 226, 221, 223, 223, 222, 217,\n",
       "        220, 219, 218, 213, 216, 215, 214, 109, 112, 111, 110,  37,  40,\n",
       "         39,  38,  13,  14,  16,  15, 277, 277, 277, 277, 273, 273, 273,\n",
       "        276, 269, 269, 269, 272, 265, 265, 265, 268, 261, 261, 261, 264,\n",
       "        257, 257, 259, 260, 253, 253, 255, 256, 250, 249, 251, 251, 248,\n",
       "        245, 245, 245, 241, 241, 243, 243])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Elastparams = {\"tol\" : [0.1,0.01,0.001,0.0001],\n",
    "          \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], \n",
    "          \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}\n",
    "\n",
    "\n",
    "MyElastic = GridSearchCV(estimator = ElasticNet(), \n",
    "                      param_grid = Elastparams,\n",
    "                      scoring = scoring,\n",
    "                      refit= False,      \n",
    "                      cv=CV,\n",
    "                      verbose=2\n",
    "                     )\n",
    "\n",
    "MyElastic.fit(X_train_std, y_train)\n",
    "MyElastic.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018828</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.1}</td>\n",
       "      <td>0.196262</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162935e+14</td>\n",
       "      <td>21</td>\n",
       "      <td>-5.779317e+06</td>\n",
       "      <td>-6.265009e+06</td>\n",
       "      <td>-6.300497e+06</td>\n",
       "      <td>-5.365622e+06</td>\n",
       "      <td>-5.322976e+06</td>\n",
       "      <td>-5.806684e+06</td>\n",
       "      <td>4.202788e+05</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018952</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.01}</td>\n",
       "      <td>0.196262</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162935e+14</td>\n",
       "      <td>21</td>\n",
       "      <td>-5.779317e+06</td>\n",
       "      <td>-6.265009e+06</td>\n",
       "      <td>-6.300497e+06</td>\n",
       "      <td>-5.365622e+06</td>\n",
       "      <td>-5.322976e+06</td>\n",
       "      <td>-5.806684e+06</td>\n",
       "      <td>4.202788e+05</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016399</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.001}</td>\n",
       "      <td>0.196262</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162935e+14</td>\n",
       "      <td>21</td>\n",
       "      <td>-5.779317e+06</td>\n",
       "      <td>-6.265009e+06</td>\n",
       "      <td>-6.300497e+06</td>\n",
       "      <td>-5.365622e+06</td>\n",
       "      <td>-5.322976e+06</td>\n",
       "      <td>-5.806684e+06</td>\n",
       "      <td>4.202788e+05</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015614</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.0001}</td>\n",
       "      <td>0.196262</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162935e+14</td>\n",
       "      <td>21</td>\n",
       "      <td>-5.779317e+06</td>\n",
       "      <td>-6.265009e+06</td>\n",
       "      <td>-6.300497e+06</td>\n",
       "      <td>-5.365622e+06</td>\n",
       "      <td>-5.322976e+06</td>\n",
       "      <td>-5.806684e+06</td>\n",
       "      <td>4.202788e+05</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017295</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.1}</td>\n",
       "      <td>0.196291</td>\n",
       "      <td>0.218706</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162885e+14</td>\n",
       "      <td>25</td>\n",
       "      <td>-5.779532e+06</td>\n",
       "      <td>-6.265564e+06</td>\n",
       "      <td>-6.301043e+06</td>\n",
       "      <td>-5.365977e+06</td>\n",
       "      <td>-5.323514e+06</td>\n",
       "      <td>-5.807126e+06</td>\n",
       "      <td>4.203272e+05</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.0001}</td>\n",
       "      <td>0.073609</td>\n",
       "      <td>0.184636</td>\n",
       "      <td>...</td>\n",
       "      <td>2.600245e+14</td>\n",
       "      <td>245</td>\n",
       "      <td>-7.388088e+06</td>\n",
       "      <td>-6.763707e+06</td>\n",
       "      <td>-8.592824e+06</td>\n",
       "      <td>-6.217323e+06</td>\n",
       "      <td>-8.987550e+06</td>\n",
       "      <td>-7.589898e+06</td>\n",
       "      <td>1.055137e+06</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.1}</td>\n",
       "      <td>0.120889</td>\n",
       "      <td>0.296065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.437526e+14</td>\n",
       "      <td>241</td>\n",
       "      <td>-6.783163e+06</td>\n",
       "      <td>-6.258622e+06</td>\n",
       "      <td>-7.998972e+06</td>\n",
       "      <td>-5.604025e+06</td>\n",
       "      <td>-8.318777e+06</td>\n",
       "      <td>-6.992712e+06</td>\n",
       "      <td>1.027839e+06</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.01}</td>\n",
       "      <td>0.120889</td>\n",
       "      <td>0.296065</td>\n",
       "      <td>...</td>\n",
       "      <td>2.437526e+14</td>\n",
       "      <td>241</td>\n",
       "      <td>-6.783163e+06</td>\n",
       "      <td>-6.258622e+06</td>\n",
       "      <td>-7.998972e+06</td>\n",
       "      <td>-5.604025e+06</td>\n",
       "      <td>-8.318777e+06</td>\n",
       "      <td>-6.992712e+06</td>\n",
       "      <td>1.027839e+06</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.001}</td>\n",
       "      <td>0.120889</td>\n",
       "      <td>0.296064</td>\n",
       "      <td>...</td>\n",
       "      <td>2.437526e+14</td>\n",
       "      <td>243</td>\n",
       "      <td>-6.783167e+06</td>\n",
       "      <td>-6.258625e+06</td>\n",
       "      <td>-7.998975e+06</td>\n",
       "      <td>-5.604028e+06</td>\n",
       "      <td>-8.318780e+06</td>\n",
       "      <td>-6.992715e+06</td>\n",
       "      <td>1.027838e+06</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.0001}</td>\n",
       "      <td>0.120889</td>\n",
       "      <td>0.296064</td>\n",
       "      <td>...</td>\n",
       "      <td>2.437526e+14</td>\n",
       "      <td>243</td>\n",
       "      <td>-6.783167e+06</td>\n",
       "      <td>-6.258625e+06</td>\n",
       "      <td>-7.998975e+06</td>\n",
       "      <td>-5.604028e+06</td>\n",
       "      <td>-8.318780e+06</td>\n",
       "      <td>-6.992715e+06</td>\n",
       "      <td>1.027838e+06</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0         0.018828      0.003435         0.000199        0.000399      0.0001   \n",
       "1         0.018952      0.003853         0.002226        0.000438      0.0001   \n",
       "2         0.016399      0.003227         0.001703        0.000874      0.0001   \n",
       "3         0.015614      0.000044         0.000000        0.000000      0.0001   \n",
       "4         0.017295      0.005201         0.001152        0.000945      0.0001   \n",
       "..             ...           ...              ...             ...         ...   \n",
       "275       0.000000      0.000000         0.000000        0.000000         100   \n",
       "276       0.003126      0.006253         0.000101        0.000201         100   \n",
       "277       0.000000      0.000000         0.003103        0.006205         100   \n",
       "278       0.000000      0.000000         0.003128        0.006255         100   \n",
       "279       0.003125      0.006250         0.000000        0.000000         100   \n",
       "\n",
       "    param_l1_ratio param_tol  \\\n",
       "0              0.0       0.1   \n",
       "1              0.0      0.01   \n",
       "2              0.0     0.001   \n",
       "3              0.0    0.0001   \n",
       "4              0.1       0.1   \n",
       "..             ...       ...   \n",
       "275            0.8    0.0001   \n",
       "276            0.9       0.1   \n",
       "277            0.9      0.01   \n",
       "278            0.9     0.001   \n",
       "279            0.9    0.0001   \n",
       "\n",
       "                                                params  split0_test_R2  \\\n",
       "0       {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.1}        0.196262   \n",
       "1      {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.01}        0.196262   \n",
       "2     {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.001}        0.196262   \n",
       "3    {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.0001}        0.196262   \n",
       "4       {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.1}        0.196291   \n",
       "..                                                 ...             ...   \n",
       "275     {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.0001}        0.073609   \n",
       "276        {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.1}        0.120889   \n",
       "277       {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.01}        0.120889   \n",
       "278      {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.001}        0.120889   \n",
       "279     {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.0001}        0.120889   \n",
       "\n",
       "     split1_test_R2  ...  std_test_MAE  rank_test_MAE  split0_test_RMSE  \\\n",
       "0          0.218800  ...  1.162935e+14             21     -5.779317e+06   \n",
       "1          0.218800  ...  1.162935e+14             21     -5.779317e+06   \n",
       "2          0.218800  ...  1.162935e+14             21     -5.779317e+06   \n",
       "3          0.218800  ...  1.162935e+14             21     -5.779317e+06   \n",
       "4          0.218706  ...  1.162885e+14             25     -5.779532e+06   \n",
       "..              ...  ...           ...            ...               ...   \n",
       "275        0.184636  ...  2.600245e+14            245     -7.388088e+06   \n",
       "276        0.296065  ...  2.437526e+14            241     -6.783163e+06   \n",
       "277        0.296065  ...  2.437526e+14            241     -6.783163e+06   \n",
       "278        0.296064  ...  2.437526e+14            243     -6.783167e+06   \n",
       "279        0.296064  ...  2.437526e+14            243     -6.783167e+06   \n",
       "\n",
       "     split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0       -6.265009e+06     -6.300497e+06     -5.365622e+06     -5.322976e+06   \n",
       "1       -6.265009e+06     -6.300497e+06     -5.365622e+06     -5.322976e+06   \n",
       "2       -6.265009e+06     -6.300497e+06     -5.365622e+06     -5.322976e+06   \n",
       "3       -6.265009e+06     -6.300497e+06     -5.365622e+06     -5.322976e+06   \n",
       "4       -6.265564e+06     -6.301043e+06     -5.365977e+06     -5.323514e+06   \n",
       "..                ...               ...               ...               ...   \n",
       "275     -6.763707e+06     -8.592824e+06     -6.217323e+06     -8.987550e+06   \n",
       "276     -6.258622e+06     -7.998972e+06     -5.604025e+06     -8.318777e+06   \n",
       "277     -6.258622e+06     -7.998972e+06     -5.604025e+06     -8.318777e+06   \n",
       "278     -6.258625e+06     -7.998975e+06     -5.604028e+06     -8.318780e+06   \n",
       "279     -6.258625e+06     -7.998975e+06     -5.604028e+06     -8.318780e+06   \n",
       "\n",
       "     mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0     -5.806684e+06   4.202788e+05             173  \n",
       "1     -5.806684e+06   4.202788e+05             173  \n",
       "2     -5.806684e+06   4.202788e+05             173  \n",
       "3     -5.806684e+06   4.202788e+05             173  \n",
       "4     -5.807126e+06   4.203272e+05             177  \n",
       "..              ...            ...             ...  \n",
       "275   -7.589898e+06   1.055137e+06             245  \n",
       "276   -6.992712e+06   1.027839e+06             241  \n",
       "277   -6.992712e+06   1.027839e+06             241  \n",
       "278   -6.992715e+06   1.027838e+06             243  \n",
       "279   -6.992715e+06   1.027838e+06             243  \n",
       "\n",
       "[280 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyElasticbest=pd.concat([pd.DataFrame(MyElastic.cv_results_)])\n",
    "MyElasticbest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236    0.433164\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyElasticbestR2=MyElasticbest[MyElasticbest['rank_test_R2'].isin([1])]\n",
    "print(MyElasticbestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00313478, 0.        , 0.00312543, 0.        , 0.0031251 ,\n",
       "        0.        , 0.        ]),\n",
       " 'std_fit_time': array([0.00626955, 0.        , 0.00625086, 0.        , 0.00625019,\n",
       "        0.        , 0.        ]),\n",
       " 'mean_score_time': array([0.00320311, 0.00312629, 0.        , 0.00312486, 0.        ,\n",
       "        0.00312524, 0.0031251 ]),\n",
       " 'std_score_time': array([0.0046677 , 0.00625257, 0.        , 0.00624971, 0.        ,\n",
       "        0.00625048, 0.00625019]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001},\n",
       "  {'alpha': 0.001},\n",
       "  {'alpha': 0.01},\n",
       "  {'alpha': 0.1},\n",
       "  {'alpha': 1},\n",
       "  {'alpha': 10},\n",
       "  {'alpha': 100}],\n",
       " 'split0_test_R2': array([0.19655073, 0.19654784, 0.19651896, 0.19623284, 0.19361492,\n",
       "        0.18088873, 0.18598827]),\n",
       " 'split1_test_R2': array([0.21783409, 0.21784397, 0.2179424 , 0.21889625, 0.22594465,\n",
       "        0.23101164, 0.25910335]),\n",
       " 'split2_test_R2': array([0.57396784, 0.57396798, 0.57396935, 0.5739814 , 0.57396696,\n",
       "        0.57053072, 0.54795716]),\n",
       " 'split3_test_R2': array([0.01147556, 0.01148095, 0.0115347 , 0.01206307, 0.0165577 ,\n",
       "        0.0339381 , 0.11871367]),\n",
       " 'split4_test_R2': array([0.80086821, 0.80086761, 0.80086162, 0.80079673, 0.79981454,\n",
       "        0.789332  , 0.7653884 ]),\n",
       " 'mean_test_R2': array([0.36013929, 0.36014167, 0.36016541, 0.36039406, 0.36197976,\n",
       "        0.36114024, 0.37543017]),\n",
       " 'std_test_R2': array([0.28584717, 0.28584504, 0.28582379, 0.2856148 , 0.28383324,\n",
       "        0.27701186, 0.24378536]),\n",
       " 'rank_test_R2': array([7, 6, 5, 4, 2, 3, 1]),\n",
       " 'split0_test_MAE': array([-3.36829963e+14, -3.36831174e+14, -3.36843279e+14, -3.36963231e+14,\n",
       "        -3.38060740e+14, -3.43395939e+14, -3.41258059e+14]),\n",
       " 'split1_test_MAE': array([-1.05626935e+14, -1.05625602e+14, -1.05612309e+14, -1.05483498e+14,\n",
       "        -1.04531652e+14, -1.03847384e+14, -1.00053764e+14]),\n",
       " 'split2_test_MAE': array([-3.56419981e+14, -3.56419865e+14, -3.56418718e+14, -3.56408637e+14,\n",
       "        -3.56420719e+14, -3.59295483e+14, -3.78180609e+14]),\n",
       " 'split3_test_MAE': array([-1.02052282e+14, -1.02051726e+14, -1.02046176e+14, -1.01991629e+14,\n",
       "        -1.01527617e+14, -9.97333167e+13, -9.09813433e+13]),\n",
       " 'split4_test_MAE': array([-1.22650829e+14, -1.22651195e+14, -1.22654884e+14, -1.22694853e+14,\n",
       "        -1.23299809e+14, -1.29756304e+14, -1.44503835e+14]),\n",
       " 'mean_test_MAE': array([-2.04715998e+14, -2.04715912e+14, -2.04715073e+14, -2.04708370e+14,\n",
       "        -2.04768107e+14, -2.07205685e+14, -2.10995522e+14]),\n",
       " 'std_test_MAE': array([1.16242308e+14, 1.16242827e+14, 1.16248005e+14, 1.16298616e+14,\n",
       "        1.16712013e+14, 1.18246139e+14, 1.23330291e+14]),\n",
       " 'rank_test_MAE': array([4, 3, 2, 1, 5, 6, 7]),\n",
       " 'split0_test_RMSE': array([-5781484.65628853, -5781462.93348657, -5781245.91394542,\n",
       "        -5779096.33737024, -5760500.68344028, -5673996.19713946,\n",
       "        -5436721.44969498]),\n",
       " 'split1_test_RMSE': array([-6270619.49229736, -6270563.07958497, -6269999.70696392,\n",
       "        -6264440.39401599, -6215793.16826011, -6081646.42090972,\n",
       "        -5940998.79276495]),\n",
       " 'split2_test_RMSE': array([-6306004.40496756, -6305949.11399135, -6305396.85684063,\n",
       "        -6299938.75762989, -6253809.44543287, -6105260.81286261,\n",
       "        -5986914.06042265]),\n",
       " 'split3_test_RMSE': array([-5369198.57848034, -5369162.7271113 , -5368804.56901493,\n",
       "        -5365258.16809069, -5334302.21593091, -5247459.43878397,\n",
       "        -5063484.9655669 ]),\n",
       " 'split4_test_RMSE': array([-5328436.05106095, -5328381.22064229, -5327833.8055901 ,\n",
       "        -5322446.87604278, -5291121.35464525, -5248892.24957315,\n",
       "        -5106840.81493926]),\n",
       " 'mean_test_RMSE': array([-5811148.63661895, -5811103.8149633 , -5810656.170471  ,\n",
       "        -5806236.10662992, -5771105.37354189, -5671451.02385378,\n",
       "        -5506992.01667775]),\n",
       " 'std_test_RMSE': array([420762.86541462, 420757.95794527, 420708.94171498, 420224.60793467,\n",
       "        412806.14630568, 378095.87584219, 395080.8755138 ]),\n",
       " 'rank_test_RMSE': array([7, 6, 5, 4, 3, 2, 1])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridgeparams = {\n",
    "          \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], \n",
    "          }\n",
    "\n",
    "\n",
    "MyRidge = GridSearchCV(estimator = Ridge(), \n",
    "                      param_grid = Ridgeparams,\n",
    "                      scoring = scoring,\n",
    "                      refit= False,      \n",
    "                      cv=CV,\n",
    "                      verbose=2\n",
    "                     )\n",
    "\n",
    "MyRidge.fit(X_train_std, y_train)\n",
    "MyRidge.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.217834</td>\n",
       "      <td>0.573968</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162423e+14</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.781485e+06</td>\n",
       "      <td>-6.270619e+06</td>\n",
       "      <td>-6.306004e+06</td>\n",
       "      <td>-5.369199e+06</td>\n",
       "      <td>-5.328436e+06</td>\n",
       "      <td>-5.811149e+06</td>\n",
       "      <td>420762.865415</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.196548</td>\n",
       "      <td>0.217844</td>\n",
       "      <td>0.573968</td>\n",
       "      <td>0.011481</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162428e+14</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.781463e+06</td>\n",
       "      <td>-6.270563e+06</td>\n",
       "      <td>-6.305949e+06</td>\n",
       "      <td>-5.369163e+06</td>\n",
       "      <td>-5.328381e+06</td>\n",
       "      <td>-5.811104e+06</td>\n",
       "      <td>420757.957945</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.196519</td>\n",
       "      <td>0.217942</td>\n",
       "      <td>0.573969</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162480e+14</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.781246e+06</td>\n",
       "      <td>-6.270000e+06</td>\n",
       "      <td>-6.305397e+06</td>\n",
       "      <td>-5.368805e+06</td>\n",
       "      <td>-5.327834e+06</td>\n",
       "      <td>-5.810656e+06</td>\n",
       "      <td>420708.941715</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.196233</td>\n",
       "      <td>0.218896</td>\n",
       "      <td>0.573981</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162986e+14</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.779096e+06</td>\n",
       "      <td>-6.264440e+06</td>\n",
       "      <td>-6.299939e+06</td>\n",
       "      <td>-5.365258e+06</td>\n",
       "      <td>-5.322447e+06</td>\n",
       "      <td>-5.806236e+06</td>\n",
       "      <td>420224.607935</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.193615</td>\n",
       "      <td>0.225945</td>\n",
       "      <td>0.573967</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>...</td>\n",
       "      <td>1.167120e+14</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.760501e+06</td>\n",
       "      <td>-6.215793e+06</td>\n",
       "      <td>-6.253809e+06</td>\n",
       "      <td>-5.334302e+06</td>\n",
       "      <td>-5.291121e+06</td>\n",
       "      <td>-5.771105e+06</td>\n",
       "      <td>412806.146306</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>0.180889</td>\n",
       "      <td>0.231012</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>...</td>\n",
       "      <td>1.182461e+14</td>\n",
       "      <td>6</td>\n",
       "      <td>-5.673996e+06</td>\n",
       "      <td>-6.081646e+06</td>\n",
       "      <td>-6.105261e+06</td>\n",
       "      <td>-5.247459e+06</td>\n",
       "      <td>-5.248892e+06</td>\n",
       "      <td>-5.671451e+06</td>\n",
       "      <td>378095.875842</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>0.185988</td>\n",
       "      <td>0.259103</td>\n",
       "      <td>0.547957</td>\n",
       "      <td>0.118714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.233303e+14</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.436721e+06</td>\n",
       "      <td>-5.940999e+06</td>\n",
       "      <td>-5.986914e+06</td>\n",
       "      <td>-5.063485e+06</td>\n",
       "      <td>-5.106841e+06</td>\n",
       "      <td>-5.506992e+06</td>\n",
       "      <td>395080.875514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.003135      0.006270         0.003203        0.004668      0.0001   \n",
       "1       0.000000      0.000000         0.003126        0.006253       0.001   \n",
       "2       0.003125      0.006251         0.000000        0.000000        0.01   \n",
       "3       0.000000      0.000000         0.003125        0.006250         0.1   \n",
       "4       0.003125      0.006250         0.000000        0.000000           1   \n",
       "5       0.000000      0.000000         0.003125        0.006250          10   \n",
       "6       0.000000      0.000000         0.003125        0.006250         100   \n",
       "\n",
       "              params  split0_test_R2  split1_test_R2  split2_test_R2  \\\n",
       "0  {'alpha': 0.0001}        0.196551        0.217834        0.573968   \n",
       "1   {'alpha': 0.001}        0.196548        0.217844        0.573968   \n",
       "2    {'alpha': 0.01}        0.196519        0.217942        0.573969   \n",
       "3     {'alpha': 0.1}        0.196233        0.218896        0.573981   \n",
       "4       {'alpha': 1}        0.193615        0.225945        0.573967   \n",
       "5      {'alpha': 10}        0.180889        0.231012        0.570531   \n",
       "6     {'alpha': 100}        0.185988        0.259103        0.547957   \n",
       "\n",
       "   split3_test_R2  ...  std_test_MAE  rank_test_MAE  split0_test_RMSE  \\\n",
       "0        0.011476  ...  1.162423e+14              4     -5.781485e+06   \n",
       "1        0.011481  ...  1.162428e+14              3     -5.781463e+06   \n",
       "2        0.011535  ...  1.162480e+14              2     -5.781246e+06   \n",
       "3        0.012063  ...  1.162986e+14              1     -5.779096e+06   \n",
       "4        0.016558  ...  1.167120e+14              5     -5.760501e+06   \n",
       "5        0.033938  ...  1.182461e+14              6     -5.673996e+06   \n",
       "6        0.118714  ...  1.233303e+14              7     -5.436721e+06   \n",
       "\n",
       "   split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0     -6.270619e+06     -6.306004e+06     -5.369199e+06     -5.328436e+06   \n",
       "1     -6.270563e+06     -6.305949e+06     -5.369163e+06     -5.328381e+06   \n",
       "2     -6.270000e+06     -6.305397e+06     -5.368805e+06     -5.327834e+06   \n",
       "3     -6.264440e+06     -6.299939e+06     -5.365258e+06     -5.322447e+06   \n",
       "4     -6.215793e+06     -6.253809e+06     -5.334302e+06     -5.291121e+06   \n",
       "5     -6.081646e+06     -6.105261e+06     -5.247459e+06     -5.248892e+06   \n",
       "6     -5.940999e+06     -5.986914e+06     -5.063485e+06     -5.106841e+06   \n",
       "\n",
       "   mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0   -5.811149e+06  420762.865415               7  \n",
       "1   -5.811104e+06  420757.957945               6  \n",
       "2   -5.810656e+06  420708.941715               5  \n",
       "3   -5.806236e+06  420224.607935               4  \n",
       "4   -5.771105e+06  412806.146306               3  \n",
       "5   -5.671451e+06  378095.875842               2  \n",
       "6   -5.506992e+06  395080.875514               1  \n",
       "\n",
       "[7 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyRidgebest=pd.concat([pd.DataFrame(MyRidge.cv_results_)])\n",
    "MyRidgebest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    0.37543\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyRidgebestR2=MyRidgebest[MyRidgebest['rank_test_R2'].isin([1])]\n",
    "print(MyRidgebestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.468e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.517e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.093e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.620e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.372e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e+16, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.080e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.012e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.323e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.370e+16, tolerance: 3.400e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+15, tolerance: 3.849e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.087e+16, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.345e+16, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.045e+16, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.354e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.415e+15, tolerance: 4.493e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.972e+14, tolerance: 2.899e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.847e+15, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.189e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.038e+13, tolerance: 4.493e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e+14, tolerance: 4.557e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.783e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+16, tolerance: 3.400e+13\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.546e+14, tolerance: 3.400e+13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0194551 , 0.01582365, 0.01306143, 0.01624374, 0.01642852,\n",
       "        0.00635095, 0.01250153]),\n",
       " 'std_fit_time': array([0.00603583, 0.00015389, 0.00502471, 0.00145119, 0.00140632,\n",
       "        0.00778004, 0.00625333]),\n",
       " 'mean_score_time': array([0.        , 0.00312533, 0.00581088, 0.00040092, 0.00250087,\n",
       "        0.00937543, 0.        ]),\n",
       " 'std_score_time': array([0.        , 0.00625067, 0.0071864 , 0.00080185, 0.00500174,\n",
       "        0.00765501, 0.        ]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001},\n",
       "  {'alpha': 0.001},\n",
       "  {'alpha': 0.01},\n",
       "  {'alpha': 0.1},\n",
       "  {'alpha': 1},\n",
       "  {'alpha': 10},\n",
       "  {'alpha': 100}],\n",
       " 'split0_test_R2': array([0.19655105, 0.19655105, 0.19655104, 0.19655103, 0.19655088,\n",
       "        0.19654936, 0.19653419]),\n",
       " 'split1_test_R2': array([0.21783301, 0.21783301, 0.21783302, 0.21783314, 0.21783426,\n",
       "        0.21784559, 0.2179586 ]),\n",
       " 'split2_test_R2': array([0.57396782, 0.57396782, 0.57396783, 0.57396783, 0.57396791,\n",
       "        0.57396868, 0.57397641]),\n",
       " 'split3_test_R2': array([0.01147494, 0.01147494, 0.01147494, 0.01147497, 0.0114753 ,\n",
       "        0.01147845, 0.01150993]),\n",
       " 'split4_test_R2': array([0.80086917, 0.80086917, 0.80086917, 0.80086919, 0.8008694 ,\n",
       "        0.80087143, 0.80089155]),\n",
       " 'mean_test_R2': array([0.3601392 , 0.3601392 , 0.3601392 , 0.36013923, 0.36013955,\n",
       "        0.3601427 , 0.36017413]),\n",
       " 'std_test_R2': array([0.28584768, 0.28584768, 0.28584768, 0.28584767, 0.28584757,\n",
       "        0.28584659, 0.28583676]),\n",
       " 'rank_test_R2': array([7, 6, 5, 4, 3, 2, 1]),\n",
       " 'split0_test_MAE': array([-3.36829828e+14, -3.36829828e+14, -3.36829829e+14, -3.36829835e+14,\n",
       "        -3.36829899e+14, -3.36830535e+14, -3.36836894e+14]),\n",
       " 'split1_test_MAE': array([-1.05627082e+14, -1.05627081e+14, -1.05627080e+14, -1.05627065e+14,\n",
       "        -1.05626913e+14, -1.05625383e+14, -1.05610122e+14]),\n",
       " 'split2_test_MAE': array([-3.56419993e+14, -3.56419993e+14, -3.56419993e+14, -3.56419986e+14,\n",
       "        -3.56419922e+14, -3.56419274e+14, -3.56412811e+14]),\n",
       " 'split3_test_MAE': array([-1.02052346e+14, -1.02052346e+14, -1.02052346e+14, -1.02052343e+14,\n",
       "        -1.02052309e+14, -1.02051983e+14, -1.02048734e+14]),\n",
       " 'split4_test_MAE': array([-1.22650237e+14, -1.22650237e+14, -1.22650235e+14, -1.22650223e+14,\n",
       "        -1.22650097e+14, -1.22648843e+14, -1.22636454e+14]),\n",
       " 'mean_test_MAE': array([-2.04715897e+14, -2.04715897e+14, -2.04715896e+14, -2.04715890e+14,\n",
       "        -2.04715828e+14, -2.04715204e+14, -2.04709003e+14]),\n",
       " 'std_test_MAE': array([1.16242328e+14, 1.16242328e+14, 1.16242329e+14, 1.16242333e+14,\n",
       "        1.16242380e+14, 1.16242852e+14, 1.16247535e+14]),\n",
       " 'rank_test_MAE': array([7, 6, 5, 4, 3, 2, 1]),\n",
       " 'split0_test_RMSE': array([-5781487.06896323, -5781487.06728661, -5781487.0505203 ,\n",
       "        -5781486.8826074 , -5781485.19375257, -5781468.29871146,\n",
       "        -5781299.29304728]),\n",
       " 'split1_test_RMSE': array([-6270625.68587334, -6270625.68070657, -6270625.62903883,\n",
       "        -6270625.11236148, -6270619.94558818, -6270567.80448409,\n",
       "        -6270046.5180965 ]),\n",
       " 'split2_test_RMSE': array([-6306010.53524675, -6306010.53039967, -6306010.48192894,\n",
       "        -6306009.9972216 , -6306005.12935756, -6305956.34167324,\n",
       "        -6305468.20012293]),\n",
       " 'split3_test_RMSE': array([-5369202.56165645, -5369202.5583452 , -5369202.52523267,\n",
       "        -5369202.1941075 , -5369198.88285567, -5369165.75283755,\n",
       "        -5368833.80329261]),\n",
       " 'split4_test_RMSE': array([-5328423.97420313, -5328423.96637187, -5328423.88805926,\n",
       "        -5328423.10493319, -5328415.27367233, -5328336.96106384,\n",
       "        -5327553.83774791]),\n",
       " 'mean_test_RMSE': array([-5811149.96518858, -5811149.96062198, -5811149.914956  ,\n",
       "        -5811149.45824623, -5811144.88504526, -5811099.03175404,\n",
       "        -5810640.33046145]),\n",
       " 'std_test_RMSE': array([420767.56029219, 420767.56053977, 420767.5630155 , 420767.58777638,\n",
       "        420767.8306375 , 420770.13452624, 420793.32912937]),\n",
       " 'rank_test_RMSE': array([7, 6, 5, 4, 3, 2, 1])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lassoparams = {\n",
    "          \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], \n",
    "          }\n",
    "\n",
    "\n",
    "MyLasso = GridSearchCV(estimator = Lasso(), \n",
    "                      param_grid = Lassoparams,\n",
    "                      scoring = scoring,\n",
    "                      refit= False,      \n",
    "                      cv=CV,\n",
    "                      verbose=2\n",
    "                     )\n",
    "\n",
    "MyLasso.fit(X_train_std, y_train)\n",
    "MyLasso.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019455</td>\n",
       "      <td>0.006036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.217833</td>\n",
       "      <td>0.573968</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162423e+14</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.781487e+06</td>\n",
       "      <td>-6.270626e+06</td>\n",
       "      <td>-6.306011e+06</td>\n",
       "      <td>-5.369203e+06</td>\n",
       "      <td>-5.328424e+06</td>\n",
       "      <td>-5.811150e+06</td>\n",
       "      <td>420767.560292</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015824</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.217833</td>\n",
       "      <td>0.573968</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162423e+14</td>\n",
       "      <td>6</td>\n",
       "      <td>-5.781487e+06</td>\n",
       "      <td>-6.270626e+06</td>\n",
       "      <td>-6.306011e+06</td>\n",
       "      <td>-5.369203e+06</td>\n",
       "      <td>-5.328424e+06</td>\n",
       "      <td>-5.811150e+06</td>\n",
       "      <td>420767.560540</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013061</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.217833</td>\n",
       "      <td>0.573968</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162423e+14</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.781487e+06</td>\n",
       "      <td>-6.270626e+06</td>\n",
       "      <td>-6.306010e+06</td>\n",
       "      <td>-5.369203e+06</td>\n",
       "      <td>-5.328424e+06</td>\n",
       "      <td>-5.811150e+06</td>\n",
       "      <td>420767.563015</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.217833</td>\n",
       "      <td>0.573968</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162423e+14</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.781487e+06</td>\n",
       "      <td>-6.270625e+06</td>\n",
       "      <td>-6.306010e+06</td>\n",
       "      <td>-5.369202e+06</td>\n",
       "      <td>-5.328423e+06</td>\n",
       "      <td>-5.811149e+06</td>\n",
       "      <td>420767.587776</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.196551</td>\n",
       "      <td>0.217834</td>\n",
       "      <td>0.573968</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162424e+14</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.781485e+06</td>\n",
       "      <td>-6.270620e+06</td>\n",
       "      <td>-6.306005e+06</td>\n",
       "      <td>-5.369199e+06</td>\n",
       "      <td>-5.328415e+06</td>\n",
       "      <td>-5.811145e+06</td>\n",
       "      <td>420767.830638</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>0.196549</td>\n",
       "      <td>0.217846</td>\n",
       "      <td>0.573969</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162429e+14</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.781468e+06</td>\n",
       "      <td>-6.270568e+06</td>\n",
       "      <td>-6.305956e+06</td>\n",
       "      <td>-5.369166e+06</td>\n",
       "      <td>-5.328337e+06</td>\n",
       "      <td>-5.811099e+06</td>\n",
       "      <td>420770.134526</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>0.196534</td>\n",
       "      <td>0.217959</td>\n",
       "      <td>0.573976</td>\n",
       "      <td>0.011510</td>\n",
       "      <td>...</td>\n",
       "      <td>1.162475e+14</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.781299e+06</td>\n",
       "      <td>-6.270047e+06</td>\n",
       "      <td>-6.305468e+06</td>\n",
       "      <td>-5.368834e+06</td>\n",
       "      <td>-5.327554e+06</td>\n",
       "      <td>-5.810640e+06</td>\n",
       "      <td>420793.329129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.019455      0.006036         0.000000        0.000000      0.0001   \n",
       "1       0.015824      0.000154         0.003125        0.006251       0.001   \n",
       "2       0.013061      0.005025         0.005811        0.007186        0.01   \n",
       "3       0.016244      0.001451         0.000401        0.000802         0.1   \n",
       "4       0.016429      0.001406         0.002501        0.005002           1   \n",
       "5       0.006351      0.007780         0.009375        0.007655          10   \n",
       "6       0.012502      0.006253         0.000000        0.000000         100   \n",
       "\n",
       "              params  split0_test_R2  split1_test_R2  split2_test_R2  \\\n",
       "0  {'alpha': 0.0001}        0.196551        0.217833        0.573968   \n",
       "1   {'alpha': 0.001}        0.196551        0.217833        0.573968   \n",
       "2    {'alpha': 0.01}        0.196551        0.217833        0.573968   \n",
       "3     {'alpha': 0.1}        0.196551        0.217833        0.573968   \n",
       "4       {'alpha': 1}        0.196551        0.217834        0.573968   \n",
       "5      {'alpha': 10}        0.196549        0.217846        0.573969   \n",
       "6     {'alpha': 100}        0.196534        0.217959        0.573976   \n",
       "\n",
       "   split3_test_R2  ...  std_test_MAE  rank_test_MAE  split0_test_RMSE  \\\n",
       "0        0.011475  ...  1.162423e+14              7     -5.781487e+06   \n",
       "1        0.011475  ...  1.162423e+14              6     -5.781487e+06   \n",
       "2        0.011475  ...  1.162423e+14              5     -5.781487e+06   \n",
       "3        0.011475  ...  1.162423e+14              4     -5.781487e+06   \n",
       "4        0.011475  ...  1.162424e+14              3     -5.781485e+06   \n",
       "5        0.011478  ...  1.162429e+14              2     -5.781468e+06   \n",
       "6        0.011510  ...  1.162475e+14              1     -5.781299e+06   \n",
       "\n",
       "   split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0     -6.270626e+06     -6.306011e+06     -5.369203e+06     -5.328424e+06   \n",
       "1     -6.270626e+06     -6.306011e+06     -5.369203e+06     -5.328424e+06   \n",
       "2     -6.270626e+06     -6.306010e+06     -5.369203e+06     -5.328424e+06   \n",
       "3     -6.270625e+06     -6.306010e+06     -5.369202e+06     -5.328423e+06   \n",
       "4     -6.270620e+06     -6.306005e+06     -5.369199e+06     -5.328415e+06   \n",
       "5     -6.270568e+06     -6.305956e+06     -5.369166e+06     -5.328337e+06   \n",
       "6     -6.270047e+06     -6.305468e+06     -5.368834e+06     -5.327554e+06   \n",
       "\n",
       "   mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0   -5.811150e+06  420767.560292               7  \n",
       "1   -5.811150e+06  420767.560540               6  \n",
       "2   -5.811150e+06  420767.563015               5  \n",
       "3   -5.811149e+06  420767.587776               4  \n",
       "4   -5.811145e+06  420767.830638               3  \n",
       "5   -5.811099e+06  420770.134526               2  \n",
       "6   -5.810640e+06  420793.329129               1  \n",
       "\n",
       "[7 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyLassobest=pd.concat([pd.DataFrame(MyLasso.cv_results_)])\n",
    "MyLassobest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    0.360174\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyLassobestR2=MyLassobest[MyLassobest['rank_test_R2'].isin([1])]\n",
    "print(MyLassobestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.4s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03134828, 0.13093491, 0.2710227 , 0.80400624, 1.33655801,\n",
       "        0.01864605, 0.09619441, 0.21158528, 0.62347507, 1.02331505,\n",
       "        0.01838951, 0.09432478, 0.17930784, 0.55777125, 0.91769581,\n",
       "        0.01794171, 0.08375378, 0.15631294, 0.46963038, 0.78397107,\n",
       "        0.01420517, 0.0595561 , 0.12678213, 0.36717849, 0.61621208,\n",
       "        0.01562858, 0.04763012, 0.09217949, 0.27193213, 0.45245199,\n",
       "        0.01250114, 0.04712162, 0.09209375, 0.25774755, 0.43880844,\n",
       "        0.00633302, 0.0439702 , 0.07849245, 0.24120936, 0.40431261]),\n",
       " 'std_fit_time': array([1.53408037e-04, 9.20259977e-03, 4.88669663e-03, 6.25951755e-03,\n",
       "        1.27386143e-02, 6.31330997e-03, 3.99557741e-03, 6.95540170e-03,\n",
       "        8.01751965e-03, 1.19145610e-02, 8.26800369e-03, 1.66820469e-04,\n",
       "        7.60960348e-03, 5.78223796e-03, 1.63385111e-02, 6.86584577e-03,\n",
       "        6.60121181e-03, 1.67335511e-03, 8.22444538e-03, 8.20135247e-03,\n",
       "        1.10318145e-02, 1.31724843e-03, 5.72066139e-03, 2.23454362e-03,\n",
       "        3.72750080e-02, 9.18891310e-05, 2.38493703e-03, 7.14419588e-03,\n",
       "        6.33766858e-03, 6.47727811e-03, 6.25057386e-03, 1.99359942e-04,\n",
       "        4.66171700e-03, 7.57112114e-03, 2.21856917e-02, 7.75730762e-03,\n",
       "        6.36086285e-03, 8.36888473e-05, 9.15855509e-03, 8.14768755e-03]),\n",
       " 'mean_score_time': array([0.        , 0.0106915 , 0.00725322, 0.0251626 , 0.03352909,\n",
       "        0.00652218, 0.00743141, 0.00502615, 0.01350183, 0.03141751,\n",
       "        0.00354505, 0.00312529, 0.01248021, 0.01794953, 0.03452382,\n",
       "        0.00090103, 0.00423336, 0.01063728, 0.01874938, 0.03074079,\n",
       "        0.00180078, 0.00470128, 0.00659275, 0.02325687, 0.04217463,\n",
       "        0.        , 0.00582848, 0.0083302 , 0.01711349, 0.03101492,\n",
       "        0.        , 0.        , 0.00200109, 0.0155076 , 0.02357907,\n",
       "        0.00312519, 0.00312524, 0.00937896, 0.01753006, 0.02518783]),\n",
       " 'std_score_time': array([0.        , 0.00654914, 0.00707997, 0.00778771, 0.00706653,\n",
       "        0.00798995, 0.00700003, 0.00645305, 0.00424454, 0.00018615,\n",
       "        0.00609673, 0.00625057, 0.00624027, 0.00742232, 0.00631849,\n",
       "        0.00180206, 0.00609963, 0.00702054, 0.0062515 , 0.00042949,\n",
       "        0.00147033, 0.00239617, 0.00596978, 0.00684195, 0.00645938,\n",
       "        0.        , 0.00716955, 0.00707937, 0.00784644, 0.00070041,\n",
       "        0.        , 0.        , 0.00400219, 0.00025161, 0.00705256,\n",
       "        0.00625038, 0.00625048, 0.00765789, 0.00309515, 0.00765345]),\n",
       " 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 50, 100, 300, 500, 10, 50, 100, 300, 500, 10, 50,\n",
       "                    100, 300, 500, 10, 50, 100, 300, 500, 10, 50, 100, 300,\n",
       "                    500, 10, 50, 100, 300, 500, 10, 50, 100, 300, 500, 10,\n",
       "                    50, 100, 300, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_features': 'auto',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 10},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 300},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 500},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 10},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 50},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 100},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 300},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 500},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 300},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 500},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 300},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 500},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 10},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 300},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 500},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 10},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 50},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 100},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 300},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 500},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 300},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 500},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 300},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 500}],\n",
       " 'split0_test_R2': array([0.33449522, 0.28689578, 0.30802638, 0.27710792, 0.29558491,\n",
       "        0.25951024, 0.09374645, 0.16718842, 0.18524012, 0.16517689,\n",
       "        0.24771852, 0.28934394, 0.31671686, 0.29002895, 0.29699902,\n",
       "        0.32265804, 0.34751425, 0.30384098, 0.32843829, 0.32849305,\n",
       "        0.26267131, 0.31637115, 0.31749178, 0.33248217, 0.33300706,\n",
       "        0.25211643, 0.3267325 , 0.3267469 , 0.31182587, 0.31172019,\n",
       "        0.33532735, 0.30909515, 0.33884227, 0.31500178, 0.33231569,\n",
       "        0.30003977, 0.32356725, 0.33315441, 0.32427264, 0.3238178 ]),\n",
       " 'split1_test_R2': array([0.57963545, 0.59382808, 0.60742815, 0.63867006, 0.63374488,\n",
       "        0.5665152 , 0.65638931, 0.63812435, 0.6468658 , 0.64804197,\n",
       "        0.49287735, 0.58018238, 0.55206486, 0.58736751, 0.59255977,\n",
       "        0.43654556, 0.51384239, 0.52366678, 0.50740704, 0.50053712,\n",
       "        0.61579015, 0.64058004, 0.61932311, 0.62075194, 0.62811073,\n",
       "        0.51421345, 0.60299643, 0.63613922, 0.62652987, 0.63182465,\n",
       "        0.58499236, 0.601486  , 0.56659   , 0.60718248, 0.60937482,\n",
       "        0.54703162, 0.60058876, 0.58452445, 0.5816036 , 0.57867339]),\n",
       " 'split2_test_R2': array([0.41411867, 0.40932491, 0.42194299, 0.42849434, 0.40006656,\n",
       "        0.34998259, 0.42813777, 0.44558305, 0.43833211, 0.42927453,\n",
       "        0.43638875, 0.45731989, 0.45839782, 0.4537824 , 0.45264789,\n",
       "        0.39302561, 0.38924604, 0.40196194, 0.39785699, 0.4050972 ,\n",
       "        0.42305103, 0.44776095, 0.46480818, 0.53395844, 0.49830745,\n",
       "        0.4158331 , 0.45857591, 0.43821767, 0.44944882, 0.44037297,\n",
       "        0.34322718, 0.39468169, 0.40387341, 0.37618519, 0.36772673,\n",
       "        0.30236038, 0.29439576, 0.29449513, 0.30180845, 0.31947115]),\n",
       " 'split3_test_R2': array([ 0.29362892,  0.21597862,  0.05238913, -0.05208755,  0.06029786,\n",
       "         0.32024747,  0.14029329,  0.15828595,  0.21577088,  0.14609911,\n",
       "         0.16295021,  0.56406501,  0.5570743 ,  0.46816995,  0.49236777,\n",
       "         0.2690908 ,  0.46481163,  0.43900692,  0.44066545,  0.44965826,\n",
       "         0.29141328,  0.4047178 ,  0.51555026,  0.4288975 ,  0.42336135,\n",
       "         0.44159079,  0.5326217 ,  0.50509519,  0.48979157,  0.47536862,\n",
       "         0.39937878,  0.50630803,  0.5583309 ,  0.5470524 ,  0.55814913,\n",
       "         0.48680197,  0.56349869,  0.56274171,  0.58394034,  0.57480613]),\n",
       " 'split4_test_R2': array([0.81213735, 0.80314786, 0.80045866, 0.79770406, 0.80416971,\n",
       "        0.74756929, 0.73002394, 0.72158719, 0.73490997, 0.73011532,\n",
       "        0.60049041, 0.61761831, 0.6187138 , 0.60580694, 0.60044917,\n",
       "        0.58038194, 0.5489065 , 0.54668942, 0.54653436, 0.54675921,\n",
       "        0.80099254, 0.84333126, 0.82243791, 0.8270684 , 0.83578153,\n",
       "        0.65041258, 0.6414747 , 0.65560851, 0.66244343, 0.6721493 ,\n",
       "        0.54714259, 0.55317879, 0.56533527, 0.55940896, 0.56991283,\n",
       "        0.54878085, 0.4683522 , 0.44941826, 0.44830123, 0.45677974]),\n",
       " 'mean_test_R2': array([0.48680312, 0.46183505, 0.43804906, 0.41797776, 0.43877278,\n",
       "        0.44876495, 0.40971815, 0.42615379, 0.44422378, 0.42374157,\n",
       "        0.38808505, 0.5017059 , 0.50059353, 0.48103115, 0.48700472,\n",
       "        0.40034039, 0.45286416, 0.44303321, 0.44418043, 0.44610897,\n",
       "        0.47878366, 0.53055224, 0.54792225, 0.54863169, 0.54371363,\n",
       "        0.45483327, 0.51248025, 0.5123615 , 0.50800791, 0.50628714,\n",
       "        0.44201365, 0.47294993, 0.48659437, 0.48096616, 0.48749584,\n",
       "        0.43700292, 0.45008053, 0.44486679, 0.44798525, 0.45070964]),\n",
       " 'std_test_R2': array([0.18987217, 0.21341183, 0.25531505, 0.29455508, 0.25952774,\n",
       "        0.18179175, 0.25931047, 0.23298333, 0.22129628, 0.24006132,\n",
       "        0.16051116, 0.11878605, 0.10524531, 0.1133721 , 0.1107455 ,\n",
       "        0.10680851, 0.07514131, 0.08754875, 0.07749631, 0.07565839,\n",
       "        0.20371925, 0.18894395, 0.16823259, 0.16970594, 0.17514005,\n",
       "        0.13005212, 0.1119342 , 0.12316129, 0.12660662, 0.13147384,\n",
       "        0.10435849, 0.10681316, 0.09635248, 0.11399513, 0.11407406,\n",
       "        0.11310887, 0.12336419, 0.1170562 , 0.12083892, 0.11413727]),\n",
       " 'rank_test_R2': array([13, 19, 33, 37, 32, 24, 38, 35, 28, 36, 40,  9, 10, 15, 12, 39, 21,\n",
       "        30, 29, 26, 17,  4,  2,  1,  3, 20,  5,  6,  7,  8, 31, 18, 14, 16,\n",
       "        11, 34, 23, 27, 25, 22]),\n",
       " 'split0_test_MAE': array([-2.78999506e+14, -2.98954612e+14, -2.90096036e+14, -3.03057978e+14,\n",
       "        -2.95311871e+14, -3.10435452e+14, -3.79928588e+14, -3.49139517e+14,\n",
       "        -3.41571705e+14, -3.49982811e+14, -3.15378892e+14, -2.97928274e+14,\n",
       "        -2.86452724e+14, -2.97641095e+14, -2.94719035e+14, -2.83962007e+14,\n",
       "        -2.73541539e+14, -2.91850679e+14, -2.81538753e+14, -2.81515795e+14,\n",
       "        -3.09110235e+14, -2.86597659e+14, -2.86127854e+14, -2.79843434e+14,\n",
       "        -2.79623386e+14, -3.13535157e+14, -2.82253869e+14, -2.82247831e+14,\n",
       "        -2.88503177e+14, -2.88547479e+14, -2.78650651e+14, -2.89647974e+14,\n",
       "        -2.77177091e+14, -2.87171737e+14, -2.79913229e+14, -2.93444260e+14,\n",
       "        -2.83580836e+14, -2.79561614e+14, -2.83285115e+14, -2.83475798e+14]),\n",
       " 'split1_test_MAE': array([-5.67677756e+13, -5.48511444e+13, -5.30145343e+13, -4.87954970e+13,\n",
       "        -4.94606134e+13, -5.85395897e+13, -4.64026165e+13, -4.88691920e+13,\n",
       "        -4.76887105e+13, -4.75298751e+13, -6.84839510e+13, -5.66939165e+13,\n",
       "        -6.04910228e+13, -5.57236065e+13, -5.50224222e+13, -7.60912296e+13,\n",
       "        -6.56527452e+13, -6.43260184e+13, -6.65218004e+13, -6.74495431e+13,\n",
       "        -5.18852955e+13, -4.85375657e+13, -5.14081892e+13, -5.12152341e+13,\n",
       "        -5.02214724e+13, -6.56026354e+13, -5.36130126e+13, -4.91372727e+13,\n",
       "        -5.04349589e+13, -4.97199300e+13, -5.60443570e+13, -5.38169877e+13,\n",
       "        -5.85294874e+13, -5.30477105e+13, -5.27516481e+13, -6.11707326e+13,\n",
       "        -5.39381547e+13, -5.61075450e+13, -5.65019887e+13, -5.68976964e+13]),\n",
       " 'split2_test_MAE': array([-4.90150351e+14, -4.94160821e+14, -4.83604499e+14, -4.78123616e+14,\n",
       "        -5.01906396e+14, -5.43806820e+14, -4.78421924e+14, -4.63827140e+14,\n",
       "        -4.69893302e+14, -4.77470903e+14, -4.71519125e+14, -4.54008057e+14,\n",
       "        -4.53106262e+14, -4.56967537e+14, -4.57916670e+14, -5.07796877e+14,\n",
       "        -5.10958879e+14, -5.00320711e+14, -5.03754924e+14, -4.97697744e+14,\n",
       "        -4.82677506e+14, -4.62005100e+14, -4.47743328e+14, -3.89891983e+14,\n",
       "        -4.19717722e+14, -4.88716048e+14, -4.52957269e+14, -4.69989040e+14,\n",
       "        -4.60593020e+14, -4.68185913e+14, -5.49458414e+14, -5.06411392e+14,\n",
       "        -4.98721573e+14, -5.21885628e+14, -5.28962008e+14, -5.83647721e+14,\n",
       "        -5.90310952e+14, -5.90227820e+14, -5.84109471e+14, -5.69332791e+14]),\n",
       " 'split3_test_MAE': array([-7.29236202e+13, -8.09400025e+13, -9.78284884e+13, -1.08614346e+14,\n",
       "        -9.70120155e+13, -7.01756018e+13, -8.87535277e+13, -8.68960203e+13,\n",
       "        -8.09614492e+13, -8.81541527e+13, -8.64144959e+13, -4.50046142e+13,\n",
       "        -4.57263139e+13, -5.49045307e+13, -5.24064211e+13, -7.54568615e+13,\n",
       "        -5.52512335e+13, -5.79152342e+13, -5.77440124e+13, -5.68156218e+13,\n",
       "        -7.31523560e+13, -6.14551395e+13, -5.00131299e+13, -5.89588996e+13,\n",
       "        -5.95304350e+13, -5.76484827e+13, -4.82507265e+13, -5.10924802e+13,\n",
       "        -5.26723793e+13, -5.41613620e+13, -6.20063231e+13, -5.09672705e+13,\n",
       "        -4.55965861e+13, -4.67609438e+13, -4.56153511e+13, -5.29810170e+13,\n",
       "        -4.50630789e+13, -4.51412275e+13, -4.29527443e+13, -4.38957332e+13]),\n",
       " 'split4_test_MAE': array([-1.15709852e+14, -1.21246729e+14, -1.22903082e+14, -1.24599717e+14,\n",
       "        -1.20617338e+14, -1.55479121e+14, -1.66285792e+14, -1.71482221e+14,\n",
       "        -1.63276348e+14, -1.66229506e+14, -2.46069107e+14, -2.35519556e+14,\n",
       "        -2.34844812e+14, -2.42794509e+14, -2.46094510e+14, -2.58454473e+14,\n",
       "        -2.77841076e+14, -2.79206638e+14, -2.79302143e+14, -2.79163650e+14,\n",
       "        -1.22574249e+14, -9.64966475e+13, -1.09365446e+14, -1.06513401e+14,\n",
       "        -1.01146737e+14, -2.15320650e+14, -2.20825737e+14, -2.12120329e+14,\n",
       "        -2.07910510e+14, -2.01932394e+14, -2.78927517e+14, -2.75209656e+14,\n",
       "        -2.67722141e+14, -2.71372320e+14, -2.64902692e+14, -2.77918466e+14,\n",
       "        -3.27456716e+14, -3.39118662e+14, -3.39806671e+14, -3.34584518e+14]),\n",
       " 'mean_test_MAE': array([-2.02910221e+14, -2.10030662e+14, -2.09489328e+14, -2.12638231e+14,\n",
       "        -2.12861647e+14, -2.27687317e+14, -2.31958490e+14, -2.24042818e+14,\n",
       "        -2.20678303e+14, -2.25873450e+14, -2.37573114e+14, -2.17830884e+14,\n",
       "        -2.16124227e+14, -2.21606256e+14, -2.21231812e+14, -2.40352290e+14,\n",
       "        -2.36649094e+14, -2.38723856e+14, -2.37772326e+14, -2.36528471e+14,\n",
       "        -2.07879928e+14, -1.91018422e+14, -1.88931589e+14, -1.77284590e+14,\n",
       "        -1.82047950e+14, -2.28164595e+14, -2.11580123e+14, -2.12917391e+14,\n",
       "        -2.12022809e+14, -2.12509416e+14, -2.45017452e+14, -2.35210656e+14,\n",
       "        -2.29549376e+14, -2.36047668e+14, -2.34428986e+14, -2.53832439e+14,\n",
       "        -2.60069948e+14, -2.62031374e+14, -2.61331198e+14, -2.57637307e+14]),\n",
       " 'std_test_MAE': array([1.63801408e+14, 1.65689519e+14, 1.58799402e+14, 1.57527401e+14,\n",
       "        1.66718298e+14, 1.81886619e+14, 1.68458256e+14, 1.58368788e+14,\n",
       "        1.60912717e+14, 1.63116429e+14, 1.49864425e+14, 1.53845494e+14,\n",
       "        1.51468931e+14, 1.52925923e+14, 1.53730818e+14, 1.59955182e+14,\n",
       "        1.67599896e+14, 1.64924585e+14, 1.64999336e+14, 1.63055450e+14,\n",
       "        1.64635468e+14, 1.60368934e+14, 1.55545765e+14, 1.34627808e+14,\n",
       "        1.44873499e+14, 1.61766681e+14, 1.51639893e+14, 1.57419444e+14,\n",
       "        1.54373897e+14, 1.56740967e+14, 1.81201152e+14, 1.70271823e+14,\n",
       "        1.66892577e+14, 1.76001869e+14, 1.77991240e+14, 1.94106764e+14,\n",
       "        2.01430449e+14, 2.01697112e+14, 2.00235033e+14, 1.94794470e+14]),\n",
       " 'rank_test_MAE': array([ 5,  8,  7, 12, 13, 22, 25, 20, 17, 21, 31, 16, 15, 19, 18, 34, 30,\n",
       "        33, 32, 29,  6,  4,  3,  1,  2, 23,  9, 14, 10, 11, 35, 27, 24, 28,\n",
       "        26, 36, 38, 40, 39, 37]),\n",
       " 'split0_test_RMSE': array([-5141765.38392685, -4844706.74675135, -4700432.12329976,\n",
       "        -4849749.63531606, -4788826.82042715, -4744203.94146633,\n",
       "        -5243061.47814959, -5128609.68018013, -5094968.28939538,\n",
       "        -5069833.11242604, -4868738.12412592, -4739628.56256942,\n",
       "        -4611346.64151468, -4773554.49899797, -4734733.12142175,\n",
       "        -4837758.69633803, -4946545.70427228, -4999852.8568685 ,\n",
       "        -4953251.3907791 , -4977872.94687166, -4707131.9287653 ,\n",
       "        -4262429.05319667, -4205608.52719525, -4258527.44212783,\n",
       "        -4324909.13719422, -4406316.94199428, -4378719.47206288,\n",
       "        -4341981.91611469, -4397987.791364  , -4407635.18229331,\n",
       "        -4447254.90868242, -4350972.79638575, -4343324.1328928 ,\n",
       "        -4329333.19236115, -4375938.43756976, -4652798.70669477,\n",
       "        -4582027.59761709, -4480553.70746158, -4618329.20814724,\n",
       "        -4523689.49459302]),\n",
       " 'split1_test_RMSE': array([-4019572.4089932 , -3909604.53444103, -3871105.87795533,\n",
       "        -3765863.08093964, -3754916.62181591, -4050466.52103046,\n",
       "        -3677278.67319501, -3801080.28149942, -3799328.08680626,\n",
       "        -3730709.50123569, -4236319.53031695, -3952370.9763364 ,\n",
       "        -3972969.15551493, -3931704.91487753, -3921346.79634368,\n",
       "        -4205745.39574125, -4069169.19197083, -4112055.53034185,\n",
       "        -4110864.395588  , -4141561.34605708, -3930387.26926612,\n",
       "        -3722683.57980196, -3688307.61232592, -3731884.75016029,\n",
       "        -3736796.23212365, -4401858.75979215, -4055721.21065229,\n",
       "        -3895169.76953762, -3935850.81787399, -3918503.79874321,\n",
       "        -4003652.26030739, -4157040.40623772, -4280634.92809831,\n",
       "        -4113609.30647913, -4104847.28395691, -4344184.2856375 ,\n",
       "        -4223193.74183889, -4301634.79551514, -4300849.44547409,\n",
       "        -4390194.41189739]),\n",
       " 'split2_test_RMSE': array([-5773763.41939106, -5640231.49996312, -5622968.39863355,\n",
       "        -5600291.8431924 , -5632499.14700643, -5448679.59918013,\n",
       "        -5513964.88307503, -5532458.45398611, -5492268.68475265,\n",
       "        -5521473.75371582, -5468646.3060198 , -5529291.86314463,\n",
       "        -5542213.6162731 , -5590574.35267319, -5545319.76005944,\n",
       "        -5632213.30792294, -5522141.1550854 , -5528053.85444762,\n",
       "        -5576381.0777396 , -5587724.71591542, -5550860.59514368,\n",
       "        -5267648.04329874, -5490578.63023403, -5228406.1374495 ,\n",
       "        -5228898.43339629, -5455380.23665719, -5369682.4134089 ,\n",
       "        -5350481.49427893, -5282742.83781593, -5326348.42683561,\n",
       "        -5576370.32989049, -5515247.41435924, -5531186.60548623,\n",
       "        -5502490.09954522, -5545783.59838726, -6137020.86866746,\n",
       "        -5731265.47792199, -5882756.88430984, -5837319.16022052,\n",
       "        -5766503.53859571]),\n",
       " 'split3_test_RMSE': array([-3891724.57546034, -3781505.75051529, -3919003.00154211,\n",
       "        -3950900.24991186, -3869503.96355253, -3814558.97118048,\n",
       "        -3873443.56346801, -3818226.20526575, -3819714.8938759 ,\n",
       "        -3878534.68869928, -4037257.50099872, -3538225.81517314,\n",
       "        -3494928.48005411, -3637050.73642092, -3629432.05404566,\n",
       "        -3893335.90776387, -3726335.48747195, -3736835.35543291,\n",
       "        -3787359.95179527, -3752759.82329403, -3641995.02207933,\n",
       "        -3736243.14566926, -3543936.56586091, -3601442.78705293,\n",
       "        -3607356.23627582, -3918121.24284529, -3712317.58631816,\n",
       "        -3625043.15760787, -3653623.99343695, -3675817.0808394 ,\n",
       "        -3907979.93540409, -3744592.68993245, -3721333.70494139,\n",
       "        -3723330.7998014 , -3676296.23931777, -3911779.21083642,\n",
       "        -3953110.14044881, -3881197.33672101, -3839830.39548524,\n",
       "        -3839894.06071164]),\n",
       " 'split4_test_RMSE': array([-4113694.25385718, -4194639.28032697, -4103725.74763899,\n",
       "        -4162265.6590226 , -4200324.37578696, -4434483.66873247,\n",
       "        -4314865.52974085, -4315705.61421569, -4370262.0269248 ,\n",
       "        -4354282.76352194, -5224762.6907585 , -4804729.96231337,\n",
       "        -4840794.48785454, -4836828.93337694, -4871952.3853751 ,\n",
       "        -4840856.95100103, -4838023.31370138, -4856850.19443825,\n",
       "        -4829479.81610248, -4834072.11440102, -4451858.66438315,\n",
       "        -4162598.7912221 , -4002936.59351541, -4049338.86412577,\n",
       "        -4037395.7925121 , -4424540.93506687, -4541783.13221969,\n",
       "        -4518293.13069612, -4473700.47524363, -4438003.36122753,\n",
       "        -4946276.37956988, -4811068.55594703, -4809577.71822632,\n",
       "        -4762420.21134582, -4781988.06525284, -5109127.97716656,\n",
       "        -5280113.43043167, -5319382.95893243, -5252751.98278556,\n",
       "        -5218409.06193999]),\n",
       " 'mean_test_RMSE': array([-4588104.00832573, -4474137.56239955, -4443447.02981395,\n",
       "        -4465814.09367651, -4449214.1857178 , -4498478.54031797,\n",
       "        -4524522.8255257 , -4519216.04702942, -4515308.396351  ,\n",
       "        -4510966.76391975, -4767144.83044398, -4512849.43590739,\n",
       "        -4492450.47624227, -4553942.68726931, -4540556.82344913,\n",
       "        -4681982.05175342, -4620442.97050037, -4646729.55830583,\n",
       "        -4651467.32640089, -4658798.18930784, -4456446.69592751,\n",
       "        -4230320.52263775, -4186273.5858263 , -4173919.99618326,\n",
       "        -4187071.16630042, -4521243.62327116, -4411644.76293238,\n",
       "        -4346193.89364705, -4348781.1831469 , -4353261.56998781,\n",
       "        -4576306.76277085, -4515784.37257244, -4537211.41792901,\n",
       "        -4486236.72190654, -4496970.72489691, -4830982.20980054,\n",
       "        -4753942.07765169, -4773105.136588  , -4769816.03842253,\n",
       "        -4747738.11354755]),\n",
       " 'std_test_RMSE': array([741021.76310453, 689006.85740931, 659596.61615861, 675522.84982721,\n",
       "        692179.05597851, 571982.36250724, 732253.56556018, 699505.96961473,\n",
       "        679407.61996656, 688008.36821059, 552512.55851333, 697682.66821081,\n",
       "        707445.18857278, 697241.691342  , 688570.31812776, 600201.82101852,\n",
       "        643439.94046167, 641773.01864246, 635163.06553029, 645580.91890516,\n",
       "        663426.85628596, 562756.30532674, 692208.76902232, 575802.95487203,\n",
       "        577169.47158431, 504614.72745889, 557063.06369909, 593584.13347209,\n",
       "        555709.54593063, 566565.27380395, 621007.72363119, 606088.41289844,\n",
       "        605185.97009506, 609022.75847392, 636106.83799083, 761151.4671091 ,\n",
       "        660998.86494002, 725688.17064444, 704349.52438747, 672551.89233974]),\n",
       " 'rank_test_RMSE': array([29, 13,  9, 12, 10, 17, 24, 22, 20, 18, 37, 19, 15, 27, 26, 34, 30,\n",
       "        31, 32, 33, 11,  4,  2,  1,  3, 23,  8,  5,  6,  7, 28, 21, 25, 14,\n",
       "        16, 40, 36, 39, 38, 35])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Randomparams = {\n",
    "    'n_estimators' : [10,50,100,300,500],\n",
    "    'min_samples_leaf' : [1,3,5,10], \n",
    "    'max_features': ['auto', 'sqrt'] \n",
    "}\n",
    "MyRandom = GridSearchCV(RandomForestRegressor(),\n",
    "                        param_grid = Randomparams,\n",
    "                        scoring=scoring,\n",
    "                        refit=False,\n",
    "                        verbose=2,\n",
    "                        cv=CV)\n",
    "\n",
    "MyRandom.fit(X_train_std, y_train)\n",
    "MyRandom.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031348</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.334495</td>\n",
       "      <td>0.579635</td>\n",
       "      <td>...</td>\n",
       "      <td>1.638014e+14</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.141765e+06</td>\n",
       "      <td>-4.019572e+06</td>\n",
       "      <td>-5.773763e+06</td>\n",
       "      <td>-3.891725e+06</td>\n",
       "      <td>-4.113694e+06</td>\n",
       "      <td>-4.588104e+06</td>\n",
       "      <td>741021.763105</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130935</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>0.010691</td>\n",
       "      <td>0.006549</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.286896</td>\n",
       "      <td>0.593828</td>\n",
       "      <td>...</td>\n",
       "      <td>1.656895e+14</td>\n",
       "      <td>8</td>\n",
       "      <td>-4.844707e+06</td>\n",
       "      <td>-3.909605e+06</td>\n",
       "      <td>-5.640231e+06</td>\n",
       "      <td>-3.781506e+06</td>\n",
       "      <td>-4.194639e+06</td>\n",
       "      <td>-4.474138e+06</td>\n",
       "      <td>689006.857409</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.271023</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.308026</td>\n",
       "      <td>0.607428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.587994e+14</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.700432e+06</td>\n",
       "      <td>-3.871106e+06</td>\n",
       "      <td>-5.622968e+06</td>\n",
       "      <td>-3.919003e+06</td>\n",
       "      <td>-4.103726e+06</td>\n",
       "      <td>-4.443447e+06</td>\n",
       "      <td>659596.616159</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.804006</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>0.025163</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.277108</td>\n",
       "      <td>0.638670</td>\n",
       "      <td>...</td>\n",
       "      <td>1.575274e+14</td>\n",
       "      <td>12</td>\n",
       "      <td>-4.849750e+06</td>\n",
       "      <td>-3.765863e+06</td>\n",
       "      <td>-5.600292e+06</td>\n",
       "      <td>-3.950900e+06</td>\n",
       "      <td>-4.162266e+06</td>\n",
       "      <td>-4.465814e+06</td>\n",
       "      <td>675522.849827</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.336558</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.295585</td>\n",
       "      <td>0.633745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.667183e+14</td>\n",
       "      <td>13</td>\n",
       "      <td>-4.788827e+06</td>\n",
       "      <td>-3.754917e+06</td>\n",
       "      <td>-5.632499e+06</td>\n",
       "      <td>-3.869504e+06</td>\n",
       "      <td>-4.200324e+06</td>\n",
       "      <td>-4.449214e+06</td>\n",
       "      <td>692179.055979</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018646</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.259510</td>\n",
       "      <td>0.566515</td>\n",
       "      <td>...</td>\n",
       "      <td>1.818866e+14</td>\n",
       "      <td>22</td>\n",
       "      <td>-4.744204e+06</td>\n",
       "      <td>-4.050467e+06</td>\n",
       "      <td>-5.448680e+06</td>\n",
       "      <td>-3.814559e+06</td>\n",
       "      <td>-4.434484e+06</td>\n",
       "      <td>-4.498479e+06</td>\n",
       "      <td>571982.362507</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.096194</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.007431</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.093746</td>\n",
       "      <td>0.656389</td>\n",
       "      <td>...</td>\n",
       "      <td>1.684583e+14</td>\n",
       "      <td>25</td>\n",
       "      <td>-5.243061e+06</td>\n",
       "      <td>-3.677279e+06</td>\n",
       "      <td>-5.513965e+06</td>\n",
       "      <td>-3.873444e+06</td>\n",
       "      <td>-4.314866e+06</td>\n",
       "      <td>-4.524523e+06</td>\n",
       "      <td>732253.565560</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.211585</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.167188</td>\n",
       "      <td>0.638124</td>\n",
       "      <td>...</td>\n",
       "      <td>1.583688e+14</td>\n",
       "      <td>20</td>\n",
       "      <td>-5.128610e+06</td>\n",
       "      <td>-3.801080e+06</td>\n",
       "      <td>-5.532458e+06</td>\n",
       "      <td>-3.818226e+06</td>\n",
       "      <td>-4.315706e+06</td>\n",
       "      <td>-4.519216e+06</td>\n",
       "      <td>699505.969615</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.623475</td>\n",
       "      <td>0.008018</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.185240</td>\n",
       "      <td>0.646866</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609127e+14</td>\n",
       "      <td>17</td>\n",
       "      <td>-5.094968e+06</td>\n",
       "      <td>-3.799328e+06</td>\n",
       "      <td>-5.492269e+06</td>\n",
       "      <td>-3.819715e+06</td>\n",
       "      <td>-4.370262e+06</td>\n",
       "      <td>-4.515308e+06</td>\n",
       "      <td>679407.619967</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.023315</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.031418</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.165177</td>\n",
       "      <td>0.648042</td>\n",
       "      <td>...</td>\n",
       "      <td>1.631164e+14</td>\n",
       "      <td>21</td>\n",
       "      <td>-5.069833e+06</td>\n",
       "      <td>-3.730710e+06</td>\n",
       "      <td>-5.521474e+06</td>\n",
       "      <td>-3.878535e+06</td>\n",
       "      <td>-4.354283e+06</td>\n",
       "      <td>-4.510967e+06</td>\n",
       "      <td>688008.368211</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018390</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.003545</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.247719</td>\n",
       "      <td>0.492877</td>\n",
       "      <td>...</td>\n",
       "      <td>1.498644e+14</td>\n",
       "      <td>31</td>\n",
       "      <td>-4.868738e+06</td>\n",
       "      <td>-4.236320e+06</td>\n",
       "      <td>-5.468646e+06</td>\n",
       "      <td>-4.037258e+06</td>\n",
       "      <td>-5.224763e+06</td>\n",
       "      <td>-4.767145e+06</td>\n",
       "      <td>552512.558513</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.094325</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.289344</td>\n",
       "      <td>0.580182</td>\n",
       "      <td>...</td>\n",
       "      <td>1.538455e+14</td>\n",
       "      <td>16</td>\n",
       "      <td>-4.739629e+06</td>\n",
       "      <td>-3.952371e+06</td>\n",
       "      <td>-5.529292e+06</td>\n",
       "      <td>-3.538226e+06</td>\n",
       "      <td>-4.804730e+06</td>\n",
       "      <td>-4.512849e+06</td>\n",
       "      <td>697682.668211</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.179308</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>0.006240</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.316717</td>\n",
       "      <td>0.552065</td>\n",
       "      <td>...</td>\n",
       "      <td>1.514689e+14</td>\n",
       "      <td>15</td>\n",
       "      <td>-4.611347e+06</td>\n",
       "      <td>-3.972969e+06</td>\n",
       "      <td>-5.542214e+06</td>\n",
       "      <td>-3.494928e+06</td>\n",
       "      <td>-4.840794e+06</td>\n",
       "      <td>-4.492450e+06</td>\n",
       "      <td>707445.188573</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.557771</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.017950</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.290029</td>\n",
       "      <td>0.587368</td>\n",
       "      <td>...</td>\n",
       "      <td>1.529259e+14</td>\n",
       "      <td>19</td>\n",
       "      <td>-4.773554e+06</td>\n",
       "      <td>-3.931705e+06</td>\n",
       "      <td>-5.590574e+06</td>\n",
       "      <td>-3.637051e+06</td>\n",
       "      <td>-4.836829e+06</td>\n",
       "      <td>-4.553943e+06</td>\n",
       "      <td>697241.691342</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.917696</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.034524</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.296999</td>\n",
       "      <td>0.592560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537308e+14</td>\n",
       "      <td>18</td>\n",
       "      <td>-4.734733e+06</td>\n",
       "      <td>-3.921347e+06</td>\n",
       "      <td>-5.545320e+06</td>\n",
       "      <td>-3.629432e+06</td>\n",
       "      <td>-4.871952e+06</td>\n",
       "      <td>-4.540557e+06</td>\n",
       "      <td>688570.318128</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.017942</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.322658</td>\n",
       "      <td>0.436546</td>\n",
       "      <td>...</td>\n",
       "      <td>1.599552e+14</td>\n",
       "      <td>34</td>\n",
       "      <td>-4.837759e+06</td>\n",
       "      <td>-4.205745e+06</td>\n",
       "      <td>-5.632213e+06</td>\n",
       "      <td>-3.893336e+06</td>\n",
       "      <td>-4.840857e+06</td>\n",
       "      <td>-4.681982e+06</td>\n",
       "      <td>600201.821019</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.083754</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.347514</td>\n",
       "      <td>0.513842</td>\n",
       "      <td>...</td>\n",
       "      <td>1.675999e+14</td>\n",
       "      <td>30</td>\n",
       "      <td>-4.946546e+06</td>\n",
       "      <td>-4.069169e+06</td>\n",
       "      <td>-5.522141e+06</td>\n",
       "      <td>-3.726335e+06</td>\n",
       "      <td>-4.838023e+06</td>\n",
       "      <td>-4.620443e+06</td>\n",
       "      <td>643439.940462</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.156313</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.010637</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.303841</td>\n",
       "      <td>0.523667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.649246e+14</td>\n",
       "      <td>33</td>\n",
       "      <td>-4.999853e+06</td>\n",
       "      <td>-4.112056e+06</td>\n",
       "      <td>-5.528054e+06</td>\n",
       "      <td>-3.736835e+06</td>\n",
       "      <td>-4.856850e+06</td>\n",
       "      <td>-4.646730e+06</td>\n",
       "      <td>641773.018642</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.469630</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.328438</td>\n",
       "      <td>0.507407</td>\n",
       "      <td>...</td>\n",
       "      <td>1.649993e+14</td>\n",
       "      <td>32</td>\n",
       "      <td>-4.953251e+06</td>\n",
       "      <td>-4.110864e+06</td>\n",
       "      <td>-5.576381e+06</td>\n",
       "      <td>-3.787360e+06</td>\n",
       "      <td>-4.829480e+06</td>\n",
       "      <td>-4.651467e+06</td>\n",
       "      <td>635163.065530</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.783971</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.030741</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.328493</td>\n",
       "      <td>0.500537</td>\n",
       "      <td>...</td>\n",
       "      <td>1.630555e+14</td>\n",
       "      <td>29</td>\n",
       "      <td>-4.977873e+06</td>\n",
       "      <td>-4.141561e+06</td>\n",
       "      <td>-5.587725e+06</td>\n",
       "      <td>-3.752760e+06</td>\n",
       "      <td>-4.834072e+06</td>\n",
       "      <td>-4.658798e+06</td>\n",
       "      <td>645580.918905</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.011032</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.262671</td>\n",
       "      <td>0.615790</td>\n",
       "      <td>...</td>\n",
       "      <td>1.646355e+14</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.707132e+06</td>\n",
       "      <td>-3.930387e+06</td>\n",
       "      <td>-5.550861e+06</td>\n",
       "      <td>-3.641995e+06</td>\n",
       "      <td>-4.451859e+06</td>\n",
       "      <td>-4.456447e+06</td>\n",
       "      <td>663426.856286</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.316371</td>\n",
       "      <td>0.640580</td>\n",
       "      <td>...</td>\n",
       "      <td>1.603689e+14</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.262429e+06</td>\n",
       "      <td>-3.722684e+06</td>\n",
       "      <td>-5.267648e+06</td>\n",
       "      <td>-3.736243e+06</td>\n",
       "      <td>-4.162599e+06</td>\n",
       "      <td>-4.230321e+06</td>\n",
       "      <td>562756.305327</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.126782</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.317492</td>\n",
       "      <td>0.619323</td>\n",
       "      <td>...</td>\n",
       "      <td>1.555458e+14</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.205609e+06</td>\n",
       "      <td>-3.688308e+06</td>\n",
       "      <td>-5.490579e+06</td>\n",
       "      <td>-3.543937e+06</td>\n",
       "      <td>-4.002937e+06</td>\n",
       "      <td>-4.186274e+06</td>\n",
       "      <td>692208.769022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.367178</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.332482</td>\n",
       "      <td>0.620752</td>\n",
       "      <td>...</td>\n",
       "      <td>1.346278e+14</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.258527e+06</td>\n",
       "      <td>-3.731885e+06</td>\n",
       "      <td>-5.228406e+06</td>\n",
       "      <td>-3.601443e+06</td>\n",
       "      <td>-4.049339e+06</td>\n",
       "      <td>-4.173920e+06</td>\n",
       "      <td>575802.954872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.616212</td>\n",
       "      <td>0.037275</td>\n",
       "      <td>0.042175</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.333007</td>\n",
       "      <td>0.628111</td>\n",
       "      <td>...</td>\n",
       "      <td>1.448735e+14</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.324909e+06</td>\n",
       "      <td>-3.736796e+06</td>\n",
       "      <td>-5.228898e+06</td>\n",
       "      <td>-3.607356e+06</td>\n",
       "      <td>-4.037396e+06</td>\n",
       "      <td>-4.187071e+06</td>\n",
       "      <td>577169.471584</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.252116</td>\n",
       "      <td>0.514213</td>\n",
       "      <td>...</td>\n",
       "      <td>1.617667e+14</td>\n",
       "      <td>23</td>\n",
       "      <td>-4.406317e+06</td>\n",
       "      <td>-4.401859e+06</td>\n",
       "      <td>-5.455380e+06</td>\n",
       "      <td>-3.918121e+06</td>\n",
       "      <td>-4.424541e+06</td>\n",
       "      <td>-4.521244e+06</td>\n",
       "      <td>504614.727459</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.047630</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>0.602996</td>\n",
       "      <td>...</td>\n",
       "      <td>1.516399e+14</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.378719e+06</td>\n",
       "      <td>-4.055721e+06</td>\n",
       "      <td>-5.369682e+06</td>\n",
       "      <td>-3.712318e+06</td>\n",
       "      <td>-4.541783e+06</td>\n",
       "      <td>-4.411645e+06</td>\n",
       "      <td>557063.063699</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.092179</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.326747</td>\n",
       "      <td>0.636139</td>\n",
       "      <td>...</td>\n",
       "      <td>1.574194e+14</td>\n",
       "      <td>14</td>\n",
       "      <td>-4.341982e+06</td>\n",
       "      <td>-3.895170e+06</td>\n",
       "      <td>-5.350481e+06</td>\n",
       "      <td>-3.625043e+06</td>\n",
       "      <td>-4.518293e+06</td>\n",
       "      <td>-4.346194e+06</td>\n",
       "      <td>593584.133472</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.271932</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.017113</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.311826</td>\n",
       "      <td>0.626530</td>\n",
       "      <td>...</td>\n",
       "      <td>1.543739e+14</td>\n",
       "      <td>10</td>\n",
       "      <td>-4.397988e+06</td>\n",
       "      <td>-3.935851e+06</td>\n",
       "      <td>-5.282743e+06</td>\n",
       "      <td>-3.653624e+06</td>\n",
       "      <td>-4.473700e+06</td>\n",
       "      <td>-4.348781e+06</td>\n",
       "      <td>555709.545931</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.452452</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>0.031015</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.311720</td>\n",
       "      <td>0.631825</td>\n",
       "      <td>...</td>\n",
       "      <td>1.567410e+14</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.407635e+06</td>\n",
       "      <td>-3.918504e+06</td>\n",
       "      <td>-5.326348e+06</td>\n",
       "      <td>-3.675817e+06</td>\n",
       "      <td>-4.438003e+06</td>\n",
       "      <td>-4.353262e+06</td>\n",
       "      <td>566565.273804</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.335327</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>...</td>\n",
       "      <td>1.812012e+14</td>\n",
       "      <td>35</td>\n",
       "      <td>-4.447255e+06</td>\n",
       "      <td>-4.003652e+06</td>\n",
       "      <td>-5.576370e+06</td>\n",
       "      <td>-3.907980e+06</td>\n",
       "      <td>-4.946276e+06</td>\n",
       "      <td>-4.576307e+06</td>\n",
       "      <td>621007.723631</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.047122</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.309095</td>\n",
       "      <td>0.601486</td>\n",
       "      <td>...</td>\n",
       "      <td>1.702718e+14</td>\n",
       "      <td>27</td>\n",
       "      <td>-4.350973e+06</td>\n",
       "      <td>-4.157040e+06</td>\n",
       "      <td>-5.515247e+06</td>\n",
       "      <td>-3.744593e+06</td>\n",
       "      <td>-4.811069e+06</td>\n",
       "      <td>-4.515784e+06</td>\n",
       "      <td>606088.412898</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.092094</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.338842</td>\n",
       "      <td>0.566590</td>\n",
       "      <td>...</td>\n",
       "      <td>1.668926e+14</td>\n",
       "      <td>24</td>\n",
       "      <td>-4.343324e+06</td>\n",
       "      <td>-4.280635e+06</td>\n",
       "      <td>-5.531187e+06</td>\n",
       "      <td>-3.721334e+06</td>\n",
       "      <td>-4.809578e+06</td>\n",
       "      <td>-4.537211e+06</td>\n",
       "      <td>605185.970095</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.257748</td>\n",
       "      <td>0.007571</td>\n",
       "      <td>0.015508</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.315002</td>\n",
       "      <td>0.607182</td>\n",
       "      <td>...</td>\n",
       "      <td>1.760019e+14</td>\n",
       "      <td>28</td>\n",
       "      <td>-4.329333e+06</td>\n",
       "      <td>-4.113609e+06</td>\n",
       "      <td>-5.502490e+06</td>\n",
       "      <td>-3.723331e+06</td>\n",
       "      <td>-4.762420e+06</td>\n",
       "      <td>-4.486237e+06</td>\n",
       "      <td>609022.758474</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.438808</td>\n",
       "      <td>0.022186</td>\n",
       "      <td>0.023579</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.332316</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.779912e+14</td>\n",
       "      <td>26</td>\n",
       "      <td>-4.375938e+06</td>\n",
       "      <td>-4.104847e+06</td>\n",
       "      <td>-5.545784e+06</td>\n",
       "      <td>-3.676296e+06</td>\n",
       "      <td>-4.781988e+06</td>\n",
       "      <td>-4.496971e+06</td>\n",
       "      <td>636106.837991</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.007757</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.300040</td>\n",
       "      <td>0.547032</td>\n",
       "      <td>...</td>\n",
       "      <td>1.941068e+14</td>\n",
       "      <td>36</td>\n",
       "      <td>-4.652799e+06</td>\n",
       "      <td>-4.344184e+06</td>\n",
       "      <td>-6.137021e+06</td>\n",
       "      <td>-3.911779e+06</td>\n",
       "      <td>-5.109128e+06</td>\n",
       "      <td>-4.830982e+06</td>\n",
       "      <td>761151.467109</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.043970</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.323567</td>\n",
       "      <td>0.600589</td>\n",
       "      <td>...</td>\n",
       "      <td>2.014304e+14</td>\n",
       "      <td>38</td>\n",
       "      <td>-4.582028e+06</td>\n",
       "      <td>-4.223194e+06</td>\n",
       "      <td>-5.731265e+06</td>\n",
       "      <td>-3.953110e+06</td>\n",
       "      <td>-5.280113e+06</td>\n",
       "      <td>-4.753942e+06</td>\n",
       "      <td>660998.864940</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.078492</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.009379</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.333154</td>\n",
       "      <td>0.584524</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016971e+14</td>\n",
       "      <td>40</td>\n",
       "      <td>-4.480554e+06</td>\n",
       "      <td>-4.301635e+06</td>\n",
       "      <td>-5.882757e+06</td>\n",
       "      <td>-3.881197e+06</td>\n",
       "      <td>-5.319383e+06</td>\n",
       "      <td>-4.773105e+06</td>\n",
       "      <td>725688.170644</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.241209</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.324273</td>\n",
       "      <td>0.581604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.002350e+14</td>\n",
       "      <td>39</td>\n",
       "      <td>-4.618329e+06</td>\n",
       "      <td>-4.300849e+06</td>\n",
       "      <td>-5.837319e+06</td>\n",
       "      <td>-3.839830e+06</td>\n",
       "      <td>-5.252752e+06</td>\n",
       "      <td>-4.769816e+06</td>\n",
       "      <td>704349.524387</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.404313</td>\n",
       "      <td>0.008148</td>\n",
       "      <td>0.025188</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.323818</td>\n",
       "      <td>0.578673</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947945e+14</td>\n",
       "      <td>37</td>\n",
       "      <td>-4.523689e+06</td>\n",
       "      <td>-4.390194e+06</td>\n",
       "      <td>-5.766504e+06</td>\n",
       "      <td>-3.839894e+06</td>\n",
       "      <td>-5.218409e+06</td>\n",
       "      <td>-4.747738e+06</td>\n",
       "      <td>672551.892340</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.031348      0.000153         0.000000        0.000000   \n",
       "1        0.130935      0.009203         0.010691        0.006549   \n",
       "2        0.271023      0.004887         0.007253        0.007080   \n",
       "3        0.804006      0.006260         0.025163        0.007788   \n",
       "4        1.336558      0.012739         0.033529        0.007067   \n",
       "5        0.018646      0.006313         0.006522        0.007990   \n",
       "6        0.096194      0.003996         0.007431        0.007000   \n",
       "7        0.211585      0.006955         0.005026        0.006453   \n",
       "8        0.623475      0.008018         0.013502        0.004245   \n",
       "9        1.023315      0.011915         0.031418        0.000186   \n",
       "10       0.018390      0.008268         0.003545        0.006097   \n",
       "11       0.094325      0.000167         0.003125        0.006251   \n",
       "12       0.179308      0.007610         0.012480        0.006240   \n",
       "13       0.557771      0.005782         0.017950        0.007422   \n",
       "14       0.917696      0.016339         0.034524        0.006318   \n",
       "15       0.017942      0.006866         0.000901        0.001802   \n",
       "16       0.083754      0.006601         0.004233        0.006100   \n",
       "17       0.156313      0.001673         0.010637        0.007021   \n",
       "18       0.469630      0.008224         0.018749        0.006252   \n",
       "19       0.783971      0.008201         0.030741        0.000429   \n",
       "20       0.014205      0.011032         0.001801        0.001470   \n",
       "21       0.059556      0.001317         0.004701        0.002396   \n",
       "22       0.126782      0.005721         0.006593        0.005970   \n",
       "23       0.367178      0.002235         0.023257        0.006842   \n",
       "24       0.616212      0.037275         0.042175        0.006459   \n",
       "25       0.015629      0.000092         0.000000        0.000000   \n",
       "26       0.047630      0.002385         0.005828        0.007170   \n",
       "27       0.092179      0.007144         0.008330        0.007079   \n",
       "28       0.271932      0.006338         0.017113        0.007846   \n",
       "29       0.452452      0.006477         0.031015        0.000700   \n",
       "30       0.012501      0.006251         0.000000        0.000000   \n",
       "31       0.047122      0.000199         0.000000        0.000000   \n",
       "32       0.092094      0.004662         0.002001        0.004002   \n",
       "33       0.257748      0.007571         0.015508        0.000252   \n",
       "34       0.438808      0.022186         0.023579        0.007053   \n",
       "35       0.006333      0.007757         0.003125        0.006250   \n",
       "36       0.043970      0.006361         0.003125        0.006250   \n",
       "37       0.078492      0.000084         0.009379        0.007658   \n",
       "38       0.241209      0.009159         0.017530        0.003095   \n",
       "39       0.404313      0.008148         0.025188        0.007653   \n",
       "\n",
       "   param_max_features param_min_samples_leaf param_n_estimators  \\\n",
       "0                auto                      1                 10   \n",
       "1                auto                      1                 50   \n",
       "2                auto                      1                100   \n",
       "3                auto                      1                300   \n",
       "4                auto                      1                500   \n",
       "5                auto                      3                 10   \n",
       "6                auto                      3                 50   \n",
       "7                auto                      3                100   \n",
       "8                auto                      3                300   \n",
       "9                auto                      3                500   \n",
       "10               auto                      5                 10   \n",
       "11               auto                      5                 50   \n",
       "12               auto                      5                100   \n",
       "13               auto                      5                300   \n",
       "14               auto                      5                500   \n",
       "15               auto                     10                 10   \n",
       "16               auto                     10                 50   \n",
       "17               auto                     10                100   \n",
       "18               auto                     10                300   \n",
       "19               auto                     10                500   \n",
       "20               sqrt                      1                 10   \n",
       "21               sqrt                      1                 50   \n",
       "22               sqrt                      1                100   \n",
       "23               sqrt                      1                300   \n",
       "24               sqrt                      1                500   \n",
       "25               sqrt                      3                 10   \n",
       "26               sqrt                      3                 50   \n",
       "27               sqrt                      3                100   \n",
       "28               sqrt                      3                300   \n",
       "29               sqrt                      3                500   \n",
       "30               sqrt                      5                 10   \n",
       "31               sqrt                      5                 50   \n",
       "32               sqrt                      5                100   \n",
       "33               sqrt                      5                300   \n",
       "34               sqrt                      5                500   \n",
       "35               sqrt                     10                 10   \n",
       "36               sqrt                     10                 50   \n",
       "37               sqrt                     10                100   \n",
       "38               sqrt                     10                300   \n",
       "39               sqrt                     10                500   \n",
       "\n",
       "                                               params  split0_test_R2  \\\n",
       "0   {'max_features': 'auto', 'min_samples_leaf': 1...        0.334495   \n",
       "1   {'max_features': 'auto', 'min_samples_leaf': 1...        0.286896   \n",
       "2   {'max_features': 'auto', 'min_samples_leaf': 1...        0.308026   \n",
       "3   {'max_features': 'auto', 'min_samples_leaf': 1...        0.277108   \n",
       "4   {'max_features': 'auto', 'min_samples_leaf': 1...        0.295585   \n",
       "5   {'max_features': 'auto', 'min_samples_leaf': 3...        0.259510   \n",
       "6   {'max_features': 'auto', 'min_samples_leaf': 3...        0.093746   \n",
       "7   {'max_features': 'auto', 'min_samples_leaf': 3...        0.167188   \n",
       "8   {'max_features': 'auto', 'min_samples_leaf': 3...        0.185240   \n",
       "9   {'max_features': 'auto', 'min_samples_leaf': 3...        0.165177   \n",
       "10  {'max_features': 'auto', 'min_samples_leaf': 5...        0.247719   \n",
       "11  {'max_features': 'auto', 'min_samples_leaf': 5...        0.289344   \n",
       "12  {'max_features': 'auto', 'min_samples_leaf': 5...        0.316717   \n",
       "13  {'max_features': 'auto', 'min_samples_leaf': 5...        0.290029   \n",
       "14  {'max_features': 'auto', 'min_samples_leaf': 5...        0.296999   \n",
       "15  {'max_features': 'auto', 'min_samples_leaf': 1...        0.322658   \n",
       "16  {'max_features': 'auto', 'min_samples_leaf': 1...        0.347514   \n",
       "17  {'max_features': 'auto', 'min_samples_leaf': 1...        0.303841   \n",
       "18  {'max_features': 'auto', 'min_samples_leaf': 1...        0.328438   \n",
       "19  {'max_features': 'auto', 'min_samples_leaf': 1...        0.328493   \n",
       "20  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.262671   \n",
       "21  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.316371   \n",
       "22  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.317492   \n",
       "23  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.332482   \n",
       "24  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.333007   \n",
       "25  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.252116   \n",
       "26  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.326733   \n",
       "27  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.326747   \n",
       "28  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.311826   \n",
       "29  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.311720   \n",
       "30  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.335327   \n",
       "31  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.309095   \n",
       "32  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.338842   \n",
       "33  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.315002   \n",
       "34  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.332316   \n",
       "35  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.300040   \n",
       "36  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.323567   \n",
       "37  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.333154   \n",
       "38  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.324273   \n",
       "39  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.323818   \n",
       "\n",
       "    split1_test_R2  ...  std_test_MAE  rank_test_MAE  split0_test_RMSE  \\\n",
       "0         0.579635  ...  1.638014e+14              5     -5.141765e+06   \n",
       "1         0.593828  ...  1.656895e+14              8     -4.844707e+06   \n",
       "2         0.607428  ...  1.587994e+14              7     -4.700432e+06   \n",
       "3         0.638670  ...  1.575274e+14             12     -4.849750e+06   \n",
       "4         0.633745  ...  1.667183e+14             13     -4.788827e+06   \n",
       "5         0.566515  ...  1.818866e+14             22     -4.744204e+06   \n",
       "6         0.656389  ...  1.684583e+14             25     -5.243061e+06   \n",
       "7         0.638124  ...  1.583688e+14             20     -5.128610e+06   \n",
       "8         0.646866  ...  1.609127e+14             17     -5.094968e+06   \n",
       "9         0.648042  ...  1.631164e+14             21     -5.069833e+06   \n",
       "10        0.492877  ...  1.498644e+14             31     -4.868738e+06   \n",
       "11        0.580182  ...  1.538455e+14             16     -4.739629e+06   \n",
       "12        0.552065  ...  1.514689e+14             15     -4.611347e+06   \n",
       "13        0.587368  ...  1.529259e+14             19     -4.773554e+06   \n",
       "14        0.592560  ...  1.537308e+14             18     -4.734733e+06   \n",
       "15        0.436546  ...  1.599552e+14             34     -4.837759e+06   \n",
       "16        0.513842  ...  1.675999e+14             30     -4.946546e+06   \n",
       "17        0.523667  ...  1.649246e+14             33     -4.999853e+06   \n",
       "18        0.507407  ...  1.649993e+14             32     -4.953251e+06   \n",
       "19        0.500537  ...  1.630555e+14             29     -4.977873e+06   \n",
       "20        0.615790  ...  1.646355e+14              6     -4.707132e+06   \n",
       "21        0.640580  ...  1.603689e+14              4     -4.262429e+06   \n",
       "22        0.619323  ...  1.555458e+14              3     -4.205609e+06   \n",
       "23        0.620752  ...  1.346278e+14              1     -4.258527e+06   \n",
       "24        0.628111  ...  1.448735e+14              2     -4.324909e+06   \n",
       "25        0.514213  ...  1.617667e+14             23     -4.406317e+06   \n",
       "26        0.602996  ...  1.516399e+14              9     -4.378719e+06   \n",
       "27        0.636139  ...  1.574194e+14             14     -4.341982e+06   \n",
       "28        0.626530  ...  1.543739e+14             10     -4.397988e+06   \n",
       "29        0.631825  ...  1.567410e+14             11     -4.407635e+06   \n",
       "30        0.584992  ...  1.812012e+14             35     -4.447255e+06   \n",
       "31        0.601486  ...  1.702718e+14             27     -4.350973e+06   \n",
       "32        0.566590  ...  1.668926e+14             24     -4.343324e+06   \n",
       "33        0.607182  ...  1.760019e+14             28     -4.329333e+06   \n",
       "34        0.609375  ...  1.779912e+14             26     -4.375938e+06   \n",
       "35        0.547032  ...  1.941068e+14             36     -4.652799e+06   \n",
       "36        0.600589  ...  2.014304e+14             38     -4.582028e+06   \n",
       "37        0.584524  ...  2.016971e+14             40     -4.480554e+06   \n",
       "38        0.581604  ...  2.002350e+14             39     -4.618329e+06   \n",
       "39        0.578673  ...  1.947945e+14             37     -4.523689e+06   \n",
       "\n",
       "    split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0      -4.019572e+06     -5.773763e+06     -3.891725e+06     -4.113694e+06   \n",
       "1      -3.909605e+06     -5.640231e+06     -3.781506e+06     -4.194639e+06   \n",
       "2      -3.871106e+06     -5.622968e+06     -3.919003e+06     -4.103726e+06   \n",
       "3      -3.765863e+06     -5.600292e+06     -3.950900e+06     -4.162266e+06   \n",
       "4      -3.754917e+06     -5.632499e+06     -3.869504e+06     -4.200324e+06   \n",
       "5      -4.050467e+06     -5.448680e+06     -3.814559e+06     -4.434484e+06   \n",
       "6      -3.677279e+06     -5.513965e+06     -3.873444e+06     -4.314866e+06   \n",
       "7      -3.801080e+06     -5.532458e+06     -3.818226e+06     -4.315706e+06   \n",
       "8      -3.799328e+06     -5.492269e+06     -3.819715e+06     -4.370262e+06   \n",
       "9      -3.730710e+06     -5.521474e+06     -3.878535e+06     -4.354283e+06   \n",
       "10     -4.236320e+06     -5.468646e+06     -4.037258e+06     -5.224763e+06   \n",
       "11     -3.952371e+06     -5.529292e+06     -3.538226e+06     -4.804730e+06   \n",
       "12     -3.972969e+06     -5.542214e+06     -3.494928e+06     -4.840794e+06   \n",
       "13     -3.931705e+06     -5.590574e+06     -3.637051e+06     -4.836829e+06   \n",
       "14     -3.921347e+06     -5.545320e+06     -3.629432e+06     -4.871952e+06   \n",
       "15     -4.205745e+06     -5.632213e+06     -3.893336e+06     -4.840857e+06   \n",
       "16     -4.069169e+06     -5.522141e+06     -3.726335e+06     -4.838023e+06   \n",
       "17     -4.112056e+06     -5.528054e+06     -3.736835e+06     -4.856850e+06   \n",
       "18     -4.110864e+06     -5.576381e+06     -3.787360e+06     -4.829480e+06   \n",
       "19     -4.141561e+06     -5.587725e+06     -3.752760e+06     -4.834072e+06   \n",
       "20     -3.930387e+06     -5.550861e+06     -3.641995e+06     -4.451859e+06   \n",
       "21     -3.722684e+06     -5.267648e+06     -3.736243e+06     -4.162599e+06   \n",
       "22     -3.688308e+06     -5.490579e+06     -3.543937e+06     -4.002937e+06   \n",
       "23     -3.731885e+06     -5.228406e+06     -3.601443e+06     -4.049339e+06   \n",
       "24     -3.736796e+06     -5.228898e+06     -3.607356e+06     -4.037396e+06   \n",
       "25     -4.401859e+06     -5.455380e+06     -3.918121e+06     -4.424541e+06   \n",
       "26     -4.055721e+06     -5.369682e+06     -3.712318e+06     -4.541783e+06   \n",
       "27     -3.895170e+06     -5.350481e+06     -3.625043e+06     -4.518293e+06   \n",
       "28     -3.935851e+06     -5.282743e+06     -3.653624e+06     -4.473700e+06   \n",
       "29     -3.918504e+06     -5.326348e+06     -3.675817e+06     -4.438003e+06   \n",
       "30     -4.003652e+06     -5.576370e+06     -3.907980e+06     -4.946276e+06   \n",
       "31     -4.157040e+06     -5.515247e+06     -3.744593e+06     -4.811069e+06   \n",
       "32     -4.280635e+06     -5.531187e+06     -3.721334e+06     -4.809578e+06   \n",
       "33     -4.113609e+06     -5.502490e+06     -3.723331e+06     -4.762420e+06   \n",
       "34     -4.104847e+06     -5.545784e+06     -3.676296e+06     -4.781988e+06   \n",
       "35     -4.344184e+06     -6.137021e+06     -3.911779e+06     -5.109128e+06   \n",
       "36     -4.223194e+06     -5.731265e+06     -3.953110e+06     -5.280113e+06   \n",
       "37     -4.301635e+06     -5.882757e+06     -3.881197e+06     -5.319383e+06   \n",
       "38     -4.300849e+06     -5.837319e+06     -3.839830e+06     -5.252752e+06   \n",
       "39     -4.390194e+06     -5.766504e+06     -3.839894e+06     -5.218409e+06   \n",
       "\n",
       "    mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0    -4.588104e+06  741021.763105              29  \n",
       "1    -4.474138e+06  689006.857409              13  \n",
       "2    -4.443447e+06  659596.616159               9  \n",
       "3    -4.465814e+06  675522.849827              12  \n",
       "4    -4.449214e+06  692179.055979              10  \n",
       "5    -4.498479e+06  571982.362507              17  \n",
       "6    -4.524523e+06  732253.565560              24  \n",
       "7    -4.519216e+06  699505.969615              22  \n",
       "8    -4.515308e+06  679407.619967              20  \n",
       "9    -4.510967e+06  688008.368211              18  \n",
       "10   -4.767145e+06  552512.558513              37  \n",
       "11   -4.512849e+06  697682.668211              19  \n",
       "12   -4.492450e+06  707445.188573              15  \n",
       "13   -4.553943e+06  697241.691342              27  \n",
       "14   -4.540557e+06  688570.318128              26  \n",
       "15   -4.681982e+06  600201.821019              34  \n",
       "16   -4.620443e+06  643439.940462              30  \n",
       "17   -4.646730e+06  641773.018642              31  \n",
       "18   -4.651467e+06  635163.065530              32  \n",
       "19   -4.658798e+06  645580.918905              33  \n",
       "20   -4.456447e+06  663426.856286              11  \n",
       "21   -4.230321e+06  562756.305327               4  \n",
       "22   -4.186274e+06  692208.769022               2  \n",
       "23   -4.173920e+06  575802.954872               1  \n",
       "24   -4.187071e+06  577169.471584               3  \n",
       "25   -4.521244e+06  504614.727459              23  \n",
       "26   -4.411645e+06  557063.063699               8  \n",
       "27   -4.346194e+06  593584.133472               5  \n",
       "28   -4.348781e+06  555709.545931               6  \n",
       "29   -4.353262e+06  566565.273804               7  \n",
       "30   -4.576307e+06  621007.723631              28  \n",
       "31   -4.515784e+06  606088.412898              21  \n",
       "32   -4.537211e+06  605185.970095              25  \n",
       "33   -4.486237e+06  609022.758474              14  \n",
       "34   -4.496971e+06  636106.837991              16  \n",
       "35   -4.830982e+06  761151.467109              40  \n",
       "36   -4.753942e+06  660998.864940              36  \n",
       "37   -4.773105e+06  725688.170644              39  \n",
       "38   -4.769816e+06  704349.524387              38  \n",
       "39   -4.747738e+06  672551.892340              35  \n",
       "\n",
       "[40 rows x 32 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyRandombest=pd.concat([pd.DataFrame(MyRandom.cv_results_)])\n",
    "MyRandombest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23    0.548632\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyRandombestR2=MyRandombest[MyRandombest['rank_test_R2'].isin([1])]\n",
    "print(MyRandombestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03139076, 0.03071465, 0.0282095 , 0.03141313, 0.02732944,\n",
       "        0.03290172, 0.02959309, 0.03011303, 0.03101597, 0.03149204,\n",
       "        0.03071675, 0.02942095, 0.02825441, 0.03023968, 0.02861733,\n",
       "        0.02985525, 0.03323536, 0.02835274, 0.03029447, 0.03141494,\n",
       "        0.03111229, 0.03221235, 0.03006473, 0.03013654, 0.02830105]),\n",
       " 'std_fit_time': array([0.01000894, 0.0049786 , 0.00609508, 0.00019561, 0.00611253,\n",
       "        0.00308288, 0.00372973, 0.0024889 , 0.00224669, 0.00023082,\n",
       "        0.00129525, 0.00734206, 0.00631647, 0.00202447, 0.00634257,\n",
       "        0.00310534, 0.0042705 , 0.00636581, 0.00400671, 0.00019853,\n",
       "        0.00050426, 0.0017274 , 0.00801191, 0.00573806, 0.00632914]),\n",
       " 'mean_score_time': array([0.01755476, 0.01127834, 0.01570764, 0.01250644, 0.01665602,\n",
       "        0.01105475, 0.01442289, 0.01380491, 0.00985379, 0.01319704,\n",
       "        0.012502  , 0.01449647, 0.01563215, 0.01369147, 0.01378565,\n",
       "        0.01563096, 0.01068258, 0.0156045 , 0.01368084, 0.01258264,\n",
       "        0.01280613, 0.01179471, 0.01382184, 0.01378074, 0.01572151]),\n",
       " 'std_score_time': array([3.79831428e-03, 6.11620800e-03, 1.60271672e-04, 6.25322008e-03,\n",
       "        2.25139133e-03, 6.28968947e-03, 8.11201260e-03, 7.34848212e-03,\n",
       "        6.41497715e-03, 6.74815606e-03, 6.25100437e-03, 2.49471434e-03,\n",
       "        5.53418775e-06, 7.15462431e-03, 2.95315208e-03, 4.83701883e-06,\n",
       "        6.71255872e-03, 4.85819613e-05, 2.62804519e-03, 6.29319078e-03,\n",
       "        6.42979581e-03, 6.98577653e-03, 3.61812404e-03, 2.34744894e-03,\n",
       "        1.55026749e-04]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 10, 10, 10, 10,\n",
       "                    10, 100, 100, 100, 100, 100, 1000, 1000, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[1, 0.1, 0.01, 0.001, 0.0001, 1, 0.1, 0.01, 0.001,\n",
       "                    0.0001, 1, 0.1, 0.01, 0.001, 0.0001, 1, 0.1, 0.01,\n",
       "                    0.001, 0.0001, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}],\n",
       " 'split0_test_R2': array([-0.05768718, -0.05768712, -0.05768712, -0.05768718, -0.05768719,\n",
       "        -0.05768704, -0.05768648, -0.05768642, -0.05768708, -0.05768718,\n",
       "        -0.05768563, -0.05768011, -0.05767947, -0.05768602, -0.05768707,\n",
       "        -0.05767155, -0.05761636, -0.05760994, -0.05767547, -0.05768596,\n",
       "        -0.0575309 , -0.05714384, -0.05691536, -0.05757001, -0.05767489]),\n",
       " 'split1_test_R2': array([-0.15893553, -0.15893522, -0.15893536, -0.15893564, -0.15893568,\n",
       "        -0.15893422, -0.15893104, -0.15893252, -0.15893525, -0.15893564,\n",
       "        -0.15892113, -0.15888933, -0.15890411, -0.15893137, -0.15893524,\n",
       "        -0.1587902 , -0.15847238, -0.15862004, -0.15889261, -0.15893124,\n",
       "        -0.15786619, -0.15738435, -0.15679951, -0.158505  , -0.15889126]),\n",
       " 'split2_test_R2': array([-0.04539244, -0.04539242, -0.04539241, -0.04539246, -0.04539247,\n",
       "        -0.04539223, -0.04539202, -0.04539195, -0.04539237, -0.04539246,\n",
       "        -0.04539014, -0.04538803, -0.04538727, -0.04539153, -0.04539236,\n",
       "        -0.04536844, -0.04535092, -0.04534046, -0.04538307, -0.04539144,\n",
       "        -0.04529473, -0.04497102, -0.04489222, -0.04529848, -0.04538224]),\n",
       " 'split3_test_R2': array([-0.11439469, -0.11439472, -0.11439476, -0.11439467, -0.11439469,\n",
       "        -0.11439464, -0.11439501, -0.11439539, -0.11439447, -0.11439466,\n",
       "        -0.11439417, -0.11439784, -0.11440167, -0.11439243, -0.11439433,\n",
       "        -0.11438946, -0.11442634, -0.11446458, -0.11437212, -0.11439112,\n",
       "        -0.1136765 , -0.11318316, -0.11270613, -0.11416902, -0.11435901]),\n",
       " 'split4_test_R2': array([-0.07762386, -0.07762384, -0.07762383, -0.07762387, -0.07762388,\n",
       "        -0.07762371, -0.07762355, -0.0776234 , -0.07762376, -0.07762386,\n",
       "        -0.0776222 , -0.07762056, -0.07761912, -0.07762267, -0.07762374,\n",
       "        -0.07760713, -0.0775907 , -0.07757631, -0.07761176, -0.07762247,\n",
       "        -0.07753542, -0.0769731 , -0.07704734, -0.07750275, -0.07760984]),\n",
       " 'mean_test_R2': array([-0.09080674, -0.09080667, -0.0908067 , -0.09080676, -0.09080678,\n",
       "        -0.09080637, -0.09080562, -0.09080594, -0.09080658, -0.09080676,\n",
       "        -0.09080265, -0.09079517, -0.09079833, -0.0908048 , -0.09080655,\n",
       "        -0.09076535, -0.09069134, -0.09072227, -0.09078701, -0.09080445,\n",
       "        -0.09038075, -0.08993109, -0.08967211, -0.09060905, -0.09078345]),\n",
       " 'std_test_R2': array([0.04130636, 0.04130627, 0.04130633, 0.04130639, 0.0413064 ,\n",
       "        0.041306  , 0.04130514, 0.0413057 , 0.04130628, 0.04130638,\n",
       "        0.04130241, 0.04129379, 0.04129947, 0.04130519, 0.04130626,\n",
       "        0.04126669, 0.04117998, 0.04123726, 0.04129433, 0.04130504,\n",
       "        0.04092393, 0.04087768, 0.04067993, 0.04118576, 0.04129279]),\n",
       " 'rank_test_R2': array([22, 20, 21, 24, 25, 17, 15, 16, 19, 23, 12, 10, 11, 14, 18,  7,  5,\n",
       "         6,  9, 13,  3,  2,  1,  4,  8]),\n",
       " 'split0_test_MAE': array([-4.43414094e+14, -4.43414071e+14, -4.43414068e+14, -4.43414096e+14,\n",
       "        -4.43414100e+14, -4.43414035e+14, -4.43413803e+14, -4.43413777e+14,\n",
       "        -4.43414051e+14, -4.43414095e+14, -4.43413444e+14, -4.43411130e+14,\n",
       "        -4.43410861e+14, -4.43413609e+14, -4.43414049e+14, -4.43407541e+14,\n",
       "        -4.43384405e+14, -4.43381712e+14, -4.43409187e+14, -4.43413585e+14,\n",
       "        -4.43348578e+14, -4.43186313e+14, -4.43090526e+14, -4.43364974e+14,\n",
       "        -4.43408942e+14]),\n",
       " 'split1_test_MAE': array([-1.56507472e+14, -1.56507429e+14, -1.56507449e+14, -1.56507486e+14,\n",
       "        -1.56507491e+14, -1.56507295e+14, -1.56506866e+14, -1.56507065e+14,\n",
       "        -1.56507433e+14, -1.56507486e+14, -1.56505527e+14, -1.56501233e+14,\n",
       "        -1.56503229e+14, -1.56506910e+14, -1.56507432e+14, -1.56487846e+14,\n",
       "        -1.56444926e+14, -1.56464867e+14, -1.56501675e+14, -1.56506892e+14,\n",
       "        -1.56363063e+14, -1.56297993e+14, -1.56219014e+14, -1.56449331e+14,\n",
       "        -1.56501492e+14]),\n",
       " 'split2_test_MAE': array([-8.74578937e+14, -8.74578919e+14, -8.74578913e+14, -8.74578949e+14,\n",
       "        -8.74578956e+14, -8.74578762e+14, -8.74578585e+14, -8.74578522e+14,\n",
       "        -8.74578878e+14, -8.74578948e+14, -8.74577008e+14, -8.74575245e+14,\n",
       "        -8.74574606e+14, -8.74578170e+14, -8.74578871e+14, -8.74558852e+14,\n",
       "        -8.74544203e+14, -8.74535452e+14, -8.74571093e+14, -8.74578101e+14,\n",
       "        -8.74497190e+14, -8.74226371e+14, -8.74160450e+14, -8.74500327e+14,\n",
       "        -8.74570405e+14]),\n",
       " 'split3_test_MAE': array([-1.15046747e+14, -1.15046750e+14, -1.15046754e+14, -1.15046745e+14,\n",
       "        -1.15046747e+14, -1.15046742e+14, -1.15046780e+14, -1.15046819e+14,\n",
       "        -1.15046724e+14, -1.15046744e+14, -1.15046693e+14, -1.15047072e+14,\n",
       "        -1.15047467e+14, -1.15046514e+14, -1.15046710e+14, -1.15046207e+14,\n",
       "        -1.15050015e+14, -1.15053963e+14, -1.15044417e+14, -1.15046379e+14,\n",
       "        -1.14972603e+14, -1.14921672e+14, -1.14872425e+14, -1.15023449e+14,\n",
       "        -1.15043064e+14]),\n",
       " 'split4_test_MAE': array([-6.63738611e+14, -6.63738601e+14, -6.63738592e+14, -6.63738614e+14,\n",
       "        -6.63738621e+14, -6.63738519e+14, -6.63738417e+14, -6.63738329e+14,\n",
       "        -6.63738547e+14, -6.63738613e+14, -6.63737590e+14, -6.63736577e+14,\n",
       "        -6.63735692e+14, -6.63737876e+14, -6.63738535e+14, -6.63728304e+14,\n",
       "        -6.63718185e+14, -6.63709327e+14, -6.63731161e+14, -6.63737757e+14,\n",
       "        -6.63684138e+14, -6.63337791e+14, -6.63383515e+14, -6.63664018e+14,\n",
       "        -6.63729973e+14]),\n",
       " 'mean_test_MAE': array([-4.50657172e+14, -4.50657154e+14, -4.50657155e+14, -4.50657178e+14,\n",
       "        -4.50657183e+14, -4.50657070e+14, -4.50656890e+14, -4.50656902e+14,\n",
       "        -4.50657127e+14, -4.50657177e+14, -4.50656053e+14, -4.50654251e+14,\n",
       "        -4.50654371e+14, -4.50656616e+14, -4.50657119e+14, -4.50645750e+14,\n",
       "        -4.50628347e+14, -4.50629064e+14, -4.50651507e+14, -4.50656543e+14,\n",
       "        -4.50573114e+14, -4.50394028e+14, -4.50345186e+14, -4.50600420e+14,\n",
       "        -4.50650775e+14]),\n",
       " 'std_test_MAE': array([2.91315715e+14, 2.91315716e+14, 2.91315708e+14, 2.91315716e+14,\n",
       "        2.91315718e+14, 2.91315687e+14, 2.91315700e+14, 2.91315620e+14,\n",
       "        2.91315701e+14, 2.91315716e+14, 2.91315412e+14, 2.91315542e+14,\n",
       "        2.91314734e+14, 2.91315553e+14, 2.91315701e+14, 2.91312482e+14,\n",
       "        2.91314644e+14, 2.91305878e+14, 2.91314074e+14, 2.91315551e+14,\n",
       "        2.91330528e+14, 2.91226727e+14, 2.91242001e+14, 2.91299278e+14,\n",
       "        2.91314050e+14]),\n",
       " 'rank_test_MAE': array([22, 20, 21, 24, 25, 17, 15, 16, 19, 23, 12, 10, 11, 14, 18,  7,  5,\n",
       "         6,  9, 13,  3,  2,  1,  4,  8]),\n",
       " 'split0_test_RMSE': array([-6346985.23739826, -6346984.34353114, -6346984.76564958,\n",
       "        -6346985.52237503, -6346985.62526338, -6346981.6406218 ,\n",
       "        -6346972.70195064, -6346976.92313504, -6346984.49038951,\n",
       "        -6346985.51927303, -6346945.67285724, -6346856.28614562,\n",
       "        -6346898.49798957, -6346974.17053431, -6346984.45936948,\n",
       "        -6346585.99521159, -6345692.12809536, -6346114.24653489,\n",
       "        -6346870.97198233, -6346973.86033403, -6342989.21875514,\n",
       "        -6334373.71099017, -6338379.51123032, -6345838.98646252,\n",
       "        -6346867.86997954]),\n",
       " 'split1_test_RMSE': array([-5963683.77711696, -5963682.95403806, -5963683.33834139,\n",
       "        -5963684.03336643, -5963684.1303193 , -5963680.49736514,\n",
       "        -5963672.26657616, -5963676.10960943, -5963683.05985985,\n",
       "        -5963684.02938848, -5963647.69984689, -5963565.39195706,\n",
       "        -5963603.82228977, -5963673.32479401, -5963683.02008034,\n",
       "        -5963319.72466436, -5962496.64576614, -5962880.94909323,\n",
       "        -5963575.97413564, -5963672.92699889, -5960080.18642604,\n",
       "        -5952304.9616753 , -5955768.79923193, -5962602.46755187,\n",
       "        -5963571.99618446]),\n",
       " 'split2_test_RMSE': array([-7628782.02692767, -7628781.11756604, -7628781.54829214,\n",
       "        -7628782.28013365, -7628782.38372005, -7628778.70752628,\n",
       "        -7628769.61390998, -7628773.92117102, -7628781.23958607,\n",
       "        -7628782.27545008, -7628745.51351239, -7628654.57734938,\n",
       "        -7628697.64995978, -7628770.83411027, -7628781.1927504 ,\n",
       "        -7628415.42103764, -7627505.06123724, -7627934.93784739,\n",
       "        -7628666.7793523 , -7628770.36575362, -7624846.03765861,\n",
       "        -7616246.84089946, -7620347.32055725, -7627626.23177265,\n",
       "        -7628662.09578576]),\n",
       " 'split3_test_RMSE': array([-4883179.4560928 , -4883178.88517638, -4883179.16329418,\n",
       "        -4883179.66632616, -4883179.74733431, -4883176.74684326,\n",
       "        -4883171.03767909, -4883173.81885704, -4883178.84917682,\n",
       "        -4883179.65925834, -4883149.65434781, -4883092.56270611,\n",
       "        -4883120.37448566, -4883170.67768342, -4883178.77849865,\n",
       "        -4882878.72939331, -4882307.81297628, -4882585.93077182,\n",
       "        -4883088.96274946, -4883169.97090177, -4879958.51035362,\n",
       "        -4874047.16166814, -4876520.09930196, -4882271.8134098 ,\n",
       "        -4883081.89493291]),\n",
       " 'split4_test_RMSE': array([-8364395.16713844, -8364394.21513387, -8364394.65821596,\n",
       "        -8364395.44887726, -8364395.56158469, -8364391.49941888,\n",
       "        -8364381.97937321, -8364386.4101941 , -8364394.31680713,\n",
       "        -8364395.44388145, -8364354.82222333, -8364259.62176663,\n",
       "        -8364303.92997549, -8364382.99610585, -8364394.26684904,\n",
       "        -8363988.05026781, -8363036.04570084, -8363479.12778944,\n",
       "        -8364269.789093  , -8364382.49652493, -8360311.60508786,\n",
       "        -8351656.50517639, -8355350.62639533, -8363137.71896457,\n",
       "        -8364264.79328379]),\n",
       " 'mean_test_RMSE': array([-6637405.13293483, -6637404.3030891 , -6637404.69475865,\n",
       "        -6637405.39021571, -6637405.48964435, -6637401.81835507,\n",
       "        -6637393.51989781, -6637397.43659332, -6637404.39116388,\n",
       "        -6637405.38545028, -6637368.67255753, -6637285.68798496,\n",
       "        -6637324.85494005, -6637394.40064557, -6637404.34350958,\n",
       "        -6637037.58411494, -6636207.53875517, -6636599.03840735,\n",
       "        -6637294.49546255, -6637393.92410265, -6633637.11165625,\n",
       "        -6625725.83608189, -6629273.27134336, -6636295.44363228,\n",
       "        -6637289.73003329]),\n",
       " 'std_test_RMSE': array([1231330.5511098 , 1231330.43254154, 1231330.48497651,\n",
       "        1231330.56952603, 1231330.57927664, 1231330.28829761,\n",
       "        1231329.10261522, 1231329.6269648 , 1231330.47245981,\n",
       "        1231330.56996597, 1231327.66017766, 1231315.80338021,\n",
       "        1231321.04686054, 1231329.50179769, 1231330.47685922,\n",
       "        1231301.6767084 , 1231182.95063971, 1231235.24710417,\n",
       "        1231319.79518284, 1231329.5457918 , 1231051.88412952,\n",
       "        1230181.16135663, 1230604.88723038, 1231222.72967163,\n",
       "        1231320.23512113]),\n",
       " 'rank_test_RMSE': array([22, 18, 21, 24, 25, 17, 13, 16, 20, 23, 12,  8, 11, 15, 19,  7,  4,\n",
       "         6, 10, 14,  3,  1,  2,  5,  9])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMparams = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']\n",
    "}\n",
    "MySVM = GridSearchCV(SVR(),\n",
    "                        param_grid = SVMparams,\n",
    "                        scoring=scoring,\n",
    "                        refit=False,\n",
    "                        verbose=2,\n",
    "                        cv=CV)\n",
    "\n",
    "MySVM.fit(X_train_std, y_train)\n",
    "MySVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031391</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057687</td>\n",
       "      <td>-0.158936</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>22</td>\n",
       "      <td>-6.346985e+06</td>\n",
       "      <td>-5.963684e+06</td>\n",
       "      <td>-7.628782e+06</td>\n",
       "      <td>-4.883179e+06</td>\n",
       "      <td>-8.364395e+06</td>\n",
       "      <td>-6.637405e+06</td>\n",
       "      <td>1.231331e+06</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030715</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057687</td>\n",
       "      <td>-0.158935</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.346984e+06</td>\n",
       "      <td>-5.963683e+06</td>\n",
       "      <td>-7.628781e+06</td>\n",
       "      <td>-4.883179e+06</td>\n",
       "      <td>-8.364394e+06</td>\n",
       "      <td>-6.637404e+06</td>\n",
       "      <td>1.231330e+06</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028209</td>\n",
       "      <td>0.006095</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057687</td>\n",
       "      <td>-0.158935</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>21</td>\n",
       "      <td>-6.346985e+06</td>\n",
       "      <td>-5.963683e+06</td>\n",
       "      <td>-7.628782e+06</td>\n",
       "      <td>-4.883179e+06</td>\n",
       "      <td>-8.364395e+06</td>\n",
       "      <td>-6.637405e+06</td>\n",
       "      <td>1.231330e+06</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031413</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.012506</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057687</td>\n",
       "      <td>-0.158936</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>24</td>\n",
       "      <td>-6.346986e+06</td>\n",
       "      <td>-5.963684e+06</td>\n",
       "      <td>-7.628782e+06</td>\n",
       "      <td>-4.883180e+06</td>\n",
       "      <td>-8.364395e+06</td>\n",
       "      <td>-6.637405e+06</td>\n",
       "      <td>1.231331e+06</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027329</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.016656</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057687</td>\n",
       "      <td>-0.158936</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>25</td>\n",
       "      <td>-6.346986e+06</td>\n",
       "      <td>-5.963684e+06</td>\n",
       "      <td>-7.628782e+06</td>\n",
       "      <td>-4.883180e+06</td>\n",
       "      <td>-8.364396e+06</td>\n",
       "      <td>-6.637405e+06</td>\n",
       "      <td>1.231331e+06</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.011055</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057687</td>\n",
       "      <td>-0.158934</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>17</td>\n",
       "      <td>-6.346982e+06</td>\n",
       "      <td>-5.963680e+06</td>\n",
       "      <td>-7.628779e+06</td>\n",
       "      <td>-4.883177e+06</td>\n",
       "      <td>-8.364391e+06</td>\n",
       "      <td>-6.637402e+06</td>\n",
       "      <td>1.231330e+06</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.029593</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.158931</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>15</td>\n",
       "      <td>-6.346973e+06</td>\n",
       "      <td>-5.963672e+06</td>\n",
       "      <td>-7.628770e+06</td>\n",
       "      <td>-4.883171e+06</td>\n",
       "      <td>-8.364382e+06</td>\n",
       "      <td>-6.637394e+06</td>\n",
       "      <td>1.231329e+06</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.030113</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.013805</td>\n",
       "      <td>0.007348</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.158933</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913156e+14</td>\n",
       "      <td>16</td>\n",
       "      <td>-6.346977e+06</td>\n",
       "      <td>-5.963676e+06</td>\n",
       "      <td>-7.628774e+06</td>\n",
       "      <td>-4.883174e+06</td>\n",
       "      <td>-8.364386e+06</td>\n",
       "      <td>-6.637397e+06</td>\n",
       "      <td>1.231330e+06</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.031016</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057687</td>\n",
       "      <td>-0.158935</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>19</td>\n",
       "      <td>-6.346984e+06</td>\n",
       "      <td>-5.963683e+06</td>\n",
       "      <td>-7.628781e+06</td>\n",
       "      <td>-4.883179e+06</td>\n",
       "      <td>-8.364394e+06</td>\n",
       "      <td>-6.637404e+06</td>\n",
       "      <td>1.231330e+06</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.031492</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057687</td>\n",
       "      <td>-0.158936</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>23</td>\n",
       "      <td>-6.346986e+06</td>\n",
       "      <td>-5.963684e+06</td>\n",
       "      <td>-7.628782e+06</td>\n",
       "      <td>-4.883180e+06</td>\n",
       "      <td>-8.364395e+06</td>\n",
       "      <td>-6.637405e+06</td>\n",
       "      <td>1.231331e+06</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.030717</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.158921</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913154e+14</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.346946e+06</td>\n",
       "      <td>-5.963648e+06</td>\n",
       "      <td>-7.628746e+06</td>\n",
       "      <td>-4.883150e+06</td>\n",
       "      <td>-8.364355e+06</td>\n",
       "      <td>-6.637369e+06</td>\n",
       "      <td>1.231328e+06</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.029421</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.014496</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057680</td>\n",
       "      <td>-0.158889</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913155e+14</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.346856e+06</td>\n",
       "      <td>-5.963565e+06</td>\n",
       "      <td>-7.628655e+06</td>\n",
       "      <td>-4.883093e+06</td>\n",
       "      <td>-8.364260e+06</td>\n",
       "      <td>-6.637286e+06</td>\n",
       "      <td>1.231316e+06</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.028254</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057679</td>\n",
       "      <td>-0.158904</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913147e+14</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.346898e+06</td>\n",
       "      <td>-5.963604e+06</td>\n",
       "      <td>-7.628698e+06</td>\n",
       "      <td>-4.883120e+06</td>\n",
       "      <td>-8.364304e+06</td>\n",
       "      <td>-6.637325e+06</td>\n",
       "      <td>1.231321e+06</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.030240</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.013691</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.158931</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913156e+14</td>\n",
       "      <td>14</td>\n",
       "      <td>-6.346974e+06</td>\n",
       "      <td>-5.963673e+06</td>\n",
       "      <td>-7.628771e+06</td>\n",
       "      <td>-4.883171e+06</td>\n",
       "      <td>-8.364383e+06</td>\n",
       "      <td>-6.637394e+06</td>\n",
       "      <td>1.231330e+06</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.028617</td>\n",
       "      <td>0.006343</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057687</td>\n",
       "      <td>-0.158935</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913157e+14</td>\n",
       "      <td>18</td>\n",
       "      <td>-6.346984e+06</td>\n",
       "      <td>-5.963683e+06</td>\n",
       "      <td>-7.628781e+06</td>\n",
       "      <td>-4.883179e+06</td>\n",
       "      <td>-8.364394e+06</td>\n",
       "      <td>-6.637404e+06</td>\n",
       "      <td>1.231330e+06</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.029855</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.015631</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057672</td>\n",
       "      <td>-0.158790</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913125e+14</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.346586e+06</td>\n",
       "      <td>-5.963320e+06</td>\n",
       "      <td>-7.628415e+06</td>\n",
       "      <td>-4.882879e+06</td>\n",
       "      <td>-8.363988e+06</td>\n",
       "      <td>-6.637038e+06</td>\n",
       "      <td>1.231302e+06</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.033235</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.010683</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057616</td>\n",
       "      <td>-0.158472</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913146e+14</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.345692e+06</td>\n",
       "      <td>-5.962497e+06</td>\n",
       "      <td>-7.627505e+06</td>\n",
       "      <td>-4.882308e+06</td>\n",
       "      <td>-8.363036e+06</td>\n",
       "      <td>-6.636208e+06</td>\n",
       "      <td>1.231183e+06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.028353</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057610</td>\n",
       "      <td>-0.158620</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913059e+14</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.346114e+06</td>\n",
       "      <td>-5.962881e+06</td>\n",
       "      <td>-7.627935e+06</td>\n",
       "      <td>-4.882586e+06</td>\n",
       "      <td>-8.363479e+06</td>\n",
       "      <td>-6.636599e+06</td>\n",
       "      <td>1.231235e+06</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.030294</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.013681</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057675</td>\n",
       "      <td>-0.158893</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913141e+14</td>\n",
       "      <td>9</td>\n",
       "      <td>-6.346871e+06</td>\n",
       "      <td>-5.963576e+06</td>\n",
       "      <td>-7.628667e+06</td>\n",
       "      <td>-4.883089e+06</td>\n",
       "      <td>-8.364270e+06</td>\n",
       "      <td>-6.637294e+06</td>\n",
       "      <td>1.231320e+06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.031415</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057686</td>\n",
       "      <td>-0.158931</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913156e+14</td>\n",
       "      <td>13</td>\n",
       "      <td>-6.346974e+06</td>\n",
       "      <td>-5.963673e+06</td>\n",
       "      <td>-7.628770e+06</td>\n",
       "      <td>-4.883170e+06</td>\n",
       "      <td>-8.364382e+06</td>\n",
       "      <td>-6.637394e+06</td>\n",
       "      <td>1.231330e+06</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.031112</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.012806</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057531</td>\n",
       "      <td>-0.157866</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913305e+14</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.342989e+06</td>\n",
       "      <td>-5.960080e+06</td>\n",
       "      <td>-7.624846e+06</td>\n",
       "      <td>-4.879959e+06</td>\n",
       "      <td>-8.360312e+06</td>\n",
       "      <td>-6.633637e+06</td>\n",
       "      <td>1.231052e+06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.032212</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057144</td>\n",
       "      <td>-0.157384</td>\n",
       "      <td>...</td>\n",
       "      <td>2.912267e+14</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.334374e+06</td>\n",
       "      <td>-5.952305e+06</td>\n",
       "      <td>-7.616247e+06</td>\n",
       "      <td>-4.874047e+06</td>\n",
       "      <td>-8.351657e+06</td>\n",
       "      <td>-6.625726e+06</td>\n",
       "      <td>1.230181e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.030065</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>-0.156800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.912420e+14</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.338380e+06</td>\n",
       "      <td>-5.955769e+06</td>\n",
       "      <td>-7.620347e+06</td>\n",
       "      <td>-4.876520e+06</td>\n",
       "      <td>-8.355351e+06</td>\n",
       "      <td>-6.629273e+06</td>\n",
       "      <td>1.230605e+06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.030137</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.013781</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057570</td>\n",
       "      <td>-0.158505</td>\n",
       "      <td>...</td>\n",
       "      <td>2.912993e+14</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.345839e+06</td>\n",
       "      <td>-5.962602e+06</td>\n",
       "      <td>-7.627626e+06</td>\n",
       "      <td>-4.882272e+06</td>\n",
       "      <td>-8.363138e+06</td>\n",
       "      <td>-6.636295e+06</td>\n",
       "      <td>1.231223e+06</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.028301</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.015722</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.057675</td>\n",
       "      <td>-0.158891</td>\n",
       "      <td>...</td>\n",
       "      <td>2.913140e+14</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.346868e+06</td>\n",
       "      <td>-5.963572e+06</td>\n",
       "      <td>-7.628662e+06</td>\n",
       "      <td>-4.883082e+06</td>\n",
       "      <td>-8.364265e+06</td>\n",
       "      <td>-6.637290e+06</td>\n",
       "      <td>1.231320e+06</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.031391      0.010009         0.017555        0.003798     0.1   \n",
       "1        0.030715      0.004979         0.011278        0.006116     0.1   \n",
       "2        0.028209      0.006095         0.015708        0.000160     0.1   \n",
       "3        0.031413      0.000196         0.012506        0.006253     0.1   \n",
       "4        0.027329      0.006113         0.016656        0.002251     0.1   \n",
       "5        0.032902      0.003083         0.011055        0.006290       1   \n",
       "6        0.029593      0.003730         0.014423        0.008112       1   \n",
       "7        0.030113      0.002489         0.013805        0.007348       1   \n",
       "8        0.031016      0.002247         0.009854        0.006415       1   \n",
       "9        0.031492      0.000231         0.013197        0.006748       1   \n",
       "10       0.030717      0.001295         0.012502        0.006251      10   \n",
       "11       0.029421      0.007342         0.014496        0.002495      10   \n",
       "12       0.028254      0.006316         0.015632        0.000006      10   \n",
       "13       0.030240      0.002024         0.013691        0.007155      10   \n",
       "14       0.028617      0.006343         0.013786        0.002953      10   \n",
       "15       0.029855      0.003105         0.015631        0.000005     100   \n",
       "16       0.033235      0.004271         0.010683        0.006713     100   \n",
       "17       0.028353      0.006366         0.015604        0.000049     100   \n",
       "18       0.030294      0.004007         0.013681        0.002628     100   \n",
       "19       0.031415      0.000199         0.012583        0.006293     100   \n",
       "20       0.031112      0.000504         0.012806        0.006430    1000   \n",
       "21       0.032212      0.001727         0.011795        0.006986    1000   \n",
       "22       0.030065      0.008012         0.013822        0.003618    1000   \n",
       "23       0.030137      0.005738         0.013781        0.002347    1000   \n",
       "24       0.028301      0.006329         0.015722        0.000155    1000   \n",
       "\n",
       "   param_gamma param_kernel                                         params  \\\n",
       "0            1          rbf        {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "1          0.1          rbf      {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "2         0.01          rbf     {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "3        0.001          rbf    {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "4       0.0001          rbf   {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "5            1          rbf          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "6          0.1          rbf        {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "7         0.01          rbf       {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "8        0.001          rbf      {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "9       0.0001          rbf     {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "10           1          rbf         {'C': 10, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "11         0.1          rbf       {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "12        0.01          rbf      {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "13       0.001          rbf     {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "14      0.0001          rbf    {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "15           1          rbf        {'C': 100, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "16         0.1          rbf      {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "17        0.01          rbf     {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "18       0.001          rbf    {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "19      0.0001          rbf   {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "20           1          rbf       {'C': 1000, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "21         0.1          rbf     {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "22        0.01          rbf    {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "23       0.001          rbf   {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "24      0.0001          rbf  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "\n",
       "    split0_test_R2  split1_test_R2  ...  std_test_MAE  rank_test_MAE  \\\n",
       "0        -0.057687       -0.158936  ...  2.913157e+14             22   \n",
       "1        -0.057687       -0.158935  ...  2.913157e+14             20   \n",
       "2        -0.057687       -0.158935  ...  2.913157e+14             21   \n",
       "3        -0.057687       -0.158936  ...  2.913157e+14             24   \n",
       "4        -0.057687       -0.158936  ...  2.913157e+14             25   \n",
       "5        -0.057687       -0.158934  ...  2.913157e+14             17   \n",
       "6        -0.057686       -0.158931  ...  2.913157e+14             15   \n",
       "7        -0.057686       -0.158933  ...  2.913156e+14             16   \n",
       "8        -0.057687       -0.158935  ...  2.913157e+14             19   \n",
       "9        -0.057687       -0.158936  ...  2.913157e+14             23   \n",
       "10       -0.057686       -0.158921  ...  2.913154e+14             12   \n",
       "11       -0.057680       -0.158889  ...  2.913155e+14             10   \n",
       "12       -0.057679       -0.158904  ...  2.913147e+14             11   \n",
       "13       -0.057686       -0.158931  ...  2.913156e+14             14   \n",
       "14       -0.057687       -0.158935  ...  2.913157e+14             18   \n",
       "15       -0.057672       -0.158790  ...  2.913125e+14              7   \n",
       "16       -0.057616       -0.158472  ...  2.913146e+14              5   \n",
       "17       -0.057610       -0.158620  ...  2.913059e+14              6   \n",
       "18       -0.057675       -0.158893  ...  2.913141e+14              9   \n",
       "19       -0.057686       -0.158931  ...  2.913156e+14             13   \n",
       "20       -0.057531       -0.157866  ...  2.913305e+14              3   \n",
       "21       -0.057144       -0.157384  ...  2.912267e+14              2   \n",
       "22       -0.056915       -0.156800  ...  2.912420e+14              1   \n",
       "23       -0.057570       -0.158505  ...  2.912993e+14              4   \n",
       "24       -0.057675       -0.158891  ...  2.913140e+14              8   \n",
       "\n",
       "    split0_test_RMSE  split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  \\\n",
       "0      -6.346985e+06     -5.963684e+06     -7.628782e+06     -4.883179e+06   \n",
       "1      -6.346984e+06     -5.963683e+06     -7.628781e+06     -4.883179e+06   \n",
       "2      -6.346985e+06     -5.963683e+06     -7.628782e+06     -4.883179e+06   \n",
       "3      -6.346986e+06     -5.963684e+06     -7.628782e+06     -4.883180e+06   \n",
       "4      -6.346986e+06     -5.963684e+06     -7.628782e+06     -4.883180e+06   \n",
       "5      -6.346982e+06     -5.963680e+06     -7.628779e+06     -4.883177e+06   \n",
       "6      -6.346973e+06     -5.963672e+06     -7.628770e+06     -4.883171e+06   \n",
       "7      -6.346977e+06     -5.963676e+06     -7.628774e+06     -4.883174e+06   \n",
       "8      -6.346984e+06     -5.963683e+06     -7.628781e+06     -4.883179e+06   \n",
       "9      -6.346986e+06     -5.963684e+06     -7.628782e+06     -4.883180e+06   \n",
       "10     -6.346946e+06     -5.963648e+06     -7.628746e+06     -4.883150e+06   \n",
       "11     -6.346856e+06     -5.963565e+06     -7.628655e+06     -4.883093e+06   \n",
       "12     -6.346898e+06     -5.963604e+06     -7.628698e+06     -4.883120e+06   \n",
       "13     -6.346974e+06     -5.963673e+06     -7.628771e+06     -4.883171e+06   \n",
       "14     -6.346984e+06     -5.963683e+06     -7.628781e+06     -4.883179e+06   \n",
       "15     -6.346586e+06     -5.963320e+06     -7.628415e+06     -4.882879e+06   \n",
       "16     -6.345692e+06     -5.962497e+06     -7.627505e+06     -4.882308e+06   \n",
       "17     -6.346114e+06     -5.962881e+06     -7.627935e+06     -4.882586e+06   \n",
       "18     -6.346871e+06     -5.963576e+06     -7.628667e+06     -4.883089e+06   \n",
       "19     -6.346974e+06     -5.963673e+06     -7.628770e+06     -4.883170e+06   \n",
       "20     -6.342989e+06     -5.960080e+06     -7.624846e+06     -4.879959e+06   \n",
       "21     -6.334374e+06     -5.952305e+06     -7.616247e+06     -4.874047e+06   \n",
       "22     -6.338380e+06     -5.955769e+06     -7.620347e+06     -4.876520e+06   \n",
       "23     -6.345839e+06     -5.962602e+06     -7.627626e+06     -4.882272e+06   \n",
       "24     -6.346868e+06     -5.963572e+06     -7.628662e+06     -4.883082e+06   \n",
       "\n",
       "    split4_test_RMSE  mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0      -8.364395e+06   -6.637405e+06   1.231331e+06              22  \n",
       "1      -8.364394e+06   -6.637404e+06   1.231330e+06              18  \n",
       "2      -8.364395e+06   -6.637405e+06   1.231330e+06              21  \n",
       "3      -8.364395e+06   -6.637405e+06   1.231331e+06              24  \n",
       "4      -8.364396e+06   -6.637405e+06   1.231331e+06              25  \n",
       "5      -8.364391e+06   -6.637402e+06   1.231330e+06              17  \n",
       "6      -8.364382e+06   -6.637394e+06   1.231329e+06              13  \n",
       "7      -8.364386e+06   -6.637397e+06   1.231330e+06              16  \n",
       "8      -8.364394e+06   -6.637404e+06   1.231330e+06              20  \n",
       "9      -8.364395e+06   -6.637405e+06   1.231331e+06              23  \n",
       "10     -8.364355e+06   -6.637369e+06   1.231328e+06              12  \n",
       "11     -8.364260e+06   -6.637286e+06   1.231316e+06               8  \n",
       "12     -8.364304e+06   -6.637325e+06   1.231321e+06              11  \n",
       "13     -8.364383e+06   -6.637394e+06   1.231330e+06              15  \n",
       "14     -8.364394e+06   -6.637404e+06   1.231330e+06              19  \n",
       "15     -8.363988e+06   -6.637038e+06   1.231302e+06               7  \n",
       "16     -8.363036e+06   -6.636208e+06   1.231183e+06               4  \n",
       "17     -8.363479e+06   -6.636599e+06   1.231235e+06               6  \n",
       "18     -8.364270e+06   -6.637294e+06   1.231320e+06              10  \n",
       "19     -8.364382e+06   -6.637394e+06   1.231330e+06              14  \n",
       "20     -8.360312e+06   -6.633637e+06   1.231052e+06               3  \n",
       "21     -8.351657e+06   -6.625726e+06   1.230181e+06               1  \n",
       "22     -8.355351e+06   -6.629273e+06   1.230605e+06               2  \n",
       "23     -8.363138e+06   -6.636295e+06   1.231223e+06               5  \n",
       "24     -8.364265e+06   -6.637290e+06   1.231320e+06               9  \n",
       "\n",
       "[25 rows x 32 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MySVMbest=pd.concat([pd.DataFrame(MySVM.cv_results_)])\n",
    "MySVMbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22   -0.089672\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MySVMbestR2=MySVMbest[MySVMbest['rank_test_R2'].isin([1])]\n",
    "print(MySVMbestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[19:25:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.0s\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.0s\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.0s\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.0s\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.0s\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[19:25:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:25:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MyXGBBoost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_87468\\1931691689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mMyXGBoost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mMyXGBBoost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'MyXGBBoost' is not defined"
     ]
    }
   ],
   "source": [
    "MyXGB = xg.XGBRegressor(objective ='reg:squarederror',\n",
    "                  n_estimators = 10, seed = 123)\n",
    "XGBparams = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "  \n",
    "# Fitting the model\n",
    "MyXGB.fit(X_train_std, y_train)\n",
    "  \n",
    "# Predict the model\n",
    "\n",
    "\n",
    "MyXGBoost = GridSearchCV(MyXGB,\n",
    "                        XGBparams,\n",
    "                          scoring=scoring,\n",
    "                        refit=False,\n",
    "                        cv = CV,\n",
    "                        \n",
    "                        verbose=2)\n",
    "\n",
    "MyXGBoost.fit(X_train_std,y_train)\n",
    "MyXGBBoost.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_nthread</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.157109</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.272226e+14</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.897615e+06</td>\n",
       "      <td>-4.116529e+06</td>\n",
       "      <td>-5.500102e+06</td>\n",
       "      <td>-4.486811e+06</td>\n",
       "      <td>-3.954688e+06</td>\n",
       "      <td>-4.591149e+06</td>\n",
       "      <td>558811.309764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179269</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.304376e+14</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.973154e+06</td>\n",
       "      <td>-4.167000e+06</td>\n",
       "      <td>-5.474085e+06</td>\n",
       "      <td>-4.529446e+06</td>\n",
       "      <td>-3.852408e+06</td>\n",
       "      <td>-4.599219e+06</td>\n",
       "      <td>575261.093759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195465</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.304518e+14</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.974130e+06</td>\n",
       "      <td>-4.135571e+06</td>\n",
       "      <td>-5.443871e+06</td>\n",
       "      <td>-4.544093e+06</td>\n",
       "      <td>-3.959193e+06</td>\n",
       "      <td>-4.611372e+06</td>\n",
       "      <td>544223.699576</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152213</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.236319e+14</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.094726e+06</td>\n",
       "      <td>-4.093877e+06</td>\n",
       "      <td>-5.492177e+06</td>\n",
       "      <td>-4.551094e+06</td>\n",
       "      <td>-3.957802e+06</td>\n",
       "      <td>-4.637935e+06</td>\n",
       "      <td>583867.896807</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.171201</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.279928e+14</td>\n",
       "      <td>8</td>\n",
       "      <td>-5.094226e+06</td>\n",
       "      <td>-4.178479e+06</td>\n",
       "      <td>-5.532459e+06</td>\n",
       "      <td>-4.666769e+06</td>\n",
       "      <td>-3.850791e+06</td>\n",
       "      <td>-4.664545e+06</td>\n",
       "      <td>606029.967921</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.191630</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.307708e+14</td>\n",
       "      <td>9</td>\n",
       "      <td>-5.235622e+06</td>\n",
       "      <td>-4.148338e+06</td>\n",
       "      <td>-5.561513e+06</td>\n",
       "      <td>-4.731349e+06</td>\n",
       "      <td>-3.931309e+06</td>\n",
       "      <td>-4.721626e+06</td>\n",
       "      <td>620154.488741</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.147619</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.230192e+14</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.153691e+06</td>\n",
       "      <td>-4.215644e+06</td>\n",
       "      <td>-5.540191e+06</td>\n",
       "      <td>-4.532082e+06</td>\n",
       "      <td>-4.007792e+06</td>\n",
       "      <td>-4.689880e+06</td>\n",
       "      <td>575011.865790</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.176062</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252374e+14</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.257488e+06</td>\n",
       "      <td>-4.247194e+06</td>\n",
       "      <td>-5.461590e+06</td>\n",
       "      <td>-4.549684e+06</td>\n",
       "      <td>-4.043475e+06</td>\n",
       "      <td>-4.711886e+06</td>\n",
       "      <td>556553.454575</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.208896</td>\n",
       "      <td>0.016351</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.267743e+14</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.347516e+06</td>\n",
       "      <td>-4.354880e+06</td>\n",
       "      <td>-5.535208e+06</td>\n",
       "      <td>-4.700631e+06</td>\n",
       "      <td>-4.072669e+06</td>\n",
       "      <td>-4.802181e+06</td>\n",
       "      <td>561657.881759</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.157109      0.001822         0.000000        0.000000   \n",
       "1       0.179269      0.012680         0.003126        0.006251   \n",
       "2       0.195465      0.007424         0.005524        0.006861   \n",
       "3       0.152213      0.008381         0.000501        0.001003   \n",
       "4       0.171201      0.003244         0.001701        0.003402   \n",
       "5       0.191630      0.006433         0.009380        0.007659   \n",
       "6       0.147619      0.007549         0.000000        0.000000   \n",
       "7       0.176062      0.006145         0.000000        0.000000   \n",
       "8       0.208896      0.016351         0.003663        0.007326   \n",
       "\n",
       "  param_colsample_bytree param_learning_rate param_max_depth  \\\n",
       "0                    0.7                0.03               5   \n",
       "1                    0.7                0.03               6   \n",
       "2                    0.7                0.03               7   \n",
       "3                    0.7                0.05               5   \n",
       "4                    0.7                0.05               6   \n",
       "5                    0.7                0.05               7   \n",
       "6                    0.7                0.07               5   \n",
       "7                    0.7                0.07               6   \n",
       "8                    0.7                0.07               7   \n",
       "\n",
       "  param_min_child_weight param_n_estimators param_nthread  ...  std_test_MAE  \\\n",
       "0                      4                500             4  ...  1.272226e+14   \n",
       "1                      4                500             4  ...  1.304376e+14   \n",
       "2                      4                500             4  ...  1.304518e+14   \n",
       "3                      4                500             4  ...  1.236319e+14   \n",
       "4                      4                500             4  ...  1.279928e+14   \n",
       "5                      4                500             4  ...  1.307708e+14   \n",
       "6                      4                500             4  ...  1.230192e+14   \n",
       "7                      4                500             4  ...  1.252374e+14   \n",
       "8                      4                500             4  ...  1.267743e+14   \n",
       "\n",
       "  rank_test_MAE split0_test_RMSE split1_test_RMSE  split2_test_RMSE  \\\n",
       "0             2    -4.897615e+06    -4.116529e+06     -5.500102e+06   \n",
       "1             5    -4.973154e+06    -4.167000e+06     -5.474085e+06   \n",
       "2             6    -4.974130e+06    -4.135571e+06     -5.443871e+06   \n",
       "3             3    -5.094726e+06    -4.093877e+06     -5.492177e+06   \n",
       "4             8    -5.094226e+06    -4.178479e+06     -5.532459e+06   \n",
       "5             9    -5.235622e+06    -4.148338e+06     -5.561513e+06   \n",
       "6             1    -5.153691e+06    -4.215644e+06     -5.540191e+06   \n",
       "7             4    -5.257488e+06    -4.247194e+06     -5.461590e+06   \n",
       "8             7    -5.347516e+06    -4.354880e+06     -5.535208e+06   \n",
       "\n",
       "   split3_test_RMSE  split4_test_RMSE  mean_test_RMSE  std_test_RMSE  \\\n",
       "0     -4.486811e+06     -3.954688e+06   -4.591149e+06  558811.309764   \n",
       "1     -4.529446e+06     -3.852408e+06   -4.599219e+06  575261.093759   \n",
       "2     -4.544093e+06     -3.959193e+06   -4.611372e+06  544223.699576   \n",
       "3     -4.551094e+06     -3.957802e+06   -4.637935e+06  583867.896807   \n",
       "4     -4.666769e+06     -3.850791e+06   -4.664545e+06  606029.967921   \n",
       "5     -4.731349e+06     -3.931309e+06   -4.721626e+06  620154.488741   \n",
       "6     -4.532082e+06     -4.007792e+06   -4.689880e+06  575011.865790   \n",
       "7     -4.549684e+06     -4.043475e+06   -4.711886e+06  556553.454575   \n",
       "8     -4.700631e+06     -4.072669e+06   -4.802181e+06  561657.881759   \n",
       "\n",
       "   rank_test_RMSE  \n",
       "0               1  \n",
       "1               2  \n",
       "2               3  \n",
       "3               4  \n",
       "4               5  \n",
       "5               8  \n",
       "6               6  \n",
       "7               7  \n",
       "8               9  \n",
       "\n",
       "[9 rows x 38 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyXGBoostbest=pd.concat([pd.DataFrame(MyXGBoost.cv_results_)])\n",
    "MyXGBoostbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    0.428865\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyXGBoostbestR2=MyXGBoostbest[MyXGBoostbest['rank_test_R2'].isin([1])]\n",
    "print(MyXGBoostbestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLEAU DES RESULTATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_features_to_select</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_nthread</th>\n",
       "      <th>param_objective</th>\n",
       "      <th>param_silent</th>\n",
       "      <th>param_subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_features_to_select': 1}</td>\n",
       "      <td>0.262110</td>\n",
       "      <td>0.274233</td>\n",
       "      <td>0.431692</td>\n",
       "      <td>0.548465</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.1}</td>\n",
       "      <td>0.232765</td>\n",
       "      <td>0.430674</td>\n",
       "      <td>0.430119</td>\n",
       "      <td>0.434232</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>0.185988</td>\n",
       "      <td>0.259103</td>\n",
       "      <td>0.547957</td>\n",
       "      <td>0.118714</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>0.196534</td>\n",
       "      <td>0.217959</td>\n",
       "      <td>0.573976</td>\n",
       "      <td>0.011510</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.367178</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.332482</td>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.533958</td>\n",
       "      <td>0.428898</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.030065</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.056915</td>\n",
       "      <td>-0.156800</td>\n",
       "      <td>-0.044892</td>\n",
       "      <td>-0.112706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.147619</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'learning_rate': 0.0...</td>\n",
       "      <td>0.203472</td>\n",
       "      <td>0.476445</td>\n",
       "      <td>0.605723</td>\n",
       "      <td>-0.027935</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>reg:linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.015712      0.000236         0.000000        0.000000   \n",
       "236       0.003125      0.006250         0.000000        0.000000   \n",
       "6         0.000000      0.000000         0.003125        0.006250   \n",
       "6         0.012502      0.006253         0.000000        0.000000   \n",
       "23        0.367178      0.002235         0.023257        0.006842   \n",
       "22        0.030065      0.008012         0.013822        0.003618   \n",
       "6         0.147619      0.007549         0.000000        0.000000   \n",
       "\n",
       "    param_n_features_to_select  \\\n",
       "0                            1   \n",
       "236                        NaN   \n",
       "6                          NaN   \n",
       "6                          NaN   \n",
       "23                         NaN   \n",
       "22                         NaN   \n",
       "6                          NaN   \n",
       "\n",
       "                                                params  split0_test_R2  \\\n",
       "0                          {'n_features_to_select': 1}        0.262110   \n",
       "236         {'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.1}        0.232765   \n",
       "6                                       {'alpha': 100}        0.185988   \n",
       "6                                       {'alpha': 100}        0.196534   \n",
       "23   {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.332482   \n",
       "22         {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}       -0.056915   \n",
       "6    {'colsample_bytree': 0.7, 'learning_rate': 0.0...        0.203472   \n",
       "\n",
       "     split1_test_R2  split2_test_R2  split3_test_R2  ...  param_gamma  \\\n",
       "0          0.274233        0.431692        0.548465  ...          NaN   \n",
       "236        0.430674        0.430119        0.434232  ...          NaN   \n",
       "6          0.259103        0.547957        0.118714  ...          NaN   \n",
       "6          0.217959        0.573976        0.011510  ...          NaN   \n",
       "23         0.620752        0.533958        0.428898  ...          NaN   \n",
       "22        -0.156800       -0.044892       -0.112706  ...         0.01   \n",
       "6          0.476445        0.605723       -0.027935  ...          NaN   \n",
       "\n",
       "     param_kernel  param_colsample_bytree  param_learning_rate  \\\n",
       "0             NaN                     NaN                  NaN   \n",
       "236           NaN                     NaN                  NaN   \n",
       "6             NaN                     NaN                  NaN   \n",
       "6             NaN                     NaN                  NaN   \n",
       "23            NaN                     NaN                  NaN   \n",
       "22            rbf                     NaN                  NaN   \n",
       "6             NaN                     0.7                 0.07   \n",
       "\n",
       "     param_max_depth  param_min_child_weight  param_nthread  param_objective  \\\n",
       "0                NaN                     NaN            NaN              NaN   \n",
       "236              NaN                     NaN            NaN              NaN   \n",
       "6                NaN                     NaN            NaN              NaN   \n",
       "6                NaN                     NaN            NaN              NaN   \n",
       "23               NaN                     NaN            NaN              NaN   \n",
       "22               NaN                     NaN            NaN              NaN   \n",
       "6                  5                       4              4       reg:linear   \n",
       "\n",
       "     param_silent  param_subsample  \n",
       "0             NaN              NaN  \n",
       "236           NaN              NaN  \n",
       "6             NaN              NaN  \n",
       "6             NaN              NaN  \n",
       "23            NaN              NaN  \n",
       "22            NaN              NaN  \n",
       "6               1              0.7  \n",
       "\n",
       "[7 rows x 68 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_concat = [MyDummybestR2,MyElasticbestR2,MyRidgebestR2,MyLassobestR2,MyRandombestR2, MySVMbestR2, MyXGBoostbestR2]\n",
    "pd.concat(liste_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST SANS CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7220455042636782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MyRandomtest = RandomForestRegressor(n_estimators = 500, random_state = 42)\n",
    "\n",
    "MyRandomtest.fit(X_train_std, y_train)\n",
    "MyRandomtest_predict = MyRandomtest.predict(X_test_std)\n",
    "\n",
    "\n",
    "mse_MyRandomtest_predict = mean_squared_error(y_test, MyRandomtest_predict)\n",
    "mae_MyRandomtest_predict = mean_absolute_error(y_test, MyRandomtest_predict)\n",
    "rmse_MyRandomtest_predict= mse_MyRandomtest_predict**.5\n",
    "r2_MyRandomtest_predict = r2_score(y_test.values.ravel(), MyRandomtest_predict)\n",
    "print(r2_MyRandomtest_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST SANS CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6648790637319353\n"
     ]
    }
   ],
   "source": [
    "MyXGBtest = xg.XGBRegressor(objective ='reg:squarederror',\n",
    "                  n_estimators = 10, seed = 123)\n",
    "XGBparams = {'nthread':[4], \n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03], \n",
    "              'max_depth': [5],\n",
    "              'min_child_weight': [4],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "  \n",
    "# Fitting the model\n",
    "MyXGBtest.fit(X_train_std, y_train)\n",
    "\n",
    "MyXGBtest_predict = MyXGBtest.predict(X_test_std)\n",
    "\n",
    "mse_MyXGBtest_predict = mean_squared_error(y_test, MyXGBtest_predict)\n",
    "mae_MyXGBtest_predict = mean_absolute_error(y_test, MyXGBtest_predict)\n",
    "rmse_MyXGBtest_predict= mse_MyXGBtest_predict**.5\n",
    "r2_MyXGBtest_predict = r2_score(y_test.values.ravel(), MyXGBtest_predict)\n",
    "print(r2_MyXGBtest_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST AVEC ENERGY SCORE LE MEILLEUR MODELE RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNRJ2[\"ENERGYSTARScore\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>SteamUse_Part</th>\n",
       "      <th>NaturalGas_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>LargestPropertyUseType_Distribution</th>\n",
       "      <th>LargestPropertyUseType_Food</th>\n",
       "      <th>LargestPropertyUseType_Hotel</th>\n",
       "      <th>LargestPropertyUseType_Legal</th>\n",
       "      <th>LargestPropertyUseType_Medical</th>\n",
       "      <th>LargestPropertyUseType_Office</th>\n",
       "      <th>LargestPropertyUseType_Other</th>\n",
       "      <th>LargestPropertyUseType_Parking</th>\n",
       "      <th>LargestPropertyUseType_School</th>\n",
       "      <th>LargestPropertyUseType_Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7.456910e+06</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277302</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.664479e+06</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7.393711e+07</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.946800e+06</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.465650e+07</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>18261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.025432e+06</td>\n",
       "      <td>20.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.053706e+06</td>\n",
       "      <td>32.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>13157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.053764e+06</td>\n",
       "      <td>223.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310820</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>14101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.828413e+05</td>\n",
       "      <td>22.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>18258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.293722e+06</td>\n",
       "      <td>41.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PropertyGFATotal  NumberofBuildings  NumberofFloors  \\\n",
       "0                88434                1.0              12   \n",
       "1               103566                1.0              11   \n",
       "2               956110                1.0              41   \n",
       "3                61320                1.0              10   \n",
       "4               175580                1.0              18   \n",
       "...                ...                ...             ...   \n",
       "1509             18261                1.0               1   \n",
       "1510             16000                1.0               1   \n",
       "1511             13157                1.0               1   \n",
       "1512             14101                1.0               1   \n",
       "1513             18258                1.0               1   \n",
       "\n",
       "      SiteEnergyUseWN(kBtu)  TotalGHGEmissions  Electricity_Use  \\\n",
       "0              7.456910e+06             249.98                1   \n",
       "1              8.664479e+06             295.86                1   \n",
       "2              7.393711e+07            2089.28                1   \n",
       "3              6.946800e+06             286.43                1   \n",
       "4              1.465650e+07             505.01                1   \n",
       "...                     ...                ...              ...   \n",
       "1509           1.025432e+06              20.33                1   \n",
       "1510           1.053706e+06              32.17                1   \n",
       "1511           6.053764e+06             223.54                1   \n",
       "1512           7.828413e+05              22.11                1   \n",
       "1513           1.293722e+06              41.27                1   \n",
       "\n",
       "      Electricity_Part  SteamUse_Use  SteamUse_Part  NaturalGas_Use  ...  \\\n",
       "0             0.546060             1       0.277302               1  ...   \n",
       "1             0.386609             0       0.000000               1  ...   \n",
       "2             0.682307             1       0.297113               1  ...   \n",
       "3             0.407519             1       0.325913               1  ...   \n",
       "4             0.378802             0       0.000000               1  ...   \n",
       "...                ...           ...            ...             ...  ...   \n",
       "1509          0.678440             0       0.000000               1  ...   \n",
       "1510          0.417296             0       0.000000               1  ...   \n",
       "1511          0.310820             0       0.000000               1  ...   \n",
       "1512          0.484898             0       0.000000               1  ...   \n",
       "1513          0.375189             0       0.000000               1  ...   \n",
       "\n",
       "      LargestPropertyUseType_Distribution  LargestPropertyUseType_Food  \\\n",
       "0                                       0                            0   \n",
       "1                                       0                            0   \n",
       "2                                       0                            0   \n",
       "3                                       0                            0   \n",
       "4                                       0                            0   \n",
       "...                                   ...                          ...   \n",
       "1509                                    0                            0   \n",
       "1510                                    0                            0   \n",
       "1511                                    0                            0   \n",
       "1512                                    0                            0   \n",
       "1513                                    0                            0   \n",
       "\n",
       "      LargestPropertyUseType_Hotel  LargestPropertyUseType_Legal  \\\n",
       "0                                1                             0   \n",
       "1                                1                             0   \n",
       "2                                1                             0   \n",
       "3                                1                             0   \n",
       "4                                1                             0   \n",
       "...                            ...                           ...   \n",
       "1509                             0                             0   \n",
       "1510                             0                             0   \n",
       "1511                             0                             0   \n",
       "1512                             0                             0   \n",
       "1513                             0                             0   \n",
       "\n",
       "      LargestPropertyUseType_Medical  LargestPropertyUseType_Office  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "...                              ...                            ...   \n",
       "1509                               0                              0   \n",
       "1510                               0                              0   \n",
       "1511                               0                              0   \n",
       "1512                               0                              0   \n",
       "1513                               0                              0   \n",
       "\n",
       "      LargestPropertyUseType_Other  LargestPropertyUseType_Parking  \\\n",
       "0                                0                               0   \n",
       "1                                0                               0   \n",
       "2                                0                               0   \n",
       "3                                0                               0   \n",
       "4                                0                               0   \n",
       "...                            ...                             ...   \n",
       "1509                             0                               0   \n",
       "1510                             0                               0   \n",
       "1511                             0                               0   \n",
       "1512                             0                               0   \n",
       "1513                             0                               0   \n",
       "\n",
       "      LargestPropertyUseType_School  LargestPropertyUseType_Sport  \n",
       "0                                 0                             0  \n",
       "1                                 0                             0  \n",
       "2                                 0                             0  \n",
       "3                                 0                             0  \n",
       "4                                 0                             0  \n",
       "...                             ...                           ...  \n",
       "1509                              0                             0  \n",
       "1510                              0                             0  \n",
       "1511                              0                             0  \n",
       "1512                              0                             0  \n",
       "1513                              0                             0  \n",
       "\n",
       "[1514 rows x 37 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNRJ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNRJ2.dropna(subset=\"ENERGYSTARScore\", inplace=True)\n",
    "dfNRJ2.dropna(subset=\"SiteEUIWN(kBtu/sf)\", inplace=True)\n",
    "dfNRJ2.dropna(subset=\"SiteEnergyUseWN(kBtu)\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropertyGFATotal                       0\n",
       "NumberofBuildings                      0\n",
       "NumberofFloors                         0\n",
       "SiteEnergyUseWN(kBtu)                  0\n",
       "TotalGHGEmissions                      0\n",
       "Electricity_Use                        0\n",
       "Electricity_Part                       0\n",
       "SteamUse_Use                           0\n",
       "SteamUse_Part                          0\n",
       "NaturalGas_Use                         0\n",
       "NaturalGas_Part                        0\n",
       "ENERGYSTARScore                        0\n",
       "age_building                           0\n",
       "part_park                              0\n",
       "SiteEUI(kBtu/sf)                       0\n",
       "SiteEUIWN(kBtu/sf)                     0\n",
       "SourceEUI(kBtu/sf)                     0\n",
       "SourceEUIWN(kBtu/sf)                   0\n",
       "SiteEnergyUse(kBtu)                    0\n",
       "PropertyGFABuilding(s)                 0\n",
       "GHGEmissionsIntensity                  0\n",
       "PrimaryPropertyType_Hotel              0\n",
       "PrimaryPropertyType_Medical            0\n",
       "PrimaryPropertyType_Office             0\n",
       "PrimaryPropertyType_Other              0\n",
       "PrimaryPropertyType_School             0\n",
       "LargestPropertyUseType_Culture         0\n",
       "LargestPropertyUseType_Distribution    0\n",
       "LargestPropertyUseType_Food            0\n",
       "LargestPropertyUseType_Hotel           0\n",
       "LargestPropertyUseType_Legal           0\n",
       "LargestPropertyUseType_Medical         0\n",
       "LargestPropertyUseType_Office          0\n",
       "LargestPropertyUseType_Other           0\n",
       "LargestPropertyUseType_Parking         0\n",
       "LargestPropertyUseType_School          0\n",
       "LargestPropertyUseType_Sport           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNRJ2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>SteamUse_Part</th>\n",
       "      <th>NaturalGas_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>LargestPropertyUseType_Distribution</th>\n",
       "      <th>LargestPropertyUseType_Food</th>\n",
       "      <th>LargestPropertyUseType_Hotel</th>\n",
       "      <th>LargestPropertyUseType_Legal</th>\n",
       "      <th>LargestPropertyUseType_Medical</th>\n",
       "      <th>LargestPropertyUseType_Office</th>\n",
       "      <th>LargestPropertyUseType_Other</th>\n",
       "      <th>LargestPropertyUseType_Parking</th>\n",
       "      <th>LargestPropertyUseType_School</th>\n",
       "      <th>LargestPropertyUseType_Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7.456910e+06</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277302</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.664479e+06</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7.393711e+07</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.946800e+06</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.465650e+07</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>536697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.403717e+07</td>\n",
       "      <td>245.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.749734</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>126823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.042400e+06</td>\n",
       "      <td>131.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.681123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>52085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.182622e+06</td>\n",
       "      <td>157.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203226</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>24990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.731814e+06</td>\n",
       "      <td>134.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490206</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>45000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.397742e+06</td>\n",
       "      <td>9.24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>983 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PropertyGFATotal  NumberofBuildings  NumberofFloors  \\\n",
       "0                88434                1.0              12   \n",
       "1               103566                1.0              11   \n",
       "2               956110                1.0              41   \n",
       "3                61320                1.0              10   \n",
       "4               175580                1.0              18   \n",
       "...                ...                ...             ...   \n",
       "1493            536697                1.0              13   \n",
       "1494            126823                1.0               4   \n",
       "1495             52085                1.0               1   \n",
       "1496             24990                1.0               2   \n",
       "1498             45000                1.0               3   \n",
       "\n",
       "      SiteEnergyUseWN(kBtu)  TotalGHGEmissions  Electricity_Use  \\\n",
       "0              7.456910e+06             249.98                1   \n",
       "1              8.664479e+06             295.86                1   \n",
       "2              7.393711e+07            2089.28                1   \n",
       "3              6.946800e+06             286.43                1   \n",
       "4              1.465650e+07             505.01                1   \n",
       "...                     ...                ...              ...   \n",
       "1493           1.403717e+07             245.16                1   \n",
       "1494           6.042400e+06             131.02                1   \n",
       "1495           4.182622e+06             157.70                1   \n",
       "1496           4.731814e+06             134.80                1   \n",
       "1498           1.397742e+06               9.24                1   \n",
       "\n",
       "      Electricity_Part  SteamUse_Use  SteamUse_Part  NaturalGas_Use  ...  \\\n",
       "0             0.546060             1       0.277302               1  ...   \n",
       "1             0.386609             0       0.000000               1  ...   \n",
       "2             0.682307             1       0.297113               1  ...   \n",
       "3             0.407519             1       0.325913               1  ...   \n",
       "4             0.378802             0       0.000000               1  ...   \n",
       "...                ...           ...            ...             ...  ...   \n",
       "1493          0.749734             0       0.000000               1  ...   \n",
       "1494          0.681123             0       0.000000               1  ...   \n",
       "1495          0.203226             0       0.000000               1  ...   \n",
       "1496          0.490206             0       0.000000               1  ...   \n",
       "1498          1.000000             0       0.000000               0  ...   \n",
       "\n",
       "      LargestPropertyUseType_Distribution  LargestPropertyUseType_Food  \\\n",
       "0                                       0                            0   \n",
       "1                                       0                            0   \n",
       "2                                       0                            0   \n",
       "3                                       0                            0   \n",
       "4                                       0                            0   \n",
       "...                                   ...                          ...   \n",
       "1493                                    0                            0   \n",
       "1494                                    0                            0   \n",
       "1495                                    1                            0   \n",
       "1496                                    0                            0   \n",
       "1498                                    0                            0   \n",
       "\n",
       "      LargestPropertyUseType_Hotel  LargestPropertyUseType_Legal  \\\n",
       "0                                1                             0   \n",
       "1                                1                             0   \n",
       "2                                1                             0   \n",
       "3                                1                             0   \n",
       "4                                1                             0   \n",
       "...                            ...                           ...   \n",
       "1493                             0                             0   \n",
       "1494                             1                             0   \n",
       "1495                             0                             0   \n",
       "1496                             0                             0   \n",
       "1498                             0                             0   \n",
       "\n",
       "      LargestPropertyUseType_Medical  LargestPropertyUseType_Office  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "...                              ...                            ...   \n",
       "1493                               0                              1   \n",
       "1494                               0                              0   \n",
       "1495                               0                              0   \n",
       "1496                               0                              1   \n",
       "1498                               0                              0   \n",
       "\n",
       "      LargestPropertyUseType_Other  LargestPropertyUseType_Parking  \\\n",
       "0                                0                               0   \n",
       "1                                0                               0   \n",
       "2                                0                               0   \n",
       "3                                0                               0   \n",
       "4                                0                               0   \n",
       "...                            ...                             ...   \n",
       "1493                             0                               0   \n",
       "1494                             0                               0   \n",
       "1495                             0                               0   \n",
       "1496                             0                               0   \n",
       "1498                             0                               0   \n",
       "\n",
       "      LargestPropertyUseType_School  LargestPropertyUseType_Sport  \n",
       "0                                 0                             0  \n",
       "1                                 0                             0  \n",
       "2                                 0                             0  \n",
       "3                                 0                             0  \n",
       "4                                 0                             0  \n",
       "...                             ...                           ...  \n",
       "1493                              0                             0  \n",
       "1494                              0                             0  \n",
       "1495                              0                             0  \n",
       "1496                              0                             0  \n",
       "1498                              1                             0  \n",
       "\n",
       "[983 rows x 37 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNRJ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfNRJ2[[\"ENERGYSTARScore\",'NumberofBuildings', 'NumberofFloors', \n",
    "       'age_building', 'part_park', \n",
    "       'PropertyGFABuilding(s)','PropertyGFATotal',\n",
    "        'PrimaryPropertyType_Hotel', 'PrimaryPropertyType_Medical', 'PrimaryPropertyType_Office', 'PrimaryPropertyType_Other', 'PrimaryPropertyType_School',\n",
    "        'LargestPropertyUseType_Culture', 'LargestPropertyUseType_Distribution',   'LargestPropertyUseType_Food', 'LargestPropertyUseType_Hotel', 'LargestPropertyUseType_Legal', 'LargestPropertyUseType_Medical', 'LargestPropertyUseType_Office', 'LargestPropertyUseType_Other', 'LargestPropertyUseType_Parking', 'LargestPropertyUseType_School', 'LargestPropertyUseType_Sport']]\n",
    "\n",
    "y = dfNRJ2[['SiteEnergyUseWN(kBtu)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "std_scale = StandardScaler().fit(X_train)\n",
    "X_train_std =  std_scale.transform(X_train)\n",
    "X_test_std =  std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23976793306372923\n"
     ]
    }
   ],
   "source": [
    "MyRandomtest_NRJ = RandomForestRegressor(n_estimators = 500, random_state = 42)\n",
    "\n",
    "MyRandomtest_NRJ.fit(X_train_std, y_train)\n",
    "MyRandomtest_NRJ_predict = MyRandomtest_NRJ.predict(X_test_std)\n",
    "\n",
    "\n",
    "mse_MyRandomtest_NRJ_predict = mean_squared_error(y_test, MyRandomtest_NRJ_predict)\n",
    "mae_MyRandomtest_NRJ_predict = mean_absolute_error(y_test, MyRandomtest_NRJ_predict)\n",
    "rmse_MyRandomtest_NRJ_predict= mse_MyRandomtest_NRJ_predict**.5\n",
    "r2_MyRandomtest_NRJ_predict = r2_score(y_test.values.ravel(), MyRandomtest_NRJ_predict)\n",
    "print(r2_MyRandomtest_NRJ_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES IMPORTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "X has feature names, but RandomForestRegressor was fitted without feature names\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(n_estimators = 500, random_state = 42)\n",
    "random_forest.fit(X_train_std, y_train)\n",
    "random_forest_preds = random_forest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>feature_importance_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PropertyGFABuilding(s)</td>\n",
       "      <td>3.759008e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PropertyGFATotal</td>\n",
       "      <td>3.627993e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENERGYSTARScore</td>\n",
       "      <td>1.585816e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NumberofBuildings</td>\n",
       "      <td>1.097029e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LargestPropertyUseType_Other</td>\n",
       "      <td>3.892364e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col_name  feature_importance_vals\n",
       "5         PropertyGFABuilding(s)             3.759008e+06\n",
       "6               PropertyGFATotal             3.627993e+06\n",
       "0                ENERGYSTARScore             1.585816e+06\n",
       "1              NumberofBuildings             1.097029e+06\n",
       "19  LargestPropertyUseType_Other             3.892364e+05"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = shap.TreeExplainer(random_forest)\n",
    "shap_values = explainer.shap_values(X_test_std)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "\n",
    "random_forest_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "vals = np.abs(random_forest_resultX.values).mean(0)\n",
    "\n",
    "shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
