{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "    \n",
    "import missingno as msno\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import folium\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "from textwrap import wrap\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, clone\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor, RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, LogisticRegression, Ridge, Lasso, LassoCV, RidgeCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score,  median_absolute_error, mean_absolute_error\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import dummy, preprocessing, utils\n",
    "\n",
    "\n",
    "import xgboost as xg\n",
    "import shap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('df_pour_explo.csv')\n",
    "df2= pd.read_csv('df_encoder_pour_explo.csv')\n",
    "\n",
    "dfNRJ= pd.read_csv('df_pour_explo.csv')\n",
    "dfNRJ2= pd.read_csv('df_encoder_pour_explo.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>age_building</th>\n",
       "      <th>part_park</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SiteEUIWN(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUIWN(kBtu/sf)</th>\n",
       "      <th>SiteEnergyUse(kBtu)</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>GHGEmissionsIntensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7.456910e+06</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>84.300003</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>7.226362e+06</td>\n",
       "      <td>88434</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.664479e+06</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>20</td>\n",
       "      <td>14.545314</td>\n",
       "      <td>94.800003</td>\n",
       "      <td>97.900002</td>\n",
       "      <td>176.100006</td>\n",
       "      <td>179.399994</td>\n",
       "      <td>8.387933e+06</td>\n",
       "      <td>88502</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7.393711e+07</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>47</td>\n",
       "      <td>20.574829</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>241.899994</td>\n",
       "      <td>244.100006</td>\n",
       "      <td>7.258702e+07</td>\n",
       "      <td>759392</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.946800e+06</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.800003</td>\n",
       "      <td>113.300003</td>\n",
       "      <td>216.199997</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>6.794584e+06</td>\n",
       "      <td>61320</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.465650e+07</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>36</td>\n",
       "      <td>35.311539</td>\n",
       "      <td>114.800003</td>\n",
       "      <td>118.699997</td>\n",
       "      <td>211.399994</td>\n",
       "      <td>215.600006</td>\n",
       "      <td>1.417261e+07</td>\n",
       "      <td>113580</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>18261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.025432e+06</td>\n",
       "      <td>20.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678440</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>136.600006</td>\n",
       "      <td>9.320821e+05</td>\n",
       "      <td>18261</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.053706e+06</td>\n",
       "      <td>32.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417296</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.400002</td>\n",
       "      <td>65.900002</td>\n",
       "      <td>114.199997</td>\n",
       "      <td>118.900002</td>\n",
       "      <td>9.502762e+05</td>\n",
       "      <td>16000</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>13157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.053764e+06</td>\n",
       "      <td>223.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310820</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>438.200012</td>\n",
       "      <td>460.100006</td>\n",
       "      <td>744.799988</td>\n",
       "      <td>767.799988</td>\n",
       "      <td>5.765898e+06</td>\n",
       "      <td>13157</td>\n",
       "      <td>16.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>14101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.828413e+05</td>\n",
       "      <td>22.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>105.300003</td>\n",
       "      <td>110.800003</td>\n",
       "      <td>7.194712e+05</td>\n",
       "      <td>14101</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>Other</td>\n",
       "      <td>Culture</td>\n",
       "      <td>18258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.293722e+06</td>\n",
       "      <td>41.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375189</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.099998</td>\n",
       "      <td>70.900002</td>\n",
       "      <td>115.800003</td>\n",
       "      <td>123.900002</td>\n",
       "      <td>1.152896e+06</td>\n",
       "      <td>18258</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PrimaryPropertyType LargestPropertyUseType  PropertyGFATotal  \\\n",
       "0                  Hotel                  Hotel             88434   \n",
       "1                  Hotel                  Hotel            103566   \n",
       "2                  Hotel                  Hotel            956110   \n",
       "3                  Hotel                  Hotel             61320   \n",
       "4                  Hotel                  Hotel            175580   \n",
       "...                  ...                    ...               ...   \n",
       "1509               Other                Culture             18261   \n",
       "1510               Other                Culture             16000   \n",
       "1511               Other                Culture             13157   \n",
       "1512               Other                Culture             14101   \n",
       "1513               Other                Culture             18258   \n",
       "\n",
       "      NumberofBuildings  NumberofFloors  SiteEnergyUseWN(kBtu)  \\\n",
       "0                   1.0              12           7.456910e+06   \n",
       "1                   1.0              11           8.664479e+06   \n",
       "2                   1.0              41           7.393711e+07   \n",
       "3                   1.0              10           6.946800e+06   \n",
       "4                   1.0              18           1.465650e+07   \n",
       "...                 ...             ...                    ...   \n",
       "1509                1.0               1           1.025432e+06   \n",
       "1510                1.0               1           1.053706e+06   \n",
       "1511                1.0               1           6.053764e+06   \n",
       "1512                1.0               1           7.828413e+05   \n",
       "1513                1.0               1           1.293722e+06   \n",
       "\n",
       "      TotalGHGEmissions  Electricity_Use  Electricity_Part  SteamUse_Use  ...  \\\n",
       "0                249.98                1          0.546060             1  ...   \n",
       "1                295.86                1          0.386609             0  ...   \n",
       "2               2089.28                1          0.682307             1  ...   \n",
       "3                286.43                1          0.407519             1  ...   \n",
       "4                505.01                1          0.378802             0  ...   \n",
       "...                 ...              ...               ...           ...  ...   \n",
       "1509              20.33                1          0.678440             0  ...   \n",
       "1510              32.17                1          0.417296             0  ...   \n",
       "1511             223.54                1          0.310820             0  ...   \n",
       "1512              22.11                1          0.484898             0  ...   \n",
       "1513              41.27                1          0.375189             0  ...   \n",
       "\n",
       "      ENERGYSTARScore  age_building  part_park  SiteEUI(kBtu/sf)  \\\n",
       "0                60.0            89   0.000000         81.699997   \n",
       "1                61.0            20  14.545314         94.800003   \n",
       "2                43.0            47  20.574829         96.000000   \n",
       "3                56.0            90   0.000000        110.800003   \n",
       "4                75.0            36  35.311539        114.800003   \n",
       "...               ...           ...        ...               ...   \n",
       "1509              NaN            34   0.000000         51.000000   \n",
       "1510              NaN            12   0.000000         59.400002   \n",
       "1511              NaN            42   0.000000        438.200012   \n",
       "1512              NaN            27   0.000000         51.000000   \n",
       "1513              NaN            78   0.000000         63.099998   \n",
       "\n",
       "      SiteEUIWN(kBtu/sf)  SourceEUI(kBtu/sf)  SourceEUIWN(kBtu/sf)  \\\n",
       "0              84.300003          182.500000            189.000000   \n",
       "1              97.900002          176.100006            179.399994   \n",
       "2              97.699997          241.899994            244.100006   \n",
       "3             113.300003          216.199997            224.000000   \n",
       "4             118.699997          211.399994            215.600006   \n",
       "...                  ...                 ...                   ...   \n",
       "1509           56.200001          126.000000            136.600006   \n",
       "1510           65.900002          114.199997            118.900002   \n",
       "1511          460.100006          744.799988            767.799988   \n",
       "1512           55.500000          105.300003            110.800003   \n",
       "1513           70.900002          115.800003            123.900002   \n",
       "\n",
       "      SiteEnergyUse(kBtu)  PropertyGFABuilding(s)  GHGEmissionsIntensity  \n",
       "0            7.226362e+06                   88434                   2.83  \n",
       "1            8.387933e+06                   88502                   2.86  \n",
       "2            7.258702e+07                  759392                   2.19  \n",
       "3            6.794584e+06                   61320                   4.67  \n",
       "4            1.417261e+07                  113580                   2.88  \n",
       "...                   ...                     ...                    ...  \n",
       "1509         9.320821e+05                   18261                   1.11  \n",
       "1510         9.502762e+05                   16000                   2.01  \n",
       "1511         5.765898e+06                   13157                  16.99  \n",
       "1512         7.194712e+05                   14101                   1.57  \n",
       "1513         1.152896e+06                   18258                   2.26  \n",
       "\n",
       "[1514 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop([\"ENERGYSTARScore\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(axis=0,how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>NaturalGas_Part</th>\n",
       "      <th>age_building</th>\n",
       "      <th>part_park</th>\n",
       "      <th>SiteEUI(kBtu/sf)</th>\n",
       "      <th>SiteEUIWN(kBtu/sf)</th>\n",
       "      <th>SourceEUI(kBtu/sf)</th>\n",
       "      <th>SourceEUIWN(kBtu/sf)</th>\n",
       "      <th>SiteEnergyUse(kBtu)</th>\n",
       "      <th>PropertyGFABuilding(s)</th>\n",
       "      <th>GHGEmissionsIntensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7456910.0</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176638</td>\n",
       "      <td>89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>84.300003</td>\n",
       "      <td>182.500000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>7226362.5</td>\n",
       "      <td>88434</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8664479.0</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613391</td>\n",
       "      <td>20</td>\n",
       "      <td>14.545314</td>\n",
       "      <td>94.800003</td>\n",
       "      <td>97.900002</td>\n",
       "      <td>176.100006</td>\n",
       "      <td>179.399994</td>\n",
       "      <td>8387933.0</td>\n",
       "      <td>88502</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>73937112.0</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020579</td>\n",
       "      <td>47</td>\n",
       "      <td>20.574829</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>241.899994</td>\n",
       "      <td>244.100006</td>\n",
       "      <td>72587024.0</td>\n",
       "      <td>759392</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6946800.5</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266567</td>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.800003</td>\n",
       "      <td>113.300003</td>\n",
       "      <td>216.199997</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>6794584.0</td>\n",
       "      <td>61320</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>14656503.0</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621198</td>\n",
       "      <td>36</td>\n",
       "      <td>35.311539</td>\n",
       "      <td>114.800003</td>\n",
       "      <td>118.699997</td>\n",
       "      <td>211.399994</td>\n",
       "      <td>215.600006</td>\n",
       "      <td>14172606.0</td>\n",
       "      <td>113580</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PrimaryPropertyType LargestPropertyUseType  PropertyGFATotal  \\\n",
       "0               Hotel                  Hotel             88434   \n",
       "1               Hotel                  Hotel            103566   \n",
       "2               Hotel                  Hotel            956110   \n",
       "3               Hotel                  Hotel             61320   \n",
       "4               Hotel                  Hotel            175580   \n",
       "\n",
       "   NumberofBuildings  NumberofFloors  SiteEnergyUseWN(kBtu)  \\\n",
       "0                1.0              12              7456910.0   \n",
       "1                1.0              11              8664479.0   \n",
       "2                1.0              41             73937112.0   \n",
       "3                1.0              10              6946800.5   \n",
       "4                1.0              18             14656503.0   \n",
       "\n",
       "   TotalGHGEmissions  Electricity_Use  Electricity_Part  SteamUse_Use  ...  \\\n",
       "0             249.98                1          0.546060             1  ...   \n",
       "1             295.86                1          0.386609             0  ...   \n",
       "2            2089.28                1          0.682307             1  ...   \n",
       "3             286.43                1          0.407519             1  ...   \n",
       "4             505.01                1          0.378802             0  ...   \n",
       "\n",
       "   NaturalGas_Part  age_building  part_park  SiteEUI(kBtu/sf)  \\\n",
       "0         0.176638            89   0.000000         81.699997   \n",
       "1         0.613391            20  14.545314         94.800003   \n",
       "2         0.020579            47  20.574829         96.000000   \n",
       "3         0.266567            90   0.000000        110.800003   \n",
       "4         0.621198            36  35.311539        114.800003   \n",
       "\n",
       "   SiteEUIWN(kBtu/sf)  SourceEUI(kBtu/sf)  SourceEUIWN(kBtu/sf)  \\\n",
       "0           84.300003          182.500000            189.000000   \n",
       "1           97.900002          176.100006            179.399994   \n",
       "2           97.699997          241.899994            244.100006   \n",
       "3          113.300003          216.199997            224.000000   \n",
       "4          118.699997          211.399994            215.600006   \n",
       "\n",
       "   SiteEnergyUse(kBtu)  PropertyGFABuilding(s)  GHGEmissionsIntensity  \n",
       "0            7226362.5                   88434                   2.83  \n",
       "1            8387933.0                   88502                   2.86  \n",
       "2           72587024.0                  759392                   2.19  \n",
       "3            6794584.0                   61320                   4.67  \n",
       "4           14172606.0                  113580                   2.88  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1509 entries, 0 to 1513\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   PrimaryPropertyType     1509 non-null   object \n",
      " 1   LargestPropertyUseType  1509 non-null   object \n",
      " 2   PropertyGFATotal        1509 non-null   int64  \n",
      " 3   NumberofBuildings       1509 non-null   float64\n",
      " 4   NumberofFloors          1509 non-null   int64  \n",
      " 5   SiteEnergyUseWN(kBtu)   1509 non-null   float64\n",
      " 6   TotalGHGEmissions       1509 non-null   float64\n",
      " 7   Electricity_Use         1509 non-null   int64  \n",
      " 8   Electricity_Part        1509 non-null   float64\n",
      " 9   SteamUse_Use            1509 non-null   int64  \n",
      " 10  SteamUse_Part           1509 non-null   float64\n",
      " 11  NaturalGas_Use          1509 non-null   int64  \n",
      " 12  NaturalGas_Part         1509 non-null   float64\n",
      " 13  age_building            1509 non-null   int64  \n",
      " 14  part_park               1509 non-null   float64\n",
      " 15  SiteEUI(kBtu/sf)        1509 non-null   float64\n",
      " 16  SiteEUIWN(kBtu/sf)      1509 non-null   float64\n",
      " 17  SourceEUI(kBtu/sf)      1509 non-null   float64\n",
      " 18  SourceEUIWN(kBtu/sf)    1509 non-null   float64\n",
      " 19  SiteEnergyUse(kBtu)     1509 non-null   float64\n",
      " 20  PropertyGFABuilding(s)  1509 non-null   int64  \n",
      " 21  GHGEmissionsIntensity   1509 non-null   float64\n",
      "dtypes: float64(13), int64(7), object(2)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>SteamUse_Part</th>\n",
       "      <th>NaturalGas_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>LargestPropertyUseType_Distribution</th>\n",
       "      <th>LargestPropertyUseType_Food</th>\n",
       "      <th>LargestPropertyUseType_Hotel</th>\n",
       "      <th>LargestPropertyUseType_Legal</th>\n",
       "      <th>LargestPropertyUseType_Medical</th>\n",
       "      <th>LargestPropertyUseType_Office</th>\n",
       "      <th>LargestPropertyUseType_Other</th>\n",
       "      <th>LargestPropertyUseType_Parking</th>\n",
       "      <th>LargestPropertyUseType_School</th>\n",
       "      <th>LargestPropertyUseType_Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7.456910e+06</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277302</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.664479e+06</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7.393711e+07</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.946800e+06</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.465650e+07</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>18261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.025432e+06</td>\n",
       "      <td>20.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.053706e+06</td>\n",
       "      <td>32.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>13157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.053764e+06</td>\n",
       "      <td>223.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310820</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>14101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.828413e+05</td>\n",
       "      <td>22.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>18258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.293722e+06</td>\n",
       "      <td>41.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PropertyGFATotal  NumberofBuildings  NumberofFloors  \\\n",
       "0                88434                1.0              12   \n",
       "1               103566                1.0              11   \n",
       "2               956110                1.0              41   \n",
       "3                61320                1.0              10   \n",
       "4               175580                1.0              18   \n",
       "...                ...                ...             ...   \n",
       "1509             18261                1.0               1   \n",
       "1510             16000                1.0               1   \n",
       "1511             13157                1.0               1   \n",
       "1512             14101                1.0               1   \n",
       "1513             18258                1.0               1   \n",
       "\n",
       "      SiteEnergyUseWN(kBtu)  TotalGHGEmissions  Electricity_Use  \\\n",
       "0              7.456910e+06             249.98                1   \n",
       "1              8.664479e+06             295.86                1   \n",
       "2              7.393711e+07            2089.28                1   \n",
       "3              6.946800e+06             286.43                1   \n",
       "4              1.465650e+07             505.01                1   \n",
       "...                     ...                ...              ...   \n",
       "1509           1.025432e+06              20.33                1   \n",
       "1510           1.053706e+06              32.17                1   \n",
       "1511           6.053764e+06             223.54                1   \n",
       "1512           7.828413e+05              22.11                1   \n",
       "1513           1.293722e+06              41.27                1   \n",
       "\n",
       "      Electricity_Part  SteamUse_Use  SteamUse_Part  NaturalGas_Use  ...  \\\n",
       "0             0.546060             1       0.277302               1  ...   \n",
       "1             0.386609             0       0.000000               1  ...   \n",
       "2             0.682307             1       0.297113               1  ...   \n",
       "3             0.407519             1       0.325913               1  ...   \n",
       "4             0.378802             0       0.000000               1  ...   \n",
       "...                ...           ...            ...             ...  ...   \n",
       "1509          0.678440             0       0.000000               1  ...   \n",
       "1510          0.417296             0       0.000000               1  ...   \n",
       "1511          0.310820             0       0.000000               1  ...   \n",
       "1512          0.484898             0       0.000000               1  ...   \n",
       "1513          0.375189             0       0.000000               1  ...   \n",
       "\n",
       "      LargestPropertyUseType_Distribution  LargestPropertyUseType_Food  \\\n",
       "0                                       0                            0   \n",
       "1                                       0                            0   \n",
       "2                                       0                            0   \n",
       "3                                       0                            0   \n",
       "4                                       0                            0   \n",
       "...                                   ...                          ...   \n",
       "1509                                    0                            0   \n",
       "1510                                    0                            0   \n",
       "1511                                    0                            0   \n",
       "1512                                    0                            0   \n",
       "1513                                    0                            0   \n",
       "\n",
       "      LargestPropertyUseType_Hotel  LargestPropertyUseType_Legal  \\\n",
       "0                                1                             0   \n",
       "1                                1                             0   \n",
       "2                                1                             0   \n",
       "3                                1                             0   \n",
       "4                                1                             0   \n",
       "...                            ...                           ...   \n",
       "1509                             0                             0   \n",
       "1510                             0                             0   \n",
       "1511                             0                             0   \n",
       "1512                             0                             0   \n",
       "1513                             0                             0   \n",
       "\n",
       "      LargestPropertyUseType_Medical  LargestPropertyUseType_Office  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "...                              ...                            ...   \n",
       "1509                               0                              0   \n",
       "1510                               0                              0   \n",
       "1511                               0                              0   \n",
       "1512                               0                              0   \n",
       "1513                               0                              0   \n",
       "\n",
       "      LargestPropertyUseType_Other  LargestPropertyUseType_Parking  \\\n",
       "0                                0                               0   \n",
       "1                                0                               0   \n",
       "2                                0                               0   \n",
       "3                                0                               0   \n",
       "4                                0                               0   \n",
       "...                            ...                             ...   \n",
       "1509                             0                               0   \n",
       "1510                             0                               0   \n",
       "1511                             0                               0   \n",
       "1512                             0                               0   \n",
       "1513                             0                               0   \n",
       "\n",
       "      LargestPropertyUseType_School  LargestPropertyUseType_Sport  \n",
       "0                                 0                             0  \n",
       "1                                 0                             0  \n",
       "2                                 0                             0  \n",
       "3                                 0                             0  \n",
       "4                                 0                             0  \n",
       "...                             ...                           ...  \n",
       "1509                              0                             0  \n",
       "1510                              0                             0  \n",
       "1511                              0                             0  \n",
       "1512                              0                             0  \n",
       "1513                              0                             0  \n",
       "\n",
       "[1514 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= df2.drop([\"ENERGYSTARScore\"], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.dropna(axis=0,how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>SteamUse_Part</th>\n",
       "      <th>NaturalGas_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>LargestPropertyUseType_Distribution</th>\n",
       "      <th>LargestPropertyUseType_Food</th>\n",
       "      <th>LargestPropertyUseType_Hotel</th>\n",
       "      <th>LargestPropertyUseType_Legal</th>\n",
       "      <th>LargestPropertyUseType_Medical</th>\n",
       "      <th>LargestPropertyUseType_Office</th>\n",
       "      <th>LargestPropertyUseType_Other</th>\n",
       "      <th>LargestPropertyUseType_Parking</th>\n",
       "      <th>LargestPropertyUseType_School</th>\n",
       "      <th>LargestPropertyUseType_Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7456910.0</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277302</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8664479.0</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>73937112.0</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6946800.5</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>14656503.0</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PropertyGFATotal  NumberofBuildings  NumberofFloors  SiteEnergyUseWN(kBtu)  \\\n",
       "0             88434                1.0              12              7456910.0   \n",
       "1            103566                1.0              11              8664479.0   \n",
       "2            956110                1.0              41             73937112.0   \n",
       "3             61320                1.0              10              6946800.5   \n",
       "4            175580                1.0              18             14656503.0   \n",
       "\n",
       "   TotalGHGEmissions  Electricity_Use  Electricity_Part  SteamUse_Use  \\\n",
       "0             249.98                1          0.546060             1   \n",
       "1             295.86                1          0.386609             0   \n",
       "2            2089.28                1          0.682307             1   \n",
       "3             286.43                1          0.407519             1   \n",
       "4             505.01                1          0.378802             0   \n",
       "\n",
       "   SteamUse_Part  NaturalGas_Use  ...  LargestPropertyUseType_Distribution  \\\n",
       "0       0.277302               1  ...                                    0   \n",
       "1       0.000000               1  ...                                    0   \n",
       "2       0.297113               1  ...                                    0   \n",
       "3       0.325913               1  ...                                    0   \n",
       "4       0.000000               1  ...                                    0   \n",
       "\n",
       "   LargestPropertyUseType_Food  LargestPropertyUseType_Hotel  \\\n",
       "0                            0                             1   \n",
       "1                            0                             1   \n",
       "2                            0                             1   \n",
       "3                            0                             1   \n",
       "4                            0                             1   \n",
       "\n",
       "   LargestPropertyUseType_Legal  LargestPropertyUseType_Medical  \\\n",
       "0                             0                               0   \n",
       "1                             0                               0   \n",
       "2                             0                               0   \n",
       "3                             0                               0   \n",
       "4                             0                               0   \n",
       "\n",
       "   LargestPropertyUseType_Office  LargestPropertyUseType_Other  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              0                             0   \n",
       "4                              0                             0   \n",
       "\n",
       "   LargestPropertyUseType_Parking  LargestPropertyUseType_School  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "\n",
       "   LargestPropertyUseType_Sport  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1513 entries, 0 to 1513\n",
      "Data columns (total 36 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   PropertyGFATotal                     1513 non-null   int64  \n",
      " 1   NumberofBuildings                    1513 non-null   float64\n",
      " 2   NumberofFloors                       1513 non-null   int64  \n",
      " 3   SiteEnergyUseWN(kBtu)                1513 non-null   float64\n",
      " 4   TotalGHGEmissions                    1513 non-null   float64\n",
      " 5   Electricity_Use                      1513 non-null   int64  \n",
      " 6   Electricity_Part                     1513 non-null   float64\n",
      " 7   SteamUse_Use                         1513 non-null   int64  \n",
      " 8   SteamUse_Part                        1513 non-null   float64\n",
      " 9   NaturalGas_Use                       1513 non-null   int64  \n",
      " 10  NaturalGas_Part                      1513 non-null   float64\n",
      " 11  age_building                         1513 non-null   int64  \n",
      " 12  part_park                            1513 non-null   float64\n",
      " 13  SiteEUI(kBtu/sf)                     1513 non-null   float64\n",
      " 14  SiteEUIWN(kBtu/sf)                   1513 non-null   float64\n",
      " 15  SourceEUI(kBtu/sf)                   1513 non-null   float64\n",
      " 16  SourceEUIWN(kBtu/sf)                 1513 non-null   float64\n",
      " 17  SiteEnergyUse(kBtu)                  1513 non-null   float64\n",
      " 18  PropertyGFABuilding(s)               1513 non-null   int64  \n",
      " 19  GHGEmissionsIntensity                1513 non-null   float64\n",
      " 20  PrimaryPropertyType_Hotel            1513 non-null   int64  \n",
      " 21  PrimaryPropertyType_Medical          1513 non-null   int64  \n",
      " 22  PrimaryPropertyType_Office           1513 non-null   int64  \n",
      " 23  PrimaryPropertyType_Other            1513 non-null   int64  \n",
      " 24  PrimaryPropertyType_School           1513 non-null   int64  \n",
      " 25  LargestPropertyUseType_Culture       1513 non-null   int64  \n",
      " 26  LargestPropertyUseType_Distribution  1513 non-null   int64  \n",
      " 27  LargestPropertyUseType_Food          1513 non-null   int64  \n",
      " 28  LargestPropertyUseType_Hotel         1513 non-null   int64  \n",
      " 29  LargestPropertyUseType_Legal         1513 non-null   int64  \n",
      " 30  LargestPropertyUseType_Medical       1513 non-null   int64  \n",
      " 31  LargestPropertyUseType_Office        1513 non-null   int64  \n",
      " 32  LargestPropertyUseType_Other         1513 non-null   int64  \n",
      " 33  LargestPropertyUseType_Parking       1513 non-null   int64  \n",
      " 34  LargestPropertyUseType_School        1513 non-null   int64  \n",
      " 35  LargestPropertyUseType_Sport         1513 non-null   int64  \n",
      "dtypes: float64(13), int64(23)\n",
      "memory usage: 437.4 KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARATION DES VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[['NumberofBuildings', 'NumberofFloors', \n",
    "       'age_building', 'part_park', 'Electricity_Use' , 'SteamUse_Use', 'NaturalGas_Use',\n",
    "         'PropertyGFABuilding(s)','PropertyGFATotal',\n",
    "        'PrimaryPropertyType_Hotel', 'PrimaryPropertyType_Medical', 'PrimaryPropertyType_Office', 'PrimaryPropertyType_Other', 'PrimaryPropertyType_School',\n",
    "        'LargestPropertyUseType_Culture', 'LargestPropertyUseType_Distribution',   'LargestPropertyUseType_Food', 'LargestPropertyUseType_Hotel', 'LargestPropertyUseType_Legal', 'LargestPropertyUseType_Medical', 'LargestPropertyUseType_Office', 'LargestPropertyUseType_Other', 'LargestPropertyUseType_Parking', 'LargestPropertyUseType_School', 'LargestPropertyUseType_Sport']]\n",
    "\n",
    "y = df2[['TotalGHGEmissions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "std_scale = StandardScaler().fit(X_train)\n",
    "X_train_std =  std_scale.transform(X_train)\n",
    "X_test_std =  std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "\n",
    "scoring = {'R2': 'r2',\n",
    "           'MAE': 'neg_mean_squared_error',\n",
    "           'RMSE': 'neg_mean_absolute_error'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DUMMY REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=1; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=2; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=3; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n",
      "[CV] END .............................n_features_to_select=4; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01317339, 0.01280298, 0.01244483, 0.01090846]),\n",
       " 'std_fit_time': array([0.00132388, 0.00116665, 0.00103798, 0.00049603]),\n",
       " 'mean_score_time': array([0.00240049, 0.00210109, 0.00180135, 0.00200233]),\n",
       " 'std_score_time': array([4.89804047e-04, 2.01272993e-04, 7.48546629e-04, 3.88731970e-06]),\n",
       " 'param_n_features_to_select': masked_array(data=[1, 2, 3, 4],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_features_to_select': 1},\n",
       "  {'n_features_to_select': 2},\n",
       "  {'n_features_to_select': 3},\n",
       "  {'n_features_to_select': 4}],\n",
       " 'split0_test_R2': array([-0.33214763, -0.42579776, -1.04378163, -0.85809427]),\n",
       " 'split1_test_R2': array([-1.57961718, -1.52252683, -1.65485978, -2.17131695]),\n",
       " 'split2_test_R2': array([0.26830075, 0.30810919, 0.47942491, 0.52801316]),\n",
       " 'split3_test_R2': array([ 0.26526687,  0.03108025, -1.19318086, -1.02876269]),\n",
       " 'split4_test_R2': array([0.35233823, 0.40291519, 0.57239082, 0.61786451]),\n",
       " 'mean_test_R2': array([-0.20517179, -0.24124399, -0.56800131, -0.58245925]),\n",
       " 'std_test_R2': array([0.72959293, 0.70237259, 0.91608663, 1.0462845 ]),\n",
       " 'rank_test_R2': array([1, 2, 3, 4]),\n",
       " 'split0_train_R2': array([0.31639095, 0.3553141 , 0.5211106 , 0.55963503]),\n",
       " 'split1_train_R2': array([0.33198278, 0.36891002, 0.51969465, 0.57066102]),\n",
       " 'split2_train_R2': array([0.30259221, 0.33349513, 0.41261982, 0.44741763]),\n",
       " 'split3_train_R2': array([0.30083993, 0.34464744, 0.52781182, 0.56722502]),\n",
       " 'split4_train_R2': array([0.25710999, 0.27899469, 0.39997847, 0.44186341]),\n",
       " 'mean_train_R2': array([0.30178317, 0.33627228, 0.47624307, 0.51736042]),\n",
       " 'std_train_R2': array([0.02499056, 0.03093991, 0.05731436, 0.0595086 ]),\n",
       " 'split0_test_MAE': array([ -79013.82242364,  -84568.50332255, -121223.05022005,\n",
       "        -110209.35476695]),\n",
       " 'split1_test_MAE': array([-101514.67984841,  -99268.02520616, -104475.67298371,\n",
       "        -124799.61265847]),\n",
       " 'split2_test_MAE': array([-727724.80090035, -688132.58466707, -517747.42727064,\n",
       "        -469423.09208598]),\n",
       " 'split3_test_MAE': array([ -47596.66769807,  -62767.48619998, -142076.21294291,\n",
       "        -131425.05703956]),\n",
       " 'split4_test_MAE': array([-517239.2936047 , -476847.24263392, -341499.65428502,\n",
       "        -305183.20007109]),\n",
       " 'mean_test_MAE': array([-294617.85289503, -282316.76840593, -245404.40354047,\n",
       "        -228208.06332441]),\n",
       " 'std_test_MAE': array([276382.1027514 , 254299.70042401, 160850.02354438, 140066.99466577]),\n",
       " 'rank_test_MAE': array([4, 3, 2, 1]),\n",
       " 'split0_train_MAE': array([-325884.77288935, -307329.63506029, -228292.4194557 ,\n",
       "        -209927.35477209]),\n",
       " 'split1_train_MAE': array([-321741.60788222, -303956.09168391, -231332.68215751,\n",
       "        -206785.40589433]),\n",
       " 'split2_train_MAE': array([-168625.19922403, -161153.22731233, -142021.78526053,\n",
       "        -133608.07540698]),\n",
       " 'split3_train_MAE': array([-332225.39894814, -311409.04138048, -224373.37662732,\n",
       "        -205645.09820049]),\n",
       " 'split4_train_MAE': array([-216630.20921933, -210248.52892925, -174969.08972385,\n",
       "        -162755.2448429 ]),\n",
       " 'mean_train_MAE': array([-273021.43763261, -258819.30487325, -200197.87064498,\n",
       "        -183744.23582336]),\n",
       " 'std_train_MAE': array([67456.41774492, 61731.75038225, 35676.55686225, 30496.79108582]),\n",
       " 'split0_test_RMSE': array([-129.1385758 , -143.42790572, -158.65226665, -148.43448588]),\n",
       " 'split1_test_RMSE': array([-153.63673852, -158.0711654 , -170.37787328, -199.40749105]),\n",
       " 'split2_test_RMSE': array([-195.55367454, -203.76128058, -200.79121908, -196.1748672 ]),\n",
       " 'split3_test_RMSE': array([-110.37756762, -127.92486608, -158.37742975, -159.67058986]),\n",
       " 'split4_test_RMSE': array([-204.17563117, -208.50415597, -195.17863086, -191.98438202]),\n",
       " 'mean_test_RMSE': array([-158.57643753, -168.33787475, -176.67548392, -179.1343632 ]),\n",
       " 'std_test_RMSE': array([36.49855314, 32.33348411, 18.01804749, 20.91804204]),\n",
       " 'rank_test_RMSE': array([1, 2, 3, 4]),\n",
       " 'split0_train_RMSE': array([-171.4950561 , -182.36111389, -187.14885318, -190.04241685]),\n",
       " 'split1_train_RMSE': array([-168.93129324, -178.57054439, -181.06559915, -182.68961588]),\n",
       " 'split2_train_RMSE': array([-133.06177019, -139.59961171, -146.65155389, -146.11134655]),\n",
       " 'split3_train_RMSE': array([-170.02361636, -182.17027924, -185.90578914, -189.38666586]),\n",
       " 'split4_train_RMSE': array([-136.50833927, -142.47066505, -154.07322732, -156.7753348 ]),\n",
       " 'mean_train_RMSE': array([-156.00401503, -165.03444286, -170.96900454, -173.00107599]),\n",
       " 'std_train_RMSE': array([17.37851587, 19.66281347, 17.10930714, 18.10577193])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Dummyparams = [{'n_features_to_select': list(range(1, 5))}]\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train_std, y_train)\n",
    "rfe = RFE(lm)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "\n",
    "MyDummy = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = Dummyparams, \n",
    "                        scoring= scoring,\n",
    "                        refit= False,  \n",
    "                        cv = CV, \n",
    "                        verbose = 2,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "MyDummy.fit(X_train_std, y_train)  \n",
    "\n",
    "MyDummy.cv_results_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_features_to_select</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "      <th>split0_train_RMSE</th>\n",
       "      <th>split1_train_RMSE</th>\n",
       "      <th>split2_train_RMSE</th>\n",
       "      <th>split3_train_RMSE</th>\n",
       "      <th>split4_train_RMSE</th>\n",
       "      <th>mean_train_RMSE</th>\n",
       "      <th>std_train_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013173</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_features_to_select': 1}</td>\n",
       "      <td>-0.332148</td>\n",
       "      <td>-1.579617</td>\n",
       "      <td>0.268301</td>\n",
       "      <td>0.265267</td>\n",
       "      <td>...</td>\n",
       "      <td>-158.576438</td>\n",
       "      <td>36.498553</td>\n",
       "      <td>1</td>\n",
       "      <td>-171.495056</td>\n",
       "      <td>-168.931293</td>\n",
       "      <td>-133.061770</td>\n",
       "      <td>-170.023616</td>\n",
       "      <td>-136.508339</td>\n",
       "      <td>-156.004015</td>\n",
       "      <td>17.378516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_features_to_select': 2}</td>\n",
       "      <td>-0.425798</td>\n",
       "      <td>-1.522527</td>\n",
       "      <td>0.308109</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>...</td>\n",
       "      <td>-168.337875</td>\n",
       "      <td>32.333484</td>\n",
       "      <td>2</td>\n",
       "      <td>-182.361114</td>\n",
       "      <td>-178.570544</td>\n",
       "      <td>-139.599612</td>\n",
       "      <td>-182.170279</td>\n",
       "      <td>-142.470665</td>\n",
       "      <td>-165.034443</td>\n",
       "      <td>19.662813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012445</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_features_to_select': 3}</td>\n",
       "      <td>-1.043782</td>\n",
       "      <td>-1.654860</td>\n",
       "      <td>0.479425</td>\n",
       "      <td>-1.193181</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.675484</td>\n",
       "      <td>18.018047</td>\n",
       "      <td>3</td>\n",
       "      <td>-187.148853</td>\n",
       "      <td>-181.065599</td>\n",
       "      <td>-146.651554</td>\n",
       "      <td>-185.905789</td>\n",
       "      <td>-154.073227</td>\n",
       "      <td>-170.969005</td>\n",
       "      <td>17.109307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_features_to_select': 4}</td>\n",
       "      <td>-0.858094</td>\n",
       "      <td>-2.171317</td>\n",
       "      <td>0.528013</td>\n",
       "      <td>-1.028763</td>\n",
       "      <td>...</td>\n",
       "      <td>-179.134363</td>\n",
       "      <td>20.918042</td>\n",
       "      <td>4</td>\n",
       "      <td>-190.042417</td>\n",
       "      <td>-182.689616</td>\n",
       "      <td>-146.111347</td>\n",
       "      <td>-189.386666</td>\n",
       "      <td>-156.775335</td>\n",
       "      <td>-173.001076</td>\n",
       "      <td>18.105772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.013173      0.001324         0.002400        0.000490   \n",
       "1       0.012803      0.001167         0.002101        0.000201   \n",
       "2       0.012445      0.001038         0.001801        0.000749   \n",
       "3       0.010908      0.000496         0.002002        0.000004   \n",
       "\n",
       "  param_n_features_to_select                       params  split0_test_R2  \\\n",
       "0                          1  {'n_features_to_select': 1}       -0.332148   \n",
       "1                          2  {'n_features_to_select': 2}       -0.425798   \n",
       "2                          3  {'n_features_to_select': 3}       -1.043782   \n",
       "3                          4  {'n_features_to_select': 4}       -0.858094   \n",
       "\n",
       "   split1_test_R2  split2_test_R2  split3_test_R2  ...  mean_test_RMSE  \\\n",
       "0       -1.579617        0.268301        0.265267  ...     -158.576438   \n",
       "1       -1.522527        0.308109        0.031080  ...     -168.337875   \n",
       "2       -1.654860        0.479425       -1.193181  ...     -176.675484   \n",
       "3       -2.171317        0.528013       -1.028763  ...     -179.134363   \n",
       "\n",
       "   std_test_RMSE  rank_test_RMSE  split0_train_RMSE  split1_train_RMSE  \\\n",
       "0      36.498553               1        -171.495056        -168.931293   \n",
       "1      32.333484               2        -182.361114        -178.570544   \n",
       "2      18.018047               3        -187.148853        -181.065599   \n",
       "3      20.918042               4        -190.042417        -182.689616   \n",
       "\n",
       "   split2_train_RMSE  split3_train_RMSE  split4_train_RMSE  mean_train_RMSE  \\\n",
       "0        -133.061770        -170.023616        -136.508339      -156.004015   \n",
       "1        -139.599612        -182.170279        -142.470665      -165.034443   \n",
       "2        -146.651554        -185.905789        -154.073227      -170.969005   \n",
       "3        -146.111347        -189.386666        -156.775335      -173.001076   \n",
       "\n",
       "   std_train_RMSE  \n",
       "0       17.378516  \n",
       "1       19.662813  \n",
       "2       17.109307  \n",
       "3       18.105772  \n",
       "\n",
       "[4 rows x 51 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyDummybest=pd.concat([pd.DataFrame(MyDummy.cv_results_)])\n",
    "MyDummybest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.205172\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyDummybestR2=MyDummybest[MyDummybest['rank_test_R2'].isin([1])]\n",
    "print(MyDummybestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ELASTICNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 280 candidates, totalling 1400 fits\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.637e+07, tolerance: 4.324e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.512e+07, tolerance: 4.368e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.358e+07, tolerance: 2.193e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+07, tolerance: 4.310e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.806e+07, tolerance: 2.648e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.637e+07, tolerance: 4.324e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.512e+07, tolerance: 4.368e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.358e+07, tolerance: 2.193e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+07, tolerance: 4.310e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.806e+07, tolerance: 2.648e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.0001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.637e+07, tolerance: 4.324e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.512e+07, tolerance: 4.368e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.358e+07, tolerance: 2.193e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+07, tolerance: 4.310e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.806e+07, tolerance: 2.648e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.637e+07, tolerance: 4.324e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.512e+07, tolerance: 4.368e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.358e+07, tolerance: 2.193e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.374e+07, tolerance: 4.310e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.806e+07, tolerance: 2.648e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.526e+07, tolerance: 2.648e+07\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.526e+07, tolerance: 2.648e+06\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.909e+05, tolerance: 4.310e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.526e+07, tolerance: 2.648e+05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.0001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e+05, tolerance: 4.368e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.909e+05, tolerance: 4.310e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.526e+07, tolerance: 2.648e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e+07, tolerance: 2.648e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e+07, tolerance: 2.648e+06\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e+07, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.089e+04, tolerance: 4.368e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+05, tolerance: 4.310e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e+07, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e+07, tolerance: 2.648e+07\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e+07, tolerance: 2.648e+06\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e+07, tolerance: 2.648e+05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.544e+04, tolerance: 4.310e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e+07, tolerance: 2.648e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+07, tolerance: 2.648e+07\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+07, tolerance: 2.648e+06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+07, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e+07, tolerance: 2.648e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+07, tolerance: 2.648e+07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+07, tolerance: 2.648e+06\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+07, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+07, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+07, tolerance: 2.648e+07\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+07, tolerance: 2.648e+06\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+07, tolerance: 2.648e+05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+07, tolerance: 2.648e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.425e+07, tolerance: 2.648e+06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.0001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.425e+07, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.425e+07, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 2.648e+06\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+07, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............alpha=0.0001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.0001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.0001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 2.648e+06\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+07, tolerance: 2.648e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.681e+07, tolerance: 4.324e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.0001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .............alpha=0.0001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e+07, tolerance: 4.368e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.397e+07, tolerance: 2.193e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.423e+07, tolerance: 4.310e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.833e+07, tolerance: 2.648e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.681e+07, tolerance: 4.324e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e+07, tolerance: 4.368e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.397e+07, tolerance: 2.193e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.423e+07, tolerance: 4.310e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.833e+07, tolerance: 2.648e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.681e+07, tolerance: 4.324e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e+07, tolerance: 4.368e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.397e+07, tolerance: 2.193e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.423e+07, tolerance: 4.310e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.833e+07, tolerance: 2.648e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.681e+07, tolerance: 4.324e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e+07, tolerance: 4.368e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.397e+07, tolerance: 2.193e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.423e+07, tolerance: 4.310e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.833e+07, tolerance: 2.648e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.001, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.1, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+06, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+06, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+05, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e+05, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.801e+05, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.801e+05, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.291e+05, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.291e+05, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.001, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.269e+05, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.269e+05, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.488e+05, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.488e+05, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=0.001, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.001, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.001, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.915e+05, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.915e+05, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.559e+05, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.559e+05, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.001, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.001, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.001, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..............alpha=0.001, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.454e+05, tolerance: 2.648e+05\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.454e+05, tolerance: 2.648e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.934e+07, tolerance: 4.324e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.754e+07, tolerance: 4.368e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.605e+07, tolerance: 2.193e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.707e+07, tolerance: 4.310e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.976e+07, tolerance: 2.648e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.934e+07, tolerance: 4.324e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.754e+07, tolerance: 4.368e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.605e+07, tolerance: 2.193e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.707e+07, tolerance: 4.310e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.976e+07, tolerance: 2.648e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.934e+07, tolerance: 4.324e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.754e+07, tolerance: 4.368e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.605e+07, tolerance: 2.193e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.707e+07, tolerance: 4.310e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.976e+07, tolerance: 2.648e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.934e+07, tolerance: 4.324e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.754e+07, tolerance: 4.368e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.605e+07, tolerance: 2.193e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.707e+07, tolerance: 4.310e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.976e+07, tolerance: 2.648e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.01, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.01, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.01, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.01, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.01, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.01, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.01, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...............alpha=0.01, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.726e+07, tolerance: 4.324e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.549e+07, tolerance: 4.368e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.057e+07, tolerance: 2.193e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.559e+07, tolerance: 4.310e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.428e+07, tolerance: 2.648e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.726e+07, tolerance: 4.324e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.549e+07, tolerance: 4.368e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.057e+07, tolerance: 2.193e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.559e+07, tolerance: 4.310e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.428e+07, tolerance: 2.648e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.726e+07, tolerance: 4.324e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.549e+07, tolerance: 4.368e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.057e+07, tolerance: 2.193e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.559e+07, tolerance: 4.310e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.428e+07, tolerance: 2.648e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.726e+07, tolerance: 4.324e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.549e+07, tolerance: 4.368e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.057e+07, tolerance: 2.193e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.559e+07, tolerance: 4.310e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.428e+07, tolerance: 2.648e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=0.1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=0.1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=0.1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=0.1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=0.1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=0.1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=0.1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=0.1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+08, tolerance: 4.324e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+08, tolerance: 4.368e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.651e+07, tolerance: 2.193e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+08, tolerance: 4.310e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.408e+07, tolerance: 2.648e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+08, tolerance: 4.324e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+08, tolerance: 4.368e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.651e+07, tolerance: 2.193e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+08, tolerance: 4.310e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.408e+07, tolerance: 2.648e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+08, tolerance: 4.324e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+08, tolerance: 4.368e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.651e+07, tolerance: 2.193e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+08, tolerance: 4.310e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.408e+07, tolerance: 2.648e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+08, tolerance: 4.324e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+08, tolerance: 4.368e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.651e+07, tolerance: 2.193e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+08, tolerance: 4.310e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.408e+07, tolerance: 2.648e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=1, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ......alpha=1, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END .....alpha=1, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ....alpha=1, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=1, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END .....................alpha=1, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ....................alpha=1, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ...................alpha=1, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..................alpha=1, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.932e+08, tolerance: 4.324e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e+08, tolerance: 4.368e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+08, tolerance: 2.193e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.927e+08, tolerance: 4.310e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+08, tolerance: 2.648e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.932e+08, tolerance: 4.324e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e+08, tolerance: 4.368e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+08, tolerance: 2.193e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.927e+08, tolerance: 4.310e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+08, tolerance: 2.648e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.932e+08, tolerance: 4.324e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e+08, tolerance: 4.368e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+08, tolerance: 2.193e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.927e+08, tolerance: 4.310e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+08, tolerance: 2.648e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.932e+08, tolerance: 4.324e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e+08, tolerance: 4.368e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+08, tolerance: 2.193e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.927e+08, tolerance: 4.310e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+08, tolerance: 2.648e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................alpha=10, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=10, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END .....alpha=10, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ....alpha=10, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...alpha=10, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ..alpha=10, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ....................alpha=10, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ...................alpha=10, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ..................alpha=10, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END .................alpha=10, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+08, tolerance: 4.324e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+08, tolerance: 4.368e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+08, tolerance: 2.193e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+08, tolerance: 4.310e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+08, tolerance: 2.648e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+08, tolerance: 4.324e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+08, tolerance: 4.368e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+08, tolerance: 2.193e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+08, tolerance: 4.310e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+08, tolerance: 2.648e+06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+08, tolerance: 4.324e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.0, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.0, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.0, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+08, tolerance: 4.368e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+08, tolerance: 2.193e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+08, tolerance: 4.310e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+08, tolerance: 2.648e+05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+08, tolerance: 4.324e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e+08, tolerance: 4.368e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.086e+08, tolerance: 2.193e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+08, tolerance: 4.310e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+08, tolerance: 2.648e+04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.0, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.1, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.1, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.1, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.1, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.2, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.2, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.2, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.2, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.30000000000000004, tol=0.1; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.30000000000000004, tol=0.01; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.30000000000000004, tol=0.001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END alpha=100, l1_ratio=0.30000000000000004, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.4, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.4, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.4, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.4, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.5, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.5, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.5, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.5, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.6000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.6000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.6000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.6000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ....alpha=100, l1_ratio=0.7000000000000001, tol=0.1; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ...alpha=100, l1_ratio=0.7000000000000001, tol=0.01; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END ..alpha=100, l1_ratio=0.7000000000000001, tol=0.001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END .alpha=100, l1_ratio=0.7000000000000001, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.8, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.8, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.8, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.8, tol=0.0001; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ...................alpha=100, l1_ratio=0.9, tol=0.1; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END ..................alpha=100, l1_ratio=0.9, tol=0.01; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END .................alpha=100, l1_ratio=0.9, tol=0.001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n",
      "[CV] END ................alpha=100, l1_ratio=0.9, tol=0.0001; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02268567, 0.01624293, 0.01634264, 0.01569452, 0.01361284,\n",
       "        0.01429377, 0.01510334, 0.01520057, 0.01237769, 0.0136694 ,\n",
       "        0.01514521, 0.01544976, 0.01226239, 0.0141243 , 0.01451936,\n",
       "        0.01493926, 0.0120183 , 0.01368117, 0.01434045, 0.0157176 ,\n",
       "        0.01161737, 0.01340694, 0.01413851, 0.01452241, 0.01132293,\n",
       "        0.01300302, 0.01410928, 0.01471009, 0.01230369, 0.01281619,\n",
       "        0.01362071, 0.01430635, 0.01150346, 0.01330357, 0.01336393,\n",
       "        0.01490431, 0.01210337, 0.01290388, 0.01360326, 0.01430416,\n",
       "        0.01690536, 0.01650391, 0.01623092, 0.01601906, 0.00981688,\n",
       "        0.01187196, 0.01250587, 0.01361194, 0.00960221, 0.01146512,\n",
       "        0.01371288, 0.01301041, 0.009582  , 0.01101017, 0.01241126,\n",
       "        0.01281228, 0.00923996, 0.01131611, 0.01200252, 0.01241193,\n",
       "        0.00881057, 0.01102037, 0.011832  , 0.01299086, 0.0090167 ,\n",
       "        0.01102281, 0.01178823, 0.0122201 , 0.00861979, 0.01102276,\n",
       "        0.01162724, 0.01221895, 0.00888186, 0.01052136, 0.01161942,\n",
       "        0.01235442, 0.00882721, 0.01102571, 0.01200271, 0.01241159,\n",
       "        0.01756024, 0.01670475, 0.01681271, 0.01660409, 0.00442419,\n",
       "        0.00540109, 0.00560131, 0.00600128, 0.0042099 , 0.00560112,\n",
       "        0.00560136, 0.00600104, 0.00440106, 0.00540562, 0.00580111,\n",
       "        0.00600166, 0.00460138, 0.00560126, 0.00580153, 0.00661011,\n",
       "        0.00480685, 0.00540867, 0.00620136, 0.00680218, 0.00465503,\n",
       "        0.00580144, 0.00660868, 0.00700169, 0.00500145, 0.00641031,\n",
       "        0.00700154, 0.00781221, 0.00533705, 0.00730243, 0.00780725,\n",
       "        0.00843878, 0.00581212, 0.00720115, 0.00822058, 0.00900192,\n",
       "        0.01681132, 0.0170383 , 0.01705766, 0.0164588 , 0.00160217,\n",
       "        0.00170455, 0.00160012, 0.00200057, 0.00141773, 0.00140023,\n",
       "        0.0016005 , 0.00180039, 0.00160007, 0.00140023, 0.00160823,\n",
       "        0.00160055, 0.00140047, 0.00144968, 0.00140033, 0.00180078,\n",
       "        0.00141659, 0.00120044, 0.0016005 , 0.00160036, 0.0012002 ,\n",
       "        0.00120034, 0.00161939, 0.00180039, 0.00141339, 0.00220051,\n",
       "        0.00200057, 0.00220051, 0.0018003 , 0.00200109, 0.00240045,\n",
       "        0.00240049, 0.00221143, 0.00280056, 0.00360084, 0.00400109,\n",
       "        0.01886368, 0.01647129, 0.016504  , 0.01650376, 0.00140104,\n",
       "        0.00120044, 0.00124917, 0.00120277, 0.00161805, 0.00140162,\n",
       "        0.00140023, 0.00120039, 0.00100021, 0.00100026, 0.00110083,\n",
       "        0.00100088, 0.00100026, 0.00100031, 0.0012002 , 0.00140028,\n",
       "        0.00142694, 0.00100026, 0.0012001 , 0.00100002, 0.00105309,\n",
       "        0.00100217, 0.00120044, 0.00120049, 0.00100017, 0.00100012,\n",
       "        0.00100055, 0.00099964, 0.00100002, 0.00140042, 0.0010005 ,\n",
       "        0.00100026, 0.00120029, 0.0012002 , 0.0014019 , 0.00183926,\n",
       "        0.01652522, 0.01730433, 0.01630325, 0.01690226, 0.00100007,\n",
       "        0.00100055, 0.00140038, 0.00100017, 0.0010004 , 0.00100031,\n",
       "        0.00099945, 0.00100021, 0.0010005 , 0.00100031, 0.0012001 ,\n",
       "        0.00100026, 0.00100007, 0.00140023, 0.00100055, 0.00090084,\n",
       "        0.00100031, 0.00100026, 0.00110145, 0.00090065, 0.00100031,\n",
       "        0.00100055, 0.0009006 , 0.00100026, 0.00100031, 0.0012002 ,\n",
       "        0.00120006, 0.00100031, 0.00110078, 0.00120034, 0.00100031,\n",
       "        0.00100026, 0.00100007, 0.00120225, 0.00100021, 0.00120044,\n",
       "        0.01683455, 0.01660409, 0.01734571, 0.01656718, 0.00110078,\n",
       "        0.00080032, 0.00100055, 0.00101562, 0.00119996, 0.00080013,\n",
       "        0.00100021, 0.00110092, 0.00140014, 0.00100017, 0.00100031,\n",
       "        0.00160108, 0.00100441, 0.00100355, 0.00110126, 0.00100026,\n",
       "        0.00100031, 0.00100031, 0.00100021, 0.00100036, 0.00100207,\n",
       "        0.00079875, 0.00099998, 0.00101285, 0.00100012, 0.00099978,\n",
       "        0.00100026, 0.0010006 , 0.00080042, 0.00100026, 0.00100646,\n",
       "        0.00100017, 0.00100036, 0.00080047, 0.00100641, 0.00100017]),\n",
       " 'std_fit_time': array([4.63943779e-03, 4.93772082e-04, 7.37040256e-04, 8.64415440e-04,\n",
       "        6.72797014e-04, 5.82170516e-04, 1.01971625e-03, 6.64539096e-04,\n",
       "        1.34076763e-03, 6.08344141e-04, 5.10940363e-04, 1.00942639e-03,\n",
       "        1.09118997e-03, 5.26729779e-04, 7.85258866e-04, 9.19462459e-04,\n",
       "        1.54979738e-03, 7.68034241e-04, 8.59760093e-04, 1.40079768e-03,\n",
       "        1.35107214e-03, 1.01838648e-03, 5.22706044e-04, 9.73196389e-04,\n",
       "        1.64806169e-03, 6.32635954e-04, 6.62949234e-04, 7.42379433e-04,\n",
       "        1.83257768e-03, 7.35520984e-04, 7.55106572e-04, 3.98507434e-04,\n",
       "        1.78825890e-03, 8.73002468e-04, 4.46487654e-04, 1.11335740e-03,\n",
       "        1.49659032e-03, 9.18145031e-04, 4.90310307e-04, 4.00370123e-04,\n",
       "        1.02117350e-03, 7.74603678e-04, 7.43036214e-04, 6.33309067e-04,\n",
       "        1.19369652e-03, 1.27571148e-03, 7.73075889e-04, 7.93685296e-04,\n",
       "        8.00144681e-04, 1.34392734e-03, 1.07135175e-03, 1.10865571e-03,\n",
       "        7.73225812e-04, 1.08900166e-03, 1.51177553e-03, 1.18433619e-03,\n",
       "        9.31943641e-04, 1.34931164e-03, 1.54951198e-03, 7.95729108e-04,\n",
       "        7.61974341e-04, 1.09634171e-03, 1.58671776e-03, 1.19095049e-03,\n",
       "        8.95110217e-04, 1.09636760e-03, 1.59009549e-03, 9.76928364e-04,\n",
       "        7.87211546e-04, 1.07846141e-03, 1.22806691e-03, 1.45719224e-03,\n",
       "        4.98795609e-04, 1.34245951e-03, 1.19211675e-03, 1.08157085e-03,\n",
       "        7.22366763e-04, 1.55616601e-03, 1.54957353e-03, 1.35415790e-03,\n",
       "        1.97234115e-03, 8.72647167e-04, 9.82467898e-04, 8.00442744e-04,\n",
       "        8.66727119e-04, 8.00634032e-04, 8.00323486e-04, 6.32485089e-04,\n",
       "        7.57796621e-04, 8.00228162e-04, 4.90037648e-04, 6.32560686e-04,\n",
       "        4.90096043e-04, 3.75595080e-04, 4.00137912e-04, 6.32334642e-04,\n",
       "        4.90096344e-04, 4.90057117e-04, 3.99637237e-04, 4.97192629e-04,\n",
       "        4.01003539e-04, 4.84008756e-04, 4.00018735e-04, 3.98564378e-04,\n",
       "        4.32627251e-04, 9.80104497e-04, 4.81125725e-04, 6.32560506e-04,\n",
       "        6.32334340e-04, 5.01414200e-04, 1.16800773e-07, 3.79777235e-04,\n",
       "        4.19488649e-04, 4.00199646e-04, 4.02941760e-04, 5.37425927e-04,\n",
       "        7.65755662e-04, 4.00328704e-04, 3.91325111e-04, 1.09567054e-03,\n",
       "        9.73086829e-04, 1.28436810e-03, 1.11092249e-03, 7.80947972e-04,\n",
       "        4.91937138e-04, 6.03614739e-04, 4.89862511e-04, 6.33088508e-04,\n",
       "        4.76753695e-04, 4.89979242e-04, 4.90174126e-04, 4.00233308e-04,\n",
       "        4.89823562e-04, 4.89979242e-04, 4.80772814e-04, 4.90310307e-04,\n",
       "        4.89882037e-04, 4.58892820e-04, 4.89998722e-04, 4.00305405e-04,\n",
       "        5.10564769e-04, 3.99947319e-04, 4.90174103e-04, 4.90057117e-04,\n",
       "        4.00066461e-04, 4.00114074e-04, 5.06589301e-04, 4.00114102e-04,\n",
       "        4.79762578e-04, 7.48608592e-04, 6.32560517e-04, 4.00352506e-04,\n",
       "        4.00066376e-04, 1.29186794e-06, 4.89940316e-04, 4.89998722e-04,\n",
       "        3.95230286e-04, 4.00114130e-04, 4.90076613e-04, 6.32409735e-04,\n",
       "        4.47747237e-03, 4.76516749e-04, 1.00069073e-03, 1.00080993e-03,\n",
       "        4.89416693e-04, 4.00066433e-04, 4.95745067e-04, 4.02236024e-04,\n",
       "        5.03094491e-04, 4.90213841e-04, 4.90076636e-04, 4.00328704e-04,\n",
       "        9.53674316e-08, 1.90734863e-07, 2.00843981e-04, 1.91329981e-06,\n",
       "        1.16800773e-07, 2.43140197e-07, 4.00185596e-04, 4.90232347e-04,\n",
       "        4.70782295e-04, 1.16800773e-07, 3.99875698e-04, 2.43140197e-07,\n",
       "        1.02777269e-04, 2.86737373e-06, 4.00304809e-04, 4.00400176e-04,\n",
       "        0.00000000e+00, 9.53674316e-08, 6.50319180e-07, 8.44957597e-07,\n",
       "        1.16800773e-07, 4.90018206e-04, 2.43140197e-07, 1.90734863e-07,\n",
       "        4.00257111e-04, 3.99589567e-04, 4.90663119e-04, 4.25833486e-04,\n",
       "        7.81581303e-04, 1.47153123e-03, 1.16668254e-03, 1.04628510e-03,\n",
       "        2.43140197e-07, 4.90933902e-07, 4.90154495e-04, 0.00000000e+00,\n",
       "        6.21719590e-07, 3.87384339e-07, 1.83442917e-06, 2.78041453e-07,\n",
       "        4.42200589e-07, 2.86102295e-07, 4.00114329e-04, 1.16800773e-07,\n",
       "        3.23406696e-07, 4.89882200e-04, 5.35248383e-07, 1.98889036e-04,\n",
       "        3.23406696e-07, 1.90734863e-07, 2.01369941e-04, 1.99032572e-04,\n",
       "        1.16800773e-07, 7.62939453e-07, 4.90534568e-04, 2.43140197e-07,\n",
       "        3.23406696e-07, 4.00185596e-04, 4.00257821e-04, 4.15696997e-07,\n",
       "        4.89493561e-04, 4.00114130e-04, 4.15696997e-07, 2.43140197e-07,\n",
       "        1.90734863e-07, 2.46238847e-04, 9.53674316e-08, 3.99709100e-04,\n",
       "        9.54971818e-04, 7.99727445e-04, 2.58313332e-03, 1.52398249e-03,\n",
       "        2.01822024e-04, 4.00162056e-04, 1.90734863e-07, 3.04225844e-05,\n",
       "        4.00185965e-04, 4.00066404e-04, 3.16297988e-07, 2.01153833e-04,\n",
       "        4.89862464e-04, 1.50789149e-07, 1.90734863e-07, 8.01372571e-04,\n",
       "        2.27886260e-06, 2.89027833e-06, 2.01702287e-04, 1.16800773e-07,\n",
       "        1.16800773e-07, 1.90734863e-07, 1.78416128e-07, 1.78416128e-07,\n",
       "        2.92779568e-06, 3.99383939e-04, 3.81469727e-07, 2.59648232e-05,\n",
       "        1.78416128e-07, 5.35248383e-07, 1.16800773e-07, 5.72204590e-07,\n",
       "        4.00209810e-04, 5.56082906e-07, 1.23523835e-05, 2.13248060e-07,\n",
       "        1.78416128e-07, 4.00234075e-04, 1.23742688e-05, 1.50789149e-07]),\n",
       " 'mean_score_time': array([0.00220156, 0.00200114, 0.00200229, 0.00190225, 0.00221181,\n",
       "        0.00180092, 0.00180082, 0.00200191, 0.00182085, 0.00166812,\n",
       "        0.00180202, 0.00140414, 0.0016006 , 0.0016005 , 0.00180044,\n",
       "        0.00200047, 0.00181403, 0.00180159, 0.00160046, 0.00202146,\n",
       "        0.00190144, 0.00180049, 0.00180044, 0.00160046, 0.00160046,\n",
       "        0.00160031, 0.00195575, 0.0016006 , 0.00200052, 0.00200214,\n",
       "        0.00200152, 0.00200047, 0.00160055, 0.00200076, 0.00160041,\n",
       "        0.00180063, 0.00180049, 0.00160031, 0.00160031, 0.00180044,\n",
       "        0.00180082, 0.00200071, 0.00200047, 0.00200052, 0.00180044,\n",
       "        0.00200191, 0.00160036, 0.00180035, 0.00160031, 0.0018003 ,\n",
       "        0.00240049, 0.00200033, 0.00190225, 0.00180039, 0.00180063,\n",
       "        0.00200129, 0.00221143, 0.00200024, 0.00200062, 0.00220032,\n",
       "        0.00200038, 0.00160036, 0.0018003 , 0.00201187, 0.00160046,\n",
       "        0.00160027, 0.00160046, 0.00200038, 0.00200047, 0.00140028,\n",
       "        0.00180063, 0.00140028, 0.00170131, 0.00180044, 0.00200982,\n",
       "        0.00220385, 0.00180058, 0.00180073, 0.00140023, 0.00200033,\n",
       "        0.00180168, 0.00200028, 0.00160027, 0.00140967, 0.00190215,\n",
       "        0.00180974, 0.00160031, 0.00160027, 0.00200047, 0.00200043,\n",
       "        0.00160055, 0.00200939, 0.00180035, 0.00171161, 0.00200062,\n",
       "        0.00180006, 0.00160899, 0.00160036, 0.00160041, 0.00180035,\n",
       "        0.0016027 , 0.0018003 , 0.00160046, 0.00140033, 0.00160017,\n",
       "        0.00180025, 0.00180068, 0.00200028, 0.00160022, 0.00160055,\n",
       "        0.00200043, 0.00200038, 0.00180235, 0.00140028, 0.00181456,\n",
       "        0.00200028, 0.0018002 , 0.00201116, 0.00200052, 0.00141425,\n",
       "        0.00180845, 0.00200038, 0.00200047, 0.00160046, 0.00157318,\n",
       "        0.00140181, 0.00161366, 0.00160036, 0.00140018, 0.0016005 ,\n",
       "        0.0019011 , 0.00201836, 0.00180068, 0.00200052, 0.00140023,\n",
       "        0.00180039, 0.00170116, 0.00160718, 0.00180035, 0.00160003,\n",
       "        0.00160427, 0.00180044, 0.00150146, 0.00180035, 0.00200043,\n",
       "        0.00180044, 0.00180058, 0.00170126, 0.00160432, 0.00140023,\n",
       "        0.0018003 , 0.00140018, 0.00120068, 0.00190167, 0.00160046,\n",
       "        0.00180044, 0.0016078 , 0.00170236, 0.00140028, 0.00160017,\n",
       "        0.00187192, 0.00140133, 0.00200081, 0.00200105, 0.00139961,\n",
       "        0.00160022, 0.00180426, 0.00170689, 0.00185103, 0.00161376,\n",
       "        0.00160036, 0.00180035, 0.00200047, 0.00200067, 0.00160046,\n",
       "        0.0009995 , 0.00120029, 0.0012001 , 0.00100021, 0.00140028,\n",
       "        0.00160017, 0.00200047, 0.00200067, 0.00180049, 0.00160213,\n",
       "        0.00150256, 0.00140047, 0.00170097, 0.00180044, 0.0016005 ,\n",
       "        0.00160003, 0.00200105, 0.00180054, 0.00120049, 0.00150065,\n",
       "        0.00140028, 0.00180054, 0.00200033, 0.00200543, 0.00164318,\n",
       "        0.00200634, 0.0016006 , 0.00206914, 0.0020031 , 0.00200095,\n",
       "        0.00150075, 0.00100021, 0.00180044, 0.00160012, 0.00220046,\n",
       "        0.00100007, 0.00180063, 0.00190091, 0.00140028, 0.00200047,\n",
       "        0.00200052, 0.00140038, 0.00140042, 0.00200038, 0.00200062,\n",
       "        0.00160027, 0.00160041, 0.00200768, 0.00200195, 0.00160027,\n",
       "        0.0018003 , 0.00200081, 0.00200043, 0.00180025, 0.00120068,\n",
       "        0.00200033, 0.00180736, 0.0016006 , 0.00180025, 0.0018003 ,\n",
       "        0.00120029, 0.00200062, 0.00190244, 0.00160055, 0.00150104,\n",
       "        0.00210118, 0.00180025, 0.00240388, 0.00160193, 0.00180097,\n",
       "        0.00180054, 0.00160012, 0.00180821, 0.00180044, 0.00180044,\n",
       "        0.00161934, 0.00140057, 0.00180054, 0.00160036, 0.00181584,\n",
       "        0.00159969, 0.0012114 , 0.00200529, 0.00180078, 0.00180035,\n",
       "        0.00200033, 0.00160041, 0.00160036, 0.00200043, 0.00159912,\n",
       "        0.00189786, 0.00200067, 0.00160046, 0.0016005 , 0.00180078,\n",
       "        0.00160041, 0.00160031, 0.00170097, 0.00180025, 0.00141306,\n",
       "        0.00160041, 0.00160022, 0.00159998, 0.00161295, 0.00150118]),\n",
       " 'std_score_time': array([7.48519904e-04, 1.16800773e-07, 6.34295760e-04, 1.98794584e-04,\n",
       "        4.21404849e-04, 4.00018735e-04, 3.99971179e-04, 6.32563152e-04,\n",
       "        4.08764337e-04, 5.58531407e-04, 4.00092160e-04, 4.86823290e-04,\n",
       "        4.89862557e-04, 4.89979288e-04, 4.00018706e-04, 6.32560510e-04,\n",
       "        4.07667929e-04, 3.97372257e-04, 4.90037671e-04, 3.21165313e-05,\n",
       "        4.91012200e-04, 4.00161743e-04, 4.00137912e-04, 4.90037671e-04,\n",
       "        4.90037648e-04, 4.89726210e-04, 8.92883149e-05, 4.89959812e-04,\n",
       "        3.81469727e-07, 4.13118241e-06, 2.53666612e-06, 1.90734863e-07,\n",
       "        4.90213006e-04, 4.10190833e-07, 4.89998745e-04, 7.48863559e-04,\n",
       "        4.00042545e-04, 4.90018183e-04, 4.90018183e-04, 4.00138026e-04,\n",
       "        4.00448555e-04, 4.15696997e-07, 6.32711281e-04, 1.78416128e-07,\n",
       "        3.99899493e-04, 1.65593675e-06, 4.89959812e-04, 3.99851810e-04,\n",
       "        4.89920871e-04, 4.00066489e-04, 4.89901429e-04, 2.13248060e-07,\n",
       "        1.99393413e-04, 4.00114074e-04, 4.00233478e-04, 1.35710234e-06,\n",
       "        2.56653524e-04, 3.23406696e-07, 1.78416128e-07, 4.00090370e-04,\n",
       "        9.53674316e-08, 4.90057117e-04, 4.00066376e-04, 6.32759686e-04,\n",
       "        4.89940362e-04, 4.89979265e-04, 4.90037648e-04, 2.33601546e-07,\n",
       "        1.90734863e-07, 4.89842988e-04, 4.00233450e-04, 4.90037648e-04,\n",
       "        3.99973197e-04, 4.00137940e-04, 1.86213305e-05, 4.05360965e-04,\n",
       "        3.99494200e-04, 4.00161970e-04, 4.89979265e-04, 0.00000000e+00,\n",
       "        4.00644085e-04, 3.81469727e-07, 4.89979265e-04, 4.82667955e-04,\n",
       "        1.99356623e-04, 4.05188727e-04, 4.90018183e-04, 4.90076589e-04,\n",
       "        1.90734863e-07, 3.23406696e-07, 4.90212913e-04, 1.77624242e-05,\n",
       "        4.00090228e-04, 4.07896048e-04, 1.78416128e-07, 3.99947831e-04,\n",
       "        4.97259259e-04, 4.90057117e-04, 4.89901406e-04, 7.48532121e-04,\n",
       "        4.91775743e-04, 4.00185624e-04, 4.90037671e-04, 4.90096066e-04,\n",
       "        4.89901522e-04, 4.00161743e-04, 4.00376586e-04, 1.78416128e-07,\n",
       "        4.90037671e-04, 4.90213006e-04, 1.16800773e-07, 9.53674316e-08,\n",
       "        4.01697245e-04, 4.90037648e-04, 4.08034084e-04, 9.53674316e-08,\n",
       "        4.00376359e-04, 2.02252042e-05, 1.78416128e-07, 5.07626568e-04,\n",
       "        4.04451675e-04, 1.78416128e-07, 6.32786671e-04, 4.89940409e-04,\n",
       "        3.85533166e-04, 5.82320043e-04, 5.01402500e-04, 4.89959881e-04,\n",
       "        4.90018253e-04, 4.90173918e-04, 4.90749406e-04, 6.04536372e-04,\n",
       "        3.99780472e-04, 1.78416128e-07, 4.90076589e-04, 4.00114074e-04,\n",
       "        6.01117902e-04, 4.95881598e-04, 4.00209469e-04, 4.90368956e-04,\n",
       "        4.85307665e-04, 4.00137912e-04, 4.47399807e-04, 4.00090257e-04,\n",
       "        1.16800773e-07, 4.00018735e-04, 3.99494200e-04, 6.01204935e-04,\n",
       "        4.93241679e-04, 4.89979288e-04, 4.00066461e-04, 4.90213029e-04,\n",
       "        4.00424043e-04, 1.96482856e-04, 4.90037648e-04, 4.00018706e-04,\n",
       "        4.96214572e-04, 4.00288404e-04, 4.89940316e-04, 4.89998769e-04,\n",
       "        4.56053739e-04, 4.91228457e-04, 3.98950589e-07, 0.00000000e+00,\n",
       "        4.90487032e-04, 4.89940316e-04, 4.00166976e-04, 4.00259974e-04,\n",
       "        4.34486509e-04, 5.00076467e-04, 4.90057210e-04, 4.00328675e-04,\n",
       "        1.16800773e-07, 5.35248383e-07, 4.89940687e-04, 1.83070696e-06,\n",
       "        4.00018706e-04, 4.00233308e-04, 9.53674316e-08, 4.90134984e-04,\n",
       "        4.89901429e-04, 1.90734863e-07, 4.67203091e-07, 4.00042573e-04,\n",
       "        4.91696050e-04, 4.46121501e-04, 4.89784791e-04, 3.99782179e-04,\n",
       "        4.00137912e-04, 4.89979242e-04, 4.89687687e-04, 6.03156597e-07,\n",
       "        4.00066404e-04, 3.99804467e-04, 4.47342091e-04, 4.89940339e-04,\n",
       "        4.00066575e-04, 6.91002691e-07, 7.15510005e-06, 5.30351484e-04,\n",
       "        1.20191344e-05, 4.90349171e-04, 1.35827347e-04, 1.99247193e-06,\n",
       "        7.77697870e-07, 6.33390295e-04, 2.33601546e-07, 4.00257167e-04,\n",
       "        4.89765353e-04, 4.00257139e-04, 3.87384339e-07, 4.00352790e-04,\n",
       "        1.99198858e-04, 4.90037671e-04, 3.87384339e-07, 2.78041453e-07,\n",
       "        4.90057140e-04, 4.90115569e-04, 2.33601546e-07, 6.97552626e-07,\n",
       "        4.89881921e-04, 4.89804047e-04, 5.53906243e-05, 2.62650287e-06,\n",
       "        4.89979265e-04, 4.00066461e-04, 7.38712949e-07, 1.16800773e-07,\n",
       "        4.00400290e-04, 4.00186107e-04, 1.50789149e-07, 4.03834811e-04,\n",
       "        4.90349449e-04, 4.00161772e-04, 4.00066631e-04, 4.00137997e-04,\n",
       "        1.78416128e-07, 1.99497555e-04, 4.90115709e-04, 4.47129555e-04,\n",
       "        2.01702118e-04, 4.00042601e-04, 4.93387295e-04, 4.89395819e-04,\n",
       "        4.00639119e-04, 3.99947177e-04, 4.89862488e-04, 4.04201541e-04,\n",
       "        3.99541869e-04, 4.00018763e-04, 5.06853720e-04, 4.89707086e-04,\n",
       "        4.00186022e-04, 4.89959789e-04, 4.08822599e-04, 4.90680904e-04,\n",
       "        3.99399612e-04, 8.67188384e-06, 4.00425065e-04, 4.00209469e-04,\n",
       "        2.13248060e-07, 4.90096066e-04, 4.89959881e-04, 2.43140197e-07,\n",
       "        4.89048764e-04, 2.08895736e-04, 4.15696997e-07, 4.89940362e-04,\n",
       "        4.89881921e-04, 4.00186079e-04, 4.90096066e-04, 4.89337192e-04,\n",
       "        3.99960270e-04, 3.99804154e-04, 5.06195792e-04, 4.90193437e-04,\n",
       "        4.89940316e-04, 4.89648691e-04, 4.75521260e-04, 6.34031698e-04]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_l1_ratio': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.30000000000000004, 0.30000000000000004,\n",
       "                    0.30000000000000004, 0.30000000000000004, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.6000000000000001,\n",
       "                    0.6000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.7000000000000001,\n",
       "                    0.7000000000000001, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9,\n",
       "                    0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tol': masked_array(data=[0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001,\n",
       "                    0.1, 0.01, 0.001, 0.0001, 0.1, 0.01, 0.001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 0.0001, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 0.1, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.0, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.1, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.2, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.30000000000000004, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.4, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.5, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.6000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.7000000000000001, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.0001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.1},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.01},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.001},\n",
       "  {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.0001}],\n",
       " 'split0_test_R2': array([-0.75179287, -0.75179287, -0.75179287, -0.75179287, -0.75183901,\n",
       "        -0.75183903, -0.75183903, -0.75183903, -0.75188549, -0.75188554,\n",
       "        -0.75188554, -0.75188554, -0.75193232, -0.75193239, -0.7519324 ,\n",
       "        -0.7519324 , -0.7519795 , -0.7519796 , -0.75197961, -0.75197961,\n",
       "        -0.75202703, -0.75202716, -0.75202717, -0.75202718, -0.75207491,\n",
       "        -0.75207508, -0.75207509, -0.75207509, -0.75212315, -0.75212335,\n",
       "        -0.75212337, -0.75212337, -0.75217174, -0.75217198, -0.752172  ,\n",
       "        -0.752172  , -0.75222069, -0.75222097, -0.75222099, -0.752221  ,\n",
       "        -0.74883643, -0.74883643, -0.74883643, -0.74883643, -0.74906402,\n",
       "        -0.74906398, -0.74906397, -0.74906397, -0.74931334, -0.74931336,\n",
       "        -0.74931336, -0.74931335, -0.74958568, -0.74958585, -0.74958585,\n",
       "        -0.74958585, -0.74988241, -0.74988286, -0.74988288, -0.74988289,\n",
       "        -0.75020498, -0.75020571, -0.75020576, -0.75020577, -0.75055483,\n",
       "        -0.75055596, -0.75055604, -0.75055606, -0.7509336 , -0.75093522,\n",
       "        -0.75093535, -0.75093537, -0.75134299, -0.7513452 , -0.75134538,\n",
       "        -0.75134542, -0.75178477, -0.7517877 , -0.75178795, -0.751788  ,\n",
       "        -0.75371438, -0.75371438, -0.75371438, -0.75371438, -0.75291083,\n",
       "        -0.75290307, -0.75290224, -0.75290204, -0.75199712, -0.75198158,\n",
       "        -0.75197997, -0.75197957, -0.75098979, -0.75096881, -0.75096661,\n",
       "        -0.75096603, -0.74994258, -0.74991401, -0.74991104, -0.74991028,\n",
       "        -0.7489165 , -0.7488839 , -0.74888052, -0.74887965, -0.74802869,\n",
       "        -0.74799527, -0.7479917 , -0.74799079, -0.74747073, -0.74744008,\n",
       "        -0.74743681, -0.74743596, -0.74755669, -0.74753649, -0.74753425,\n",
       "        -0.74753363, -0.74881757, -0.74881909, -0.74881892, -0.74881882,\n",
       "        -0.64840554, -0.64840554, -0.64840554, -0.64840554, -0.66365306,\n",
       "        -0.66367669, -0.66369943, -0.66370492, -0.67893162, -0.67898131,\n",
       "        -0.67903769, -0.67905124, -0.69414253, -0.69422768, -0.6943016 ,\n",
       "        -0.69432393, -0.70903561, -0.70917918, -0.70929745, -0.70932832,\n",
       "        -0.72336105, -0.72354507, -0.72370045, -0.72373951, -0.73671149,\n",
       "        -0.73689529, -0.73694609, -0.73699161, -0.74971719, -0.74867769,\n",
       "        -0.74861589, -0.74860412, -0.75618046, -0.7555979 , -0.75553633,\n",
       "        -0.75552167, -0.75521759, -0.75448362, -0.75441001, -0.75439114,\n",
       "         0.05605865,  0.05605865,  0.05605865,  0.05605865,  0.0180668 ,\n",
       "         0.01776995,  0.01771233,  0.01770868, -0.0257073 , -0.02617559,\n",
       "        -0.02629425, -0.02631477, -0.07611114, -0.0770419 , -0.0770419 ,\n",
       "        -0.07711131, -0.1345032 , -0.13588775, -0.13602627, -0.13606703,\n",
       "        -0.20285677, -0.2047712 , -0.20504169, -0.20518564, -0.28506802,\n",
       "        -0.28655425, -0.28692801, -0.28700413, -0.38249789, -0.38381816,\n",
       "        -0.38426897, -0.38445079, -0.49893518, -0.50030403, -0.50137777,\n",
       "        -0.5015264 , -0.63811535, -0.63987263, -0.64193012, -0.64220826,\n",
       "         0.254754  ,  0.254754  ,  0.254754  ,  0.254754  ,  0.26882192,\n",
       "         0.26882192,  0.26882936,  0.26882936,  0.2837137 ,  0.2837137 ,\n",
       "         0.2837238 ,  0.2837238 ,  0.2988628 ,  0.2988628 ,  0.29887503,\n",
       "         0.29887498,  0.31352721,  0.31352721,  0.31353685,  0.31353728,\n",
       "         0.32601388,  0.32600297,  0.32600297,  0.32600451,  0.33212168,\n",
       "         0.3320205 ,  0.33202279,  0.33202279,  0.32203153,  0.32158811,\n",
       "         0.32157034,  0.32157238,  0.26954885,  0.26797033,  0.26769399,\n",
       "         0.26769399,  0.0784081 ,  0.07365988,  0.07343585,  0.07339071,\n",
       "         0.01046242,  0.01046242,  0.01046242,  0.01046242,  0.01322377,\n",
       "         0.01322589,  0.01322589,  0.01322589,  0.01648612,  0.01648877,\n",
       "         0.01648877,  0.01648876,  0.02046521,  0.02046884,  0.02046884,\n",
       "         0.02046883,  0.02564033,  0.02564557,  0.02564557,  0.02564555,\n",
       "         0.03286226,  0.03287082,  0.03287082,  0.03287078,  0.04417883,\n",
       "         0.04419347,  0.04419347,  0.04419339,  0.06236803,  0.06239509,\n",
       "         0.06239509,  0.06239493,  0.09456131,  0.09462524,  0.09462486,\n",
       "         0.09462486,  0.16465762,  0.16465762,  0.16465846,  0.16465846]),\n",
       " 'split1_test_R2': array([-2.16862379e+00, -2.16862379e+00, -2.16862379e+00, -2.16862379e+00,\n",
       "        -2.16813702e+00, -2.16813624e+00, -2.16813617e+00, -2.16813616e+00,\n",
       "        -2.16764973e+00, -2.16764819e+00, -2.16764804e+00, -2.16764801e+00,\n",
       "        -2.16716193e+00, -2.16715961e+00, -2.16715939e+00, -2.16715933e+00,\n",
       "        -2.16667362e+00, -2.16667051e+00, -2.16667022e+00, -2.16667014e+00,\n",
       "        -2.16618479e+00, -2.16618090e+00, -2.16618052e+00, -2.16618043e+00,\n",
       "        -2.16569540e+00, -2.16569076e+00, -2.16569031e+00, -2.16569020e+00,\n",
       "        -2.16520556e+00, -2.16520011e+00, -2.16519958e+00, -2.16519945e+00,\n",
       "        -2.16471512e+00, -2.16470893e+00, -2.16470834e+00, -2.16470819e+00,\n",
       "        -2.16422428e+00, -2.16421724e+00, -2.16421657e+00, -2.16421641e+00,\n",
       "        -2.21028799e+00, -2.21028799e+00, -2.21028799e+00, -2.21028799e+00,\n",
       "        -2.20589654e+00, -2.20588864e+00, -2.20588787e+00, -2.20588768e+00,\n",
       "        -2.20144778e+00, -2.20143204e+00, -2.20143050e+00, -2.20143012e+00,\n",
       "        -2.19694211e+00, -2.19691836e+00, -2.19691604e+00, -2.19691546e+00,\n",
       "        -2.19237988e+00, -2.19234780e+00, -2.19234471e+00, -2.19234394e+00,\n",
       "        -2.18776013e+00, -2.18772070e+00, -2.18771686e+00, -2.18771592e+00,\n",
       "        -2.18308520e+00, -2.18303758e+00, -2.18303304e+00, -2.18303189e+00,\n",
       "        -2.17835444e+00, -2.17829913e+00, -2.17829381e+00, -2.17829246e+00,\n",
       "        -2.17356913e+00, -2.17350594e+00, -2.17349992e+00, -2.17349841e+00,\n",
       "        -2.16872993e+00, -2.16865918e+00, -2.16865237e+00, -2.16865066e+00,\n",
       "        -2.42775866e+00, -2.42775866e+00, -2.42775866e+00, -2.42775866e+00,\n",
       "        -2.41591617e+00, -2.41586659e+00, -2.41586140e+00, -2.41586010e+00,\n",
       "        -2.40197797e+00, -2.40186874e+00, -2.40185791e+00, -2.40185517e+00,\n",
       "        -2.38561840e+00, -2.38544784e+00, -2.38543092e+00, -2.38542649e+00,\n",
       "        -2.36647818e+00, -2.36623182e+00, -2.36620730e+00, -2.36620118e+00,\n",
       "        -2.34404003e+00, -2.34371372e+00, -2.34368113e+00, -2.34367281e+00,\n",
       "        -2.31791955e+00, -2.31750585e+00, -2.31746501e+00, -2.31745462e+00,\n",
       "        -2.28750390e+00, -2.28699047e+00, -2.28694011e+00, -2.28692730e+00,\n",
       "        -2.25218425e+00, -2.25156625e+00, -2.25150481e+00, -2.25148975e+00,\n",
       "        -2.21141019e+00, -2.21068700e+00, -2.21061647e+00, -2.21059919e+00,\n",
       "        -2.13465953e+00, -2.13465953e+00, -2.13465953e+00, -2.13465953e+00,\n",
       "        -2.17983881e+00, -2.17977760e+00, -2.17972753e+00, -2.17971089e+00,\n",
       "        -2.22675920e+00, -2.22665885e+00, -2.22655676e+00, -2.22653669e+00,\n",
       "        -2.27508865e+00, -2.27495024e+00, -2.27483999e+00, -2.27481807e+00,\n",
       "        -2.32410120e+00, -2.32402823e+00, -2.32396421e+00, -2.32395068e+00,\n",
       "        -2.37253832e+00, -2.37259559e+00, -2.37264969e+00, -2.37266632e+00,\n",
       "        -2.41760307e+00, -2.41796817e+00, -2.41826680e+00, -2.41834209e+00,\n",
       "        -2.45334746e+00, -2.45431910e+00, -2.45509219e+00, -2.45527640e+00,\n",
       "        -2.47167532e+00, -2.47333036e+00, -2.47481496e+00, -2.47531217e+00,\n",
       "        -2.43504357e+00, -2.43115452e+00, -2.43074465e+00, -2.43064148e+00,\n",
       "        -7.12862844e-01, -7.12862844e-01, -7.12862844e-01, -7.12862844e-01,\n",
       "        -7.86455470e-01, -7.86470821e-01, -7.86486973e-01, -7.86492956e-01,\n",
       "        -8.69037678e-01, -8.68634807e-01, -8.68651080e-01, -8.68662274e-01,\n",
       "        -9.62263669e-01, -9.61151592e-01, -9.61136166e-01, -9.61148607e-01,\n",
       "        -1.06935281e+00, -1.06678189e+00, -1.06662140e+00, -1.06660300e+00,\n",
       "        -1.19494544e+00, -1.18895745e+00, -1.18877422e+00, -1.18873014e+00,\n",
       "        -1.34055226e+00, -1.33521656e+00, -1.33410335e+00, -1.33394648e+00,\n",
       "        -1.52320481e+00, -1.51664844e+00, -1.51420093e+00, -1.51389671e+00,\n",
       "        -1.76816430e+00, -1.75691697e+00, -1.75251395e+00, -1.75208609e+00,\n",
       "        -2.11276519e+00, -2.10641454e+00, -2.09942354e+00, -2.09871493e+00,\n",
       "         1.56608876e-01,  1.56608876e-01,  1.56608876e-01,  1.56608876e-01,\n",
       "         1.58539425e-01,  1.58539425e-01,  1.58553946e-01,  1.58553946e-01,\n",
       "         1.57847361e-01,  1.57847361e-01,  1.57869551e-01,  1.57868826e-01,\n",
       "         1.52805626e-01,  1.52805626e-01,  1.52838846e-01,  1.52838084e-01,\n",
       "         1.40470030e-01,  1.40517107e-01,  1.40517107e-01,  1.40516674e-01,\n",
       "         1.15324795e-01,  1.15385914e-01,  1.15385914e-01,  1.15386742e-01,\n",
       "         6.68047946e-02,  6.68720202e-02,  6.68758316e-02,  6.68758316e-02,\n",
       "        -2.73547476e-02, -2.73123520e-02, -2.73120375e-02, -2.73124964e-02,\n",
       "        -2.17809532e-01, -2.17229908e-01, -2.17259657e-01, -2.17259657e-01,\n",
       "        -6.53671540e-01, -6.43234278e-01, -6.43073552e-01, -6.43089587e-01,\n",
       "        -1.82583985e-02, -1.82583985e-02, -1.82583985e-02, -1.82583985e-02,\n",
       "        -1.58283976e-02, -1.58253053e-02, -1.58253053e-02, -1.58253133e-02,\n",
       "        -1.30464089e-02, -1.30423202e-02, -1.30423202e-02, -1.30423322e-02,\n",
       "        -9.66398319e-03, -9.65833503e-03, -9.65833503e-03, -9.65835303e-03,\n",
       "        -5.32080447e-03, -5.31260909e-03, -5.31260909e-03, -5.31263762e-03,\n",
       "         1.36692209e-03,  1.38047764e-03,  1.38047764e-03,  1.38042133e-03,\n",
       "         1.12128229e-02,  1.12362391e-02,  1.12362391e-02,  1.12361224e-02,\n",
       "         2.71319800e-02,  2.71782829e-02,  2.71782829e-02,  2.71780214e-02,\n",
       "         5.37128843e-02,  5.38312129e-02,  5.38305034e-02,  5.38305034e-02,\n",
       "         1.01374306e-01,  1.01374306e-01,  1.01374970e-01,  1.01374970e-01]),\n",
       " 'split2_test_R2': array([0.55124613, 0.55124613, 0.55124613, 0.55124613, 0.551254  ,\n",
       "        0.55125399, 0.55125399, 0.55125399, 0.55126186, 0.55126184,\n",
       "        0.55126184, 0.55126184, 0.55126971, 0.55126968, 0.55126968,\n",
       "        0.55126967, 0.55127755, 0.55127751, 0.5512775 , 0.5512775 ,\n",
       "        0.55128538, 0.55128533, 0.55128532, 0.55128532, 0.5512932 ,\n",
       "        0.55129314, 0.55129313, 0.55129313, 0.551301  , 0.55130094,\n",
       "        0.55130093, 0.55130092, 0.5513088 , 0.55130872, 0.55130871,\n",
       "        0.55130871, 0.55131658, 0.5513165 , 0.55131648, 0.55131648,\n",
       "        0.5505068 , 0.5505068 , 0.5505068 , 0.5505068 , 0.55059126,\n",
       "        0.55059122, 0.55059121, 0.55059121, 0.55067528, 0.55067522,\n",
       "        0.55067521, 0.5506752 , 0.55075884, 0.55075875, 0.55075873,\n",
       "        0.55075872, 0.55084186, 0.55084175, 0.55084172, 0.55084171,\n",
       "        0.55092442, 0.55092429, 0.55092425, 0.55092423, 0.55100622,\n",
       "        0.55100604, 0.55100599, 0.55100597, 0.55108727, 0.55108703,\n",
       "        0.55108697, 0.55108695, 0.55116748, 0.55116719, 0.55116712,\n",
       "        0.55116709, 0.55124679, 0.55124642, 0.55124633, 0.55124631,\n",
       "        0.54357989, 0.54357989, 0.54357989, 0.54357989, 0.54422968,\n",
       "        0.54423058, 0.54423068, 0.54423071, 0.54490763, 0.54490944,\n",
       "        0.54490966, 0.54490971, 0.54561583, 0.54561854, 0.54561886,\n",
       "        0.54561894, 0.54635608, 0.54635963, 0.54636005, 0.54636015,\n",
       "        0.54713135, 0.54713601, 0.54713653, 0.54713666, 0.54793852,\n",
       "        0.54794339, 0.54794392, 0.54794403, 0.5487759 , 0.54878152,\n",
       "        0.54878211, 0.54878224, 0.54963483, 0.54963967, 0.54964007,\n",
       "        0.54964014, 0.55049687, 0.55050078, 0.55050099, 0.55050099,\n",
       "        0.51305156, 0.51305156, 0.51305156, 0.51305156, 0.51566541,\n",
       "        0.51565971, 0.51565455, 0.51565339, 0.51835585, 0.51834102,\n",
       "        0.51833105, 0.51832826, 0.52113935, 0.52111208, 0.52109622,\n",
       "        0.52109187, 0.52403062, 0.52399772, 0.5239748 , 0.52396807,\n",
       "        0.52709296, 0.52701542, 0.52699836, 0.52699391, 0.53028724,\n",
       "        0.53025632, 0.53024628, 0.53024156, 0.5337634 , 0.53380564,\n",
       "        0.53381149, 0.53381296, 0.53790119, 0.53797009, 0.53797835,\n",
       "        0.53798048, 0.54324866, 0.54333668, 0.54334799, 0.54335078,\n",
       "        0.36666775, 0.36666775, 0.36666775, 0.36666775, 0.37789082,\n",
       "        0.37790291, 0.37790859, 0.37791011, 0.38994938, 0.38995366,\n",
       "        0.38995996, 0.38996226, 0.40294209, 0.4029251 , 0.40292837,\n",
       "        0.40293213, 0.41702039, 0.41694677, 0.41694704, 0.41694797,\n",
       "        0.43238733, 0.43218725, 0.43217515, 0.43217185, 0.4493272 ,\n",
       "        0.44889099, 0.44881281, 0.44880862, 0.46767072, 0.46724127,\n",
       "        0.46710208, 0.46709339, 0.48827909, 0.48765248, 0.48745568,\n",
       "        0.48743363, 0.51208257, 0.5112875 , 0.51084446, 0.51079773,\n",
       "        0.10019075, 0.10019075, 0.10019075, 0.10019075, 0.10861782,\n",
       "        0.10861782, 0.10862223, 0.10862219, 0.11864338, 0.11864338,\n",
       "        0.11865009, 0.11865007, 0.13075667, 0.13075667, 0.13076727,\n",
       "        0.13076732, 0.14569493, 0.14569493, 0.1457119 , 0.14571223,\n",
       "        0.16459048, 0.16459048, 0.16461959, 0.16461959, 0.18925934,\n",
       "        0.1893111 , 0.18931463, 0.18931463, 0.22287799, 0.22294917,\n",
       "        0.22296163, 0.22296182, 0.27200823, 0.27198464, 0.27202915,\n",
       "        0.27202915, 0.35156617, 0.35151507, 0.35149926, 0.35149861,\n",
       "        0.00677042, 0.00677042, 0.00677042, 0.00677042, 0.00733806,\n",
       "        0.00733837, 0.00733837, 0.00733837, 0.00803717, 0.00803758,\n",
       "        0.00803758, 0.00803758, 0.00891401, 0.00891456, 0.00891456,\n",
       "        0.00891456, 0.01008889, 0.01008968, 0.01008968, 0.01008968,\n",
       "        0.01178803, 0.01178913, 0.01178913, 0.01178913, 0.01437283,\n",
       "        0.01437469, 0.01437469, 0.01437469, 0.01856784, 0.01857145,\n",
       "        0.01857145, 0.01857145, 0.02650587, 0.02651459, 0.02651463,\n",
       "        0.02651463, 0.04731837, 0.04733921, 0.04733941, 0.04733941]),\n",
       " 'split3_test_R2': array([-1.08859862e+00, -1.08859862e+00, -1.08859862e+00, -1.08859862e+00,\n",
       "        -1.08876256e+00, -1.08876372e+00, -1.08876384e+00, -1.08876384e+00,\n",
       "        -1.08892686e+00, -1.08892926e+00, -1.08892952e+00, -1.08892956e+00,\n",
       "        -1.08909175e+00, -1.08909532e+00, -1.08909571e+00, -1.08909579e+00,\n",
       "        -1.08925753e+00, -1.08926189e+00, -1.08926241e+00, -1.08926254e+00,\n",
       "        -1.08942391e+00, -1.08942898e+00, -1.08942963e+00, -1.08942979e+00,\n",
       "        -1.08959085e+00, -1.08959657e+00, -1.08959737e+00, -1.08959756e+00,\n",
       "        -1.08975828e+00, -1.08976470e+00, -1.08976564e+00, -1.08976586e+00,\n",
       "        -1.08992635e+00, -1.08993334e+00, -1.08993442e+00, -1.08993468e+00,\n",
       "        -1.09009488e+00, -1.09010251e+00, -1.09010373e+00, -1.09010402e+00,\n",
       "        -1.07549823e+00, -1.07549823e+00, -1.07549823e+00, -1.07549823e+00,\n",
       "        -1.07678004e+00, -1.07678487e+00, -1.07678567e+00, -1.07678595e+00,\n",
       "        -1.07809903e+00, -1.07810774e+00, -1.07810906e+00, -1.07810963e+00,\n",
       "        -1.07945554e+00, -1.07946812e+00, -1.07947002e+00, -1.07947081e+00,\n",
       "        -1.08085078e+00, -1.08086760e+00, -1.08087009e+00, -1.08087110e+00,\n",
       "        -1.08228684e+00, -1.08230783e+00, -1.08231096e+00, -1.08231219e+00,\n",
       "        -1.08376522e+00, -1.08379059e+00, -1.08379440e+00, -1.08379590e+00,\n",
       "        -1.08528810e+00, -1.08531783e+00, -1.08532228e+00, -1.08532407e+00,\n",
       "        -1.08685655e+00, -1.08689133e+00, -1.08689658e+00, -1.08689870e+00,\n",
       "        -1.08847395e+00, -1.08851345e+00, -1.08851941e+00, -1.08852189e+00,\n",
       "        -1.02070460e+00, -1.02070460e+00, -1.02070460e+00, -1.02070460e+00,\n",
       "        -1.02419234e+00, -1.02419431e+00, -1.02419455e+00, -1.02419463e+00,\n",
       "        -1.02794360e+00, -1.02794888e+00, -1.02794953e+00, -1.02794972e+00,\n",
       "        -1.03203813e+00, -1.03204889e+00, -1.03205019e+00, -1.03205057e+00,\n",
       "        -1.03660082e+00, -1.03661891e+00, -1.03662104e+00, -1.03662164e+00,\n",
       "        -1.04176150e+00, -1.04179392e+00, -1.04179775e+00, -1.04179886e+00,\n",
       "        -1.04774446e+00, -1.04779511e+00, -1.04780121e+00, -1.04780304e+00,\n",
       "        -1.05486309e+00, -1.05494191e+00, -1.05495173e+00, -1.05495460e+00,\n",
       "        -1.06358254e+00, -1.06370506e+00, -1.06372004e+00, -1.06372460e+00,\n",
       "        -1.07461329e+00, -1.07480204e+00, -1.07482579e+00, -1.07483335e+00,\n",
       "        -8.08348827e-01, -8.08348827e-01, -8.08348827e-01, -8.08348827e-01,\n",
       "        -8.29095306e-01, -8.29112974e-01, -8.29131714e-01, -8.29135519e-01,\n",
       "        -8.50373929e-01, -8.50408900e-01, -8.50451460e-01, -8.50460089e-01,\n",
       "        -8.72186137e-01, -8.72252116e-01, -8.72312770e-01, -8.72328989e-01,\n",
       "        -8.94528010e-01, -8.94633169e-01, -8.94716513e-01, -8.94739200e-01,\n",
       "        -9.17316086e-01, -9.17557999e-01, -9.17651998e-01, -9.17678254e-01,\n",
       "        -9.40819283e-01, -9.41120371e-01, -9.41174185e-01, -9.41186778e-01,\n",
       "        -9.65224516e-01, -9.65164221e-01, -9.65153766e-01, -9.65150689e-01,\n",
       "        -9.90005658e-01, -9.89875855e-01, -9.89861941e-01, -9.89858546e-01,\n",
       "        -1.01764409e+00, -1.01755020e+00, -1.01754157e+00, -1.01753944e+00,\n",
       "         3.43114962e-02,  3.43114962e-02,  3.43114962e-02,  3.43114962e-02,\n",
       "        -8.29715540e-03, -8.48700438e-03, -8.48700438e-03, -8.49042662e-03,\n",
       "        -5.76737623e-02, -5.80085220e-02, -5.80085220e-02, -5.80214817e-02,\n",
       "        -1.14964663e-01, -1.15531781e-01, -1.15568325e-01, -1.15576596e-01,\n",
       "        -1.81931781e-01, -1.82850306e-01, -1.82939687e-01, -1.82975692e-01,\n",
       "        -2.60855877e-01, -2.62257482e-01, -2.62533741e-01, -2.62575572e-01,\n",
       "        -3.56094813e-01, -3.57224516e-01, -3.57510855e-01, -3.57586242e-01,\n",
       "        -4.70880527e-01, -4.71552746e-01, -4.72420043e-01, -4.72517743e-01,\n",
       "        -6.11749383e-01, -6.12421163e-01, -6.13837011e-01, -6.13995738e-01,\n",
       "        -7.88985543e-01, -7.90267629e-01, -7.91803315e-01, -7.92045214e-01,\n",
       "         2.47532978e-01,  2.47532978e-01,  2.47532978e-01,  2.47532978e-01,\n",
       "         2.61997157e-01,  2.61997157e-01,  2.62012823e-01,  2.62012823e-01,\n",
       "         2.77406568e-01,  2.77406568e-01,  2.77431158e-01,  2.77430400e-01,\n",
       "         2.93434240e-01,  2.93434240e-01,  2.93473117e-01,  2.93472265e-01,\n",
       "         3.09303557e-01,  3.09303557e-01,  3.09363976e-01,  3.09363452e-01,\n",
       "         3.23232736e-01,  3.23321310e-01,  3.23321310e-01,  3.23322435e-01,\n",
       "         3.31061598e-01,  3.31168074e-01,  3.31174225e-01,  3.31174225e-01,\n",
       "         3.22524323e-01,  3.22540607e-01,  3.22555096e-01,  3.22555408e-01,\n",
       "         2.69430534e-01,  2.68693255e-01,  2.68603020e-01,  2.68603020e-01,\n",
       "         7.63787121e-02,  7.30143311e-02,  7.24865202e-02,  7.24704552e-02,\n",
       "         4.47230212e-04,  4.47230212e-04,  4.47230212e-04,  4.47230212e-04,\n",
       "         2.83948146e-03,  2.84202984e-03,  2.84202984e-03,  2.84202377e-03,\n",
       "         5.81623214e-03,  5.81960216e-03,  5.81960216e-03,  5.81959352e-03,\n",
       "         9.43471293e-03,  9.43940654e-03,  9.43940654e-03,  9.43939336e-03,\n",
       "         1.41199792e-02,  1.41268672e-02,  1.41268672e-02,  1.41268459e-02,\n",
       "         2.10965224e-02,  2.11071722e-02,  2.11071722e-02,  2.11071288e-02,\n",
       "         3.22060144e-02,  3.22244225e-02,  3.22244225e-02,  3.22243356e-02,\n",
       "         5.00318112e-02,  5.00674628e-02,  5.00674628e-02,  5.00672863e-02,\n",
       "         8.17476008e-02,  8.18377684e-02,  8.18373339e-02,  8.18373339e-02,\n",
       "         1.51987137e-01,  1.51987137e-01,  1.51986519e-01,  1.51986519e-01]),\n",
       " 'split4_test_R2': array([0.65437547, 0.65437547, 0.65437547, 0.65437547, 0.65440172,\n",
       "        0.65440172, 0.65440172, 0.65440172, 0.65442798, 0.65442798,\n",
       "        0.65442798, 0.65442798, 0.65445426, 0.65445426, 0.65445426,\n",
       "        0.65445426, 0.65448054, 0.65448054, 0.65448054, 0.65448054,\n",
       "        0.65450683, 0.65450683, 0.65450683, 0.65450683, 0.65453313,\n",
       "        0.65453313, 0.65453313, 0.65453313, 0.65455947, 0.65455945,\n",
       "        0.65455945, 0.65455945, 0.65458581, 0.65458577, 0.65458577,\n",
       "        0.65458577, 0.65461217, 0.6546121 , 0.6546121 , 0.6546121 ,\n",
       "        0.65207344, 0.65207344, 0.65207344, 0.65207344, 0.65232178,\n",
       "        0.65232162, 0.65232161, 0.65232161, 0.65257221, 0.65257188,\n",
       "        0.65257184, 0.65257184, 0.65282464, 0.65282413, 0.65282407,\n",
       "        0.65282407, 0.65307909, 0.65307837, 0.65307828, 0.65307828,\n",
       "        0.65333534, 0.65333439, 0.65333427, 0.65333427, 0.65359334,\n",
       "        0.65359213, 0.65359199, 0.65359199, 0.65385298, 0.65385148,\n",
       "        0.65385131, 0.65385131, 0.65411409, 0.6541123 , 0.6541121 ,\n",
       "        0.6541121 , 0.65437655, 0.65437441, 0.65437418, 0.65437418,\n",
       "        0.63716772, 0.63716772, 0.63716772, 0.63716772, 0.63829044,\n",
       "        0.63829318, 0.63829353, 0.63829362, 0.63950386, 0.6395095 ,\n",
       "        0.63951021, 0.6395104 , 0.64082176, 0.6408304 , 0.64083149,\n",
       "        0.64083178, 0.64226005, 0.64227211, 0.64227372, 0.64227408,\n",
       "        0.64383817, 0.64385377, 0.643856  , 0.64385618, 0.64557989,\n",
       "        0.64559835, 0.64560096, 0.64560129, 0.64750928, 0.64753279,\n",
       "        0.6475336 , 0.64753356, 0.64965094, 0.6496759 , 0.64967562,\n",
       "        0.64967542, 0.65203756, 0.65204597, 0.65204461, 0.65204421,\n",
       "        0.60162629, 0.60162629, 0.60162629, 0.60162629, 0.60423761,\n",
       "        0.60421988, 0.60421567, 0.60421537, 0.60694415, 0.60692596,\n",
       "        0.60689659, 0.60689503, 0.60977354, 0.60973628, 0.60969728,\n",
       "        0.60969224, 0.61277856, 0.6127023 , 0.61266357, 0.61264921,\n",
       "        0.61600512, 0.61591642, 0.61584648, 0.61583768, 0.61960458,\n",
       "        0.61948612, 0.61940001, 0.61938168, 0.62372637, 0.62359278,\n",
       "        0.62354133, 0.62352943, 0.62853187, 0.62866381, 0.62868438,\n",
       "        0.62869026, 0.63647879, 0.636735  , 0.63676707, 0.63677513,\n",
       "        0.44838715, 0.44838715, 0.44838715, 0.44838715, 0.46093982,\n",
       "        0.46095279, 0.4609564 , 0.46095676, 0.47428445, 0.47429597,\n",
       "        0.47430151, 0.47430151, 0.48853356, 0.48850502, 0.48850502,\n",
       "        0.48850672, 0.50373081, 0.50347879, 0.50348018, 0.50348431,\n",
       "        0.52021257, 0.51966665, 0.51964532, 0.51964547, 0.53742233,\n",
       "        0.5370486 , 0.5370207 , 0.53701188, 0.55683146, 0.55587252,\n",
       "        0.55579989, 0.55578617, 0.5776957 , 0.57677699, 0.57633114,\n",
       "        0.57630464, 0.60135596, 0.60031879, 0.59958821, 0.5995303 ,\n",
       "        0.12776619, 0.12776619, 0.12776619, 0.12776619, 0.13835869,\n",
       "        0.13835869, 0.13836116, 0.13836116, 0.15092387, 0.15092387,\n",
       "        0.15092756, 0.15092756, 0.16608078, 0.16608078, 0.16608707,\n",
       "        0.16608707, 0.18471601, 0.18471601, 0.18472704, 0.18472685,\n",
       "        0.20820253, 0.20820253, 0.20822227, 0.20822223, 0.23872707,\n",
       "        0.23876361, 0.23876361, 0.23876461, 0.28006175, 0.28012205,\n",
       "        0.28012849, 0.28012849, 0.33952425, 0.33951749, 0.33954255,\n",
       "        0.33954486, 0.43434081, 0.43302378, 0.43303319, 0.43304107,\n",
       "        0.01001475, 0.01001475, 0.01001475, 0.01001475, 0.01077614,\n",
       "        0.01077653, 0.01077653, 0.01077653, 0.01175033, 0.01175082,\n",
       "        0.01175082, 0.01175082, 0.01299574, 0.01299636, 0.01299636,\n",
       "        0.01299636, 0.01468646, 0.01468731, 0.01468731, 0.01468731,\n",
       "        0.0171152 , 0.01711647, 0.01711647, 0.01711647, 0.02081347,\n",
       "        0.02081564, 0.02081564, 0.02081563, 0.02680716, 0.02681145,\n",
       "        0.02681145, 0.02681143, 0.03819774, 0.03820856, 0.03820851,\n",
       "        0.03820851, 0.06837221, 0.06840635, 0.06840608, 0.06840608]),\n",
       " 'mean_test_R2': array([-0.56067874, -0.56067874, -0.56067874, -0.56067874, -0.56061657,\n",
       "        -0.56061666, -0.56061667, -0.56061666, -0.56055445, -0.56055463,\n",
       "        -0.56055466, -0.56055466, -0.56049241, -0.56049268, -0.56049271,\n",
       "        -0.56049272, -0.56043051, -0.56043079, -0.56043084, -0.56043085,\n",
       "        -0.5603687 , -0.56036898, -0.56036904, -0.56036905, -0.56030697,\n",
       "        -0.56030723, -0.5603073 , -0.56030732, -0.5602453 , -0.56024555,\n",
       "        -0.56024564, -0.56024566, -0.56018372, -0.56018395, -0.56018405,\n",
       "        -0.56018408, -0.56012222, -0.56012242, -0.56012254, -0.56012257,\n",
       "        -0.56640848, -0.56640848, -0.56640848, -0.56640848, -0.56576551,\n",
       "        -0.56576493, -0.56576494, -0.56576496, -0.56512253, -0.56512121,\n",
       "        -0.56512117, -0.56512121, -0.56447997, -0.56447789, -0.56447782,\n",
       "        -0.56447786, -0.56383842, -0.56383563, -0.56383554, -0.56383559,\n",
       "        -0.56319844, -0.56319511, -0.56319501, -0.56319508, -0.56256114,\n",
       "        -0.56255719, -0.5625571 , -0.56255718, -0.56192718, -0.56192273,\n",
       "        -0.56192263, -0.56192273, -0.56129742, -0.5612926 , -0.56129253,\n",
       "        -0.56129267, -0.56067306, -0.5606679 , -0.56066784, -0.56066801,\n",
       "        -0.60428601, -0.60428601, -0.60428601, -0.60428601, -0.60209984,\n",
       "        -0.60208804, -0.6020868 , -0.60208649, -0.59950144, -0.59947605,\n",
       "        -0.59947351, -0.59947287, -0.59644175, -0.59640332, -0.59639947,\n",
       "        -0.59639848, -0.59288109, -0.5928266 , -0.59282112, -0.59281978,\n",
       "        -0.5887497 , -0.58868035, -0.58867337, -0.5886717 , -0.58403486,\n",
       "        -0.5839509 , -0.58394261, -0.58394062, -0.57871051, -0.57861163,\n",
       "        -0.57860259, -0.57860041, -0.57280754, -0.57269844, -0.57268868,\n",
       "        -0.57268648, -0.56646133, -0.56635228, -0.56634312, -0.56634123,\n",
       "        -0.49534721, -0.49534721, -0.49534721, -0.49534721, -0.51053683,\n",
       "        -0.51053753, -0.51053769, -0.51053651, -0.52615295, -0.52615642,\n",
       "        -0.52616365, -0.52616494, -0.54210089, -0.54211634, -0.54213217,\n",
       "        -0.54213738, -0.55817113, -0.55822811, -0.55826796, -0.55828018,\n",
       "        -0.57402348, -0.57415336, -0.57423146, -0.5742505 , -0.58904841,\n",
       "        -0.58924828, -0.58934816, -0.58937945, -0.60215988, -0.60215252,\n",
       "        -0.60230181, -0.60233776, -0.61028568, -0.61043404, -0.6107101 ,\n",
       "        -0.61080433, -0.60563556, -0.60462333, -0.60451623, -0.60448923,\n",
       "         0.03851244,  0.03851244,  0.03851244,  0.03851244,  0.01242896,\n",
       "         0.01233357,  0.01232067,  0.01231843, -0.01763698, -0.01771386,\n",
       "        -0.01773847, -0.01774695, -0.05237276, -0.05245903, -0.0524626 ,\n",
       "        -0.05247953, -0.09300732, -0.09301888, -0.09303203, -0.09304269,\n",
       "        -0.14121164, -0.14082645, -0.14090584, -0.14093481, -0.19899311,\n",
       "        -0.19861115, -0.19854174, -0.19854327, -0.27041621, -0.26978111,\n",
       "        -0.2695976 , -0.26959714, -0.36257482, -0.36104254, -0.36078838,\n",
       "        -0.36077399, -0.48528551, -0.4849897 , -0.48454486, -0.48452807,\n",
       "         0.17737056,  0.17737056,  0.17737056,  0.17737056,  0.187267  ,\n",
       "         0.187267  ,  0.1872759 ,  0.18727589,  0.19770697,  0.19770697,\n",
       "         0.19772043,  0.19772013,  0.20838802,  0.20838802,  0.20840827,\n",
       "         0.20840794,  0.21874235,  0.21875176,  0.21877137,  0.2187713 ,\n",
       "         0.22747288,  0.22750064,  0.22751041,  0.2275111 ,  0.2315949 ,\n",
       "         0.23162706,  0.23163022,  0.23163042,  0.22402817,  0.22397752,\n",
       "         0.2239807 ,  0.22398112,  0.18654047,  0.18618716,  0.18612181,\n",
       "         0.18612227,  0.05740445,  0.05759576,  0.05747625,  0.05746225,\n",
       "         0.00188728,  0.00188728,  0.00188728,  0.00188728,  0.00366981,\n",
       "         0.0036715 ,  0.0036715 ,  0.0036715 ,  0.00580869,  0.00581089,\n",
       "         0.00581089,  0.00581088,  0.00842914,  0.00843217,  0.00843217,\n",
       "         0.00843216,  0.01184297,  0.01184736,  0.01184736,  0.01184735,\n",
       "         0.01684579,  0.01685281,  0.01685281,  0.01685279,  0.02455679,\n",
       "         0.02456889,  0.02456889,  0.02456884,  0.03698136,  0.03700475,\n",
       "         0.03700475,  0.03700462,  0.05894508,  0.05900347,  0.05900317,\n",
       "         0.05900317,  0.10674193,  0.10675293,  0.10675309,  0.10675309]),\n",
       " 'std_test_R2': array([1.05957019, 1.05957019, 1.05957019, 1.05957019, 1.05944814,\n",
       "        1.05944802, 1.05944801, 1.05944801, 1.05932602, 1.05932578,\n",
       "        1.05932576, 1.05932576, 1.05920384, 1.05920349, 1.05920346,\n",
       "        1.05920345, 1.05908164, 1.05908113, 1.05908109, 1.05908108,\n",
       "        1.05895939, 1.05895871, 1.05895867, 1.05895865, 1.05883708,\n",
       "        1.05883624, 1.05883618, 1.05883616, 1.05871472, 1.0587137 ,\n",
       "        1.05871363, 1.05871362, 1.0585923 , 1.05859111, 1.05859103,\n",
       "        1.05859101, 1.05846985, 1.05846846, 1.05846837, 1.05846835,\n",
       "        1.0702327 , 1.0702327 , 1.0702327 , 1.0702327 , 1.06908868,\n",
       "        1.06908668, 1.06908651, 1.06908648, 1.06793415, 1.06793007,\n",
       "        1.06792972, 1.06792965, 1.06676939, 1.06676321, 1.06676267,\n",
       "        1.06676256, 1.06559484, 1.06558649, 1.06558576, 1.06558562,\n",
       "        1.06441055, 1.06440034, 1.06439944, 1.06439927, 1.06321753,\n",
       "        1.06320522, 1.06320417, 1.06320396, 1.06201598, 1.06200174,\n",
       "        1.06200051, 1.06200027, 1.06080659, 1.06079044, 1.06078907,\n",
       "        1.06078882, 1.05959008, 1.05957208, 1.05957054, 1.05957027,\n",
       "        1.12956534, 1.12956534, 1.12956534, 1.12956534, 1.12636363,\n",
       "        1.12634839, 1.12634681, 1.12634642, 1.12254581, 1.12251233,\n",
       "        1.12250906, 1.12250823, 1.11802495, 1.11797308, 1.11796801,\n",
       "        1.11796669, 1.11271174, 1.11263725, 1.11262996, 1.11262814,\n",
       "        1.1064733 , 1.10637592, 1.1063664 , 1.10636389, 1.09923545,\n",
       "        1.09911335, 1.09910157, 1.09909852, 1.09087274, 1.09072428,\n",
       "        1.09070957, 1.0907058 , 1.08129414, 1.08111931, 1.08110154,\n",
       "        1.08109722, 1.07048252, 1.07028099, 1.07026131, 1.07025662,\n",
       "        1.00289189, 1.00289189, 1.00289189, 1.00289189, 1.02052009,\n",
       "        1.02049686, 1.02048037, 1.02047503, 1.03879063, 1.03875447,\n",
       "        1.03871695, 1.03871041, 1.05760239, 1.05754999, 1.05750809,\n",
       "        1.05750059, 1.07672548, 1.07668894, 1.07666344, 1.07665681,\n",
       "        1.09575843, 1.09576255, 1.09577182, 1.09577718, 1.11381449,\n",
       "        1.11392634, 1.11400843, 1.11403023, 1.12903528, 1.12930249,\n",
       "        1.12954383, 1.12960148, 1.13870505, 1.13926528, 1.13975449,\n",
       "        1.13991825, 1.13151602, 1.13030665, 1.13018094, 1.13014928,\n",
       "        0.41001793, 0.41001793, 0.41001793, 0.41001793, 0.44122603,\n",
       "        0.44123727, 0.44124465, 0.44124717, 0.47637476, 0.47624116,\n",
       "        0.47624962, 0.47625431, 0.5161926 , 0.5158142 , 0.51581024,\n",
       "        0.51581651, 0.56197947, 0.56106974, 0.56101936, 0.5610158 ,\n",
       "        0.61562449, 0.61351591, 0.61346305, 0.61345208, 0.67791947,\n",
       "        0.67605005, 0.67567796, 0.67562805, 0.75516072, 0.75276826,\n",
       "        0.75197491, 0.75188032, 0.85608702, 0.85215481, 0.85069501,\n",
       "        0.85055916, 0.99396313, 0.99163145, 0.98925785, 0.98902832,\n",
       "        0.06286386, 0.06286386, 0.06286386, 0.06286386, 0.0657857 ,\n",
       "        0.0657857 , 0.06578841, 0.06578842, 0.0689604 , 0.0689604 ,\n",
       "        0.068964  , 0.06896391, 0.0725596 , 0.0725596 , 0.07256367,\n",
       "        0.07256357, 0.07720852, 0.07719897, 0.07721133, 0.07721136,\n",
       "        0.08459671, 0.08459802, 0.08459279, 0.08459319, 0.09899314,\n",
       "        0.09896772, 0.09896785, 0.09896787, 0.13087445, 0.13079937,\n",
       "        0.13079931, 0.13079984, 0.20394551, 0.20352517, 0.203515  ,\n",
       "        0.20351535, 0.38341684, 0.37920794, 0.37914182, 0.3791487 ,\n",
       "        0.01068977, 0.01068977, 0.01068977, 0.01068977, 0.01035475,\n",
       "        0.01035401, 0.01035401, 0.01035401, 0.01009744, 0.01009655,\n",
       "        0.01009655, 0.01009655, 0.00994312, 0.0099421 , 0.0099421 ,\n",
       "        0.00994211, 0.01001308, 0.01001205, 0.01001205, 0.01001206,\n",
       "        0.01039081, 0.01039018, 0.01039018, 0.01039019, 0.01215995,\n",
       "        0.01216141, 0.01216141, 0.0121614 , 0.01645831, 0.01646544,\n",
       "        0.01646544, 0.01646539, 0.02568502, 0.02571001, 0.02570985,\n",
       "        0.02570985, 0.04568055, 0.04566939, 0.04566946, 0.04566946]),\n",
       " 'rank_test_R2': array([181, 181, 181, 181, 173, 174, 176, 175, 169, 170, 171, 172, 165,\n",
       "        166, 167, 168, 161, 162, 163, 164, 157, 158, 159, 160, 153, 154,\n",
       "        155, 156, 149, 150, 151, 152, 145, 146, 147, 148, 141, 142, 143,\n",
       "        144, 220, 220, 220, 220, 216, 213, 214, 215, 212, 210, 209, 211,\n",
       "        208, 207, 205, 206, 204, 203, 201, 202, 200, 199, 197, 198, 196,\n",
       "        195, 193, 194, 192, 191, 189, 190, 188, 186, 185, 187, 180, 178,\n",
       "        177, 179, 269, 269, 269, 269, 264, 263, 262, 261, 260, 259, 258,\n",
       "        257, 256, 255, 254, 253, 252, 251, 250, 249, 244, 243, 242, 241,\n",
       "        240, 239, 238, 237, 236, 235, 234, 233, 228, 227, 226, 225, 224,\n",
       "        219, 218, 217, 121, 121, 121, 121, 126, 127, 128, 125, 129, 130,\n",
       "        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 229, 230, 231,\n",
       "        232, 245, 246, 247, 248, 266, 265, 267, 268, 277, 278, 279, 280,\n",
       "        276, 275, 274, 273,  49,  49,  49,  49,  65,  66,  67,  68,  89,\n",
       "         90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 104, 101,\n",
       "        102, 103, 108, 107, 105, 106, 112, 111, 110, 109, 116, 115, 114,\n",
       "        113, 120, 119, 118, 117,  33,  33,  33,  33,  27,  27,  25,  26,\n",
       "         23,  23,  21,  22,  19,  19,  17,  18,  16,  15,  13,  14,   8,\n",
       "          7,   6,   5,   4,   3,   2,   1,   9,  12,  11,  10,  29,  30,\n",
       "         32,  31,  48,  45,  46,  47,  85,  85,  85,  85,  84,  81,  81,\n",
       "         83,  80,  77,  77,  79,  76,  73,  73,  75,  72,  69,  69,  71,\n",
       "         64,  61,  61,  63,  60,  57,  57,  59,  56,  53,  53,  55,  44,\n",
       "         41,  42,  42,  40,  39,  37,  37]),\n",
       " 'split0_test_MAE': array([-103904.28779374, -103904.28779374, -103904.28779374,\n",
       "        -103904.28779374, -103907.02458433, -103907.02584947,\n",
       "        -103907.02594236, -103907.02596061, -103909.78161218,\n",
       "        -103909.78442998, -103909.78464387, -103909.78468771,\n",
       "        -103912.55919932, -103912.56367738, -103912.56402375,\n",
       "        -103912.56409561, -103915.35743703, -103915.36370911,\n",
       "        -103915.36420106, -103915.36430521, -103918.17657767,\n",
       "        -103918.18464061, -103918.18529868, -103918.18543481,\n",
       "        -103921.01665596, -103921.0266151 , -103921.02743567,\n",
       "        -103921.0276069 , -103923.87769026, -103923.88975675,\n",
       "        -103923.89073123, -103923.89094316, -103926.75986369,\n",
       "        -103926.77414625, -103926.77531582, -103926.7755652 ,\n",
       "        -103929.66338069, -103929.67993589, -103929.68130141,\n",
       "        -103929.68159442, -103728.93209621, -103728.93209621,\n",
       "        -103728.93209621, -103728.93209621, -103742.43114806,\n",
       "        -103742.4290434 , -103742.4285822 , -103742.42842249,\n",
       "        -103757.21920862, -103757.2206492 , -103757.22029126,\n",
       "        -103757.22011146, -103773.3726895 , -103773.38271212,\n",
       "        -103773.38292721, -103773.38284843, -103790.97261997,\n",
       "        -103790.99912028, -103791.00076439, -103791.00099984,\n",
       "        -103810.10548218, -103810.1484948 , -103810.15141982,\n",
       "        -103810.15194387, -103830.85584736, -103830.92287407,\n",
       "        -103830.9279133 , -103830.92888402, -103853.3220672 ,\n",
       "        -103853.4180464 , -103853.42566054, -103853.42725503,\n",
       "        -103877.60452741, -103877.7351475 , -103877.74595379,\n",
       "        -103877.74827287, -103903.80735755, -103903.98124136,\n",
       "        -103903.99609634, -103903.99935057, -104018.25877695,\n",
       "        -104018.25877695, -104018.25877695, -104018.25877695,\n",
       "        -103970.59787956, -103970.1373548 , -103970.08850932,\n",
       "        -103970.07617811, -103916.40289642, -103915.48103835,\n",
       "        -103915.38580641, -103915.36156884, -103856.65493012,\n",
       "        -103855.41072035, -103855.27971091, -103855.24539452,\n",
       "        -103794.54185172, -103792.84686701, -103792.67096058,\n",
       "        -103792.62567421, -103733.6814084 , -103731.74807975,\n",
       "        -103731.54761959, -103731.49560306, -103681.02275225,\n",
       "        -103679.0405247 , -103678.82876214, -103678.77458892,\n",
       "        -103647.92863267, -103646.11074955, -103645.91643427,\n",
       "        -103645.86634027, -103653.02691538, -103651.82875845,\n",
       "        -103651.69586655, -103651.65928061, -103727.81382296,\n",
       "        -103727.90369483, -103727.89393747, -103727.88798398,\n",
       "         -97772.06385751,  -97772.06385751,  -97772.06385751,\n",
       "         -97772.06385751,  -98676.44165035,  -98677.8430766 ,\n",
       "         -98679.19180802,  -98679.51756343,  -99582.66049301,\n",
       "         -99585.60759978,  -99588.95200091,  -99589.75524936,\n",
       "        -100484.86699916, -100489.91766269, -100494.30169536,\n",
       "        -100495.62649596, -101368.22172028, -101376.73716995,\n",
       "        -101383.75212994, -101385.58362622, -102217.90836567,\n",
       "        -102228.82291875, -102238.03910868, -102240.35568072,\n",
       "        -103009.7644989 , -103020.66635848, -103023.67909074,\n",
       "        -103026.37941053, -103781.172702  , -103719.51728329,\n",
       "        -103715.85133893, -103715.15325118, -104164.52973774,\n",
       "        -104129.97614328, -104126.32458536, -104125.45488099,\n",
       "        -104107.41885458, -104063.88484658, -104059.51850458,\n",
       "        -104058.39973964,  -55988.0998044 ,  -55988.0998044 ,\n",
       "         -55988.0998044 ,  -55988.0998044 ,  -58241.51451985,\n",
       "         -58259.12162429,  -58262.5395269 ,  -58262.75593487,\n",
       "         -60837.89281963,  -60865.66846142,  -60872.70647123,\n",
       "         -60873.92372138,  -63827.50164365,  -63882.70738   ,\n",
       "         -63882.70738   ,  -63886.82437172,  -67290.91612415,\n",
       "         -67373.03830623,  -67381.25404452,  -67383.67211214,\n",
       "         -71345.17933058,  -71458.72992701,  -71474.7737091 ,\n",
       "         -71483.31201806,  -76221.38459392,  -76309.53752119,\n",
       "         -76331.70615185,  -76336.22137351,  -82000.25333347,\n",
       "         -82078.56275473,  -82105.30164134,  -82116.08590146,\n",
       "         -88906.51145082,  -88987.70228598,  -89051.38886291,\n",
       "         -89060.20444376,  -97161.72051327,  -97265.95005513,\n",
       "         -97387.98627709,  -97404.48389811,  -44202.8599878 ,\n",
       "         -44202.8599878 ,  -44202.8599878 ,  -44202.8599878 ,\n",
       "         -43368.44815313,  -43368.44815313,  -43368.00690821,\n",
       "         -43368.00690821,  -42485.17032722,  -42485.17032722,\n",
       "         -42484.57091485,  -42484.57091485,  -41586.62998244,\n",
       "         -41586.62998244,  -41585.90439389,  -41585.90732814,\n",
       "         -40716.8379261 ,  -40716.8379261 ,  -40716.26625619,\n",
       "         -40716.2406383 ,  -39976.21461794,  -39976.86172534,\n",
       "         -39976.86172534,  -39976.77034231,  -39613.94191493,\n",
       "         -39619.9433193 ,  -39619.80766022,  -39619.80766022,\n",
       "         -40212.42029861,  -40238.72065838,  -40239.77465442,\n",
       "         -40239.65408199,  -43325.33131271,  -43418.95817388,\n",
       "         -43435.34921248,  -43435.34921248,  -54662.48418965,\n",
       "         -54944.11592047,  -54957.40408779,  -54960.0812948 ,\n",
       "         -58692.55429797,  -58692.55429797,  -58692.55429797,\n",
       "         -58692.55429797,  -58528.76952481,  -58528.64384948,\n",
       "         -58528.64384948,  -58528.64421149,  -58335.26940142,\n",
       "         -58335.11263464,  -58335.11263464,  -58335.11310441,\n",
       "         -58099.25756409,  -58099.04196118,  -58099.04196118,\n",
       "         -58099.04266842,  -57792.3052032 ,  -57791.99434002,\n",
       "         -57791.99434002,  -57791.9954615 ,  -57363.94987271,\n",
       "         -57363.44234264,  -57363.44234264,  -57363.44455051,\n",
       "         -56692.72872279,  -56691.86038813,  -56691.86038813,\n",
       "         -56691.86495278,  -55613.8710249 ,  -55612.2658548 ,\n",
       "         -55612.2658548 ,  -55612.27502051,  -53704.38705489,\n",
       "         -53700.5954717 ,  -53700.61799698,  -53700.61799698,\n",
       "         -49546.75648853,  -49546.75648853,  -49546.70706481,\n",
       "         -49546.70706481]),\n",
       " 'split1_test_MAE': array([-124693.6297993 , -124693.6297993 , -124693.6297993 ,\n",
       "        -124693.6297993 , -124674.47431297, -124674.44357088,\n",
       "        -124674.44063986, -124674.44026859, -124655.29818624,\n",
       "        -124655.23736966, -124655.23149591, -124655.23011315,\n",
       "        -124636.10189096, -124636.01057166, -124636.00181966,\n",
       "        -124635.99962429, -124616.88555259, -124616.76330845,\n",
       "        -124616.75160116, -124616.74866638, -124597.64880833,\n",
       "        -124597.49558819, -124597.48091413, -124597.4772361 ,\n",
       "        -124578.39006437, -124578.20727814, -124578.18976272,\n",
       "        -124578.18537135, -124559.11334628, -124558.89888419,\n",
       "        -124558.8782014 , -124558.8731598 , -124539.81331407,\n",
       "        -124539.56984741, -124539.54647417, -124539.540608  ,\n",
       "        -124520.49739947, -124520.22048623, -124520.19435435,\n",
       "        -124520.1877907 , -126333.22506105, -126333.22506105,\n",
       "        -126333.22506105, -126333.22506105, -126160.40996918,\n",
       "        -126160.09915638, -126160.06878935, -126160.06131718,\n",
       "        -125985.33975159, -125984.72010444, -125984.65979465,\n",
       "        -125984.6446796 , -125808.02964798, -125807.09509327,\n",
       "        -125807.00367759, -125806.98085852, -125628.49396323,\n",
       "        -125627.23162936, -125627.10983068, -125627.07951773,\n",
       "        -125446.69476975, -125445.14300231, -125444.99218641,\n",
       "        -125444.95500753, -125262.72409991, -125260.85026991,\n",
       "        -125260.67135701, -125260.62629408, -125076.55622745,\n",
       "        -125074.37978309, -125074.17020683, -125074.11712387,\n",
       "        -124888.24194451, -124885.75528298, -124885.5182311 ,\n",
       "        -124885.45866568, -124697.80654005, -124695.02256358,\n",
       "        -124694.75464527, -124694.68736436, -134891.26432921,\n",
       "        -134891.26432921, -134891.26432921, -134891.26432921,\n",
       "        -134425.2314126 , -134423.28030361, -134423.07611428,\n",
       "        -134423.02509981, -133876.72681963, -133872.42838268,\n",
       "        -133872.00220948, -133871.8943241 , -133232.93495852,\n",
       "        -133226.22280952, -133225.55732822, -133225.38301179,\n",
       "        -132479.71735642, -132470.02244956, -132469.05725896,\n",
       "        -132468.81661692, -131596.71754605, -131583.87623489,\n",
       "        -131582.59361689, -131582.26633303, -130568.8081604 ,\n",
       "        -130552.5281177 , -130550.92079768, -130550.51211242,\n",
       "        -129371.87297451, -129351.66829536, -129349.6861266 ,\n",
       "        -129349.18208008, -127981.95229077, -127957.63237217,\n",
       "        -127955.21445391, -127954.62192349, -126377.38654269,\n",
       "        -126348.92688361, -126346.15163044, -126345.47139344,\n",
       "        -123357.04747082, -123357.04747082, -123357.04747082,\n",
       "        -123357.04747082, -125134.97015695, -125132.56129978,\n",
       "        -125130.5909503 , -125129.93623532, -126981.40998707,\n",
       "        -126977.4611781 , -126973.4434619 , -126972.65362152,\n",
       "        -128883.30051438, -128877.8534838 , -128873.51486989,\n",
       "        -128872.65246953, -130812.07238753, -130809.20076736,\n",
       "        -130806.68142001, -130806.14917274, -132718.19977113,\n",
       "        -132720.45342858, -132722.58224703, -132723.23669325,\n",
       "        -134491.61528732, -134505.98286489, -134517.73483952,\n",
       "        -134520.69773788, -135898.25038836, -135936.48695271,\n",
       "        -135966.91024287, -135974.15921815, -136619.49992172,\n",
       "        -136684.63002047, -136743.05280948, -136762.61916051,\n",
       "        -135177.94465428, -135024.90031594, -135008.77092299,\n",
       "        -135004.71083108,  -67405.63081268,  -67405.63081268,\n",
       "         -67405.63081268,  -67405.63081268,  -70301.69302568,\n",
       "         -70302.29712242,  -70302.93277665,  -70303.16821554,\n",
       "         -73551.51879549,  -73535.66476939,  -73536.30516276,\n",
       "         -73536.74569619,  -77220.20529433,  -77176.44214917,\n",
       "         -77175.83510618,  -77176.32469108,  -81434.4427935 ,\n",
       "         -81333.27069274,  -81326.95470872,  -81326.2307019 ,\n",
       "         -86376.84126632,  -86141.19811361,  -86133.98757649,\n",
       "         -86132.25305564,  -92106.85026422,  -91896.8766478 ,\n",
       "         -91853.06900972,  -91846.8955145 ,  -99294.70564192,\n",
       "         -99036.69540965,  -98940.37930492,  -98928.407561  ,\n",
       "        -108934.50199242, -108491.89018203, -108318.61982726,\n",
       "        -108301.78246798, -122495.44766244, -122245.53314446,\n",
       "        -121970.41909918, -121942.53341983,  -33189.64558723,\n",
       "         -33189.64558723,  -33189.64558723,  -33189.64558723,\n",
       "         -33113.67344674,  -33113.67344674,  -33113.10199854,\n",
       "         -33113.10199854,  -33140.90796749,  -33140.90796749,\n",
       "         -33140.03474531,  -33140.06325448,  -33339.31340989,\n",
       "         -33339.31340989,  -33338.00612099,  -33338.03610665,\n",
       "         -33824.75135603,  -33822.89878364,  -33822.89878364,\n",
       "         -33822.91581304,  -34814.28211991,  -34811.87689727,\n",
       "         -34811.87689727,  -34811.84434551,  -36723.670965  ,\n",
       "         -36721.0254593 ,  -36720.87547257,  -36720.87547257,\n",
       "         -40429.09510819,  -40427.42672961,  -40427.4143555 ,\n",
       "         -40427.43241483,  -47923.98876856,  -47901.17905412,\n",
       "         -47902.34974335,  -47902.34974335,  -65076.29825859,\n",
       "         -64665.56471244,  -64659.23973366,  -64659.8707314 ,\n",
       "         -40071.12999131,  -40071.12999131,  -40071.12999131,\n",
       "         -40071.12999131,  -39975.50310407,  -39975.38141188,\n",
       "         -39975.38141188,  -39975.38172703,  -39866.02457515,\n",
       "         -39865.86367341,  -39865.86367341,  -39865.86414476,\n",
       "         -39732.9172806 ,  -39732.69501048,  -39732.69501048,\n",
       "         -39732.6957191 ,  -39562.00184369,  -39561.67933384,\n",
       "         -39561.67933384,  -39561.68045653,  -39298.82231974,\n",
       "         -39298.28887374,  -39298.28887374,  -39298.29108934,\n",
       "         -38911.36038221,  -38910.43889586,  -38910.43889586,\n",
       "         -38910.44348864,  -38284.89993457,  -38283.07779544,\n",
       "         -38283.07779544,  -38283.08808452,  -37238.87186051,\n",
       "         -37234.21532015,  -37234.24324062,  -37234.24324062,\n",
       "         -35363.27031873,  -35363.27031873,  -35363.24418129,\n",
       "         -35363.24418129]),\n",
       " 'split2_test_MAE': array([-446316.32586162, -446316.32586162, -446316.32586162,\n",
       "        -446316.32586162, -446308.4961473 , -446308.50712936,\n",
       "        -446308.50859356, -446308.50898658, -446300.67789185,\n",
       "        -446300.69867303, -446300.70151238, -446300.70228299,\n",
       "        -446292.87044717, -446292.90066353, -446292.90486567,\n",
       "        -446292.90601529, -446285.07372893, -446285.11318511,\n",
       "        -446285.11878683, -446285.12029592, -446277.28787788,\n",
       "        -446277.33650351, -446277.34332247, -446277.34521014,\n",
       "        -446269.51241884, -446269.57035731, -446269.57862661,\n",
       "        -446269.58087779, -446261.74923362, -446261.81528893,\n",
       "        -446261.82474226, -446261.82740304, -446253.99568308,\n",
       "        -446254.07091888, -446254.08185636, -446254.08488154,\n",
       "        -446246.25459297, -446246.33784406, -446246.35003909,\n",
       "        -446246.35342447, -447051.63662499, -447051.63662499,\n",
       "        -447051.63662499, -447051.63662499, -446967.64058598,\n",
       "        -446967.67767982, -446967.68526716, -446967.68756901,\n",
       "        -446884.06995556, -446884.13069085, -446884.14501159,\n",
       "        -446884.14962457, -446800.96865222, -446801.05289484,\n",
       "        -446801.07454006, -446801.08159008, -446718.39464327,\n",
       "        -446718.50690023, -446718.5370617 , -446718.54661566,\n",
       "        -446636.28825918, -446636.41941102, -446636.457301  ,\n",
       "        -446636.46934933, -446554.93066967, -446555.11248705,\n",
       "        -446555.1618148 , -446555.17723413, -446474.32441436,\n",
       "        -446474.55593591, -446474.61701089, -446474.63593362,\n",
       "        -446394.54285756, -446394.83218603, -446394.9064509 ,\n",
       "        -446394.92925932, -446315.67042724, -446316.03318902,\n",
       "        -446316.12030346, -446316.14735781, -453940.92095459,\n",
       "        -453940.92095459, -453940.92095459, -453940.92095459,\n",
       "        -453294.6618018 , -453293.76956369, -453293.66299316,\n",
       "        -453293.63540715, -452620.39550226, -452618.59286542,\n",
       "        -452618.37695166, -452618.32475104, -451916.03720876,\n",
       "        -451913.34831577, -451913.02670747, -451912.94755591,\n",
       "        -451179.80913943, -451176.27642582, -451175.86235126,\n",
       "        -451175.76403693, -450408.75177663, -450404.11573084,\n",
       "        -450403.59895747, -450403.47265081, -449605.97016618,\n",
       "        -449601.12143338, -449600.60075679, -449600.48164969,\n",
       "        -448773.13264233, -448767.54935831, -448766.95832586,\n",
       "        -448766.82831723, -447918.87362361, -447914.05636845,\n",
       "        -447913.65519129, -447913.58647642, -447061.51107484,\n",
       "        -447057.62101552, -447057.41535153, -447057.41609367,\n",
       "        -484303.42977696, -484303.42977696, -484303.42977696,\n",
       "        -484303.42977696, -481703.77454927, -481709.43976006,\n",
       "        -481714.5721655 , -481715.72807749, -479027.94448914,\n",
       "        -479042.70329731, -479052.61383323, -479055.38471682,\n",
       "        -476259.56366972, -476286.68887966, -476302.46637974,\n",
       "        -476306.78889453, -473384.00796841, -473416.72108344,\n",
       "        -473439.52240763, -473446.21060589, -470338.30138189,\n",
       "        -470415.41179556, -470432.3839702 , -470436.81185425,\n",
       "        -467161.37117506, -467192.12036254, -467202.10330798,\n",
       "        -467206.80022492, -463704.09178363, -463662.08011547,\n",
       "        -463656.2635282 , -463654.80291673, -459588.77508506,\n",
       "        -459520.24634161, -459512.03734604, -459509.91630323,\n",
       "        -454270.35137585, -454182.81089046, -454171.56361017,\n",
       "        -454168.7842243 , -629892.10462152, -629892.10462152,\n",
       "        -629892.10462152, -629892.10462152, -618729.99546061,\n",
       "        -618717.97813563, -618712.32662525, -618710.81056703,\n",
       "        -606736.93745225, -606732.67793996, -606726.4140895 ,\n",
       "        -606724.13134838, -593814.80131847, -593831.7042631 ,\n",
       "        -593828.45187759, -593824.71256761, -579812.97407822,\n",
       "        -579886.19358218, -579885.92233674, -579885.00287286,\n",
       "        -564529.50890013, -564728.50150351, -564740.52912114,\n",
       "        -564743.81819083, -547681.64528282, -548115.49274873,\n",
       "        -548193.24618909, -548197.41213771, -529437.76556101,\n",
       "        -529864.8821692 , -530003.32245124, -530011.95942253,\n",
       "        -508941.34224791, -509564.54868464, -509760.2733588 ,\n",
       "        -509782.20800172, -485267.15247176, -486057.90640457,\n",
       "        -486498.54273348, -486545.01131343, -894921.65053188,\n",
       "        -894921.65053188, -894921.65053188, -894921.65053188,\n",
       "        -886540.35932322, -886540.35932322, -886535.97353839,\n",
       "        -886536.01520489, -876569.25997616, -876569.25997616,\n",
       "        -876562.57972904, -876562.60406578, -864521.76266446,\n",
       "        -864521.76266446, -864511.22113455, -864511.17231625,\n",
       "        -849664.64673763, -849664.64673763, -849647.76403321,\n",
       "        -849647.43874128, -830871.7313639 , -830871.7313639 ,\n",
       "        -830842.77948366, -830842.77948366, -806336.87165443,\n",
       "        -806285.39118692, -806281.87496346, -806281.87496346,\n",
       "        -772900.83080827, -772830.0332171 , -772817.64436051,\n",
       "        -772817.45864879, -724037.4576534 , -724060.91796366,\n",
       "        -724016.64656813, -724016.64656813, -644911.65505017,\n",
       "        -644962.4822322 , -644978.2034727 , -644978.84762307,\n",
       "        -987834.53946574, -987834.53946574, -987834.53946574,\n",
       "        -987834.53946574, -987269.98641822, -987269.67774698,\n",
       "        -987269.67774698, -987269.67808822, -986574.67148091,\n",
       "        -986574.26780264, -986574.26780264, -986574.26828877,\n",
       "        -985702.5968311 , -985702.04873164, -985702.04873164,\n",
       "        -985702.04935213, -984534.1020636 , -984533.31319442,\n",
       "        -984533.31319442, -984533.31424253, -982844.18644065,\n",
       "        -982843.0934607 , -982843.0934607 , -982843.09465891,\n",
       "        -980273.42333013, -980271.57530337, -980271.57530337,\n",
       "        -980271.5767057 , -976101.19982318, -976097.61257697,\n",
       "        -976097.61257697, -976097.61151496, -968206.29289522,\n",
       "        -968197.61790528, -968197.5805348 , -968197.5805348 ,\n",
       "        -947506.84124772, -947486.11387597, -947485.91559339,\n",
       "        -947485.91559339]),\n",
       " 'split3_test_MAE': array([-135301.28241689, -135301.28241689, -135301.28241689,\n",
       "        -135301.28241689, -135311.9024526 , -135311.97714078,\n",
       "        -135311.98491236, -135311.98491236, -135322.54561635,\n",
       "        -135322.70146729, -135322.71790696, -135322.72046563,\n",
       "        -135333.22764867, -135333.45901251, -135333.48386682,\n",
       "        -135333.48922506, -135343.96680209, -135344.24959453,\n",
       "        -135344.2831069 , -135344.29117394, -135354.74532336,\n",
       "        -135355.07339051, -135355.11578136, -135355.12602193,\n",
       "        -135365.55935701, -135365.9304041 , -135365.98222239,\n",
       "        -135365.99445139, -135376.40590173, -135376.8217288 ,\n",
       "        -135376.88241298, -135376.89672406, -135387.29390729,\n",
       "        -135387.74620938, -135387.81636251, -135387.83298332,\n",
       "        -135398.21119923, -135398.70558544, -135398.78461435,\n",
       "        -135398.80333505, -134452.62748377, -134452.62748377,\n",
       "        -134452.62748377, -134452.62748377, -134535.66391468,\n",
       "        -134535.97712571, -134536.02887328, -134536.04701419,\n",
       "        -134621.10904303, -134621.67387905, -134621.7592195 ,\n",
       "        -134621.79611909, -134708.985003  , -134709.80041371,\n",
       "        -134709.92346072, -134709.97427245, -134799.3703838 ,\n",
       "        -134800.45969164, -134800.62134903, -134800.68638327,\n",
       "        -134892.39913766, -134893.75912716, -134893.96181332,\n",
       "        -134894.04187561, -134988.17008415, -134989.81397769,\n",
       "        -134990.0603713 , -134990.1574116 , -135086.82385026,\n",
       "        -135088.74938823, -135089.03769904, -135089.15357639,\n",
       "        -135188.42931766, -135190.68264542, -135191.02259812,\n",
       "        -135191.15993701, -135293.20591652, -135295.76459013,\n",
       "        -135296.15101955, -135296.31153035, -130903.04699954,\n",
       "        -130903.04699954, -130903.04699954, -130903.04699954,\n",
       "        -131128.98601172, -131129.11368122, -131129.12929936,\n",
       "        -131129.13398853, -131371.99567324, -131372.33803996,\n",
       "        -131372.38027635, -131372.39241112, -131637.24283233,\n",
       "        -131637.94018647, -131638.02436392, -131638.04914099,\n",
       "        -131932.81820496, -131933.9902477 , -131934.12823539,\n",
       "        -131934.16708865, -132267.13196485, -132269.23219302,\n",
       "        -132269.48032775, -132269.5519735 , -132654.71347828,\n",
       "        -132657.99455757, -132658.38982155, -132658.5080954 ,\n",
       "        -133115.86442492, -133120.97033524, -133121.60664138,\n",
       "        -133121.79272115, -133680.71838132, -133688.6549362 ,\n",
       "        -133689.62567374, -133689.92111429, -134395.30014658,\n",
       "        -134407.52766174, -134409.06617856, -134409.55582691,\n",
       "        -117146.4504772 , -117146.4504772 , -117146.4504772 ,\n",
       "        -117146.4504772 , -118490.42588514, -118491.57046115,\n",
       "        -118492.7844372 , -118493.03094829, -119868.87411808,\n",
       "        -119871.13952638, -119873.89662474, -119874.45564303,\n",
       "        -121281.88841741, -121286.16254217, -121290.09177992,\n",
       "        -121291.14245213, -122729.21484912, -122736.02714473,\n",
       "        -122741.42625291, -122742.89591226, -124205.44674946,\n",
       "        -124221.1181164 , -124227.20745425, -124228.90832462,\n",
       "        -125728.00483868, -125747.50957356, -125750.99569071,\n",
       "        -125751.81144767, -127308.99758788, -127305.09165389,\n",
       "        -127304.41432378, -127304.21502439, -128914.342064  ,\n",
       "        -128905.93330168, -128905.03195097, -128904.81206185,\n",
       "        -130704.7843671 , -130698.70225953, -130698.14296376,\n",
       "        -130698.0051334 ,  -62558.16289573,  -62558.16289573,\n",
       "         -62558.16289573,  -62558.16289573,  -65318.38936608,\n",
       "         -65330.68795249,  -65330.68795249,  -65330.90964854,\n",
       "         -68517.05001502,  -68538.73604768,  -68538.73604768,\n",
       "         -68539.57558918,  -72228.40565262,  -72265.14406611,\n",
       "         -72267.51145125,  -72268.04722086,  -76566.59530753,\n",
       "         -76626.09821643,  -76631.88836385,  -76634.22081372,\n",
       "         -81679.36869809,  -81770.16592466,  -81788.0622466 ,\n",
       "         -81790.77209853,  -87849.03194312,  -87922.21513798,\n",
       "         -87940.76443581,  -87945.64802977,  -95284.95292413,\n",
       "         -95328.49984727,  -95384.68410787,  -95391.01322729,\n",
       "        -104410.56307835, -104454.08160493, -104545.80148349,\n",
       "        -104556.08395215, -115892.07964405, -115975.13434886,\n",
       "        -116074.61747774, -116090.28791672,  -48745.48503483,\n",
       "         -48745.48503483,  -48745.48503483,  -48745.48503483,\n",
       "         -47808.48264568,  -47808.48264568,  -47807.46776928,\n",
       "         -47807.46776928,  -46810.24722293,  -46810.24722293,\n",
       "         -46808.6542586 ,  -46808.70338448,  -45771.96036988,\n",
       "         -45771.96036988,  -45769.44184194,  -45769.49704336,\n",
       "         -44743.93185124,  -44743.93185124,  -44740.01784085,\n",
       "         -44740.05176536,  -43841.58719766,  -43835.84927972,\n",
       "         -43835.84927972,  -43835.77639149,  -43334.42652468,\n",
       "         -43327.5289316 ,  -43327.13046124,  -43327.13046124,\n",
       "         -43887.47883503,  -43886.4239602 ,  -43885.48534121,\n",
       "         -43885.46509456,  -47326.94184188,  -47374.70341508,\n",
       "         -47380.5489743 ,  -47380.5489743 ,  -59833.01111931,\n",
       "         -60050.95872254,  -60085.15078325,  -60086.19148808,\n",
       "         -64751.92026417,  -64751.92026417,  -64751.92026417,\n",
       "         -64751.92026417,  -64596.94809408,  -64596.78300784,\n",
       "         -64596.78300784,  -64596.78340043,  -64404.11152861,\n",
       "         -64403.89321574,  -64403.89321574,  -64403.89377551,\n",
       "         -64169.70311493,  -64169.3990585 ,  -64169.3990585 ,\n",
       "         -64169.39991215,  -63866.18738436,  -63865.74117548,\n",
       "         -63865.74117548,  -63865.74255342,  -63414.2406938 ,\n",
       "         -63413.55078977,  -63413.55078977,  -63413.55359924,\n",
       "         -62694.55789133,  -62693.36539501,  -62693.36539501,\n",
       "         -62693.37102569,  -61539.78686925,  -61537.47732215,\n",
       "         -61537.47732215,  -61537.48875598,  -59485.20971584,\n",
       "         -59479.36858166,  -59479.3967279 ,  -59479.3967279 ,\n",
       "         -54935.0298647 ,  -54935.0298647 ,  -54935.06995786,\n",
       "         -54935.06995786]),\n",
       " 'split4_test_MAE': array([-276024.61064177, -276024.61064177, -276024.61064177,\n",
       "        -276024.61064177, -276003.64593206, -276003.64593206,\n",
       "        -276003.64593206, -276003.64593206, -275982.67264489,\n",
       "        -275982.67264489, -275982.67264489, -275982.67264489,\n",
       "        -275961.69094834, -275961.69094834, -275961.69094834,\n",
       "        -275961.69094834, -275940.70101278, -275940.70101278,\n",
       "        -275940.70101278, -275940.70101278, -275919.7030113 ,\n",
       "        -275919.7030113 , -275919.7030113 , -275919.7030113 ,\n",
       "        -275898.69711916, -275898.69711916, -275898.69711916,\n",
       "        -275898.69711916, -275877.66697653, -275877.68351467,\n",
       "        -275877.68351467, -275877.68351467, -275856.62506185,\n",
       "        -275856.66237834, -275856.66237834, -275856.66237834,\n",
       "        -275835.57578677, -275835.63389343, -275835.63389343,\n",
       "        -275835.63389343, -277863.07401512, -277863.07401512,\n",
       "        -277863.07401512, -277863.07401512, -277664.74121109,\n",
       "        -277664.86655527, -277664.87449004, -277664.87449004,\n",
       "        -277464.74373739, -277465.00596177, -277465.03385747,\n",
       "        -277465.03385747, -277263.14142035, -277263.55323274,\n",
       "        -277263.60227845, -277263.60227845, -277059.9314947 ,\n",
       "        -277060.51211937, -277060.58349069, -277060.58349069,\n",
       "        -276855.28406343, -276856.04884961, -276856.14259868,\n",
       "        -276856.14259868, -276649.23794978, -276650.20597145,\n",
       "        -276650.32258628, -276650.32258628, -276441.88840103,\n",
       "        -276443.08079727, -276443.22033743, -276443.22033743,\n",
       "        -276233.35576857, -276234.7882249 , -276234.94875459,\n",
       "        -276234.94875459, -276023.74788074, -276025.45948232,\n",
       "        -276025.63896909, -276025.63896909, -289767.16589874,\n",
       "        -289767.16589874, -289767.16589874, -289767.16589874,\n",
       "        -288870.52734079, -288868.3445708 , -288868.06489562,\n",
       "        -288867.99205066, -287901.45796335, -287896.95762421,\n",
       "        -287896.38920756, -287896.23956599, -286848.95386588,\n",
       "        -286842.05276513, -286841.18317148, -286840.95109466,\n",
       "        -285700.29339143, -285690.66341516, -285689.38135994,\n",
       "        -285689.09599382, -284439.96871686, -284427.51122292,\n",
       "        -284425.72994552, -284425.5885952 , -283048.98826305,\n",
       "        -283034.24125532, -283032.16321315, -283031.89477374,\n",
       "        -281508.13068572, -281489.35442036, -281488.70422247,\n",
       "        -281488.73521599, -279797.74450202, -279777.80599183,\n",
       "        -279778.03310404, -279778.19112977, -277891.72783547,\n",
       "        -277885.01206465, -277886.0962648 , -277886.41895706,\n",
       "        -318151.45982103, -318151.45982103, -318151.45982103,\n",
       "        -318151.45982103, -316065.99375997, -316080.15179213,\n",
       "        -316083.51104699, -316083.75324578, -313904.47640734,\n",
       "        -313919.00967618, -313942.459643  , -313943.70932894,\n",
       "        -311644.86064633, -311674.61299149, -311705.76245523,\n",
       "        -311709.78650304, -309244.97263939, -309305.87704345,\n",
       "        -309336.80434868, -309348.27113801, -306668.15855527,\n",
       "        -306738.99454418, -306794.85283013, -306801.87916545,\n",
       "        -303793.53706683, -303888.14220818, -303956.91421324,\n",
       "        -303971.54642283, -300501.77073918, -300608.45886217,\n",
       "        -300649.54618282, -300659.05105848, -296663.9711089 ,\n",
       "        -296558.59977925, -296542.17267762, -296537.47862958,\n",
       "        -290317.36133351, -290112.74505877, -290087.13352058,\n",
       "        -290080.69493239, -440532.16289941, -440532.16289941,\n",
       "        -440532.16289941, -440532.16289941, -430507.28149874,\n",
       "        -430496.9197206 , -430494.04448424, -430493.75498125,\n",
       "        -419849.91566468, -419840.71815605, -419836.29129557,\n",
       "        -419836.29129557, -408470.21053802, -408493.0049423 ,\n",
       "        -408493.0049423 , -408491.64927322, -396333.29672666,\n",
       "        -396534.56795684, -396533.46254256, -396530.1593205 ,\n",
       "        -383170.54302906, -383606.52553788, -383623.56096601,\n",
       "        -383623.4479806 , -369426.39086952, -369724.8600727 ,\n",
       "        -369747.14287522, -369754.18396306, -353925.75792132,\n",
       "        -354691.59507603, -354749.59754965, -354760.55605197,\n",
       "        -337263.04051956, -337996.74888459, -338352.81679346,\n",
       "        -338373.9767599 , -318367.35249967, -319195.65911144,\n",
       "        -319779.12224006, -319825.37028205, -696588.28400513,\n",
       "        -696588.28400513, -696588.28400513, -696588.28400513,\n",
       "        -688128.84313017, -688128.84313017, -688126.87323366,\n",
       "        -688126.87323366, -678093.96770423, -678093.96770423,\n",
       "        -678091.02343319, -678091.02343319, -665989.26981627,\n",
       "        -665989.26981627, -665984.24719975, -665984.24719975,\n",
       "        -651106.69536536, -651106.69536536, -651097.89368737,\n",
       "        -651098.04134681, -632349.76136396, -632349.76136396,\n",
       "        -632333.99464612, -632334.02815424, -607972.0818414 ,\n",
       "        -607942.90177161, -607942.90177161, -607942.103349  ,\n",
       "        -574961.14270028, -574912.99316853, -574907.84701919,\n",
       "        -574907.84701919, -527472.87282722, -527478.26861466,\n",
       "        -527458.25285128, -527456.41309861, -451749.93157109,\n",
       "        -452801.74348551, -452794.23588089, -452787.93664392,\n",
       "        -790627.60695949, -790627.60695949, -790627.60695949,\n",
       "        -790627.60695949, -790019.53880284, -790019.23129924,\n",
       "        -790019.23129924, -790019.23129924, -789241.52605338,\n",
       "        -789241.13652145, -789241.13652145, -789241.13652145,\n",
       "        -788246.90946997, -788246.41085793, -788246.41085793,\n",
       "        -788246.41195868, -786896.65600262, -786895.98034904,\n",
       "        -786895.98034904, -786895.98198898, -784957.00535691,\n",
       "        -784955.9870205 , -784955.9870205 , -784955.99017575,\n",
       "        -782003.47076831, -782001.73708373, -782001.73708373,\n",
       "        -782001.74319684, -777216.75306182, -777213.33080393,\n",
       "        -777213.33080393, -777213.34443942, -768119.94875028,\n",
       "        -768111.30807096, -768111.34237792, -768111.34237792,\n",
       "        -744021.8409704 , -743994.57492843, -743994.78825056,\n",
       "        -743994.78825056]),\n",
       " 'mean_test_MAE': array([-217248.02730267, -217248.02730267, -217248.02730267,\n",
       "        -217248.02730267, -217241.10868585, -217241.11992451,\n",
       "        -217241.12120404, -217241.12121204, -217234.1951903 ,\n",
       "        -217234.21891697, -217234.2216408 , -217234.22203887,\n",
       "        -217227.2900269 , -217227.32497468, -217227.32910485,\n",
       "        -217227.32998172, -217220.39690668, -217220.438162  ,\n",
       "        -217220.44374174, -217220.44509085, -217213.51231971,\n",
       "        -217213.55862682, -217213.56566559, -217213.56738286,\n",
       "        -217206.63512307, -217206.68635476, -217206.69503331,\n",
       "        -217206.69708532, -217199.76262968, -217199.82183467,\n",
       "        -217199.83192051, -217199.83434895, -217192.897566  ,\n",
       "        -217192.96470005, -217192.97647744, -217192.97928328,\n",
       "        -217186.04047183, -217186.11554901, -217186.12884052,\n",
       "        -217186.13200761, -217885.89905623, -217885.89905623,\n",
       "        -217885.89905623, -217885.89905623, -217814.1773658 ,\n",
       "        -217814.20991212, -217814.21720041, -217814.21976258,\n",
       "        -217742.49633924, -217742.55025706, -217742.56363489,\n",
       "        -217742.56887844, -217670.89948261, -217670.97686934,\n",
       "        -217670.9973768 , -217671.00436959, -217599.43262099,\n",
       "        -217599.54189218, -217599.5704993 , -217599.57940144,\n",
       "        -217528.15434244, -217528.30377698, -217528.34106385,\n",
       "        -217528.352155  , -217457.18373017, -217457.38111603,\n",
       "        -217457.42880853, -217457.44248202, -217386.58299206,\n",
       "        -217386.83679018, -217386.89418295, -217386.91084527,\n",
       "        -217316.43488314, -217316.75869737, -217316.8283977 ,\n",
       "        -217316.8489779 , -217246.84762442, -217247.25221328,\n",
       "        -217247.33220674, -217247.35691444, -222704.13139181,\n",
       "        -222704.13139181, -222704.13139181, -222704.13139181,\n",
       "        -222338.00088929, -222336.92909482, -222336.80436235,\n",
       "        -222336.77254485, -221937.39577098, -221935.15959012,\n",
       "        -221934.90689029, -221934.84252422, -221498.36475912,\n",
       "        -221494.99495945, -221494.6142564 , -221494.51523957,\n",
       "        -221017.43598879, -221012.75988105, -221012.22003322,\n",
       "        -221012.0938821 , -220489.25028256, -220483.29669228,\n",
       "        -220482.59009344, -220482.47503112, -219911.90056403,\n",
       "        -219904.98517773, -219904.18067026, -219904.03424404,\n",
       "        -219283.38587203, -219275.13063177, -219274.57435011,\n",
       "        -219274.48093494, -218606.46314262, -218597.99568542,\n",
       "        -218597.64485791, -218597.59598492, -217890.74788451,\n",
       "        -217885.39826407, -217885.32467256, -217885.35005101,\n",
       "        -228146.0902807 , -228146.0902807 , -228146.0902807 ,\n",
       "        -228146.0902807 , -228014.32120033, -228018.31327794,\n",
       "        -228020.1300816 , -228020.39321406, -227873.07309893,\n",
       "        -227879.18425555, -227886.27311276, -227887.19171194,\n",
       "        -227710.8960494 , -227723.04711196, -227733.22743603,\n",
       "        -227735.19936304, -227507.69791295, -227528.91264179,\n",
       "        -227541.63731183, -227545.82209102, -227229.60296469,\n",
       "        -227264.96016069, -227283.01312206, -227286.23834366,\n",
       "        -226836.85857336, -226870.88427353, -226890.28542844,\n",
       "        -226895.44704877, -226238.85664021, -226246.32697351,\n",
       "        -226258.59712332, -226261.47629378, -225190.22358348,\n",
       "        -225159.87711726, -225165.72387389, -225168.05620723,\n",
       "        -222915.57211706, -222816.60867426, -222805.02590442,\n",
       "        -222802.11897216, -251275.23220675, -251275.23220675,\n",
       "        -251275.23220675, -251275.23220675, -248619.77477419,\n",
       "        -248621.40091109, -248620.50627311, -248620.27986945,\n",
       "        -245898.66294941, -245902.6930749 , -245902.09061335,\n",
       "        -245902.13353014, -243112.22488942, -243129.80056014,\n",
       "        -243129.50215146, -243129.5116249 , -240287.64500601,\n",
       "        -240350.63375089, -240351.89639928, -240351.85716422,\n",
       "        -237420.28824484, -237541.02420133, -237552.18272387,\n",
       "        -237554.72066873, -234657.06059072, -234793.79642568,\n",
       "        -234813.18573234, -234816.07220371, -231988.68707637,\n",
       "        -232200.04705138, -232236.65701101, -232241.60443285,\n",
       "        -229691.19185781, -229898.99432844, -230005.78006518,\n",
       "        -230014.8511251 , -227836.75055824, -228148.03661289,\n",
       "        -228342.13756551, -228361.53736603, -343529.58502937,\n",
       "        -343529.58502937, -343529.58502937, -343529.58502937,\n",
       "        -339791.96133979, -339791.96133979, -339790.28468962,\n",
       "        -339790.29302292, -335419.91063961, -335419.91063961,\n",
       "        -335417.3726162 , -335417.39301056, -330241.78724859,\n",
       "        -330241.78724859, -330237.76413822, -330237.77199883,\n",
       "        -324011.37264727, -324011.0021328 , -324004.96812025,\n",
       "        -324004.93766096, -316370.71533268, -316369.21612604,\n",
       "        -316360.27240642, -316360.23974344, -306796.19858009,\n",
       "        -306779.35813375, -306778.51806582, -306778.3583813 ,\n",
       "        -294478.19355008, -294459.11954676, -294455.63314617,\n",
       "        -294455.57145187, -278017.31848075, -278046.80544428,\n",
       "        -278038.62946991, -278038.26151937, -255246.67603776,\n",
       "        -255484.97301463, -255494.84679166, -255494.58555625,\n",
       "        -388395.55019573, -388395.55019573, -388395.55019573,\n",
       "        -388395.55019573, -388078.1491888 , -388077.94346309,\n",
       "        -388077.94346309, -388077.94374528, -387684.32060789,\n",
       "        -387684.05476958, -387684.05476958, -387684.05516698,\n",
       "        -387190.27685214, -387189.91912394, -387189.91912394,\n",
       "        -387189.9199221 , -386530.25049949, -386529.74167856,\n",
       "        -386529.74167856, -386529.74294059, -385575.64093676,\n",
       "        -385574.87249747, -385574.87249747, -385574.87481475,\n",
       "        -384115.10821895, -384113.79541322, -384113.79541322,\n",
       "        -384113.79987393, -381751.30214274, -381748.75287066,\n",
       "        -381748.75287066, -381748.76156308, -377350.94205535,\n",
       "        -377344.62106995, -377344.63617564, -377344.63617564,\n",
       "        -366274.74777802, -366265.14909527, -366265.14500958,\n",
       "        -366265.14500958]),\n",
       " 'std_test_MAE': array([129657.51882106, 129657.51882106, 129657.51882106, 129657.51882106,\n",
       "        129653.76587997, 129653.76448981, 129653.76442728, 129653.76461598,\n",
       "        129650.01374449, 129650.00958758, 129650.00931507, 129650.00945388,\n",
       "        129646.2600931 , 129646.25380239, 129646.25333691, 129646.25336724,\n",
       "        129642.50257766, 129642.49716833, 129642.4965014 , 129642.49641678,\n",
       "        129638.74352022, 129638.7397565 , 129638.73879448, 129638.73867004,\n",
       "        129634.98348289, 129634.98148911, 129634.98022836, 129634.98007747,\n",
       "        129631.22145546, 129631.2223472 , 129631.22081319, 129631.22063046,\n",
       "        129627.45724241, 129627.4624299 , 129627.46057782, 129627.46034416,\n",
       "        129623.69268595, 129623.70167837, 129623.69951319, 129623.69923451,\n",
       "        129991.54804674, 129991.54804674, 129991.54804674, 129991.54804674,\n",
       "        129954.98210087, 129955.0107965 , 129955.01193535, 129955.01150413,\n",
       "        129918.2757023 , 129918.33623401, 129918.34151211, 129918.34058433,\n",
       "        129881.43563635, 129881.52942259, 129881.53873495, 129881.53797303,\n",
       "        129844.46011775, 129844.58816825, 129844.60169874, 129844.60102931,\n",
       "        129807.32122621, 129807.47689814, 129807.49392174, 129807.49316437,\n",
       "        129770.08586102, 129770.28394521, 129770.30522398, 129770.3045678 ,\n",
       "        129732.73688567, 129732.97583881, 129733.00202633, 129733.00128284,\n",
       "        129695.28248961, 129695.56105011, 129695.59071456, 129695.58946315,\n",
       "        129657.71766908, 129658.04462421, 129658.0784817 , 129658.07678716,\n",
       "        132810.22439577, 132810.22439577, 132810.22439577, 132810.22439577,\n",
       "        132533.87327256, 132533.66668717, 132533.6351297 , 132533.62652682,\n",
       "        132250.99752823, 132250.60981929, 132250.54576329, 132250.52965728,\n",
       "        131960.89003718, 131960.29231294, 131960.19479816, 131960.17023612,\n",
       "        131662.29051045, 131661.55635727, 131661.42809464, 131661.40085759,\n",
       "        131354.14645564, 131353.1102303 , 131352.93181196, 131352.9177575 ,\n",
       "        131035.32292384, 131034.33683513, 131034.15820109, 131034.14017577,\n",
       "        130704.20315708, 130702.88332586, 130702.83712078, 130702.84810704,\n",
       "        130359.52677565, 130358.51930391, 130358.63270379, 130358.67372817,\n",
       "        129999.01300156, 129999.44259609, 129999.66512516, 129999.72913487,\n",
       "        151007.68153919, 151007.68153919, 151007.68153919, 151007.68153919,\n",
       "        149277.83987159, 149281.35693538, 149283.35743234, 149283.77651159,\n",
       "        147500.93994807, 147507.3571814 , 147513.03211462, 147514.00798274,\n",
       "        145672.12524121, 145684.04260743, 145692.26561984, 145693.93655253,\n",
       "        143788.653161  , 143804.66552872, 143814.30190918, 143817.42951625,\n",
       "        141835.55918345, 141865.42709503, 141874.71155405, 141876.27416631,\n",
       "        139829.89323461, 139844.22972412, 139852.64765559, 139854.88680093,\n",
       "        137731.00218743, 137734.54239442, 137733.73506449, 137733.46080738,\n",
       "        135508.09168056, 135472.12867553, 135460.70856864, 135457.11251816,\n",
       "        132954.22746748, 132931.85596796, 132928.33601357, 132927.47202337,\n",
       "        239469.47552473, 239469.47552473, 239469.47552473, 239469.47552473,\n",
       "        233111.67225495, 233101.33694326, 233098.43818199, 233097.80536261,\n",
       "        226220.49509876, 226212.19274119, 226208.26470834, 226207.13854989,\n",
       "        218723.57639877, 218724.29359568, 218722.97286838, 218720.73597965,\n",
       "        210520.53803555, 210566.52702163, 210564.97932928, 210563.54217355,\n",
       "        201441.74230019, 201572.10723864, 201574.15429293, 201573.64052835,\n",
       "        191375.12177582, 191564.57329899, 191593.17188407, 191594.95208559,\n",
       "        180075.9492183 , 180339.2869594 , 180394.11944392, 180397.47332175,\n",
       "        167122.76293152, 167469.43012021, 167581.48374893, 167590.96625154,\n",
       "        151769.93420066, 152141.63882615, 152363.63082536, 152383.67803545,\n",
       "        374563.39564037, 374563.39564037, 374563.39564037, 374563.39564037,\n",
       "        370795.15023207, 370795.15023207, 370793.81163078, 370793.82391846,\n",
       "        366264.11864345, 366264.11864345, 366262.08478639, 366262.07952998,\n",
       "        360715.24097914, 360715.24097914, 360711.91180043, 360711.88322633,\n",
       "        353767.46226131, 353767.76618574, 353761.83097505, 353761.75756564,\n",
       "        344817.08885114, 344818.28491084, 344806.75548734, 344806.79311604,\n",
       "        332861.96253025, 332841.78804768, 332840.84186418, 332840.69737695,\n",
       "        316084.36809585, 316050.59538475, 316045.91301296, 316045.87649904,\n",
       "        290655.58905158, 290644.62771625, 290623.84510374, 290623.52932145,\n",
       "        246997.01064783, 247163.82178084, 247160.9913429 , 247159.49224544,\n",
       "        413738.29790229, 413738.29790229, 413738.29790229, 413738.29790229,\n",
       "        413522.93087495, 413522.84799112, 413522.84799112, 413522.84791783,\n",
       "        413249.63394589, 413249.52746953, 413249.52746953, 413249.52736863,\n",
       "        412900.28493266, 412900.14852341, 412900.14852341, 412900.14855156,\n",
       "        412424.43308317, 412424.24677654, 412424.24677654, 412424.24681559,\n",
       "        411741.10962195, 411740.87357587, 411740.87357587, 411740.87337129,\n",
       "        410707.21883521, 410706.82642729, 410706.82642729, 410706.82563768,\n",
       "        409026.87727803, 409026.0966101 , 409026.0966101 , 409026.09395828,\n",
       "        405776.39134407, 405774.50133867, 405774.48437981, 405774.48437981,\n",
       "        396806.01286406, 396794.74940433, 396794.73788816, 396794.73788816]),\n",
       " 'rank_test_MAE': array([ 41,  41,  41,  41,  33,  34,  35,  36,  29,  30,  31,  32,  25,\n",
       "         26,  27,  28,  21,  22,  23,  24,  17,  18,  19,  20,  13,  14,\n",
       "         15,  16,   9,  10,  11,  12,   5,   6,   7,   8,   1,   2,   3,\n",
       "          4,  80,  80,  80,  80,  73,  74,  75,  76,  69,  70,  71,  72,\n",
       "         65,  66,  67,  68,  61,  62,  63,  64,  57,  58,  59,  60,  53,\n",
       "         54,  55,  56,  49,  50,  51,  52,  45,  46,  47,  48,  37,  38,\n",
       "         39,  40, 117, 117, 117, 117, 116, 115, 114, 113, 112, 111, 110,\n",
       "        109, 108, 107, 106, 105, 104, 103, 102, 101, 100,  99,  98,  97,\n",
       "         96,  95,  94,  93,  92,  91,  90,  89,  88,  87,  86,  85,  84,\n",
       "         79,  77,  78, 158, 158, 158, 158, 154, 155, 156, 157, 150, 151,\n",
       "        152, 153, 145, 146, 147, 148, 141, 142, 143, 144, 137, 138, 139,\n",
       "        140, 133, 134, 135, 136, 129, 130, 131, 132, 128, 125, 126, 127,\n",
       "        124, 123, 122, 121, 197, 197, 197, 197, 193, 196, 195, 194, 189,\n",
       "        192, 190, 191, 185, 188, 186, 187, 181, 182, 184, 183, 177, 178,\n",
       "        179, 180, 173, 174, 175, 176, 169, 170, 171, 172, 165, 166, 167,\n",
       "        168, 149, 162, 163, 164, 237, 237, 237, 237, 235, 235, 233, 234,\n",
       "        231, 231, 229, 230, 227, 227, 225, 226, 224, 223, 222, 221, 220,\n",
       "        219, 218, 217, 216, 215, 214, 213, 212, 211, 210, 209, 205, 208,\n",
       "        207, 206, 201, 202, 204, 203, 277, 277, 277, 277, 276, 273, 273,\n",
       "        275, 272, 269, 269, 271, 268, 265, 265, 267, 264, 261, 261, 263,\n",
       "        260, 257, 257, 259, 256, 253, 253, 255, 252, 249, 249, 251, 248,\n",
       "        245, 246, 246, 244, 243, 241, 241]),\n",
       " 'split0_test_RMSE': array([-171.3357474 , -171.3357474 , -171.3357474 , -171.3357474 ,\n",
       "        -171.3528744 , -171.35290054, -171.35290309, -171.35290373,\n",
       "        -171.37008167, -171.37013425, -171.37013938, -171.37014068,\n",
       "        -171.38732224, -171.38740084, -171.38740852, -171.38741046,\n",
       "        -171.40459519, -171.40470031, -171.40471059, -171.4047132 ,\n",
       "        -171.42190246, -171.42203263, -171.42204574, -171.42204896,\n",
       "        -171.43924265, -171.43939833, -171.43941402, -171.43941789,\n",
       "        -171.45661433, -171.4567975 , -171.45681549, -171.45682008,\n",
       "        -171.47401852, -171.47422952, -171.47425042, -171.47425563,\n",
       "        -171.49145645, -171.49169502, -171.49171869, -171.4917246 ,\n",
       "        -170.04167436, -170.04167436, -170.04167436, -170.04167436,\n",
       "        -170.16848984, -170.16869731, -170.16871825, -170.16872355,\n",
       "        -170.29750162, -170.29792577, -170.29796739, -170.29797813,\n",
       "        -170.42877344, -170.42942159, -170.42948582, -170.42950172,\n",
       "        -170.56294289, -170.56380494, -170.56389179, -170.56391373,\n",
       "        -170.70148701, -170.70264778, -170.70276186, -170.70279129,\n",
       "        -170.85137335, -170.85282871, -170.85297332, -170.85300918,\n",
       "        -171.00785588, -171.00955984, -171.00972879, -171.00977158,\n",
       "        -171.16727789, -171.16923343, -171.16942829, -171.16947704,\n",
       "        -171.32980043, -171.33211369, -171.33234554, -171.33240333,\n",
       "        -164.59709973, -164.59709973, -164.59709973, -164.59709973,\n",
       "        -164.88773208, -164.88844296, -164.88851768, -164.88853643,\n",
       "        -165.19790143, -165.19941756, -165.19957249, -165.19961164,\n",
       "        -165.53901454, -165.54141963, -165.54167041, -165.54173545,\n",
       "        -165.92717286, -165.93102195, -165.93141434, -165.93151415,\n",
       "        -166.4347018 , -166.44096236, -166.44159506, -166.44175641,\n",
       "        -167.05796121, -167.06628502, -167.06714393, -167.06735848,\n",
       "        -167.85982764, -167.87207436, -167.87331281, -167.87362025,\n",
       "        -168.83963493, -168.8546945 , -168.85618988, -168.85657268,\n",
       "        -169.98678911, -170.00540428, -170.00725862, -170.00772773,\n",
       "        -154.40297584, -154.40297584, -154.40297584, -154.40297584,\n",
       "        -155.28605015, -155.28499829, -155.28404148, -155.28383027,\n",
       "        -156.1869314 , -156.18465307, -156.18219163, -156.18164961,\n",
       "        -157.10903651, -157.10456811, -157.10089707, -157.09987321,\n",
       "        -158.08975973, -158.08222256, -158.07643363, -158.07509377,\n",
       "        -159.09618696, -159.08659785, -159.07910004, -159.07741307,\n",
       "        -160.12106338, -160.10617998, -160.09853325, -160.09419971,\n",
       "        -161.25425314, -161.27850688, -161.27960238, -161.27990073,\n",
       "        -162.53067435, -162.55325658, -162.55577104, -162.55637913,\n",
       "        -164.31634491, -164.37584064, -164.38184023, -164.3833706 ,\n",
       "        -119.08979201, -119.08979201, -119.08979201, -119.08979201,\n",
       "        -120.5618099 , -120.57951945, -120.58207002, -120.58139651,\n",
       "        -122.43916684, -122.46193259, -122.466532  , -122.46655348,\n",
       "        -124.73380467, -124.77816724, -124.77816724, -124.7798235 ,\n",
       "        -127.4430957 , -127.50325786, -127.50989547, -127.51135026,\n",
       "        -130.91853248, -130.97773716, -130.98773865, -130.99189954,\n",
       "        -135.1747447 , -135.20412221, -135.21281013, -135.21409472,\n",
       "        -140.0654212 , -140.07599035, -140.08089024, -140.08255187,\n",
       "        -145.78224885, -145.713885  , -145.66936797, -145.66335745,\n",
       "        -153.28713408, -153.18424432, -153.09074892, -153.08041733,\n",
       "        -132.88543737, -132.88543737, -132.88543737, -132.88543737,\n",
       "        -131.53736245, -131.53736245, -131.53668644, -131.53668644,\n",
       "        -130.0856826 , -130.0856826 , -130.08494503, -130.08494503,\n",
       "        -128.39706237, -128.39706237, -128.3961042 , -128.39608006,\n",
       "        -126.38437511, -126.38437511, -126.38347456, -126.38339696,\n",
       "        -124.03746419, -124.03694571, -124.03694571, -124.0367417 ,\n",
       "        -121.23705209, -121.24202648, -121.24162423, -121.24162423,\n",
       "        -118.37066722, -118.39620409, -118.39618126, -118.39599711,\n",
       "        -115.58169137, -115.69510886, -115.70591691, -115.70591691,\n",
       "        -117.59413477, -117.78213044, -117.78861383, -117.78890469,\n",
       "        -157.06091639, -157.06091639, -157.06091639, -157.06091639,\n",
       "        -156.82500066, -156.82477389, -156.82477389, -156.82477453,\n",
       "        -156.52018547, -156.51990936, -156.51990936, -156.51991017,\n",
       "        -156.12590859, -156.12552453, -156.12552453, -156.12552576,\n",
       "        -155.62366812, -155.62315727, -155.62315727, -155.62315908,\n",
       "        -154.96689767, -154.96604648, -154.96604648, -154.96605012,\n",
       "        -153.90053211, -153.89907028, -153.89907028, -153.89907793,\n",
       "        -152.20067897, -152.1982336 , -152.1982336 , -152.19824753,\n",
       "        -149.40684904, -149.40166355, -149.40169314, -149.40169314,\n",
       "        -143.00785464, -143.00785464, -143.00776887, -143.00776887]),\n",
       " 'split1_test_RMSE': array([-209.36651149, -209.36651149, -209.36651149, -209.36651149,\n",
       "        -209.36101698, -209.36102003, -209.36102061, -209.3610207 ,\n",
       "        -209.35550756, -209.35551169, -209.35551264, -209.35551296,\n",
       "        -209.34998187, -209.34998643, -209.34998769, -209.34998815,\n",
       "        -209.34443958, -209.34444417, -209.34444569, -209.34444626,\n",
       "        -209.33888052, -209.33888482, -209.33888657, -209.33888725,\n",
       "        -209.33330453, -209.33330833, -209.33331029, -209.33331107,\n",
       "        -209.32771154, -209.32771461, -209.32771678, -209.32771764,\n",
       "        -209.32210139, -209.32210364, -209.32210595, -209.32210692,\n",
       "        -209.31647413, -209.31647533, -209.31647779, -209.31647884,\n",
       "        -209.9864032 , -209.9864032 , -209.9864032 , -209.9864032 ,\n",
       "        -209.92153289, -209.92148213, -209.92147903, -209.9214786 ,\n",
       "        -209.85487681, -209.85476284, -209.85475537, -209.85475417,\n",
       "        -209.78637077, -209.78618683, -209.78617433, -209.78617224,\n",
       "        -209.71595452, -209.71569353, -209.7156758 , -209.71567276,\n",
       "        -209.64355289, -209.64322009, -209.64319709, -209.64319315,\n",
       "        -209.57061503, -209.57021674, -209.57018988, -209.57018521,\n",
       "        -209.49629058, -209.49581379, -209.49578121, -209.49577551,\n",
       "        -209.41983628, -209.41927622, -209.41923834, -209.41923176,\n",
       "        -209.36496686, -209.36472939, -209.3647257 , -209.36472842,\n",
       "        -214.27718042, -214.27718042, -214.27718042, -214.27718042,\n",
       "        -214.05806561, -214.05731919, -214.05724426, -214.05722624,\n",
       "        -213.79227999, -213.79051694, -213.79034867, -213.79030743,\n",
       "        -213.46684   , -213.46390533, -213.46362564, -213.46355476,\n",
       "        -213.06951886, -213.06502398, -213.06459506, -213.0644918 ,\n",
       "        -212.57857844, -212.57199935, -212.57136983, -212.57121458,\n",
       "        -211.98553419, -211.9771925 , -211.97640946, -211.97621828,\n",
       "        -211.28176524, -211.27110854, -211.27012236, -211.26988323,\n",
       "        -210.58028798, -210.57203436, -210.57128812, -210.57111979,\n",
       "        -209.98098986, -209.97326398, -209.97261856, -209.97248148,\n",
       "        -205.96453945, -205.96453945, -205.96453945, -205.96453945,\n",
       "        -207.2222047 , -207.22131687, -207.22061147, -207.22038237,\n",
       "        -208.49240166, -208.49116288, -208.48996881, -208.48974462,\n",
       "        -209.77610893, -209.77510212, -209.77449267, -209.77440534,\n",
       "        -211.05680619, -211.05755156, -211.0586559 , -211.05898981,\n",
       "        -212.29645599, -212.30258802, -212.30740386, -212.30880426,\n",
       "        -213.44262773, -213.45450118, -213.46430216, -213.46682148,\n",
       "        -214.3855377 , -214.41522973, -214.43906641, -214.44482937,\n",
       "        -214.88832758, -214.95401742, -215.01068126, -215.02964485,\n",
       "        -214.33101572, -214.27948005, -214.27396795, -214.27257887,\n",
       "        -151.48383834, -151.48383834, -151.48383834, -151.48383834,\n",
       "        -154.74561039, -154.74495253, -154.7445567 , -154.74434302,\n",
       "        -158.37731899, -158.36840667, -158.3680854 , -158.36787894,\n",
       "        -162.56694923, -162.54408855, -162.54333889, -162.54309261,\n",
       "        -167.22928047, -167.18617762, -167.18411045, -167.18307811,\n",
       "        -172.506944  , -172.3950439 , -172.39333578, -172.39312194,\n",
       "        -178.47753192, -178.38363724, -178.36833816, -178.36643154,\n",
       "        -185.37368865, -185.24526448, -185.20113688, -185.19558506,\n",
       "        -193.7241366 , -193.52213393, -193.45243462, -193.44565222,\n",
       "        -204.51482606, -204.38833697, -204.25313403, -204.23908733,\n",
       "        -132.62421577, -132.62421577, -132.62421577, -132.62421577,\n",
       "        -131.769766  , -131.769766  , -131.76873731, -131.76873731,\n",
       "        -130.81951476, -130.81951476, -130.81783025, -130.8178725 ,\n",
       "        -129.7211313 , -129.7211313 , -129.71826481, -129.7183087 ,\n",
       "        -128.5875496 , -128.58333177, -128.58333177, -128.58331158,\n",
       "        -127.58168549, -127.57585231, -127.57585231, -127.57569465,\n",
       "        -127.56089071, -127.54973056, -127.54898004, -127.54898004,\n",
       "        -128.32357339, -128.32377849, -128.32197729, -128.32183372,\n",
       "        -131.32475092, -131.33467194, -131.33395894, -131.33395894,\n",
       "        -148.11105042, -147.65557343, -147.67626563, -147.67590454,\n",
       "        -147.48394856, -147.48394856, -147.48394856, -147.48394856,\n",
       "        -147.30902928, -147.30880417, -147.30880417, -147.30880477,\n",
       "        -147.10944797, -147.10914755, -147.10914755, -147.10914846,\n",
       "        -146.86045257, -146.86003295, -146.86003295, -146.86003433,\n",
       "        -146.53301153, -146.5323939 , -146.5323939 , -146.53239612,\n",
       "        -146.00284651, -146.00180696, -146.00180696, -146.0018114 ,\n",
       "        -145.32972097, -145.3281678 , -145.3281678 , -145.32817536,\n",
       "        -144.31997487, -144.31677918, -144.31677918, -144.31679667,\n",
       "        -142.42248631, -142.41371994, -142.41377002, -142.41377002,\n",
       "        -138.48872887, -138.48872887, -138.48862842, -138.48862842]),\n",
       " 'split2_test_RMSE': array([-208.91874005, -208.91874005, -208.91874005, -208.91874005,\n",
       "        -208.92904886, -208.92907154, -208.92907419, -208.92907486,\n",
       "        -208.93937905, -208.93942487, -208.93943022, -208.93943156,\n",
       "        -208.94973077, -208.94980035, -208.94980846, -208.94981051,\n",
       "        -208.96010415, -208.96019805, -208.96020907, -208.96021178,\n",
       "        -208.97049966, -208.97061841, -208.97063201, -208.97063544,\n",
       "        -208.98091597, -208.98106076, -208.98107746, -208.98108158,\n",
       "        -208.99135828, -208.99152611, -208.99154537, -208.99155028,\n",
       "        -209.00181903, -209.00201352, -209.002036  , -209.0020416 ,\n",
       "        -209.0123062 , -209.01252411, -209.01254934, -209.01255563,\n",
       "        -208.07950319, -208.07950319, -208.07950319, -208.07950319,\n",
       "        -208.16446904, -208.16468203, -208.16470817, -208.16471461,\n",
       "        -208.25111783, -208.25153353, -208.25158649, -208.25159991,\n",
       "        -208.33950081, -208.34011029, -208.34019156, -208.34021207,\n",
       "        -208.42965308, -208.43046708, -208.43057902, -208.43060633,\n",
       "        -208.52144839, -208.5224607 , -208.52260322, -208.52263764,\n",
       "        -208.61529185, -208.61651459, -208.61668766, -208.61672943,\n",
       "        -208.71150271, -208.71297218, -208.71318117, -208.71323158,\n",
       "        -208.8112053 , -208.81289861, -208.81314072, -208.81319911,\n",
       "        -208.91300465, -208.9149665 , -208.91523586, -208.91530234,\n",
       "        -205.3226178 , -205.3226178 , -205.3226178 , -205.3226178 ,\n",
       "        -205.44336915, -205.44376519, -205.44381867, -205.44383379,\n",
       "        -205.57405279, -205.57491008, -205.57502808, -205.57505966,\n",
       "        -205.72202704, -205.72339059, -205.72358184, -205.72363483,\n",
       "        -205.88818618, -205.89035255, -205.89065948, -205.8907435 ,\n",
       "        -206.09426351, -206.09707648, -206.09746508, -206.09757675,\n",
       "        -206.34750514, -206.35225099, -206.35290784, -206.35309171,\n",
       "        -206.75451777, -206.76109215, -206.7620179 , -206.76227716,\n",
       "        -207.29358895, -207.30308382, -207.30437542, -207.30474157,\n",
       "        -208.0370351 , -208.05014585, -208.05195964, -208.05247115,\n",
       "        -201.1884135 , -201.1884135 , -201.1884135 , -201.1884135 ,\n",
       "        -201.51462712, -201.51461614, -201.51459822, -201.51459381,\n",
       "        -201.858714  , -201.85875325, -201.85875472, -201.85875054,\n",
       "        -202.20766472, -202.2081074 , -202.20831259, -202.20835688,\n",
       "        -202.5709196 , -202.57139827, -202.5717198 , -202.57181233,\n",
       "        -202.93248444, -202.93711416, -202.9381349 , -202.93840169,\n",
       "        -203.32197138, -203.34002956, -203.3412758 , -203.34186461,\n",
       "        -203.70697571, -203.7201694 , -203.7219264 , -203.72235788,\n",
       "        -204.30023568, -204.31808056, -204.32029055, -204.32087643,\n",
       "        -205.14795328, -205.17368903, -205.17737787, -205.17836483,\n",
       "        -189.14031651, -189.14031651, -189.14031651, -189.14031651,\n",
       "        -188.96295251, -188.96766123, -188.96703576, -188.96616302,\n",
       "        -188.95144907, -188.96205147, -188.9628308 , -188.96219455,\n",
       "        -189.1629826 , -189.17463714, -189.17735325, -189.17702135,\n",
       "        -189.96244745, -189.98640292, -189.98784248, -189.98794624,\n",
       "        -191.21485611, -191.24537544, -191.24900118, -191.25013891,\n",
       "        -192.77462778, -192.80820424, -192.82104191, -192.82153494,\n",
       "        -194.81543253, -194.83745021, -194.84570499, -194.84627761,\n",
       "        -197.22612786, -197.22891699, -197.23080563, -197.23118681,\n",
       "        -199.99656473, -199.98827681, -199.98455224, -199.98454459,\n",
       "        -226.41168197, -226.41168197, -226.41168197, -226.41168197,\n",
       "        -224.64819995, -224.64819995, -224.64643618, -224.64646655,\n",
       "        -222.61479761, -222.61479761, -222.61239255, -222.61241805,\n",
       "        -220.40700745, -220.40700745, -220.40306887, -220.40308253,\n",
       "        -217.69285752, -217.69285752, -217.68688414, -217.6868267 ,\n",
       "        -214.48975099, -214.48975099, -214.47973725, -214.47973725,\n",
       "        -210.44517099, -210.42876828, -210.42774825, -210.42774825,\n",
       "        -205.04510233, -205.02419974, -205.02063559, -205.02060151,\n",
       "        -197.58570382, -197.60561411, -197.59474082, -197.59474082,\n",
       "        -187.95304819, -187.98975232, -187.99868603, -187.99902674,\n",
       "        -247.5513034 , -247.5513034 , -247.5513034 , -247.5513034 ,\n",
       "        -247.45199896, -247.45185649, -247.45185649, -247.4518567 ,\n",
       "        -247.31721412, -247.31702488, -247.31702488, -247.31702518,\n",
       "        -247.15389026, -247.15366277, -247.15366277, -247.15366308,\n",
       "        -246.92978825, -246.92945416, -246.92945416, -246.9294547 ,\n",
       "        -246.57056076, -246.57010691, -246.57010691, -246.57010771,\n",
       "        -245.97403799, -245.9732975 , -245.9732975 , -245.97329871,\n",
       "        -245.01617463, -245.01470214, -245.01470214, -245.01470367,\n",
       "        -243.29658206, -243.29338059, -243.2933749 , -243.2933749 ,\n",
       "        -239.15896716, -239.15763617, -239.15761396, -239.15761396]),\n",
       " 'split3_test_RMSE': array([-181.41835798, -181.41835798, -181.41835798, -181.41835798,\n",
       "        -181.4300023 , -181.43000596, -181.4300056 , -181.4300056 ,\n",
       "        -181.44165767, -181.441674  , -181.44167367, -181.44167352,\n",
       "        -181.45332963, -181.45336211, -181.45336207, -181.45336179,\n",
       "        -181.46502468, -181.46507039, -181.46507084, -181.46507048,\n",
       "        -181.47674046, -181.47679895, -181.47680006, -181.47679967,\n",
       "        -181.48847643, -181.48854786, -181.48854979, -181.4885494 ,\n",
       "        -181.50023197, -181.50031726, -181.50032008, -181.5003197 ,\n",
       "        -181.51200976, -181.51210712, -181.51211101, -181.51211065,\n",
       "        -181.52380642, -181.52391767, -181.52392263, -181.52392231,\n",
       "        -180.44864584, -180.44864584, -180.44864584, -180.44864584,\n",
       "        -180.54860869, -180.54872739, -180.54873753, -180.54873919,\n",
       "        -180.65015924, -180.65040686, -180.65042769, -180.65043268,\n",
       "        -180.75334869, -180.75372992, -180.75376257, -180.75377033,\n",
       "        -180.85821466, -180.85874255, -180.85878721, -180.85879771,\n",
       "        -180.96509617, -180.96577596, -180.96583413, -180.96584771,\n",
       "        -181.07456128, -181.07538825, -181.0754594 , -181.07547589,\n",
       "        -181.18589335, -181.18685893, -181.18694179, -181.18696136,\n",
       "        -181.29911144, -181.30023765, -181.30033469, -181.30035749,\n",
       "        -181.41432251, -181.4155852 , -181.41569359, -181.41571955,\n",
       "        -175.43909842, -175.43909842, -175.43909842, -175.43909842,\n",
       "        -175.75215025, -175.75270874, -175.75276314, -175.75277717,\n",
       "        -176.09618786, -176.09736651, -176.09748428, -176.09751347,\n",
       "        -176.47165255, -176.47389058, -176.47411183, -176.47416822,\n",
       "        -176.94121628, -176.94457113, -176.94490683, -176.94499074,\n",
       "        -177.47412856, -177.47873235, -177.47917489, -177.47928425,\n",
       "        -178.06562838, -178.07145847, -178.07202443, -178.07216745,\n",
       "        -178.73491789, -178.74243161, -178.74317233, -178.7433513 ,\n",
       "        -179.50698081, -179.51679163, -179.51771152, -179.51793646,\n",
       "        -180.40904017, -180.42152625, -180.4226777 , -180.42295921,\n",
       "        -166.23850381, -166.23850381, -166.23850381, -166.23850381,\n",
       "        -167.03221011, -167.03203904, -167.03183851, -167.03180434,\n",
       "        -167.83560086, -167.8353974 , -167.8350054 , -167.83491732,\n",
       "        -168.6472322 , -168.64716099, -168.64673155, -168.6465604 ,\n",
       "        -169.48878005, -169.48903651, -169.48810777, -169.48765904,\n",
       "        -170.33523366, -170.34162992, -170.34072573, -170.33992718,\n",
       "        -171.17962041, -171.20099473, -171.1994801 , -171.19842413,\n",
       "        -172.03335853, -172.02718603, -172.02594484, -172.02564015,\n",
       "        -173.15022067, -173.16134314, -173.1625805 , -173.16289016,\n",
       "        -175.17027475, -175.21750791, -175.22232656, -175.2235264 ,\n",
       "        -123.35091078, -123.35091078, -123.35091078, -123.35091078,\n",
       "        -126.13267979, -126.14941641, -126.14941641, -126.14875859,\n",
       "        -129.22983663, -129.25718688, -129.25718688, -129.25721051,\n",
       "        -132.71732696, -132.75751535, -132.75912897, -132.75896347,\n",
       "        -136.5450705 , -136.59326681, -136.597171  , -136.59746898,\n",
       "        -140.88736492, -140.95229537, -140.96603068, -140.96703523,\n",
       "        -145.84321215, -145.87959401, -145.88849015, -145.88962643,\n",
       "        -151.40185882, -151.41570325, -151.43381828, -151.43432116,\n",
       "        -157.69057649, -157.69533495, -157.7067201 , -157.70658952,\n",
       "        -164.79476321, -164.82016622, -164.84371609, -164.84380216,\n",
       "        -127.09634732, -127.09634732, -127.09634732, -127.09634732,\n",
       "        -125.107874  , -125.107874  , -125.10635713, -125.10635713,\n",
       "        -122.96586977, -122.96586977, -122.96347824, -122.9635616 ,\n",
       "        -120.56408564, -120.56408564, -120.56018315, -120.56028894,\n",
       "        -118.11659709, -118.11659709, -118.11099722, -118.11107702,\n",
       "        -115.77737236, -115.77015255, -115.77015255, -115.77008156,\n",
       "        -113.6802223 , -113.67770353, -113.67743527, -113.67743527,\n",
       "        -111.38347344, -111.38450359, -111.38313185, -111.38310882,\n",
       "        -110.1838991 , -110.2400764 , -110.24163584, -110.24163584,\n",
       "        -119.29049459, -119.39116107, -119.42421963, -119.42423064,\n",
       "        -154.97280908, -154.97280908, -154.97280908, -154.97280908,\n",
       "        -154.68074879, -154.68051518, -154.68051518, -154.68051573,\n",
       "        -154.3425584 , -154.34225171, -154.34225171, -154.34225248,\n",
       "        -153.92883958, -153.92840699, -153.92840699, -153.92840819,\n",
       "        -153.40672697, -153.40609046, -153.40609046, -153.40609238,\n",
       "        -152.65962369, -152.65865377, -152.65865377, -152.65865763,\n",
       "        -151.46371126, -151.46205444, -151.46205444, -151.46206199,\n",
       "        -149.56734997, -149.56403758, -149.56403758, -149.56405318,\n",
       "        -146.01692805, -146.00815128, -146.00819036, -146.00819036,\n",
       "        -137.57722998, -137.57722998, -137.57728944, -137.57728944]),\n",
       " 'split4_test_RMSE': array([-195.45508783, -195.45508783, -195.45508783, -195.45508783,\n",
       "        -195.47265708, -195.47265708, -195.47265708, -195.47265708,\n",
       "        -195.49027843, -195.49027843, -195.49027843, -195.49027843,\n",
       "        -195.50795217, -195.50795217, -195.50795217, -195.50795217,\n",
       "        -195.52567856, -195.52567856, -195.52567856, -195.52567856,\n",
       "        -195.54345789, -195.54345789, -195.54345789, -195.54345789,\n",
       "        -195.56129046, -195.56129046, -195.56129046, -195.56129046,\n",
       "        -195.57912471, -195.57917655, -195.57917655, -195.57917655,\n",
       "        -195.59699987, -195.59711644, -195.59711644, -195.59711644,\n",
       "        -195.61492955, -195.61511045, -195.61511045, -195.61511045,\n",
       "        -194.79393181, -194.79393181, -194.79393181, -194.79393181,\n",
       "        -194.85186708, -194.85237932, -194.85241163, -194.85241163,\n",
       "        -194.91137126, -194.91241429, -194.91252447, -194.91252447,\n",
       "        -194.97258634, -194.97417847, -194.97436627, -194.97436627,\n",
       "        -195.03534971, -195.03752959, -195.03779442, -195.03779442,\n",
       "        -195.1002267 , -195.10301028, -195.10334715, -195.10334715,\n",
       "        -195.16714788, -195.17055981, -195.17096541, -195.17096541,\n",
       "        -195.23624652, -195.24031237, -195.24078187, -195.24078187,\n",
       "        -195.30769852, -195.31241902, -195.31294124, -195.31294124,\n",
       "        -195.4367031 , -195.44231083, -195.44289089, -195.44289089,\n",
       "        -192.8530186 , -192.8530186 , -192.8530186 , -192.8530186 ,\n",
       "        -192.95815257, -192.95804533, -192.95800758, -192.95798904,\n",
       "        -193.06270405, -193.06310321, -193.06318385, -193.06321392,\n",
       "        -193.16712969, -193.16850249, -193.16883074, -193.1689733 ,\n",
       "        -193.27543788, -193.27888387, -193.27979574, -193.28020636,\n",
       "        -193.44429767, -193.45047636, -193.45258927, -193.45311108,\n",
       "        -193.63321738, -193.64108779, -193.64312665, -193.64383113,\n",
       "        -193.85544195, -193.87384275, -193.87737954, -193.87827365,\n",
       "        -194.18485528, -194.22011179, -194.22461006, -194.22575568,\n",
       "        -194.65459349, -194.70301208, -194.70887103, -194.71036266,\n",
       "        -187.14668409, -187.14668409, -187.14668409, -187.14668409,\n",
       "        -187.54546827, -187.53923009, -187.53636843, -187.53593071,\n",
       "        -187.94348709, -187.94002272, -187.93041715, -187.92906348,\n",
       "        -188.48134086, -188.47690087, -188.46801174, -188.4652788 ,\n",
       "        -189.10234502, -189.09877136, -189.0933727 , -189.08863042,\n",
       "        -189.71666559, -189.71455705, -189.70730591, -189.70613105,\n",
       "        -190.30954262, -190.31831658, -190.31196275, -190.30493725,\n",
       "        -190.86483779, -190.89606377, -190.89077786, -190.88352382,\n",
       "        -191.73078   , -191.77262572, -191.76540826, -191.76146214,\n",
       "        -192.60211862, -192.58910908, -192.58883956, -192.58892881,\n",
       "        -173.45458044, -173.45458044, -173.45458044, -173.45458044,\n",
       "        -173.78474746, -173.78154248, -173.7801734 , -173.77965314,\n",
       "        -174.30000378, -174.29558814, -174.29375397, -174.29375397,\n",
       "        -174.91826668, -174.8782743 , -174.8782743 , -174.8752686 ,\n",
       "        -175.76068682, -175.70997117, -175.70521754, -175.70232589,\n",
       "        -176.90181743, -176.82600189, -176.81707574, -176.810617  ,\n",
       "        -178.28285762, -178.21778963, -178.20892781, -178.20158255,\n",
       "        -180.30196076, -180.14068564, -180.1205553 , -180.11323851,\n",
       "        -182.99010327, -182.83598905, -182.74425962, -182.73464236,\n",
       "        -186.24439503, -186.1497839 , -186.06365463, -186.05211891,\n",
       "        -210.12751791, -210.12751791, -210.12751791, -210.12751791,\n",
       "        -207.96959137, -207.96959137, -207.96876114, -207.96876114,\n",
       "        -205.60069291, -205.60069291, -205.59941981, -205.59941981,\n",
       "        -202.78820693, -202.78820693, -202.78601843, -202.78601843,\n",
       "        -199.64224067, -199.64224067, -199.63878286, -199.63881907,\n",
       "        -195.88285929, -195.88285929, -195.87548562, -195.87555419,\n",
       "        -191.56065355, -191.54922457, -191.54922457, -191.5490086 ,\n",
       "        -186.70047113, -186.67957682, -186.67799166, -186.67799166,\n",
       "        -180.44591151, -180.44636715, -180.44146857, -180.44101684,\n",
       "        -173.79427489, -173.85087126, -173.84912745, -173.84661023,\n",
       "        -238.59792346, -238.59792346, -238.59792346, -238.59792346,\n",
       "        -238.52411769, -238.52397892, -238.52397892, -238.52397892,\n",
       "        -238.39370662, -238.39353533, -238.39353533, -238.39353533,\n",
       "        -238.22248574, -238.22228092, -238.22228092, -238.22228144,\n",
       "        -237.94548375, -237.94520476, -237.94520476, -237.94520556,\n",
       "        -237.5054608 , -237.5050135 , -237.5050135 , -237.50501513,\n",
       "        -236.71483168, -236.71405936, -236.71405936, -236.7140626 ,\n",
       "        -235.45048532, -235.44900567, -235.44900567, -235.44901286,\n",
       "        -233.09059825, -233.08671848, -233.08673948, -233.08673948,\n",
       "        -226.84805039, -226.84312318, -226.84317378, -226.84317378]),\n",
       " 'mean_test_RMSE': array([-193.29888895, -193.29888895, -193.29888895, -193.29888895,\n",
       "        -193.30911993, -193.30913103, -193.30913211, -193.30913239,\n",
       "        -193.31938088, -193.31940465, -193.31940687, -193.31940743,\n",
       "        -193.32966333, -193.32970038, -193.32970378, -193.32970461,\n",
       "        -193.33996843, -193.3400183 , -193.34002295, -193.34002406,\n",
       "        -193.3502962 , -193.35035854, -193.35036445, -193.35036584,\n",
       "        -193.36064601, -193.36072115, -193.3607284 , -193.36073008,\n",
       "        -193.37100817, -193.37110641, -193.37111485, -193.37111685,\n",
       "        -193.38138971, -193.38151405, -193.38152397, -193.38152625,\n",
       "        -193.39179455, -193.39194452, -193.39195578, -193.39195837,\n",
       "        -192.67003168, -192.67003168, -192.67003168, -192.67003168,\n",
       "        -192.73099351, -192.73119364, -192.73121092, -192.73121352,\n",
       "        -192.79300535, -192.79340866, -192.79345228, -192.79345787,\n",
       "        -192.85611601, -192.85672542, -192.85679611, -192.85680453,\n",
       "        -192.92042297, -192.92124754, -192.92134565, -192.92135699,\n",
       "        -192.98636223, -192.98742296, -192.98754869, -192.98756339,\n",
       "        -193.05579788, -193.05710162, -193.05725513, -193.05727302,\n",
       "        -193.12755781, -193.12910342, -193.12928297, -193.12930438,\n",
       "        -193.20102589, -193.20281299, -193.20301666, -193.20304133,\n",
       "        -193.29175951, -193.29394112, -193.29417832, -193.29420891,\n",
       "        -190.497803  , -190.497803  , -190.497803  , -190.497803  ,\n",
       "        -190.61989393, -190.62005628, -190.62007027, -190.62007254,\n",
       "        -190.74462523, -190.74506286, -190.74512347, -190.74514122,\n",
       "        -190.87333276, -190.87422172, -190.87436409, -190.87441331,\n",
       "        -191.02030641, -191.0219707 , -191.02227429, -191.02238931,\n",
       "        -191.20519399, -191.20784938, -191.20843882, -191.20858861,\n",
       "        -191.41796926, -191.42165495, -191.42232246, -191.42253341,\n",
       "        -191.6972941 , -191.70410988, -191.70520099, -191.70548112,\n",
       "        -192.08106959, -192.09334322, -192.094835  , -192.09522524,\n",
       "        -192.61368954, -192.63067049, -192.63267711, -192.63320045,\n",
       "        -182.98822334, -182.98822334, -182.98822334, -182.98822334,\n",
       "        -183.72011207, -183.71844009, -183.71749162, -183.7173083 ,\n",
       "        -184.463427  , -184.46199786, -184.45926754, -184.45882511,\n",
       "        -185.24427664, -185.2423679 , -185.23968913, -185.23889493,\n",
       "        -186.06172212, -186.05979605, -186.05765796, -186.05643707,\n",
       "        -186.87540533, -186.8764974 , -186.87453409, -186.87413545,\n",
       "        -187.6749651 , -187.6840044 , -187.68311081, -187.68124944,\n",
       "        -188.44899257, -188.46743116, -188.47146358, -188.47125039,\n",
       "        -189.32004766, -189.35186468, -189.36294632, -189.36625054,\n",
       "        -190.31354146, -190.32712534, -190.32887043, -190.3293539 ,\n",
       "        -151.30388762, -151.30388762, -151.30388762, -151.30388762,\n",
       "        -152.83756001, -152.84461842, -152.84465046, -152.84406286,\n",
       "        -154.65955507, -154.66903315, -154.66967781, -154.66951829,\n",
       "        -156.81986603, -156.82653652, -156.82725253, -156.8268339 ,\n",
       "        -159.38811619, -159.39581527, -159.39684739, -159.3964339 ,\n",
       "        -162.48590299, -162.47929075, -162.4826364 , -162.48256252,\n",
       "        -166.11059484, -166.09866947, -166.09992163, -166.09865403,\n",
       "        -170.39167239, -170.34301879, -170.33642114, -170.33439484,\n",
       "        -175.48263862, -175.39925198, -175.36071759, -175.35628567,\n",
       "        -181.76753662, -181.70616164, -181.64716118, -181.63999406,\n",
       "        -165.82904007, -165.82904007, -165.82904007, -165.82904007,\n",
       "        -164.20655876, -164.20655876, -164.20539564, -164.20540171,\n",
       "        -162.41731153, -162.41731153, -162.41561318, -162.4156434 ,\n",
       "        -160.37549874, -160.37549874, -160.37272789, -160.37275573,\n",
       "        -158.084724  , -158.08388043, -158.08069411, -158.08068627,\n",
       "        -155.55382646, -155.55111217, -155.54763469, -155.54756187,\n",
       "        -152.89679793, -152.88949068, -152.88900247, -152.88895928,\n",
       "        -149.9646575 , -149.96165255, -149.95998353, -149.95990657,\n",
       "        -147.02439134, -147.06436769, -147.06354421, -147.06345387,\n",
       "        -149.34860057, -149.3338977 , -149.34738251, -149.34693537,\n",
       "        -189.13338018, -189.13338018, -189.13338018, -189.13338018,\n",
       "        -188.95817907, -188.95798573, -188.95798573, -188.95798613,\n",
       "        -188.73662252, -188.73637377, -188.73637377, -188.73637432,\n",
       "        -188.45831535, -188.45798163, -188.45798163, -188.45798256,\n",
       "        -188.08773572, -188.08726011, -188.08726011, -188.08726157,\n",
       "        -187.54107789, -187.54032552, -187.54032552, -187.5403284 ,\n",
       "        -186.6765668 , -186.67532988, -186.67532988, -186.67533532,\n",
       "        -185.31093275, -185.30855163, -185.30855163, -185.30856278,\n",
       "        -182.84668874, -182.84072677, -182.84075358, -182.84075358,\n",
       "        -177.01616621, -177.01491457, -177.01489489, -177.01489489]),\n",
       " 'std_test_RMSE': array([15.0354517 , 15.0354517 , 15.0354517 , 15.0354517 , 15.03008067,\n",
       "        15.03007782, 15.03007781, 15.03007778, 15.02468996, 15.02468243,\n",
       "        15.0246823 , 15.02468229, 15.01929219, 15.01927954, 15.01927925,\n",
       "        15.01927926, 15.0138866 , 15.01386917, 15.01386871, 15.01386869,\n",
       "        15.00847308, 15.00845142, 15.00845062, 15.0084506 , 15.00305186,\n",
       "        15.00302602, 15.00302502, 15.00302498, 14.99762304, 14.99759315,\n",
       "        14.99759191, 14.99759184, 14.99218545, 14.99215281, 14.99215127,\n",
       "        14.99215118, 14.98674137, 14.98670507, 14.98670315, 14.98670301,\n",
       "        15.51273227, 15.51273227, 15.51273227, 15.51273227, 15.46403562,\n",
       "        15.46400165, 15.46399936, 15.46399874, 15.41456826, 15.41449226,\n",
       "        15.41448883, 15.41448734, 15.36431482, 15.36419171, 15.36418662,\n",
       "        15.36418443, 15.31308459, 15.31291757, 15.31291128, 15.31290809,\n",
       "        15.26037894, 15.26014342, 15.26013428, 15.26012969, 15.20448181,\n",
       "        15.20418495, 15.20417236, 15.20416682, 15.14678766, 15.14645033,\n",
       "        15.14643698, 15.14643053, 15.08845386, 15.08806693, 15.08805127,\n",
       "        15.0880441 , 15.03577889, 15.03542061, 15.03540752, 15.03540093,\n",
       "        18.37602774, 18.37602774, 18.37602774, 18.37602774, 18.20848548,\n",
       "        18.20806293, 18.20802138, 18.20801113, 18.0204973 , 18.01957622,\n",
       "        18.0194916 , 18.01947118, 17.80700912, 17.80548087, 17.80534311,\n",
       "        17.80531001, 17.55103055, 17.54871803, 17.54851967, 17.54847653,\n",
       "        17.23739528, 17.23387774, 17.23359146, 17.23352206, 16.86723505,\n",
       "        16.86292083, 16.86256221, 16.86248211, 16.43883877, 16.43325234,\n",
       "        16.43280454, 16.43270134, 15.97710696, 15.97201192, 15.97162511,\n",
       "        15.97153964, 15.52158553, 15.51635423, 15.51600511, 15.51593494,\n",
       "        19.87018016, 19.87018016, 19.87018016, 19.87018016, 19.8524982 ,\n",
       "        19.85237581, 19.85240324, 19.85239761, 19.8400769 , 19.84034575,\n",
       "        19.84048765, 19.84055451, 19.83481554, 19.83577696, 19.83648504,\n",
       "        19.83670119, 19.81739794, 19.81964101, 19.82159736, 19.82200514,\n",
       "        19.78582633, 19.78971671, 19.79316905, 19.79414582, 19.7335052 ,\n",
       "        19.74028995, 19.74526689, 19.7472184 , 19.59782449, 19.60281507,\n",
       "        19.60917386, 19.61055706, 19.30330764, 19.31639879, 19.33068429,\n",
       "        19.33548952, 18.47868601, 18.44463085, 18.44130891, 18.4404821 ,\n",
       "        27.35469903, 27.35469903, 27.35469903, 27.35469903, 26.46637102,\n",
       "        26.45944331, 26.45842816, 26.45840145, 25.53557121, 25.52628993,\n",
       "        25.52504739, 25.52486032, 24.56463305, 24.54127546, 24.54164007,\n",
       "        24.54069885, 23.69229296, 23.66312285, 23.660162  , 23.65927273,\n",
       "        22.78854241, 22.74817495, 22.74244825, 22.74056092, 21.81682558,\n",
       "        21.79209405, 21.78841877, 21.78693374, 20.97374176, 20.93984077,\n",
       "        20.92892541, 20.92701576, 20.30056268, 20.27277916, 20.265081  ,\n",
       "        20.26503585, 19.84433053, 19.83481384, 19.82230956, 19.82155333,\n",
       "        43.17562841, 43.17562841, 43.17562841, 43.17562841, 42.93372585,\n",
       "        42.93372585, 42.93359458, 42.93360313, 42.63499268, 42.63499268,\n",
       "        42.63485978, 42.63484529, 42.30810585, 42.30810585, 42.30784405,\n",
       "        42.30782531, 41.83922408, 41.83981884, 41.83863624, 41.83862643,\n",
       "        41.12848685, 41.13075631, 41.12644037, 41.12652026, 39.97223156,\n",
       "        39.96641884, 39.96633665, 39.96629487, 38.3103117 , 38.29585256,\n",
       "        38.29500735, 38.29504877, 35.39996692, 35.37303389, 35.36682413,\n",
       "        35.36673886, 28.28873179, 28.24979772, 28.24323975, 28.24283321,\n",
       "        44.24851975, 44.24851975, 44.24851975, 44.24851975, 44.31804214,\n",
       "        44.31808483, 44.31808483, 44.31808459, 44.38734918, 44.38740486,\n",
       "        44.38740486, 44.38740453, 44.47402518, 44.47412081, 44.47412081,\n",
       "        44.47412039, 44.56829667, 44.56843469, 44.56843469, 44.56843403,\n",
       "        44.68587503, 44.68612388, 44.68612388, 44.6861225 , 44.81917747,\n",
       "        44.8195698 , 44.8195698 , 44.81956714, 45.01742303, 45.01817054,\n",
       "        45.01817054, 45.01816483, 45.35947605, 45.36151559, 45.36149909,\n",
       "        45.36149909, 45.91579851, 45.91436877, 45.91439309, 45.91439309]),\n",
       " 'rank_test_RMSE': array([241, 241, 241, 241, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
       "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
       "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
       "        280, 201, 201, 201, 201, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "        213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "        239, 240, 161, 161, 161, 161, 165, 166, 167, 168, 169, 170, 171,\n",
       "        172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
       "        185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
       "        198, 199, 200,  89,  89,  89,  89,  96,  95,  94,  93, 100,  99,\n",
       "         98,  97, 104, 103, 102, 101, 112, 111, 110, 109, 119, 120, 118,\n",
       "        117, 125, 128, 127, 126, 133, 138, 140, 139, 153, 154, 155, 156,\n",
       "        157, 158, 159, 160,  13,  13,  13,  13,  17,  19,  20,  18,  25,\n",
       "         26,  28,  27,  33,  34,  36,  35,  41,  42,  44,  43,  56,  53,\n",
       "         55,  54,  68,  66,  67,  65,  72,  71,  70,  69,  76,  75,  74,\n",
       "         73,  84,  83,  82,  81,  61,  61,  61,  61,  59,  59,  57,  58,\n",
       "         51,  51,  49,  50,  47,  47,  45,  46,  40,  39,  38,  37,  32,\n",
       "         31,  30,  29,  24,  23,  22,  21,  12,  11,  10,   9,   1,   4,\n",
       "          3,   2,   8,   5,   7,   6, 149, 149, 149, 149, 148, 145, 145,\n",
       "        147, 144, 141, 141, 143, 137, 134, 134, 136, 132, 129, 129, 131,\n",
       "        124, 121, 121, 123, 116, 113, 113, 115, 108, 105, 105, 107,  88,\n",
       "         85,  86,  86,  80,  79,  77,  77])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Elastparams = {\"tol\" : [0.1,0.01,0.001,0.0001],\n",
    "          \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], \n",
    "          \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}\n",
    "\n",
    "\n",
    "MyElastic = GridSearchCV(estimator = ElasticNet(), \n",
    "                      param_grid = Elastparams,\n",
    "                      scoring = scoring,\n",
    "                      refit= False,      \n",
    "                      cv=CV,\n",
    "                      verbose=2\n",
    "                     )\n",
    "\n",
    "MyElastic.fit(X_train_std, y_train)\n",
    "MyElastic.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>param_tol</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022686</td>\n",
       "      <td>4.639438e-03</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>7.485199e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.1}</td>\n",
       "      <td>-0.751793</td>\n",
       "      <td>-2.168624</td>\n",
       "      <td>...</td>\n",
       "      <td>129657.518821</td>\n",
       "      <td>41</td>\n",
       "      <td>-171.335747</td>\n",
       "      <td>-209.366511</td>\n",
       "      <td>-208.918740</td>\n",
       "      <td>-181.418358</td>\n",
       "      <td>-195.455088</td>\n",
       "      <td>-193.298889</td>\n",
       "      <td>15.035452</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016243</td>\n",
       "      <td>4.937721e-04</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>1.168008e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.01}</td>\n",
       "      <td>-0.751793</td>\n",
       "      <td>-2.168624</td>\n",
       "      <td>...</td>\n",
       "      <td>129657.518821</td>\n",
       "      <td>41</td>\n",
       "      <td>-171.335747</td>\n",
       "      <td>-209.366511</td>\n",
       "      <td>-208.918740</td>\n",
       "      <td>-181.418358</td>\n",
       "      <td>-195.455088</td>\n",
       "      <td>-193.298889</td>\n",
       "      <td>15.035452</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016343</td>\n",
       "      <td>7.370403e-04</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>6.342958e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.001}</td>\n",
       "      <td>-0.751793</td>\n",
       "      <td>-2.168624</td>\n",
       "      <td>...</td>\n",
       "      <td>129657.518821</td>\n",
       "      <td>41</td>\n",
       "      <td>-171.335747</td>\n",
       "      <td>-209.366511</td>\n",
       "      <td>-208.918740</td>\n",
       "      <td>-181.418358</td>\n",
       "      <td>-195.455088</td>\n",
       "      <td>-193.298889</td>\n",
       "      <td>15.035452</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015695</td>\n",
       "      <td>8.644154e-04</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>1.987946e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.0001}</td>\n",
       "      <td>-0.751793</td>\n",
       "      <td>-2.168624</td>\n",
       "      <td>...</td>\n",
       "      <td>129657.518821</td>\n",
       "      <td>41</td>\n",
       "      <td>-171.335747</td>\n",
       "      <td>-209.366511</td>\n",
       "      <td>-208.918740</td>\n",
       "      <td>-181.418358</td>\n",
       "      <td>-195.455088</td>\n",
       "      <td>-193.298889</td>\n",
       "      <td>15.035452</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013613</td>\n",
       "      <td>6.727970e-04</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>4.214048e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.1}</td>\n",
       "      <td>-0.751839</td>\n",
       "      <td>-2.168137</td>\n",
       "      <td>...</td>\n",
       "      <td>129653.765880</td>\n",
       "      <td>33</td>\n",
       "      <td>-171.352874</td>\n",
       "      <td>-209.361017</td>\n",
       "      <td>-208.929049</td>\n",
       "      <td>-181.430002</td>\n",
       "      <td>-195.472657</td>\n",
       "      <td>-193.309120</td>\n",
       "      <td>15.030081</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.132481e-07</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.901934e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.0001}</td>\n",
       "      <td>0.094625</td>\n",
       "      <td>0.053831</td>\n",
       "      <td>...</td>\n",
       "      <td>405774.484380</td>\n",
       "      <td>246</td>\n",
       "      <td>-149.401693</td>\n",
       "      <td>-142.413770</td>\n",
       "      <td>-243.293375</td>\n",
       "      <td>-146.008190</td>\n",
       "      <td>-233.086739</td>\n",
       "      <td>-182.840754</td>\n",
       "      <td>45.361499</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.784161e-07</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.899403e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.1}</td>\n",
       "      <td>0.164658</td>\n",
       "      <td>0.101374</td>\n",
       "      <td>...</td>\n",
       "      <td>396806.012864</td>\n",
       "      <td>244</td>\n",
       "      <td>-143.007855</td>\n",
       "      <td>-138.488729</td>\n",
       "      <td>-239.158967</td>\n",
       "      <td>-137.577230</td>\n",
       "      <td>-226.848050</td>\n",
       "      <td>-177.016166</td>\n",
       "      <td>45.915799</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>4.002341e-04</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>4.896487e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.01}</td>\n",
       "      <td>0.164658</td>\n",
       "      <td>0.101374</td>\n",
       "      <td>...</td>\n",
       "      <td>396794.749404</td>\n",
       "      <td>243</td>\n",
       "      <td>-143.007855</td>\n",
       "      <td>-138.488729</td>\n",
       "      <td>-239.157636</td>\n",
       "      <td>-137.577230</td>\n",
       "      <td>-226.843123</td>\n",
       "      <td>-177.014915</td>\n",
       "      <td>45.914369</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.001006</td>\n",
       "      <td>1.237427e-05</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>4.755213e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.001}</td>\n",
       "      <td>0.164658</td>\n",
       "      <td>0.101375</td>\n",
       "      <td>...</td>\n",
       "      <td>396794.737888</td>\n",
       "      <td>241</td>\n",
       "      <td>-143.007769</td>\n",
       "      <td>-138.488628</td>\n",
       "      <td>-239.157614</td>\n",
       "      <td>-137.577289</td>\n",
       "      <td>-226.843174</td>\n",
       "      <td>-177.014895</td>\n",
       "      <td>45.914393</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.507891e-07</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>6.340317e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.0001}</td>\n",
       "      <td>0.164658</td>\n",
       "      <td>0.101375</td>\n",
       "      <td>...</td>\n",
       "      <td>396794.737888</td>\n",
       "      <td>241</td>\n",
       "      <td>-143.007769</td>\n",
       "      <td>-138.488628</td>\n",
       "      <td>-239.157614</td>\n",
       "      <td>-137.577289</td>\n",
       "      <td>-226.843174</td>\n",
       "      <td>-177.014895</td>\n",
       "      <td>45.914393</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0         0.022686  4.639438e-03         0.002202    7.485199e-04      0.0001   \n",
       "1         0.016243  4.937721e-04         0.002001    1.168008e-07      0.0001   \n",
       "2         0.016343  7.370403e-04         0.002002    6.342958e-04      0.0001   \n",
       "3         0.015695  8.644154e-04         0.001902    1.987946e-04      0.0001   \n",
       "4         0.013613  6.727970e-04         0.002212    4.214048e-04      0.0001   \n",
       "..             ...           ...              ...             ...         ...   \n",
       "275       0.001000  2.132481e-07         0.001600    4.901934e-04         100   \n",
       "276       0.001000  1.784161e-07         0.001600    4.899403e-04         100   \n",
       "277       0.000800  4.002341e-04         0.001600    4.896487e-04         100   \n",
       "278       0.001006  1.237427e-05         0.001613    4.755213e-04         100   \n",
       "279       0.001000  1.507891e-07         0.001501    6.340317e-04         100   \n",
       "\n",
       "    param_l1_ratio param_tol  \\\n",
       "0              0.0       0.1   \n",
       "1              0.0      0.01   \n",
       "2              0.0     0.001   \n",
       "3              0.0    0.0001   \n",
       "4              0.1       0.1   \n",
       "..             ...       ...   \n",
       "275            0.8    0.0001   \n",
       "276            0.9       0.1   \n",
       "277            0.9      0.01   \n",
       "278            0.9     0.001   \n",
       "279            0.9    0.0001   \n",
       "\n",
       "                                                params  split0_test_R2  \\\n",
       "0       {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.1}       -0.751793   \n",
       "1      {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.01}       -0.751793   \n",
       "2     {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.001}       -0.751793   \n",
       "3    {'alpha': 0.0001, 'l1_ratio': 0.0, 'tol': 0.0001}       -0.751793   \n",
       "4       {'alpha': 0.0001, 'l1_ratio': 0.1, 'tol': 0.1}       -0.751839   \n",
       "..                                                 ...             ...   \n",
       "275     {'alpha': 100, 'l1_ratio': 0.8, 'tol': 0.0001}        0.094625   \n",
       "276        {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.1}        0.164658   \n",
       "277       {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.01}        0.164658   \n",
       "278      {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.001}        0.164658   \n",
       "279     {'alpha': 100, 'l1_ratio': 0.9, 'tol': 0.0001}        0.164658   \n",
       "\n",
       "     split1_test_R2  ...   std_test_MAE  rank_test_MAE  split0_test_RMSE  \\\n",
       "0         -2.168624  ...  129657.518821             41       -171.335747   \n",
       "1         -2.168624  ...  129657.518821             41       -171.335747   \n",
       "2         -2.168624  ...  129657.518821             41       -171.335747   \n",
       "3         -2.168624  ...  129657.518821             41       -171.335747   \n",
       "4         -2.168137  ...  129653.765880             33       -171.352874   \n",
       "..              ...  ...            ...            ...               ...   \n",
       "275        0.053831  ...  405774.484380            246       -149.401693   \n",
       "276        0.101374  ...  396806.012864            244       -143.007855   \n",
       "277        0.101374  ...  396794.749404            243       -143.007855   \n",
       "278        0.101375  ...  396794.737888            241       -143.007769   \n",
       "279        0.101375  ...  396794.737888            241       -143.007769   \n",
       "\n",
       "     split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0         -209.366511       -208.918740       -181.418358       -195.455088   \n",
       "1         -209.366511       -208.918740       -181.418358       -195.455088   \n",
       "2         -209.366511       -208.918740       -181.418358       -195.455088   \n",
       "3         -209.366511       -208.918740       -181.418358       -195.455088   \n",
       "4         -209.361017       -208.929049       -181.430002       -195.472657   \n",
       "..                ...               ...               ...               ...   \n",
       "275       -142.413770       -243.293375       -146.008190       -233.086739   \n",
       "276       -138.488729       -239.158967       -137.577230       -226.848050   \n",
       "277       -138.488729       -239.157636       -137.577230       -226.843123   \n",
       "278       -138.488628       -239.157614       -137.577289       -226.843174   \n",
       "279       -138.488628       -239.157614       -137.577289       -226.843174   \n",
       "\n",
       "     mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0       -193.298889      15.035452             241  \n",
       "1       -193.298889      15.035452             241  \n",
       "2       -193.298889      15.035452             241  \n",
       "3       -193.298889      15.035452             241  \n",
       "4       -193.309120      15.030081             245  \n",
       "..              ...            ...             ...  \n",
       "275     -182.840754      45.361499              86  \n",
       "276     -177.016166      45.915799              80  \n",
       "277     -177.014915      45.914369              79  \n",
       "278     -177.014895      45.914393              77  \n",
       "279     -177.014895      45.914393              77  \n",
       "\n",
       "[280 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyElasticbest=pd.concat([pd.DataFrame(MyElastic.cv_results_)])\n",
    "MyElasticbest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227    0.23163\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyElasticbestR2=MyElasticbest[MyElasticbest['rank_test_R2'].isin([1])]\n",
    "print(MyElasticbestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00326457, 0.00121412, 0.00151682, 0.00146537, 0.0020402 ,\n",
       "        0.00164061, 0.00182719]),\n",
       " 'std_fit_time': array([0.0044976 , 0.0003974 , 0.00089887, 0.00057518, 0.00069281,\n",
       "        0.00050944, 0.00041408]),\n",
       " 'mean_score_time': array([0.00201187, 0.00121784, 0.00185771, 0.00205035, 0.0022264 ,\n",
       "        0.00248747, 0.00170722]),\n",
       " 'std_score_time': array([5.14365637e-06, 3.95898110e-04, 4.30484546e-04, 7.29860606e-05,\n",
       "        4.18438379e-04, 4.53969445e-04, 5.01585041e-04]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001},\n",
       "  {'alpha': 0.001},\n",
       "  {'alpha': 0.01},\n",
       "  {'alpha': 0.1},\n",
       "  {'alpha': 1},\n",
       "  {'alpha': 10},\n",
       "  {'alpha': 100}],\n",
       " 'split0_test_R2': array([-0.7522704 , -0.75226548, -0.75221648, -0.75174583, -0.74862436,\n",
       "        -0.75442817, -0.63277134]),\n",
       " 'split1_test_R2': array([-2.16372664, -2.16377554, -2.16426426, -2.16912352, -2.21474392,\n",
       "        -2.43808371, -2.0899921 ]),\n",
       " 'split2_test_R2': array([0.55132413, 0.55132336, 0.55131566, 0.55123806, 0.55041981,\n",
       "        0.54293699, 0.51042305]),\n",
       " 'split3_test_R2': array([-1.09028067, -1.09026371, -1.09009433, -1.08842894, -1.07420616,\n",
       "        -1.01729932, -0.78739608]),\n",
       " 'split4_test_R2': array([0.65463806, 0.65463545, 0.65460934, 0.65434872, 0.65182379,\n",
       "        0.63610293, 0.59905351]),\n",
       " 'mean_test_R2': array([-0.5600631 , -0.56006918, -0.56013001, -0.5607423 , -0.56706617,\n",
       "        -0.60615426, -0.48013659]),\n",
       " 'std_test_R2': array([1.05834697, 1.05835915, 1.05848092, 1.05969545, 1.07139759,\n",
       "        1.13230778, 0.98541364]),\n",
       " 'rank_test_R2': array([2, 3, 4, 5, 6, 7, 1]),\n",
       " 'split0_test_MAE': array([-103932.61166256, -103932.31984761, -103929.41343155,\n",
       "        -103901.49817208, -103716.3536795 , -104060.59572104,\n",
       "         -96844.7504857 ]),\n",
       " 'split1_test_MAE': array([-124500.91411543, -124502.83845132, -124522.07091884,\n",
       "        -124713.29558866, -126508.57751081, -135297.5821796 ,\n",
       "        -121599.26734724]),\n",
       " 'split2_test_MAE': array([-446238.74575966, -446239.51099197, -446247.16948227,\n",
       "        -446324.34993647, -447138.15347339, -454580.32545936,\n",
       "        -486917.65794619]),\n",
       " 'split3_test_MAE': array([-135410.24708478, -135409.14795781, -135398.17539573,\n",
       "        -135290.28994355, -134368.92549167, -130682.4498428 ,\n",
       "        -115789.11289144]),\n",
       " 'split4_test_MAE': array([-275814.89847757, -275816.98408779, -275837.8366846 ,\n",
       "        -276045.97443755, -278062.45219505, -290617.53286075,\n",
       "        -320206.14444187]),\n",
       " 'mean_test_MAE': array([-217179.48342   , -217180.1602673 , -217186.9331826 ,\n",
       "        -217255.08161566, -217958.89247008, -223047.69721271,\n",
       "        -228271.38662249]),\n",
       " 'std_test_MAE': array([129619.93422664, 129620.30786492, 129624.04384535, 129661.36115454,\n",
       "        130028.74445334, 133088.23581649, 152744.26796811]),\n",
       " 'rank_test_MAE': array([1, 2, 3, 4, 5, 6, 7]),\n",
       " 'split0_test_RMSE': array([-171.5094132 , -171.50767119, -171.49026939, -171.31853766,\n",
       "        -169.9132445 , -164.33080967, -153.50627031]),\n",
       " 'split1_test_RMSE': array([-209.31110164, -209.31165306, -209.31723344, -209.3721039 ,\n",
       "        -210.05100347, -214.46388244, -204.67426738]),\n",
       " 'split2_test_RMSE': array([-209.02336198, -209.02231156, -209.01181975, -208.90812756,\n",
       "        -207.99351134, -205.20530313, -200.84994878]),\n",
       " 'split3_test_RMSE': array([-181.53591729, -181.53473935, -181.5229712 , -181.40640574,\n",
       "        -180.34734166, -175.1352425 , -165.42080099]),\n",
       " 'split4_test_RMSE': array([-195.63483839, -195.63303195, -195.6149975 , -195.43758633,\n",
       "        -194.73536985, -192.74657694, -186.74796596]),\n",
       " 'mean_test_RMSE': array([-193.4029265 , -193.40188142, -193.39145826, -193.28855224,\n",
       "        -192.60809417, -190.37636294, -182.23985068]),\n",
       " 'std_test_RMSE': array([14.98133041, 14.98187042, 14.98728257, 15.04085809, 15.56196454,\n",
       "        18.52774446, 19.89201337]),\n",
       " 'rank_test_RMSE': array([7, 6, 5, 4, 3, 2, 1])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridgeparams = {\n",
    "          \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], \n",
    "          }\n",
    "\n",
    "\n",
    "MyRidge = GridSearchCV(estimator = Ridge(), \n",
    "                      param_grid = Ridgeparams,\n",
    "                      scoring = scoring,\n",
    "                      refit= False,      \n",
    "                      cv=CV,\n",
    "                      verbose=2\n",
    "                     )\n",
    "\n",
    "MyRidge.fit(X_train_std, y_train)\n",
    "MyRidge.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>-0.752270</td>\n",
       "      <td>-2.163727</td>\n",
       "      <td>0.551324</td>\n",
       "      <td>-1.090281</td>\n",
       "      <td>...</td>\n",
       "      <td>129619.934227</td>\n",
       "      <td>1</td>\n",
       "      <td>-171.509413</td>\n",
       "      <td>-209.311102</td>\n",
       "      <td>-209.023362</td>\n",
       "      <td>-181.535917</td>\n",
       "      <td>-195.634838</td>\n",
       "      <td>-193.402926</td>\n",
       "      <td>14.981330</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>-0.752265</td>\n",
       "      <td>-2.163776</td>\n",
       "      <td>0.551323</td>\n",
       "      <td>-1.090264</td>\n",
       "      <td>...</td>\n",
       "      <td>129620.307865</td>\n",
       "      <td>2</td>\n",
       "      <td>-171.507671</td>\n",
       "      <td>-209.311653</td>\n",
       "      <td>-209.022312</td>\n",
       "      <td>-181.534739</td>\n",
       "      <td>-195.633032</td>\n",
       "      <td>-193.401881</td>\n",
       "      <td>14.981870</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>-0.752216</td>\n",
       "      <td>-2.164264</td>\n",
       "      <td>0.551316</td>\n",
       "      <td>-1.090094</td>\n",
       "      <td>...</td>\n",
       "      <td>129624.043845</td>\n",
       "      <td>3</td>\n",
       "      <td>-171.490269</td>\n",
       "      <td>-209.317233</td>\n",
       "      <td>-209.011820</td>\n",
       "      <td>-181.522971</td>\n",
       "      <td>-195.614997</td>\n",
       "      <td>-193.391458</td>\n",
       "      <td>14.987283</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>-0.751746</td>\n",
       "      <td>-2.169124</td>\n",
       "      <td>0.551238</td>\n",
       "      <td>-1.088429</td>\n",
       "      <td>...</td>\n",
       "      <td>129661.361155</td>\n",
       "      <td>4</td>\n",
       "      <td>-171.318538</td>\n",
       "      <td>-209.372104</td>\n",
       "      <td>-208.908128</td>\n",
       "      <td>-181.406406</td>\n",
       "      <td>-195.437586</td>\n",
       "      <td>-193.288552</td>\n",
       "      <td>15.040858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>-0.748624</td>\n",
       "      <td>-2.214744</td>\n",
       "      <td>0.550420</td>\n",
       "      <td>-1.074206</td>\n",
       "      <td>...</td>\n",
       "      <td>130028.744453</td>\n",
       "      <td>5</td>\n",
       "      <td>-169.913245</td>\n",
       "      <td>-210.051003</td>\n",
       "      <td>-207.993511</td>\n",
       "      <td>-180.347342</td>\n",
       "      <td>-194.735370</td>\n",
       "      <td>-192.608094</td>\n",
       "      <td>15.561965</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>-0.754428</td>\n",
       "      <td>-2.438084</td>\n",
       "      <td>0.542937</td>\n",
       "      <td>-1.017299</td>\n",
       "      <td>...</td>\n",
       "      <td>133088.235816</td>\n",
       "      <td>6</td>\n",
       "      <td>-164.330810</td>\n",
       "      <td>-214.463882</td>\n",
       "      <td>-205.205303</td>\n",
       "      <td>-175.135243</td>\n",
       "      <td>-192.746577</td>\n",
       "      <td>-190.376363</td>\n",
       "      <td>18.527744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>-0.632771</td>\n",
       "      <td>-2.089992</td>\n",
       "      <td>0.510423</td>\n",
       "      <td>-0.787396</td>\n",
       "      <td>...</td>\n",
       "      <td>152744.267968</td>\n",
       "      <td>7</td>\n",
       "      <td>-153.506270</td>\n",
       "      <td>-204.674267</td>\n",
       "      <td>-200.849949</td>\n",
       "      <td>-165.420801</td>\n",
       "      <td>-186.747966</td>\n",
       "      <td>-182.239851</td>\n",
       "      <td>19.892013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.003265      0.004498         0.002012        0.000005      0.0001   \n",
       "1       0.001214      0.000397         0.001218        0.000396       0.001   \n",
       "2       0.001517      0.000899         0.001858        0.000430        0.01   \n",
       "3       0.001465      0.000575         0.002050        0.000073         0.1   \n",
       "4       0.002040      0.000693         0.002226        0.000418           1   \n",
       "5       0.001641      0.000509         0.002487        0.000454          10   \n",
       "6       0.001827      0.000414         0.001707        0.000502         100   \n",
       "\n",
       "              params  split0_test_R2  split1_test_R2  split2_test_R2  \\\n",
       "0  {'alpha': 0.0001}       -0.752270       -2.163727        0.551324   \n",
       "1   {'alpha': 0.001}       -0.752265       -2.163776        0.551323   \n",
       "2    {'alpha': 0.01}       -0.752216       -2.164264        0.551316   \n",
       "3     {'alpha': 0.1}       -0.751746       -2.169124        0.551238   \n",
       "4       {'alpha': 1}       -0.748624       -2.214744        0.550420   \n",
       "5      {'alpha': 10}       -0.754428       -2.438084        0.542937   \n",
       "6     {'alpha': 100}       -0.632771       -2.089992        0.510423   \n",
       "\n",
       "   split3_test_R2  ...   std_test_MAE  rank_test_MAE  split0_test_RMSE  \\\n",
       "0       -1.090281  ...  129619.934227              1       -171.509413   \n",
       "1       -1.090264  ...  129620.307865              2       -171.507671   \n",
       "2       -1.090094  ...  129624.043845              3       -171.490269   \n",
       "3       -1.088429  ...  129661.361155              4       -171.318538   \n",
       "4       -1.074206  ...  130028.744453              5       -169.913245   \n",
       "5       -1.017299  ...  133088.235816              6       -164.330810   \n",
       "6       -0.787396  ...  152744.267968              7       -153.506270   \n",
       "\n",
       "   split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0       -209.311102       -209.023362       -181.535917       -195.634838   \n",
       "1       -209.311653       -209.022312       -181.534739       -195.633032   \n",
       "2       -209.317233       -209.011820       -181.522971       -195.614997   \n",
       "3       -209.372104       -208.908128       -181.406406       -195.437586   \n",
       "4       -210.051003       -207.993511       -180.347342       -194.735370   \n",
       "5       -214.463882       -205.205303       -175.135243       -192.746577   \n",
       "6       -204.674267       -200.849949       -165.420801       -186.747966   \n",
       "\n",
       "   mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0     -193.402926      14.981330               7  \n",
       "1     -193.401881      14.981870               6  \n",
       "2     -193.391458      14.987283               5  \n",
       "3     -193.288552      15.040858               4  \n",
       "4     -192.608094      15.561965               3  \n",
       "5     -190.376363      18.527744               2  \n",
       "6     -182.239851      19.892013               1  \n",
       "\n",
       "[7 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyRidgebest=pd.concat([pd.DataFrame(MyRidge.cv_results_)])\n",
    "MyRidgebest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6   -0.480137\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyRidgebestR2=MyRidgebest[MyRidgebest['rank_test_R2'].isin([1])]\n",
    "print(MyRidgebestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END .......................................alpha=0.0001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n",
      "[CV] END ........................................alpha=0.001; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+07, tolerance: 2.648e+04\n",
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.659e+05, tolerance: 2.648e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END .........................................alpha=0.01; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ............................................alpha=1; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ...........................................alpha=10; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n",
      "[CV] END ..........................................alpha=100; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01905508, 0.01275434, 0.01047125, 0.00716491, 0.00503025,\n",
       "        0.00191145, 0.00107293]),\n",
       " 'std_fit_time': array([0.0012326 , 0.00244508, 0.00146987, 0.00065898, 0.00063869,\n",
       "        0.00049341, 0.00013647]),\n",
       " 'mean_score_time': array([0.00221314, 0.00206809, 0.00166368, 0.00181103, 0.00181093,\n",
       "        0.00115261, 0.00141349]),\n",
       " 'std_score_time': array([0.00039702, 0.00064684, 0.00054896, 0.00040046, 0.0004041 ,\n",
       "        0.00019051, 0.00048525]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001},\n",
       "  {'alpha': 0.001},\n",
       "  {'alpha': 0.01},\n",
       "  {'alpha': 0.1},\n",
       "  {'alpha': 1},\n",
       "  {'alpha': 10},\n",
       "  {'alpha': 100}],\n",
       " 'split0_test_R2': array([-0.75227036, -0.75226505, -0.75221239, -0.75172153, -0.75102824,\n",
       "        -0.73765982, -0.31522661]),\n",
       " 'split1_test_R2': array([-2.16372412, -2.16375035, -2.16401619, -2.16701235, -2.23395292,\n",
       "        -2.27309508, -0.8136881 ]),\n",
       " 'split2_test_R2': array([0.55132424, 0.55132449, 0.55132685, 0.55131771, 0.54942758,\n",
       "        0.51964836, 0.27766698]),\n",
       " 'split3_test_R2': array([-1.0902739 , -1.09019584, -1.08942231, -1.08189061, -1.03888938,\n",
       "        -0.86922205, -0.27927595]),\n",
       " 'split4_test_R2': array([0.65463844, 0.65463738, 0.65462567, 0.65435458, 0.6480507 ,\n",
       "        0.61113776, 0.40679327]),\n",
       " 'mean_test_R2': array([-0.56006114, -0.56004987, -0.55993967, -0.55899044, -0.56527845,\n",
       "        -0.54983817, -0.14474608]),\n",
       " 'std_test_R2': array([1.05834564, 1.05834538, 1.0583444 , 1.05842285, 1.07312832,\n",
       "        1.05816482, 0.44210265]),\n",
       " 'rank_test_R2': array([6, 5, 4, 3, 7, 2, 1]),\n",
       " 'split0_test_MAE': array([-103932.60915656, -103932.29452873, -103929.17103035,\n",
       "        -103900.05663352, -103858.93561346, -103066.01280148,\n",
       "         -78010.18444492]),\n",
       " 'split1_test_MAE': array([-124500.81480183, -124501.84727546, -124512.3087863 ,\n",
       "        -124630.21527679, -127264.50199665, -128804.84823897,\n",
       "         -71373.36815306]),\n",
       " 'split2_test_MAE': array([-446238.63311719, -446238.38710201, -446236.03856133,\n",
       "        -446245.13399502, -448124.99703841, -477742.45699562,\n",
       "        -718409.4416651 ]),\n",
       " 'split3_test_MAE': array([-135409.80795396, -135404.75164082, -135354.64150673,\n",
       "        -134866.7310758 , -132081.07290665, -121089.87225794,\n",
       "         -82872.63752515]),\n",
       " 'split4_test_MAE': array([-275814.59824585, -275815.44293856, -275824.79777533,\n",
       "        -276041.29389368, -281075.73169864, -310555.35751166,\n",
       "        -473750.10807403]),\n",
       " 'mean_test_MAE': array([-217179.29265508, -217178.54469712, -217171.39153201,\n",
       "        -217136.68617496, -218481.04785076, -228251.70956113,\n",
       "        -284883.14797245]),\n",
       " 'std_test_MAE': array([129619.93729636, 129620.47206436, 129625.86260985, 129698.69745913,\n",
       "        130826.66422878, 145646.36610339, 265633.91025593]),\n",
       " 'rank_test_MAE': array([4, 3, 2, 1, 5, 6, 7]),\n",
       " 'split0_test_RMSE': array([-171.50922713, -171.50581035, -171.47164154, -171.10777933,\n",
       "        -167.68198042, -152.70636577, -136.8162029 ]),\n",
       " 'split1_test_RMSE': array([-209.31083546, -209.30904955, -209.29124391, -209.11359178,\n",
       "        -209.25117497, -206.7116679 , -155.68344885]),\n",
       " 'split2_test_RMSE': array([-209.02309241, -209.01961458, -208.98481198, -208.66604104,\n",
       "        -205.67132074, -194.18435928, -203.53341178]),\n",
       " 'split3_test_RMSE': array([-181.53575474, -181.53310502, -181.50652502, -181.24050111,\n",
       "        -178.10218501, -162.29307188, -133.32149305]),\n",
       " 'split4_test_RMSE': array([-195.63315885, -195.62073125, -195.49601731, -194.4161126 ,\n",
       "        -191.29715988, -183.07854643, -192.33415614]),\n",
       " 'mean_test_RMSE': array([-193.40241372, -193.39766215, -193.35004795, -192.90880517,\n",
       "        -190.40076421, -179.79480225, -164.33774255]),\n",
       " 'std_test_RMSE': array([14.98124777, 14.98119203, 14.98069732, 14.99727718, 15.85389287,\n",
       "        19.91207644, 28.68602216]),\n",
       " 'rank_test_RMSE': array([7, 6, 5, 4, 3, 2, 1])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lassoparams = {\n",
    "          \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], \n",
    "          }\n",
    "\n",
    "\n",
    "MyLasso = GridSearchCV(estimator = Lasso(), \n",
    "                      param_grid = Lassoparams,\n",
    "                      scoring = scoring,\n",
    "                      refit= False,      \n",
    "                      cv=CV,\n",
    "                      verbose=2\n",
    "                     )\n",
    "\n",
    "MyLasso.fit(X_train_std, y_train)\n",
    "MyLasso.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>-0.752270</td>\n",
       "      <td>-2.163724</td>\n",
       "      <td>0.551324</td>\n",
       "      <td>-1.090274</td>\n",
       "      <td>...</td>\n",
       "      <td>129619.937296</td>\n",
       "      <td>4</td>\n",
       "      <td>-171.509227</td>\n",
       "      <td>-209.310835</td>\n",
       "      <td>-209.023092</td>\n",
       "      <td>-181.535755</td>\n",
       "      <td>-195.633159</td>\n",
       "      <td>-193.402414</td>\n",
       "      <td>14.981248</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>-0.752265</td>\n",
       "      <td>-2.163750</td>\n",
       "      <td>0.551324</td>\n",
       "      <td>-1.090196</td>\n",
       "      <td>...</td>\n",
       "      <td>129620.472064</td>\n",
       "      <td>3</td>\n",
       "      <td>-171.505810</td>\n",
       "      <td>-209.309050</td>\n",
       "      <td>-209.019615</td>\n",
       "      <td>-181.533105</td>\n",
       "      <td>-195.620731</td>\n",
       "      <td>-193.397662</td>\n",
       "      <td>14.981192</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>-0.752212</td>\n",
       "      <td>-2.164016</td>\n",
       "      <td>0.551327</td>\n",
       "      <td>-1.089422</td>\n",
       "      <td>...</td>\n",
       "      <td>129625.862610</td>\n",
       "      <td>2</td>\n",
       "      <td>-171.471642</td>\n",
       "      <td>-209.291244</td>\n",
       "      <td>-208.984812</td>\n",
       "      <td>-181.506525</td>\n",
       "      <td>-195.496017</td>\n",
       "      <td>-193.350048</td>\n",
       "      <td>14.980697</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>-0.751722</td>\n",
       "      <td>-2.167012</td>\n",
       "      <td>0.551318</td>\n",
       "      <td>-1.081891</td>\n",
       "      <td>...</td>\n",
       "      <td>129698.697459</td>\n",
       "      <td>1</td>\n",
       "      <td>-171.107779</td>\n",
       "      <td>-209.113592</td>\n",
       "      <td>-208.666041</td>\n",
       "      <td>-181.240501</td>\n",
       "      <td>-194.416113</td>\n",
       "      <td>-192.908805</td>\n",
       "      <td>14.997277</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>-0.751028</td>\n",
       "      <td>-2.233953</td>\n",
       "      <td>0.549428</td>\n",
       "      <td>-1.038889</td>\n",
       "      <td>...</td>\n",
       "      <td>130826.664229</td>\n",
       "      <td>5</td>\n",
       "      <td>-167.681980</td>\n",
       "      <td>-209.251175</td>\n",
       "      <td>-205.671321</td>\n",
       "      <td>-178.102185</td>\n",
       "      <td>-191.297160</td>\n",
       "      <td>-190.400764</td>\n",
       "      <td>15.853893</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>-0.737660</td>\n",
       "      <td>-2.273095</td>\n",
       "      <td>0.519648</td>\n",
       "      <td>-0.869222</td>\n",
       "      <td>...</td>\n",
       "      <td>145646.366103</td>\n",
       "      <td>6</td>\n",
       "      <td>-152.706366</td>\n",
       "      <td>-206.711668</td>\n",
       "      <td>-194.184359</td>\n",
       "      <td>-162.293072</td>\n",
       "      <td>-183.078546</td>\n",
       "      <td>-179.794802</td>\n",
       "      <td>19.912076</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>-0.315227</td>\n",
       "      <td>-0.813688</td>\n",
       "      <td>0.277667</td>\n",
       "      <td>-0.279276</td>\n",
       "      <td>...</td>\n",
       "      <td>265633.910256</td>\n",
       "      <td>7</td>\n",
       "      <td>-136.816203</td>\n",
       "      <td>-155.683449</td>\n",
       "      <td>-203.533412</td>\n",
       "      <td>-133.321493</td>\n",
       "      <td>-192.334156</td>\n",
       "      <td>-164.337743</td>\n",
       "      <td>28.686022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.019055      0.001233         0.002213        0.000397      0.0001   \n",
       "1       0.012754      0.002445         0.002068        0.000647       0.001   \n",
       "2       0.010471      0.001470         0.001664        0.000549        0.01   \n",
       "3       0.007165      0.000659         0.001811        0.000400         0.1   \n",
       "4       0.005030      0.000639         0.001811        0.000404           1   \n",
       "5       0.001911      0.000493         0.001153        0.000191          10   \n",
       "6       0.001073      0.000136         0.001413        0.000485         100   \n",
       "\n",
       "              params  split0_test_R2  split1_test_R2  split2_test_R2  \\\n",
       "0  {'alpha': 0.0001}       -0.752270       -2.163724        0.551324   \n",
       "1   {'alpha': 0.001}       -0.752265       -2.163750        0.551324   \n",
       "2    {'alpha': 0.01}       -0.752212       -2.164016        0.551327   \n",
       "3     {'alpha': 0.1}       -0.751722       -2.167012        0.551318   \n",
       "4       {'alpha': 1}       -0.751028       -2.233953        0.549428   \n",
       "5      {'alpha': 10}       -0.737660       -2.273095        0.519648   \n",
       "6     {'alpha': 100}       -0.315227       -0.813688        0.277667   \n",
       "\n",
       "   split3_test_R2  ...   std_test_MAE  rank_test_MAE  split0_test_RMSE  \\\n",
       "0       -1.090274  ...  129619.937296              4       -171.509227   \n",
       "1       -1.090196  ...  129620.472064              3       -171.505810   \n",
       "2       -1.089422  ...  129625.862610              2       -171.471642   \n",
       "3       -1.081891  ...  129698.697459              1       -171.107779   \n",
       "4       -1.038889  ...  130826.664229              5       -167.681980   \n",
       "5       -0.869222  ...  145646.366103              6       -152.706366   \n",
       "6       -0.279276  ...  265633.910256              7       -136.816203   \n",
       "\n",
       "   split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0       -209.310835       -209.023092       -181.535755       -195.633159   \n",
       "1       -209.309050       -209.019615       -181.533105       -195.620731   \n",
       "2       -209.291244       -208.984812       -181.506525       -195.496017   \n",
       "3       -209.113592       -208.666041       -181.240501       -194.416113   \n",
       "4       -209.251175       -205.671321       -178.102185       -191.297160   \n",
       "5       -206.711668       -194.184359       -162.293072       -183.078546   \n",
       "6       -155.683449       -203.533412       -133.321493       -192.334156   \n",
       "\n",
       "   mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0     -193.402414      14.981248               7  \n",
       "1     -193.397662      14.981192               6  \n",
       "2     -193.350048      14.980697               5  \n",
       "3     -192.908805      14.997277               4  \n",
       "4     -190.400764      15.853893               3  \n",
       "5     -179.794802      19.912076               2  \n",
       "6     -164.337743      28.686022               1  \n",
       "\n",
       "[7 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyLassobest=pd.concat([pd.DataFrame(MyLasso.cv_results_)])\n",
    "MyLassobest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6   -0.144746\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyLassobestR2=MyLassobest[MyLassobest['rank_test_R2'].isin([1])]\n",
    "print(MyLassobestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=100; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=300; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=1, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=300; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=3, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=300; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=5, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=100; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=300; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=auto, min_samples_leaf=10, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=300; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=1, n_estimators=500; total time=   0.6s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=3, n_estimators=500; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=5, n_estimators=500; total time=   0.5s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=10; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_features=sqrt, min_samples_leaf=10, n_estimators=500; total time=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02926674, 0.14622631, 0.28993511, 0.84251523, 1.39038439,\n",
       "        0.02320056, 0.10809774, 0.21607585, 0.65443082, 1.08263841,\n",
       "        0.02010546, 0.09833417, 0.19449883, 0.58186026, 0.98778429,\n",
       "        0.01785636, 0.08594537, 0.16899996, 0.4974628 , 0.83163357,\n",
       "        0.01332107, 0.06256709, 0.12539644, 0.36939077, 0.63792777,\n",
       "        0.01100297, 0.05047412, 0.09677515, 0.29083362, 0.52572351,\n",
       "        0.01270466, 0.053935  , 0.10641932, 0.3182929 , 0.53858085,\n",
       "        0.00910277, 0.04175544, 0.08132448, 0.29178987, 0.52603221]),\n",
       " 'std_fit_time': array([1.53464030e-03, 8.57186393e-03, 7.24128471e-03, 1.16775779e-02,\n",
       "        1.59751133e-02, 6.91502210e-04, 1.14715593e-03, 2.09853958e-03,\n",
       "        6.47686640e-03, 1.39133359e-02, 4.89474623e-04, 1.51329001e-03,\n",
       "        1.95904965e-03, 4.66758887e-03, 1.62266328e-02, 7.14071231e-04,\n",
       "        1.53161569e-03, 5.76213744e-03, 5.37905035e-03, 1.25624899e-02,\n",
       "        4.30152250e-04, 7.30049425e-04, 2.80586254e-03, 3.69008546e-03,\n",
       "        3.52280822e-02, 9.46494734e-07, 2.49149378e-03, 7.67388834e-04,\n",
       "        3.50957467e-03, 5.35568346e-02, 9.81725601e-04, 1.79712944e-03,\n",
       "        1.21625965e-03, 2.44715643e-03, 1.45000696e-02, 2.01606807e-04,\n",
       "        6.44358822e-04, 1.72043493e-03, 1.96024477e-02, 7.63041902e-03]),\n",
       " 'mean_score_time': array([0.00251408, 0.00592389, 0.00913849, 0.02485609, 0.03837485,\n",
       "        0.00240612, 0.00500207, 0.00800309, 0.02098784, 0.03170691,\n",
       "        0.00260053, 0.00490203, 0.00840406, 0.01940436, 0.0312407 ,\n",
       "        0.00261068, 0.00500345, 0.00720863, 0.01751528, 0.03002672,\n",
       "        0.00260038, 0.00570502, 0.0098927 , 0.02450643, 0.03964458,\n",
       "        0.00280051, 0.00521832, 0.00870342, 0.02032351, 0.03379192,\n",
       "        0.00300069, 0.00600166, 0.00912623, 0.0236877 , 0.03423138,\n",
       "        0.00260057, 0.0042016 , 0.00720143, 0.01995716, 0.03435836]),\n",
       " 'std_score_time': array([4.48906171e-04, 3.34485737e-04, 2.53767100e-04, 4.04414278e-04,\n",
       "        4.66443619e-04, 4.90483819e-04, 1.36878015e-06, 8.86968386e-07,\n",
       "        1.98557290e-03, 7.43571333e-04, 4.90057163e-04, 1.98913042e-04,\n",
       "        5.82670490e-04, 3.76470392e-04, 4.77832994e-04, 4.97503634e-04,\n",
       "        4.50352438e-06, 3.97072222e-04, 4.35837682e-04, 3.26210512e-03,\n",
       "        4.89940316e-04, 4.02122224e-04, 6.45787220e-04, 1.00190640e-03,\n",
       "        1.64388462e-03, 4.00209469e-04, 3.92623019e-04, 1.07879336e-03,\n",
       "        1.26705103e-03, 4.67851860e-03, 3.81469727e-07, 1.78416128e-07,\n",
       "        4.92059661e-04, 6.45027559e-04, 2.73538957e-03, 4.90096043e-04,\n",
       "        3.99613789e-04, 9.80104497e-04, 2.95277071e-03, 3.65660134e-03]),\n",
       " 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 50, 100, 300, 500, 10, 50, 100, 300, 500, 10, 50,\n",
       "                    100, 300, 500, 10, 50, 100, 300, 500, 10, 50, 100, 300,\n",
       "                    500, 10, 50, 100, 300, 500, 10, 50, 100, 300, 500, 10,\n",
       "                    50, 100, 300, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_features': 'auto',\n",
       "   'min_samples_leaf': 1,\n",
       "   'n_estimators': 10},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 300},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 500},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 10},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 50},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 100},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 300},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 500},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 300},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 5, 'n_estimators': 500},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 300},\n",
       "  {'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 500},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 10},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 50},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 300},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 500},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 10},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 50},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 100},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 300},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 3, 'n_estimators': 500},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 10},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 50},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 300},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 5, 'n_estimators': 500},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 10},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 50},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 100},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 300},\n",
       "  {'max_features': 'sqrt', 'min_samples_leaf': 10, 'n_estimators': 500}],\n",
       " 'split0_test_R2': array([ 0.54603829, -0.44805675, -0.36042695, -0.22158336, -0.1357412 ,\n",
       "        -1.59418885, -1.46832626, -2.43412198, -2.15970246, -2.35672856,\n",
       "        -0.10092651, -0.19641273, -0.41933383, -0.54753816, -0.31326164,\n",
       "        -0.00627535, -0.02346125, -0.05325844, -0.11169625, -0.00996056,\n",
       "         0.4096256 ,  0.66725501,  0.59810368,  0.58931771,  0.57719635,\n",
       "         0.41175783,  0.60234955,  0.51492668,  0.35697223,  0.43751102,\n",
       "         0.43974709,  0.38060543,  0.43403234,  0.4589458 ,  0.43403542,\n",
       "         0.24290791,  0.48913209,  0.46627679,  0.45585811,  0.46171088]),\n",
       " 'split1_test_R2': array([-0.24036956, -0.31462781, -0.3504366 , -0.35999103, -0.44572155,\n",
       "         0.0874433 , -0.23301786, -0.0976353 , -0.05688884, -0.06476103,\n",
       "        -0.14901428, -0.27173338, -0.28869915, -0.18705592, -0.25204026,\n",
       "        -0.68005233, -0.90303813, -0.76706107, -0.83220498, -0.75491713,\n",
       "         0.22867183,  0.16327224,  0.24118113,  0.21935992,  0.27224851,\n",
       "         0.24504515,  0.02016112,  0.19498208,  0.17515279,  0.10605999,\n",
       "        -0.44296679, -0.270492  ,  0.07225001,  0.04824151,  0.0291426 ,\n",
       "         0.2745667 , -0.04353346,  0.0228345 , -0.03806723, -0.05626158]),\n",
       " 'split2_test_R2': array([0.36318184, 0.44172802, 0.45476429, 0.44514904, 0.43685626,\n",
       "        0.45164283, 0.42162288, 0.42993228, 0.44721535, 0.43277885,\n",
       "        0.42376333, 0.37575729, 0.39748767, 0.39265589, 0.3836338 ,\n",
       "        0.28961352, 0.30224973, 0.29825926, 0.31079324, 0.30871171,\n",
       "        0.55688801, 0.47434825, 0.46178758, 0.49513501, 0.49006579,\n",
       "        0.38433028, 0.36930803, 0.39375834, 0.35983677, 0.37798104,\n",
       "        0.26555564, 0.27285894, 0.30586691, 0.29814405, 0.30886843,\n",
       "        0.19051817, 0.1942021 , 0.22672421, 0.22569432, 0.22728126]),\n",
       " 'split3_test_R2': array([-0.86449958, -0.66572865, -0.45231864, -0.89765443, -0.82930061,\n",
       "        -1.5617651 , -1.01360126, -1.02290585, -1.12892283, -1.05142118,\n",
       "         0.25690461,  0.02439777,  0.02289273, -0.03905994,  0.10726497,\n",
       "         0.37458111,  0.43242685,  0.46404727,  0.45664439,  0.465588  ,\n",
       "         0.30289481,  0.19359263, -0.05032717,  0.13680443,  0.08805195,\n",
       "        -0.0494412 ,  0.32086135,  0.26520735,  0.31222057,  0.29857873,\n",
       "         0.21441   ,  0.23674845,  0.34644887,  0.42691583,  0.40188841,\n",
       "         0.4281035 ,  0.47851623,  0.48212128,  0.45274855,  0.48432734]),\n",
       " 'split4_test_R2': array([0.36678   , 0.60506622, 0.66910303, 0.64573179, 0.65220269,\n",
       "        0.55889694, 0.57113557, 0.55780363, 0.54862526, 0.54077742,\n",
       "        0.34987777, 0.38922595, 0.37726995, 0.36887769, 0.37017137,\n",
       "        0.29012816, 0.29559783, 0.29963251, 0.29919844, 0.29551852,\n",
       "        0.56993874, 0.76145556, 0.71684655, 0.75690544, 0.77430307,\n",
       "        0.61646537, 0.45239047, 0.49946921, 0.50440134, 0.49346587,\n",
       "        0.33655543, 0.35086707, 0.38637878, 0.37976307, 0.36313331,\n",
       "        0.19636502, 0.24313884, 0.26266909, 0.27369434, 0.25778233]),\n",
       " 'mean_test_R2': array([ 0.0342262 , -0.07632379, -0.00786298, -0.0776696 , -0.06434088,\n",
       "        -0.41159418, -0.34443739, -0.51338544, -0.4699347 , -0.4998709 ,\n",
       "         0.15612098,  0.06424698,  0.01792347, -0.00242409,  0.05915365,\n",
       "         0.05359902,  0.020755  ,  0.04832391,  0.02454697,  0.06098811,\n",
       "         0.4136038 ,  0.45198474,  0.39351835,  0.4395045 ,  0.44037313,\n",
       "         0.32163149,  0.3530141 ,  0.37366873,  0.34171674,  0.34271933,\n",
       "         0.16266027,  0.19411758,  0.30899538,  0.32240205,  0.30741364,\n",
       "         0.26649226,  0.27229116,  0.29212518,  0.27398562,  0.27496804]),\n",
       " 'std_test_R2': array([0.522277  , 0.50498362, 0.47148825, 0.56025719, 0.5477857 ,\n",
       "        0.96514174, 0.7935292 , 1.10986327, 1.03332627, 1.08574704,\n",
       "        0.23601373, 0.27751189, 0.33419603, 0.35398691, 0.29660374,\n",
       "        0.38897497, 0.48571605, 0.44127571, 0.46832994, 0.43607514,\n",
       "        0.13523544, 0.24196487, 0.2724931 , 0.23081294, 0.23878662,\n",
       "        0.22024592, 0.19190322, 0.126393  , 0.10549021, 0.13484021,\n",
       "        0.31211096, 0.23800327, 0.12576435, 0.14738389, 0.14525848,\n",
       "        0.0865211 , 0.19811195, 0.16975849, 0.18151744, 0.19544137]),\n",
       " 'rank_test_R2': array([27, 34, 32, 35, 33, 37, 36, 40, 38, 39, 21, 22, 30, 31, 24, 25, 29,\n",
       "        26, 28, 23,  4,  1,  5,  3,  2, 11,  7,  6,  9,  8, 20, 19, 12, 10,\n",
       "        13, 18, 17, 14, 16, 15]),\n",
       " 'split0_test_MAE': array([ -26925.88225385,  -85888.75336839,  -80691.15702204,\n",
       "         -72455.91164349,  -67364.34600872, -153869.41561299,\n",
       "        -146404.11371378, -203688.46393413, -187411.78839503,\n",
       "        -199098.01945426,  -65299.37812293,  -70962.96299534,\n",
       "         -84185.10769867,  -91789.30539814,  -77893.63564256,\n",
       "         -59685.32330275,  -60704.67276888,  -62472.0366724 ,\n",
       "         -65938.16489487,  -59903.90445474,  -35016.94357567,\n",
       "         -19736.14105936,  -23837.72169827,  -24358.84491453,\n",
       "         -25077.80034893,  -34890.47400153,  -23585.88623003,\n",
       "         -28771.20834076,  -38139.97855753,  -33362.97202112,\n",
       "         -33230.34406304,  -36738.21976768,  -33569.30363364,\n",
       "         -32091.60875031,  -33569.12088792,  -44905.48842049,\n",
       "         -30301.16587698,  -31656.78519557,  -32274.74898999,\n",
       "         -31927.60313418]),\n",
       " 'split1_test_MAE': array([-48811.78475742, -51734.0409559 , -53143.21072236, -53519.20261159,\n",
       "        -56892.92249329, -35911.49197363, -48522.47626455, -43194.8185995 ,\n",
       "        -41591.33875973, -41901.13004716, -45216.71583653, -50046.03316762,\n",
       "        -50713.68043793, -46713.75367566, -49271.05748636, -66114.45134744,\n",
       "        -74889.5256544 , -69538.47266392, -72102.05600881, -69060.57706461,\n",
       "        -30353.77989451, -32927.42489886, -29861.50628132, -30720.22812392,\n",
       "        -28638.92378887, -29709.4468695 , -38559.22151659, -31679.55952085,\n",
       "        -32459.89427343, -35178.87633181, -56784.51534087, -49997.18163871,\n",
       "        -36509.38769477, -37454.18457915, -38205.77671722, -28547.69681088,\n",
       "        -41065.76962519, -38454.01700001, -40850.65947388, -41566.65471653]),\n",
       " 'split2_test_MAE': array([-633359.08590991, -555239.55519281, -542274.095623  ,\n",
       "        -551837.11803624, -560084.85073779, -545378.59632702,\n",
       "        -575235.48755938, -566971.21533098, -549782.02209887,\n",
       "        -564140.10958953, -573106.663589  , -620851.94385406,\n",
       "        -599239.59871291, -604045.13185162, -613018.20924157,\n",
       "        -706527.79555055, -693960.21851753, -697929.01106155,\n",
       "        -685463.12108722, -687533.34236763, -440705.09242188,\n",
       "        -522796.50475393, -535288.95001597, -502122.65818235,\n",
       "        -507164.34415637, -612325.52185642, -627266.17203891,\n",
       "        -602948.66386416, -636685.98124677, -618640.2711947 ,\n",
       "        -730454.99835471, -723191.36635364, -690362.69161883,\n",
       "        -698043.5954929 , -687377.47087848, -805084.87851568,\n",
       "        -801420.95430019, -769075.49702642, -770099.79237607,\n",
       "        -768521.48084398]),\n",
       " 'split3_test_MAE': array([-120783.94646873, -107907.38801688,  -94082.49724784,\n",
       "        -122931.747299  , -118503.72585378, -165953.42915493,\n",
       "        -130442.88621769, -131045.6457551 , -137913.52026966,\n",
       "        -132892.89466298,  -48138.38259413,  -63200.38304381,\n",
       "         -63297.88097426,  -67311.22979986,  -57832.17175469,\n",
       "         -40515.19343581,  -36767.89486092,  -34719.49622225,\n",
       "         -35199.06121437,  -34619.68605367,  -45159.09620883,\n",
       "         -52239.78875118,  -68041.13127787,  -55918.57889386,\n",
       "         -59076.80826285,  -67983.73730919,  -43995.20791265,\n",
       "         -47600.52356243,  -44554.96515422,  -45438.6959224 ,\n",
       "         -50891.22096247,  -49444.11641305,  -42337.62556525,\n",
       "         -37124.90407877,  -38746.20231797,  -37047.96555285,\n",
       "         -33782.18393067,  -33548.64524458,  -35451.43708199,\n",
       "         -33405.73497494]),\n",
       " 'split4_test_MAE': array([-505705.72621569, -315404.24167183, -264262.80596825,\n",
       "        -282927.67312565, -277759.84739406, -352276.2179951 ,\n",
       "        -342502.13108195, -353149.36133184, -360479.44050498,\n",
       "        -366746.92504712, -519204.28309674, -487779.81880186,\n",
       "        -497328.18293744, -504030.46199487, -502997.29088531,\n",
       "        -566921.85496886, -562553.63804926, -559331.43601851,\n",
       "        -559678.09868988, -562616.97289602, -343457.95084703,\n",
       "        -190507.70983402, -226133.60777783, -194141.55050528,\n",
       "        -180247.35886279, -306300.5892256 , -437335.01051411,\n",
       "        -399736.72510967, -395797.80017915, -404531.14372959,\n",
       "        -529843.84536096, -518414.20240688, -490053.64120369,\n",
       "        -495337.1147544 , -508618.06832898, -641803.50205315,\n",
       "        -604448.72736028, -588851.36892987, -580046.32198407,\n",
       "        -592754.06551755]),\n",
       " 'mean_test_MAE': array([-267117.28512112, -223234.79584116, -206890.7533167 ,\n",
       "        -216734.33054319, -216121.13849753, -250677.83021274,\n",
       "        -248621.41896747, -259609.90099031, -255435.62200565,\n",
       "        -260955.81576021, -250193.08464786, -258568.22837254,\n",
       "        -258952.89015224, -262777.97654403, -260202.4730021 ,\n",
       "        -287952.92372108, -285775.1899702 , -284798.09052772,\n",
       "        -283676.10037903, -282746.89656733, -178938.57258958,\n",
       "        -163641.51385947, -176632.58341025, -161452.37212399,\n",
       "        -160041.04708396, -210241.95385245, -234148.29964246,\n",
       "        -222147.33607957, -229527.72388222, -227430.39183992,\n",
       "        -280240.98481641, -275557.01731599, -258566.52994324,\n",
       "        -260010.28153111, -261303.32782611, -311477.90627061,\n",
       "        -302203.76021866, -292317.26267929, -291744.5919812 ,\n",
       "        -293635.10783744]),\n",
       " 'std_test_MAE': array([252119.07836199, 189894.29811424, 183337.87732928, 185973.00963154,\n",
       "        189273.20629568, 178799.01971816, 189707.38935336, 184234.67150731,\n",
       "        179912.24019796, 185107.49789545, 242349.87165712, 245207.37353063,\n",
       "        238665.47848237, 240330.67060808, 245809.10495218, 288295.82845512,\n",
       "        282968.35900717, 284376.72053916, 279829.99727451, 282512.75411969,\n",
       "        176791.49354327, 189694.16105995, 193785.89372998, 181189.25816806,\n",
       "        182525.75265018, 225599.63866375, 250829.15173119, 236933.12676152,\n",
       "        246212.71486686, 241724.48450991, 292760.17849223, 289273.16649719,\n",
       "        278108.71013924, 282279.27013862, 280667.35352827, 340348.3486147 ,\n",
       "        333089.78987262, 320806.02225817, 318716.21587441, 320854.44291396]),\n",
       " 'rank_test_MAE': array([28, 11,  6,  9,  8, 17, 15, 22, 18, 25, 16, 20, 21, 27, 24, 35, 34,\n",
       "        33, 32, 31,  5,  3,  4,  2,  1,  7, 14, 10, 13, 12, 30, 29, 19, 23,\n",
       "        26, 40, 39, 37, 36, 38]),\n",
       " 'split0_test_RMSE': array([ -85.56188987, -101.5265489 , -103.96630837,  -98.181221  ,\n",
       "         -99.31286775, -117.16076469, -111.15378052, -120.24050672,\n",
       "        -117.32831132, -119.20344151, -109.39356748, -101.72148412,\n",
       "        -103.85194319, -107.5757133 , -103.63019632, -107.52016639,\n",
       "        -110.10218574, -107.6531801 , -109.62959014, -107.09027838,\n",
       "         -92.05705727,  -73.76045639,  -78.90480396,  -82.10663128,\n",
       "         -81.44508943,  -92.53353071,  -80.99079653,  -86.79713382,\n",
       "         -91.12601301,  -88.57465744,  -93.81435816,  -97.22108657,\n",
       "         -90.78318398,  -91.60676398,  -92.29220714, -110.71863089,\n",
       "         -96.14911812,  -97.88643579, -100.1435815 ,  -98.29132994]),\n",
       " 'split1_test_RMSE': array([ -99.95937665, -101.44926043, -102.01415753, -101.49498784,\n",
       "        -101.37082382,  -95.77573936, -104.73336966, -101.75704031,\n",
       "         -99.79387719, -100.37418864, -104.42236211, -107.62221474,\n",
       "        -109.31360837, -106.39355794, -108.14170755, -114.45497444,\n",
       "        -122.8912219 , -120.47907611, -121.281995  , -121.4300012 ,\n",
       "         -90.39832856,  -92.04779317,  -89.61686885,  -90.03319449,\n",
       "         -89.09092511,  -98.73885663,  -99.23372596,  -98.44994207,\n",
       "         -98.24363411, -100.28777436, -124.12483905, -114.11418515,\n",
       "        -107.33420273, -105.31809528, -107.45193854, -103.66604151,\n",
       "        -116.63303266, -114.51639488, -116.69394147, -118.05355739]),\n",
       " 'split2_test_RMSE': array([-175.14571806, -165.94087037, -167.2469864 , -166.24397885,\n",
       "        -165.93151862, -172.2042253 , -165.45762122, -165.79188191,\n",
       "        -163.75040645, -163.75552749, -168.42253571, -172.56451877,\n",
       "        -171.8415505 , -170.94384907, -171.57658348, -177.19003344,\n",
       "        -175.11818287, -175.71517241, -176.79385839, -176.29659918,\n",
       "        -164.99183921, -162.14888928, -164.10029745, -159.91363925,\n",
       "        -160.79905816, -169.30418999, -173.84123884, -171.34917333,\n",
       "        -173.03851762, -171.30501745, -176.32969436, -177.81705075,\n",
       "        -176.53788458, -176.38095241, -175.45140015, -186.71636059,\n",
       "        -189.59920426, -184.31282757, -184.88331255, -185.12287068]),\n",
       " 'split3_test_RMSE': array([-110.90246696, -103.32465131, -101.10025988, -106.7456382 ,\n",
       "        -106.8912654 , -108.08236227, -102.67754346, -104.09916947,\n",
       "        -104.67667322, -103.78971767,  -90.78520506,  -94.69072085,\n",
       "         -95.88902369,  -95.86738202,  -93.89368528,  -96.85345253,\n",
       "         -93.21979566,  -89.20424804,  -90.38890379,  -90.11000162,\n",
       "        -101.52487665,  -91.32905947,  -99.93654641,  -93.60848448,\n",
       "         -93.86655272,  -99.61563517,  -93.10318022,  -93.89290779,\n",
       "         -91.89978544,  -92.78153229, -101.59716523,  -96.33686015,\n",
       "         -93.9515643 ,  -92.14070057,  -92.78451441, -100.34838857,\n",
       "         -94.35904654,  -95.77138978,  -96.05869736,  -95.65496501]),\n",
       " 'split4_test_RMSE': array([-150.60519027, -132.69293717, -132.47034159, -134.62283466,\n",
       "        -131.60747195, -153.46325693, -148.06064904, -155.55768339,\n",
       "        -152.54647317, -150.71055577, -174.23168293, -173.4432268 ,\n",
       "        -172.34371625, -173.373257  , -174.06892681, -156.30045128,\n",
       "        -176.44461915, -173.79008939, -174.36192134, -173.38285505,\n",
       "        -139.20416372, -130.78611947, -130.10885354, -124.2188264 ,\n",
       "        -128.55825363, -145.92841644, -157.59136966, -150.1690656 ,\n",
       "        -153.07170092, -150.731291  , -169.10574492, -161.55560965,\n",
       "        -161.01794707, -161.4398257 , -161.72699091, -173.89106136,\n",
       "        -169.538474  , -168.74744066, -164.36768651, -168.08738491]),\n",
       " 'mean_test_RMSE': array([-124.43492836, -120.98685363, -121.35961075, -121.45773211,\n",
       "        -121.02278951, -129.33726971, -126.41659278, -129.48925636,\n",
       "        -127.61914827, -127.56668622, -129.45107066, -130.00843306,\n",
       "        -130.6479684 , -130.83075186, -130.26221989, -130.46381562,\n",
       "        -135.55520106, -133.36835321, -134.49125373, -133.66194709,\n",
       "        -117.63525308, -110.01446356, -112.53347404, -109.97615518,\n",
       "        -110.75197581, -121.22412579, -120.95206224, -120.13164452,\n",
       "        -121.47593022, -120.73605451, -132.99436034, -129.40895846,\n",
       "        -125.92495653, -125.37726759, -125.94141023, -135.06809658,\n",
       "        -133.25577512, -132.24689774, -132.42944388, -133.04202159]),\n",
       " 'std_test_RMSE': array([33.31594232, 25.41759395, 25.75389062, 25.82975284, 25.24301838,\n",
       "        28.79601995, 25.53164757, 26.44509481, 25.81992851, 25.37711942,\n",
       "        34.77892227, 35.34469348, 34.10810085, 33.99804643, 35.06324647,\n",
       "        30.86493712, 34.16926381, 35.22794808, 34.97651955, 35.06539639,\n",
       "        29.54150485, 32.04920792, 30.92821389, 28.77130058, 29.78249889,\n",
       "        30.71696271, 37.37339419, 34.04479124, 34.61964339, 33.7368557 ,\n",
       "        34.00443533, 33.88363456, 35.76603022, 36.19218329, 35.51156448,\n",
       "        37.30739722, 39.13359503, 37.06379754, 35.73310462, 36.79850258]),\n",
       " 'rank_test_RMSE': array([15,  9, 12, 13, 10, 22, 19, 25, 21, 20, 24, 26, 29, 30, 27, 28, 40,\n",
       "        36, 38, 37,  5,  2,  4,  1,  3, 11,  8,  6, 14,  7, 33, 23, 17, 16,\n",
       "        18, 39, 35, 31, 32, 34])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Randomparams = {\n",
    "    'n_estimators' : [10,50,100,300,500],\n",
    "    'min_samples_leaf' : [1,3,5,10], \n",
    "    'max_features': ['auto', 'sqrt'] \n",
    "}\n",
    "MyRandom = GridSearchCV(RandomForestRegressor(),\n",
    "                        param_grid = Randomparams,\n",
    "                        scoring=scoring,\n",
    "                        refit=False,\n",
    "                        verbose=2,\n",
    "                        cv=CV)\n",
    "\n",
    "MyRandom.fit(X_train_std, y_train)\n",
    "MyRandom.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029267</td>\n",
       "      <td>1.534640e-03</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>4.489062e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.546038</td>\n",
       "      <td>-0.240370</td>\n",
       "      <td>...</td>\n",
       "      <td>252119.078362</td>\n",
       "      <td>28</td>\n",
       "      <td>-85.561890</td>\n",
       "      <td>-99.959377</td>\n",
       "      <td>-175.145718</td>\n",
       "      <td>-110.902467</td>\n",
       "      <td>-150.605190</td>\n",
       "      <td>-124.434928</td>\n",
       "      <td>33.315942</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146226</td>\n",
       "      <td>8.571864e-03</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>3.344857e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>-0.448057</td>\n",
       "      <td>-0.314628</td>\n",
       "      <td>...</td>\n",
       "      <td>189894.298114</td>\n",
       "      <td>11</td>\n",
       "      <td>-101.526549</td>\n",
       "      <td>-101.449260</td>\n",
       "      <td>-165.940870</td>\n",
       "      <td>-103.324651</td>\n",
       "      <td>-132.692937</td>\n",
       "      <td>-120.986854</td>\n",
       "      <td>25.417594</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.289935</td>\n",
       "      <td>7.241285e-03</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>2.537671e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>-0.360427</td>\n",
       "      <td>-0.350437</td>\n",
       "      <td>...</td>\n",
       "      <td>183337.877329</td>\n",
       "      <td>6</td>\n",
       "      <td>-103.966308</td>\n",
       "      <td>-102.014158</td>\n",
       "      <td>-167.246986</td>\n",
       "      <td>-101.100260</td>\n",
       "      <td>-132.470342</td>\n",
       "      <td>-121.359611</td>\n",
       "      <td>25.753891</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.842515</td>\n",
       "      <td>1.167758e-02</td>\n",
       "      <td>0.024856</td>\n",
       "      <td>4.044143e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>-0.221583</td>\n",
       "      <td>-0.359991</td>\n",
       "      <td>...</td>\n",
       "      <td>185973.009632</td>\n",
       "      <td>9</td>\n",
       "      <td>-98.181221</td>\n",
       "      <td>-101.494988</td>\n",
       "      <td>-166.243979</td>\n",
       "      <td>-106.745638</td>\n",
       "      <td>-134.622835</td>\n",
       "      <td>-121.457732</td>\n",
       "      <td>25.829753</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.390384</td>\n",
       "      <td>1.597511e-02</td>\n",
       "      <td>0.038375</td>\n",
       "      <td>4.664436e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>-0.135741</td>\n",
       "      <td>-0.445722</td>\n",
       "      <td>...</td>\n",
       "      <td>189273.206296</td>\n",
       "      <td>8</td>\n",
       "      <td>-99.312868</td>\n",
       "      <td>-101.370824</td>\n",
       "      <td>-165.931519</td>\n",
       "      <td>-106.891265</td>\n",
       "      <td>-131.607472</td>\n",
       "      <td>-121.022790</td>\n",
       "      <td>25.243018</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.023201</td>\n",
       "      <td>6.915022e-04</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>4.904838e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>-1.594189</td>\n",
       "      <td>0.087443</td>\n",
       "      <td>...</td>\n",
       "      <td>178799.019718</td>\n",
       "      <td>17</td>\n",
       "      <td>-117.160765</td>\n",
       "      <td>-95.775739</td>\n",
       "      <td>-172.204225</td>\n",
       "      <td>-108.082362</td>\n",
       "      <td>-153.463257</td>\n",
       "      <td>-129.337270</td>\n",
       "      <td>28.796020</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.108098</td>\n",
       "      <td>1.147156e-03</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>1.368780e-06</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>-1.468326</td>\n",
       "      <td>-0.233018</td>\n",
       "      <td>...</td>\n",
       "      <td>189707.389353</td>\n",
       "      <td>15</td>\n",
       "      <td>-111.153781</td>\n",
       "      <td>-104.733370</td>\n",
       "      <td>-165.457621</td>\n",
       "      <td>-102.677543</td>\n",
       "      <td>-148.060649</td>\n",
       "      <td>-126.416593</td>\n",
       "      <td>25.531648</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.216076</td>\n",
       "      <td>2.098540e-03</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>8.869684e-07</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>-2.434122</td>\n",
       "      <td>-0.097635</td>\n",
       "      <td>...</td>\n",
       "      <td>184234.671507</td>\n",
       "      <td>22</td>\n",
       "      <td>-120.240507</td>\n",
       "      <td>-101.757040</td>\n",
       "      <td>-165.791882</td>\n",
       "      <td>-104.099169</td>\n",
       "      <td>-155.557683</td>\n",
       "      <td>-129.489256</td>\n",
       "      <td>26.445095</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.654431</td>\n",
       "      <td>6.476866e-03</td>\n",
       "      <td>0.020988</td>\n",
       "      <td>1.985573e-03</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>-2.159702</td>\n",
       "      <td>-0.056889</td>\n",
       "      <td>...</td>\n",
       "      <td>179912.240198</td>\n",
       "      <td>18</td>\n",
       "      <td>-117.328311</td>\n",
       "      <td>-99.793877</td>\n",
       "      <td>-163.750406</td>\n",
       "      <td>-104.676673</td>\n",
       "      <td>-152.546473</td>\n",
       "      <td>-127.619148</td>\n",
       "      <td>25.819929</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.082638</td>\n",
       "      <td>1.391334e-02</td>\n",
       "      <td>0.031707</td>\n",
       "      <td>7.435713e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 3...</td>\n",
       "      <td>-2.356729</td>\n",
       "      <td>-0.064761</td>\n",
       "      <td>...</td>\n",
       "      <td>185107.497895</td>\n",
       "      <td>25</td>\n",
       "      <td>-119.203442</td>\n",
       "      <td>-100.374189</td>\n",
       "      <td>-163.755527</td>\n",
       "      <td>-103.789718</td>\n",
       "      <td>-150.710556</td>\n",
       "      <td>-127.566686</td>\n",
       "      <td>25.377119</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.020105</td>\n",
       "      <td>4.894746e-04</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>4.900572e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>-0.100927</td>\n",
       "      <td>-0.149014</td>\n",
       "      <td>...</td>\n",
       "      <td>242349.871657</td>\n",
       "      <td>16</td>\n",
       "      <td>-109.393567</td>\n",
       "      <td>-104.422362</td>\n",
       "      <td>-168.422536</td>\n",
       "      <td>-90.785205</td>\n",
       "      <td>-174.231683</td>\n",
       "      <td>-129.451071</td>\n",
       "      <td>34.778922</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.098334</td>\n",
       "      <td>1.513290e-03</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>1.989130e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>-0.196413</td>\n",
       "      <td>-0.271733</td>\n",
       "      <td>...</td>\n",
       "      <td>245207.373531</td>\n",
       "      <td>20</td>\n",
       "      <td>-101.721484</td>\n",
       "      <td>-107.622215</td>\n",
       "      <td>-172.564519</td>\n",
       "      <td>-94.690721</td>\n",
       "      <td>-173.443227</td>\n",
       "      <td>-130.008433</td>\n",
       "      <td>35.344693</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.194499</td>\n",
       "      <td>1.959050e-03</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>5.826705e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>-0.419334</td>\n",
       "      <td>-0.288699</td>\n",
       "      <td>...</td>\n",
       "      <td>238665.478482</td>\n",
       "      <td>21</td>\n",
       "      <td>-103.851943</td>\n",
       "      <td>-109.313608</td>\n",
       "      <td>-171.841551</td>\n",
       "      <td>-95.889024</td>\n",
       "      <td>-172.343716</td>\n",
       "      <td>-130.647968</td>\n",
       "      <td>34.108101</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.581860</td>\n",
       "      <td>4.667589e-03</td>\n",
       "      <td>0.019404</td>\n",
       "      <td>3.764704e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>-0.547538</td>\n",
       "      <td>-0.187056</td>\n",
       "      <td>...</td>\n",
       "      <td>240330.670608</td>\n",
       "      <td>27</td>\n",
       "      <td>-107.575713</td>\n",
       "      <td>-106.393558</td>\n",
       "      <td>-170.943849</td>\n",
       "      <td>-95.867382</td>\n",
       "      <td>-173.373257</td>\n",
       "      <td>-130.830752</td>\n",
       "      <td>33.998046</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.987784</td>\n",
       "      <td>1.622663e-02</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>4.778330e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 5...</td>\n",
       "      <td>-0.313262</td>\n",
       "      <td>-0.252040</td>\n",
       "      <td>...</td>\n",
       "      <td>245809.104952</td>\n",
       "      <td>24</td>\n",
       "      <td>-103.630196</td>\n",
       "      <td>-108.141708</td>\n",
       "      <td>-171.576583</td>\n",
       "      <td>-93.893685</td>\n",
       "      <td>-174.068927</td>\n",
       "      <td>-130.262220</td>\n",
       "      <td>35.063246</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.017856</td>\n",
       "      <td>7.140712e-04</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>4.975036e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>-0.006275</td>\n",
       "      <td>-0.680052</td>\n",
       "      <td>...</td>\n",
       "      <td>288295.828455</td>\n",
       "      <td>35</td>\n",
       "      <td>-107.520166</td>\n",
       "      <td>-114.454974</td>\n",
       "      <td>-177.190033</td>\n",
       "      <td>-96.853453</td>\n",
       "      <td>-156.300451</td>\n",
       "      <td>-130.463816</td>\n",
       "      <td>30.864937</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.085945</td>\n",
       "      <td>1.531616e-03</td>\n",
       "      <td>0.005003</td>\n",
       "      <td>4.503524e-06</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>-0.023461</td>\n",
       "      <td>-0.903038</td>\n",
       "      <td>...</td>\n",
       "      <td>282968.359007</td>\n",
       "      <td>34</td>\n",
       "      <td>-110.102186</td>\n",
       "      <td>-122.891222</td>\n",
       "      <td>-175.118183</td>\n",
       "      <td>-93.219796</td>\n",
       "      <td>-176.444619</td>\n",
       "      <td>-135.555201</td>\n",
       "      <td>34.169264</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.169000</td>\n",
       "      <td>5.762137e-03</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>3.970722e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>-0.053258</td>\n",
       "      <td>-0.767061</td>\n",
       "      <td>...</td>\n",
       "      <td>284376.720539</td>\n",
       "      <td>33</td>\n",
       "      <td>-107.653180</td>\n",
       "      <td>-120.479076</td>\n",
       "      <td>-175.715172</td>\n",
       "      <td>-89.204248</td>\n",
       "      <td>-173.790089</td>\n",
       "      <td>-133.368353</td>\n",
       "      <td>35.227948</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.497463</td>\n",
       "      <td>5.379050e-03</td>\n",
       "      <td>0.017515</td>\n",
       "      <td>4.358377e-04</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>-0.111696</td>\n",
       "      <td>-0.832205</td>\n",
       "      <td>...</td>\n",
       "      <td>279829.997275</td>\n",
       "      <td>32</td>\n",
       "      <td>-109.629590</td>\n",
       "      <td>-121.281995</td>\n",
       "      <td>-176.793858</td>\n",
       "      <td>-90.388904</td>\n",
       "      <td>-174.361921</td>\n",
       "      <td>-134.491254</td>\n",
       "      <td>34.976520</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.831634</td>\n",
       "      <td>1.256249e-02</td>\n",
       "      <td>0.030027</td>\n",
       "      <td>3.262105e-03</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'auto', 'min_samples_leaf': 1...</td>\n",
       "      <td>-0.009961</td>\n",
       "      <td>-0.754917</td>\n",
       "      <td>...</td>\n",
       "      <td>282512.754120</td>\n",
       "      <td>31</td>\n",
       "      <td>-107.090278</td>\n",
       "      <td>-121.430001</td>\n",
       "      <td>-176.296599</td>\n",
       "      <td>-90.110002</td>\n",
       "      <td>-173.382855</td>\n",
       "      <td>-133.661947</td>\n",
       "      <td>35.065396</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.013321</td>\n",
       "      <td>4.301522e-04</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>4.899403e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.409626</td>\n",
       "      <td>0.228672</td>\n",
       "      <td>...</td>\n",
       "      <td>176791.493543</td>\n",
       "      <td>5</td>\n",
       "      <td>-92.057057</td>\n",
       "      <td>-90.398329</td>\n",
       "      <td>-164.991839</td>\n",
       "      <td>-101.524877</td>\n",
       "      <td>-139.204164</td>\n",
       "      <td>-117.635253</td>\n",
       "      <td>29.541505</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.062567</td>\n",
       "      <td>7.300494e-04</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>4.021222e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.667255</td>\n",
       "      <td>0.163272</td>\n",
       "      <td>...</td>\n",
       "      <td>189694.161060</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.760456</td>\n",
       "      <td>-92.047793</td>\n",
       "      <td>-162.148889</td>\n",
       "      <td>-91.329059</td>\n",
       "      <td>-130.786119</td>\n",
       "      <td>-110.014464</td>\n",
       "      <td>32.049208</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.125396</td>\n",
       "      <td>2.805863e-03</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>6.457872e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.598104</td>\n",
       "      <td>0.241181</td>\n",
       "      <td>...</td>\n",
       "      <td>193785.893730</td>\n",
       "      <td>4</td>\n",
       "      <td>-78.904804</td>\n",
       "      <td>-89.616869</td>\n",
       "      <td>-164.100297</td>\n",
       "      <td>-99.936546</td>\n",
       "      <td>-130.108854</td>\n",
       "      <td>-112.533474</td>\n",
       "      <td>30.928214</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.369391</td>\n",
       "      <td>3.690085e-03</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>1.001906e-03</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.589318</td>\n",
       "      <td>0.219360</td>\n",
       "      <td>...</td>\n",
       "      <td>181189.258168</td>\n",
       "      <td>2</td>\n",
       "      <td>-82.106631</td>\n",
       "      <td>-90.033194</td>\n",
       "      <td>-159.913639</td>\n",
       "      <td>-93.608484</td>\n",
       "      <td>-124.218826</td>\n",
       "      <td>-109.976155</td>\n",
       "      <td>28.771301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.637928</td>\n",
       "      <td>3.522808e-02</td>\n",
       "      <td>0.039645</td>\n",
       "      <td>1.643885e-03</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.577196</td>\n",
       "      <td>0.272249</td>\n",
       "      <td>...</td>\n",
       "      <td>182525.752650</td>\n",
       "      <td>1</td>\n",
       "      <td>-81.445089</td>\n",
       "      <td>-89.090925</td>\n",
       "      <td>-160.799058</td>\n",
       "      <td>-93.866553</td>\n",
       "      <td>-128.558254</td>\n",
       "      <td>-110.751976</td>\n",
       "      <td>29.782499</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.011003</td>\n",
       "      <td>9.464947e-07</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>4.002095e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.411758</td>\n",
       "      <td>0.245045</td>\n",
       "      <td>...</td>\n",
       "      <td>225599.638664</td>\n",
       "      <td>7</td>\n",
       "      <td>-92.533531</td>\n",
       "      <td>-98.738857</td>\n",
       "      <td>-169.304190</td>\n",
       "      <td>-99.615635</td>\n",
       "      <td>-145.928416</td>\n",
       "      <td>-121.224126</td>\n",
       "      <td>30.716963</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.050474</td>\n",
       "      <td>2.491494e-03</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>3.926230e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.602350</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>...</td>\n",
       "      <td>250829.151731</td>\n",
       "      <td>14</td>\n",
       "      <td>-80.990797</td>\n",
       "      <td>-99.233726</td>\n",
       "      <td>-173.841239</td>\n",
       "      <td>-93.103180</td>\n",
       "      <td>-157.591370</td>\n",
       "      <td>-120.952062</td>\n",
       "      <td>37.373394</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.096775</td>\n",
       "      <td>7.673888e-04</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>1.078793e-03</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.514927</td>\n",
       "      <td>0.194982</td>\n",
       "      <td>...</td>\n",
       "      <td>236933.126762</td>\n",
       "      <td>10</td>\n",
       "      <td>-86.797134</td>\n",
       "      <td>-98.449942</td>\n",
       "      <td>-171.349173</td>\n",
       "      <td>-93.892908</td>\n",
       "      <td>-150.169066</td>\n",
       "      <td>-120.131645</td>\n",
       "      <td>34.044791</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.290834</td>\n",
       "      <td>3.509575e-03</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>1.267051e-03</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.356972</td>\n",
       "      <td>0.175153</td>\n",
       "      <td>...</td>\n",
       "      <td>246212.714867</td>\n",
       "      <td>13</td>\n",
       "      <td>-91.126013</td>\n",
       "      <td>-98.243634</td>\n",
       "      <td>-173.038518</td>\n",
       "      <td>-91.899785</td>\n",
       "      <td>-153.071701</td>\n",
       "      <td>-121.475930</td>\n",
       "      <td>34.619643</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.525724</td>\n",
       "      <td>5.355683e-02</td>\n",
       "      <td>0.033792</td>\n",
       "      <td>4.678519e-03</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 3...</td>\n",
       "      <td>0.437511</td>\n",
       "      <td>0.106060</td>\n",
       "      <td>...</td>\n",
       "      <td>241724.484510</td>\n",
       "      <td>12</td>\n",
       "      <td>-88.574657</td>\n",
       "      <td>-100.287774</td>\n",
       "      <td>-171.305017</td>\n",
       "      <td>-92.781532</td>\n",
       "      <td>-150.731291</td>\n",
       "      <td>-120.736055</td>\n",
       "      <td>33.736856</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.012705</td>\n",
       "      <td>9.817256e-04</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>3.814697e-07</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.439747</td>\n",
       "      <td>-0.442967</td>\n",
       "      <td>...</td>\n",
       "      <td>292760.178492</td>\n",
       "      <td>30</td>\n",
       "      <td>-93.814358</td>\n",
       "      <td>-124.124839</td>\n",
       "      <td>-176.329694</td>\n",
       "      <td>-101.597165</td>\n",
       "      <td>-169.105745</td>\n",
       "      <td>-132.994360</td>\n",
       "      <td>34.004435</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.053935</td>\n",
       "      <td>1.797129e-03</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>1.784161e-07</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.380605</td>\n",
       "      <td>-0.270492</td>\n",
       "      <td>...</td>\n",
       "      <td>289273.166497</td>\n",
       "      <td>29</td>\n",
       "      <td>-97.221087</td>\n",
       "      <td>-114.114185</td>\n",
       "      <td>-177.817051</td>\n",
       "      <td>-96.336860</td>\n",
       "      <td>-161.555610</td>\n",
       "      <td>-129.408958</td>\n",
       "      <td>33.883635</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.106419</td>\n",
       "      <td>1.216260e-03</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>4.920597e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.434032</td>\n",
       "      <td>0.072250</td>\n",
       "      <td>...</td>\n",
       "      <td>278108.710139</td>\n",
       "      <td>19</td>\n",
       "      <td>-90.783184</td>\n",
       "      <td>-107.334203</td>\n",
       "      <td>-176.537885</td>\n",
       "      <td>-93.951564</td>\n",
       "      <td>-161.017947</td>\n",
       "      <td>-125.924957</td>\n",
       "      <td>35.766030</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.318293</td>\n",
       "      <td>2.447156e-03</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>6.450276e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.458946</td>\n",
       "      <td>0.048242</td>\n",
       "      <td>...</td>\n",
       "      <td>282279.270139</td>\n",
       "      <td>23</td>\n",
       "      <td>-91.606764</td>\n",
       "      <td>-105.318095</td>\n",
       "      <td>-176.380952</td>\n",
       "      <td>-92.140701</td>\n",
       "      <td>-161.439826</td>\n",
       "      <td>-125.377268</td>\n",
       "      <td>36.192183</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.538581</td>\n",
       "      <td>1.450007e-02</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>2.735390e-03</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 5...</td>\n",
       "      <td>0.434035</td>\n",
       "      <td>0.029143</td>\n",
       "      <td>...</td>\n",
       "      <td>280667.353528</td>\n",
       "      <td>26</td>\n",
       "      <td>-92.292207</td>\n",
       "      <td>-107.451939</td>\n",
       "      <td>-175.451400</td>\n",
       "      <td>-92.784514</td>\n",
       "      <td>-161.726991</td>\n",
       "      <td>-125.941410</td>\n",
       "      <td>35.511564</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.009103</td>\n",
       "      <td>2.016068e-04</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>4.900960e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.242908</td>\n",
       "      <td>0.274567</td>\n",
       "      <td>...</td>\n",
       "      <td>340348.348615</td>\n",
       "      <td>40</td>\n",
       "      <td>-110.718631</td>\n",
       "      <td>-103.666042</td>\n",
       "      <td>-186.716361</td>\n",
       "      <td>-100.348389</td>\n",
       "      <td>-173.891061</td>\n",
       "      <td>-135.068097</td>\n",
       "      <td>37.307397</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.041755</td>\n",
       "      <td>6.443588e-04</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>3.996138e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.489132</td>\n",
       "      <td>-0.043533</td>\n",
       "      <td>...</td>\n",
       "      <td>333089.789873</td>\n",
       "      <td>39</td>\n",
       "      <td>-96.149118</td>\n",
       "      <td>-116.633033</td>\n",
       "      <td>-189.599204</td>\n",
       "      <td>-94.359047</td>\n",
       "      <td>-169.538474</td>\n",
       "      <td>-133.255775</td>\n",
       "      <td>39.133595</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.081324</td>\n",
       "      <td>1.720435e-03</td>\n",
       "      <td>0.007201</td>\n",
       "      <td>9.801045e-04</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.466277</td>\n",
       "      <td>0.022835</td>\n",
       "      <td>...</td>\n",
       "      <td>320806.022258</td>\n",
       "      <td>37</td>\n",
       "      <td>-97.886436</td>\n",
       "      <td>-114.516395</td>\n",
       "      <td>-184.312828</td>\n",
       "      <td>-95.771390</td>\n",
       "      <td>-168.747441</td>\n",
       "      <td>-132.246898</td>\n",
       "      <td>37.063798</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.291790</td>\n",
       "      <td>1.960245e-02</td>\n",
       "      <td>0.019957</td>\n",
       "      <td>2.952771e-03</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.455858</td>\n",
       "      <td>-0.038067</td>\n",
       "      <td>...</td>\n",
       "      <td>318716.215874</td>\n",
       "      <td>36</td>\n",
       "      <td>-100.143581</td>\n",
       "      <td>-116.693941</td>\n",
       "      <td>-184.883313</td>\n",
       "      <td>-96.058697</td>\n",
       "      <td>-164.367687</td>\n",
       "      <td>-132.429444</td>\n",
       "      <td>35.733105</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.526032</td>\n",
       "      <td>7.630419e-03</td>\n",
       "      <td>0.034358</td>\n",
       "      <td>3.656601e-03</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.461711</td>\n",
       "      <td>-0.056262</td>\n",
       "      <td>...</td>\n",
       "      <td>320854.442914</td>\n",
       "      <td>38</td>\n",
       "      <td>-98.291330</td>\n",
       "      <td>-118.053557</td>\n",
       "      <td>-185.122871</td>\n",
       "      <td>-95.654965</td>\n",
       "      <td>-168.087385</td>\n",
       "      <td>-133.042022</td>\n",
       "      <td>36.798503</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.029267  1.534640e-03         0.002514    4.489062e-04   \n",
       "1        0.146226  8.571864e-03         0.005924    3.344857e-04   \n",
       "2        0.289935  7.241285e-03         0.009138    2.537671e-04   \n",
       "3        0.842515  1.167758e-02         0.024856    4.044143e-04   \n",
       "4        1.390384  1.597511e-02         0.038375    4.664436e-04   \n",
       "5        0.023201  6.915022e-04         0.002406    4.904838e-04   \n",
       "6        0.108098  1.147156e-03         0.005002    1.368780e-06   \n",
       "7        0.216076  2.098540e-03         0.008003    8.869684e-07   \n",
       "8        0.654431  6.476866e-03         0.020988    1.985573e-03   \n",
       "9        1.082638  1.391334e-02         0.031707    7.435713e-04   \n",
       "10       0.020105  4.894746e-04         0.002601    4.900572e-04   \n",
       "11       0.098334  1.513290e-03         0.004902    1.989130e-04   \n",
       "12       0.194499  1.959050e-03         0.008404    5.826705e-04   \n",
       "13       0.581860  4.667589e-03         0.019404    3.764704e-04   \n",
       "14       0.987784  1.622663e-02         0.031241    4.778330e-04   \n",
       "15       0.017856  7.140712e-04         0.002611    4.975036e-04   \n",
       "16       0.085945  1.531616e-03         0.005003    4.503524e-06   \n",
       "17       0.169000  5.762137e-03         0.007209    3.970722e-04   \n",
       "18       0.497463  5.379050e-03         0.017515    4.358377e-04   \n",
       "19       0.831634  1.256249e-02         0.030027    3.262105e-03   \n",
       "20       0.013321  4.301522e-04         0.002600    4.899403e-04   \n",
       "21       0.062567  7.300494e-04         0.005705    4.021222e-04   \n",
       "22       0.125396  2.805863e-03         0.009893    6.457872e-04   \n",
       "23       0.369391  3.690085e-03         0.024506    1.001906e-03   \n",
       "24       0.637928  3.522808e-02         0.039645    1.643885e-03   \n",
       "25       0.011003  9.464947e-07         0.002801    4.002095e-04   \n",
       "26       0.050474  2.491494e-03         0.005218    3.926230e-04   \n",
       "27       0.096775  7.673888e-04         0.008703    1.078793e-03   \n",
       "28       0.290834  3.509575e-03         0.020324    1.267051e-03   \n",
       "29       0.525724  5.355683e-02         0.033792    4.678519e-03   \n",
       "30       0.012705  9.817256e-04         0.003001    3.814697e-07   \n",
       "31       0.053935  1.797129e-03         0.006002    1.784161e-07   \n",
       "32       0.106419  1.216260e-03         0.009126    4.920597e-04   \n",
       "33       0.318293  2.447156e-03         0.023688    6.450276e-04   \n",
       "34       0.538581  1.450007e-02         0.034231    2.735390e-03   \n",
       "35       0.009103  2.016068e-04         0.002601    4.900960e-04   \n",
       "36       0.041755  6.443588e-04         0.004202    3.996138e-04   \n",
       "37       0.081324  1.720435e-03         0.007201    9.801045e-04   \n",
       "38       0.291790  1.960245e-02         0.019957    2.952771e-03   \n",
       "39       0.526032  7.630419e-03         0.034358    3.656601e-03   \n",
       "\n",
       "   param_max_features param_min_samples_leaf param_n_estimators  \\\n",
       "0                auto                      1                 10   \n",
       "1                auto                      1                 50   \n",
       "2                auto                      1                100   \n",
       "3                auto                      1                300   \n",
       "4                auto                      1                500   \n",
       "5                auto                      3                 10   \n",
       "6                auto                      3                 50   \n",
       "7                auto                      3                100   \n",
       "8                auto                      3                300   \n",
       "9                auto                      3                500   \n",
       "10               auto                      5                 10   \n",
       "11               auto                      5                 50   \n",
       "12               auto                      5                100   \n",
       "13               auto                      5                300   \n",
       "14               auto                      5                500   \n",
       "15               auto                     10                 10   \n",
       "16               auto                     10                 50   \n",
       "17               auto                     10                100   \n",
       "18               auto                     10                300   \n",
       "19               auto                     10                500   \n",
       "20               sqrt                      1                 10   \n",
       "21               sqrt                      1                 50   \n",
       "22               sqrt                      1                100   \n",
       "23               sqrt                      1                300   \n",
       "24               sqrt                      1                500   \n",
       "25               sqrt                      3                 10   \n",
       "26               sqrt                      3                 50   \n",
       "27               sqrt                      3                100   \n",
       "28               sqrt                      3                300   \n",
       "29               sqrt                      3                500   \n",
       "30               sqrt                      5                 10   \n",
       "31               sqrt                      5                 50   \n",
       "32               sqrt                      5                100   \n",
       "33               sqrt                      5                300   \n",
       "34               sqrt                      5                500   \n",
       "35               sqrt                     10                 10   \n",
       "36               sqrt                     10                 50   \n",
       "37               sqrt                     10                100   \n",
       "38               sqrt                     10                300   \n",
       "39               sqrt                     10                500   \n",
       "\n",
       "                                               params  split0_test_R2  \\\n",
       "0   {'max_features': 'auto', 'min_samples_leaf': 1...        0.546038   \n",
       "1   {'max_features': 'auto', 'min_samples_leaf': 1...       -0.448057   \n",
       "2   {'max_features': 'auto', 'min_samples_leaf': 1...       -0.360427   \n",
       "3   {'max_features': 'auto', 'min_samples_leaf': 1...       -0.221583   \n",
       "4   {'max_features': 'auto', 'min_samples_leaf': 1...       -0.135741   \n",
       "5   {'max_features': 'auto', 'min_samples_leaf': 3...       -1.594189   \n",
       "6   {'max_features': 'auto', 'min_samples_leaf': 3...       -1.468326   \n",
       "7   {'max_features': 'auto', 'min_samples_leaf': 3...       -2.434122   \n",
       "8   {'max_features': 'auto', 'min_samples_leaf': 3...       -2.159702   \n",
       "9   {'max_features': 'auto', 'min_samples_leaf': 3...       -2.356729   \n",
       "10  {'max_features': 'auto', 'min_samples_leaf': 5...       -0.100927   \n",
       "11  {'max_features': 'auto', 'min_samples_leaf': 5...       -0.196413   \n",
       "12  {'max_features': 'auto', 'min_samples_leaf': 5...       -0.419334   \n",
       "13  {'max_features': 'auto', 'min_samples_leaf': 5...       -0.547538   \n",
       "14  {'max_features': 'auto', 'min_samples_leaf': 5...       -0.313262   \n",
       "15  {'max_features': 'auto', 'min_samples_leaf': 1...       -0.006275   \n",
       "16  {'max_features': 'auto', 'min_samples_leaf': 1...       -0.023461   \n",
       "17  {'max_features': 'auto', 'min_samples_leaf': 1...       -0.053258   \n",
       "18  {'max_features': 'auto', 'min_samples_leaf': 1...       -0.111696   \n",
       "19  {'max_features': 'auto', 'min_samples_leaf': 1...       -0.009961   \n",
       "20  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.409626   \n",
       "21  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.667255   \n",
       "22  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.598104   \n",
       "23  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.589318   \n",
       "24  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.577196   \n",
       "25  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.411758   \n",
       "26  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.602350   \n",
       "27  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.514927   \n",
       "28  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.356972   \n",
       "29  {'max_features': 'sqrt', 'min_samples_leaf': 3...        0.437511   \n",
       "30  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.439747   \n",
       "31  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.380605   \n",
       "32  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.434032   \n",
       "33  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.458946   \n",
       "34  {'max_features': 'sqrt', 'min_samples_leaf': 5...        0.434035   \n",
       "35  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.242908   \n",
       "36  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.489132   \n",
       "37  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.466277   \n",
       "38  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.455858   \n",
       "39  {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.461711   \n",
       "\n",
       "    split1_test_R2  ...   std_test_MAE  rank_test_MAE  split0_test_RMSE  \\\n",
       "0        -0.240370  ...  252119.078362             28        -85.561890   \n",
       "1        -0.314628  ...  189894.298114             11       -101.526549   \n",
       "2        -0.350437  ...  183337.877329              6       -103.966308   \n",
       "3        -0.359991  ...  185973.009632              9        -98.181221   \n",
       "4        -0.445722  ...  189273.206296              8        -99.312868   \n",
       "5         0.087443  ...  178799.019718             17       -117.160765   \n",
       "6        -0.233018  ...  189707.389353             15       -111.153781   \n",
       "7        -0.097635  ...  184234.671507             22       -120.240507   \n",
       "8        -0.056889  ...  179912.240198             18       -117.328311   \n",
       "9        -0.064761  ...  185107.497895             25       -119.203442   \n",
       "10       -0.149014  ...  242349.871657             16       -109.393567   \n",
       "11       -0.271733  ...  245207.373531             20       -101.721484   \n",
       "12       -0.288699  ...  238665.478482             21       -103.851943   \n",
       "13       -0.187056  ...  240330.670608             27       -107.575713   \n",
       "14       -0.252040  ...  245809.104952             24       -103.630196   \n",
       "15       -0.680052  ...  288295.828455             35       -107.520166   \n",
       "16       -0.903038  ...  282968.359007             34       -110.102186   \n",
       "17       -0.767061  ...  284376.720539             33       -107.653180   \n",
       "18       -0.832205  ...  279829.997275             32       -109.629590   \n",
       "19       -0.754917  ...  282512.754120             31       -107.090278   \n",
       "20        0.228672  ...  176791.493543              5        -92.057057   \n",
       "21        0.163272  ...  189694.161060              3        -73.760456   \n",
       "22        0.241181  ...  193785.893730              4        -78.904804   \n",
       "23        0.219360  ...  181189.258168              2        -82.106631   \n",
       "24        0.272249  ...  182525.752650              1        -81.445089   \n",
       "25        0.245045  ...  225599.638664              7        -92.533531   \n",
       "26        0.020161  ...  250829.151731             14        -80.990797   \n",
       "27        0.194982  ...  236933.126762             10        -86.797134   \n",
       "28        0.175153  ...  246212.714867             13        -91.126013   \n",
       "29        0.106060  ...  241724.484510             12        -88.574657   \n",
       "30       -0.442967  ...  292760.178492             30        -93.814358   \n",
       "31       -0.270492  ...  289273.166497             29        -97.221087   \n",
       "32        0.072250  ...  278108.710139             19        -90.783184   \n",
       "33        0.048242  ...  282279.270139             23        -91.606764   \n",
       "34        0.029143  ...  280667.353528             26        -92.292207   \n",
       "35        0.274567  ...  340348.348615             40       -110.718631   \n",
       "36       -0.043533  ...  333089.789873             39        -96.149118   \n",
       "37        0.022835  ...  320806.022258             37        -97.886436   \n",
       "38       -0.038067  ...  318716.215874             36       -100.143581   \n",
       "39       -0.056262  ...  320854.442914             38        -98.291330   \n",
       "\n",
       "    split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  split4_test_RMSE  \\\n",
       "0         -99.959377       -175.145718       -110.902467       -150.605190   \n",
       "1        -101.449260       -165.940870       -103.324651       -132.692937   \n",
       "2        -102.014158       -167.246986       -101.100260       -132.470342   \n",
       "3        -101.494988       -166.243979       -106.745638       -134.622835   \n",
       "4        -101.370824       -165.931519       -106.891265       -131.607472   \n",
       "5         -95.775739       -172.204225       -108.082362       -153.463257   \n",
       "6        -104.733370       -165.457621       -102.677543       -148.060649   \n",
       "7        -101.757040       -165.791882       -104.099169       -155.557683   \n",
       "8         -99.793877       -163.750406       -104.676673       -152.546473   \n",
       "9        -100.374189       -163.755527       -103.789718       -150.710556   \n",
       "10       -104.422362       -168.422536        -90.785205       -174.231683   \n",
       "11       -107.622215       -172.564519        -94.690721       -173.443227   \n",
       "12       -109.313608       -171.841551        -95.889024       -172.343716   \n",
       "13       -106.393558       -170.943849        -95.867382       -173.373257   \n",
       "14       -108.141708       -171.576583        -93.893685       -174.068927   \n",
       "15       -114.454974       -177.190033        -96.853453       -156.300451   \n",
       "16       -122.891222       -175.118183        -93.219796       -176.444619   \n",
       "17       -120.479076       -175.715172        -89.204248       -173.790089   \n",
       "18       -121.281995       -176.793858        -90.388904       -174.361921   \n",
       "19       -121.430001       -176.296599        -90.110002       -173.382855   \n",
       "20        -90.398329       -164.991839       -101.524877       -139.204164   \n",
       "21        -92.047793       -162.148889        -91.329059       -130.786119   \n",
       "22        -89.616869       -164.100297        -99.936546       -130.108854   \n",
       "23        -90.033194       -159.913639        -93.608484       -124.218826   \n",
       "24        -89.090925       -160.799058        -93.866553       -128.558254   \n",
       "25        -98.738857       -169.304190        -99.615635       -145.928416   \n",
       "26        -99.233726       -173.841239        -93.103180       -157.591370   \n",
       "27        -98.449942       -171.349173        -93.892908       -150.169066   \n",
       "28        -98.243634       -173.038518        -91.899785       -153.071701   \n",
       "29       -100.287774       -171.305017        -92.781532       -150.731291   \n",
       "30       -124.124839       -176.329694       -101.597165       -169.105745   \n",
       "31       -114.114185       -177.817051        -96.336860       -161.555610   \n",
       "32       -107.334203       -176.537885        -93.951564       -161.017947   \n",
       "33       -105.318095       -176.380952        -92.140701       -161.439826   \n",
       "34       -107.451939       -175.451400        -92.784514       -161.726991   \n",
       "35       -103.666042       -186.716361       -100.348389       -173.891061   \n",
       "36       -116.633033       -189.599204        -94.359047       -169.538474   \n",
       "37       -114.516395       -184.312828        -95.771390       -168.747441   \n",
       "38       -116.693941       -184.883313        -96.058697       -164.367687   \n",
       "39       -118.053557       -185.122871        -95.654965       -168.087385   \n",
       "\n",
       "    mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0      -124.434928      33.315942              15  \n",
       "1      -120.986854      25.417594               9  \n",
       "2      -121.359611      25.753891              12  \n",
       "3      -121.457732      25.829753              13  \n",
       "4      -121.022790      25.243018              10  \n",
       "5      -129.337270      28.796020              22  \n",
       "6      -126.416593      25.531648              19  \n",
       "7      -129.489256      26.445095              25  \n",
       "8      -127.619148      25.819929              21  \n",
       "9      -127.566686      25.377119              20  \n",
       "10     -129.451071      34.778922              24  \n",
       "11     -130.008433      35.344693              26  \n",
       "12     -130.647968      34.108101              29  \n",
       "13     -130.830752      33.998046              30  \n",
       "14     -130.262220      35.063246              27  \n",
       "15     -130.463816      30.864937              28  \n",
       "16     -135.555201      34.169264              40  \n",
       "17     -133.368353      35.227948              36  \n",
       "18     -134.491254      34.976520              38  \n",
       "19     -133.661947      35.065396              37  \n",
       "20     -117.635253      29.541505               5  \n",
       "21     -110.014464      32.049208               2  \n",
       "22     -112.533474      30.928214               4  \n",
       "23     -109.976155      28.771301               1  \n",
       "24     -110.751976      29.782499               3  \n",
       "25     -121.224126      30.716963              11  \n",
       "26     -120.952062      37.373394               8  \n",
       "27     -120.131645      34.044791               6  \n",
       "28     -121.475930      34.619643              14  \n",
       "29     -120.736055      33.736856               7  \n",
       "30     -132.994360      34.004435              33  \n",
       "31     -129.408958      33.883635              23  \n",
       "32     -125.924957      35.766030              17  \n",
       "33     -125.377268      36.192183              16  \n",
       "34     -125.941410      35.511564              18  \n",
       "35     -135.068097      37.307397              39  \n",
       "36     -133.255775      39.133595              35  \n",
       "37     -132.246898      37.063798              31  \n",
       "38     -132.429444      35.733105              32  \n",
       "39     -133.042022      36.798503              34  \n",
       "\n",
       "[40 rows x 32 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyRandombest=pd.concat([pd.DataFrame(MyRandom.cv_results_)])\n",
    "MyRandombest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21    0.451985\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyRandombestR2=MyRandombest[MyRandombest['rank_test_R2'].isin([1])]\n",
    "print(MyRandombestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.03864965, 0.03833613, 0.03922338, 0.04014025, 0.0368999 ,\n",
       "        0.034551  , 0.03371096, 0.03665156, 0.03618116, 0.03735571,\n",
       "        0.03889394, 0.04001102, 0.03963008, 0.03620949, 0.03803349,\n",
       "        0.05256286, 0.04566545, 0.04319024, 0.04000149, 0.03813429,\n",
       "        0.13856988, 0.08299928, 0.05094218, 0.04077673, 0.03738174]),\n",
       " 'std_fit_time': array([0.0016703 , 0.00180688, 0.00173852, 0.00324645, 0.00549695,\n",
       "        0.00278506, 0.00312869, 0.00305042, 0.00426874, 0.00149455,\n",
       "        0.00233708, 0.00254808, 0.00204613, 0.00341419, 0.00244467,\n",
       "        0.00290564, 0.00242728, 0.00304141, 0.00260423, 0.00244798,\n",
       "        0.014401  , 0.00488311, 0.00730732, 0.00110546, 0.00166494]),\n",
       " 'mean_score_time': array([0.01910224, 0.02052593, 0.01871867, 0.02039576, 0.0196218 ,\n",
       "        0.01578937, 0.01801434, 0.01963506, 0.01689515, 0.01891861,\n",
       "        0.01880441, 0.01830497, 0.02012544, 0.01910539, 0.01834445,\n",
       "        0.02067447, 0.02110605, 0.02100692, 0.01840806, 0.0182116 ,\n",
       "        0.02005067, 0.01740384, 0.01883292, 0.01809392, 0.01749992]),\n",
       " 'std_score_time': array([0.00236109, 0.00238952, 0.00294281, 0.00144846, 0.00142523,\n",
       "        0.00149072, 0.00207379, 0.00184396, 0.00020907, 0.0013631 ,\n",
       "        0.00318813, 0.00244298, 0.0024623 , 0.00313881, 0.00217764,\n",
       "        0.00249998, 0.00228915, 0.00122641, 0.00174304, 0.00193534,\n",
       "        0.0023658 , 0.00205977, 0.00261693, 0.00139459, 0.00209308]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 1, 10, 10, 10, 10,\n",
       "                    10, 100, 100, 100, 100, 100, 1000, 1000, 1000, 1000,\n",
       "                    1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[1, 0.1, 0.01, 0.001, 0.0001, 1, 0.1, 0.01, 0.001,\n",
       "                    0.0001, 1, 0.1, 0.01, 0.001, 0.0001, 1, 0.1, 0.01,\n",
       "                    0.001, 0.0001, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}],\n",
       " 'split0_test_R2': array([-0.11487856, -0.10718601, -0.10830333, -0.11608686, -0.11707041,\n",
       "        -0.09969476, -0.05098492, -0.04351816, -0.10521315, -0.11606669,\n",
       "        -0.0259622 ,  0.06984659,  0.16507581, -0.01530186, -0.10479454,\n",
       "         0.08373926,  0.24282052,  0.30521802,  0.2392603 , -0.01239455,\n",
       "         0.22521723,  0.54038898,  0.43340076,  0.3720921 ,  0.24745977]),\n",
       " 'split1_test_R2': array([-0.16541329, -0.15600595, -0.15622181, -0.16607539, -0.16755504,\n",
       "        -0.14674988, -0.08124644, -0.06986558, -0.15115621, -0.16601385,\n",
       "        -0.03974859,  0.10478229,  0.18679859, -0.0320565 , -0.15078143,\n",
       "         0.13163413,  0.31906946,  0.35502118,  0.27153143, -0.02703962,\n",
       "         0.26283982,  0.32337083,  0.34622744,  0.33222287,  0.27960497]),\n",
       " 'split2_test_R2': array([-0.03457543, -0.03327087, -0.03318224, -0.03441721, -0.03466999,\n",
       "        -0.03305214, -0.02570977, -0.02206614, -0.03206759, -0.03439859,\n",
       "        -0.02301398, -0.00760542,  0.0145702 , -0.0110033 , -0.03183842,\n",
       "        -0.00407971,  0.03091914,  0.07085976,  0.06357485, -0.00879473,\n",
       "         0.03426324,  0.11575369,  0.25381649,  0.15017087,  0.07547863]),\n",
       " 'split3_test_R2': array([-0.08788745, -0.08214402, -0.08250889, -0.08839093, -0.08926878,\n",
       "        -0.0767508 , -0.03954786, -0.029912  , -0.07920733, -0.08831769,\n",
       "        -0.01550065,  0.05548931,  0.1381741 ,  0.00131359, -0.07868871,\n",
       "         0.08446525,  0.19879214,  0.28436108,  0.22002098,  0.00692646,\n",
       "         0.23963122,  0.5175205 ,  0.47642959,  0.32477813,  0.22712312]),\n",
       " 'split4_test_R2': array([-0.04051494, -0.03905319, -0.0391054 , -0.04041786, -0.04068781,\n",
       "        -0.03846055, -0.03099228, -0.02752407, -0.0375665 , -0.04038175,\n",
       "        -0.02776923, -0.01191787,  0.00919214, -0.01301327, -0.03717272,\n",
       "        -0.0077518 ,  0.02475121,  0.05355109,  0.07184828, -0.00913227,\n",
       "         0.03311515,  0.09313299,  0.24817435,  0.17187758,  0.08688709]),\n",
       " 'mean_test_R2': array([-0.08865393, -0.08353201, -0.08386433, -0.08907765, -0.0898504 ,\n",
       "        -0.07894163, -0.04569625, -0.03857719, -0.08104215, -0.08903572,\n",
       "        -0.02639893,  0.04211898,  0.10276217, -0.01401227, -0.08065517,\n",
       "         0.05760143,  0.16327049,  0.21380223,  0.17324717, -0.01008694,\n",
       "         0.15901333,  0.3180334 ,  0.35160973,  0.27022831,  0.18331072]),\n",
       " 'std_test_R2': array([0.04862543, 0.04542787, 0.0456218 , 0.04901869, 0.04947953,\n",
       "        0.04189991, 0.01972438, 0.01716536, 0.04425432, 0.04900867,\n",
       "        0.00788051, 0.04531396, 0.07580539, 0.01069758, 0.04422232,\n",
       "        0.05470155, 0.1171049 , 0.12600886, 0.08776682, 0.01081439,\n",
       "        0.1030292 , 0.1901383 , 0.09226173, 0.09086462, 0.08512636]),\n",
       " 'rank_test_R2': array([22, 20, 21, 24, 25, 17, 16, 15, 19, 23, 14, 11,  9, 13, 18, 10,  7,\n",
       "         4,  6, 12,  8,  2,  1,  3,  5]),\n",
       " 'split0_test_MAE': array([-66126.91795179, -65670.64865831, -65736.92031598, -66198.58549741,\n",
       "        -66256.92318624, -65226.31946839, -62337.18678047, -61894.31006313,\n",
       "        -65553.6320431 , -66197.38958024, -60853.01161421, -55170.29407825,\n",
       "        -49521.95241927, -60220.71342876, -65528.80330883, -54346.27653679,\n",
       "        -44910.67174944, -41209.68199797, -45121.83934704, -60048.2719012 ,\n",
       "        -45954.77786192, -27260.95996257, -33606.76439772, -37243.17200556,\n",
       "        -44635.50332532]),\n",
       " 'split1_test_MAE': array([-45862.059573  , -45491.85622655, -45500.35091009, -45888.11509803,\n",
       "        -45946.34310991, -45127.60572429, -42549.87424462, -42102.00746451,\n",
       "        -45301.00624308, -45885.69344521, -40916.82537065, -35229.15730093,\n",
       "        -32001.60148864, -40614.12136788, -45286.25792701, -34172.46710731,\n",
       "        -26796.39674194, -25381.60261995, -28667.14276431, -40416.69398023,\n",
       "        -29009.18040817, -26627.12658815, -25727.65924702, -26278.77598731,\n",
       "        -28349.42781913]),\n",
       " 'split2_test_MAE': array([-1028955.8142923 , -1027658.33875526, -1027570.1866386 ,\n",
       "        -1028798.45219102, -1029049.85145037, -1027440.79279987,\n",
       "        -1020138.30588007, -1016514.46842421, -1026461.58783294,\n",
       "        -1028779.92835345, -1017457.16084016, -1002132.29942928,\n",
       "         -980077.12522941, -1005511.72141819, -1026233.66688029,\n",
       "         -998625.73246095,  -963816.99774753,  -924093.32845931,\n",
       "         -931338.6614107 , -1003315.14411669,  -960491.05419238,\n",
       "         -879443.24705321,  -742130.38074376,  -845213.01809864,\n",
       "         -919499.54747007]),\n",
       " 'split3_test_MAE': array([-70474.31955117, -70102.25495024, -70125.892007  , -70506.93563121,\n",
       "        -70563.8037319 , -69752.87765033, -67342.83801191, -66718.61858766,\n",
       "        -69912.01378093, -70502.19127821, -65785.03824845, -61186.24539192,\n",
       "        -55829.85073494, -64695.79658481, -69878.41729907, -59309.15784426,\n",
       "        -51902.96009437, -46359.72760818, -50527.73654604, -64332.19008985,\n",
       "        -49257.36795077, -31255.45246351, -33917.35814986, -43741.47489144,\n",
       "        -50067.65380025]),\n",
       " 'split4_test_MAE': array([-830981.90836322, -829814.51703842, -829856.21301598,\n",
       "        -830904.38282369, -831119.96598447, -829341.22532338,\n",
       "        -823376.87125261, -820607.06682131, -828627.20820839,\n",
       "        -830875.54544455, -820802.86313376, -808143.56086675,\n",
       "        -791284.56047294, -809018.37555925, -828312.73130762,\n",
       "        -804816.42354006, -778858.69168209, -755858.36720292,\n",
       "        -741245.7638145 , -805918.90432018, -772179.0338741 ,\n",
       "        -724247.24791012, -600427.24086779, -661359.79475266,\n",
       "        -729235.38210732]),\n",
       " 'mean_test_MAE': array([-408480.2039463 , -407747.52312575, -407757.91257753,\n",
       "        -408459.29424827, -408587.37749258, -407377.76419325,\n",
       "        -403149.01523394, -401567.29427216, -407171.08962169,\n",
       "        -408448.14962033, -401162.97984145, -392372.31141343,\n",
       "        -381743.01806904, -396012.14567178, -407047.97534456,\n",
       "        -390254.01149788, -373257.14360307, -358580.54157767,\n",
       "        -359380.22877652, -394806.24088163, -371378.28285747,\n",
       "        -337766.80679551, -287161.88068123, -322767.24714712,\n",
       "        -354357.50290442]),\n",
       " 'std_test_MAE': array([430451.70279955, 430041.87006668, 430008.95612932, 430370.20648239,\n",
       "        430456.98184816, 430073.17387276, 428069.49606403, 426724.97517827,\n",
       "        429544.43539005, 430360.54851358, 427547.11533945, 423228.92580924,\n",
       "        415845.46800965, 422113.26526897, 429428.71612147, 422168.38184968,\n",
       "        410947.32584215, 396701.90697017, 394075.39330811, 420990.41660149,\n",
       "        408552.08801357, 382086.76740914, 316828.77371368, 356336.71982498,\n",
       "        388515.18610305]),\n",
       " 'rank_test_MAE': array([24, 20, 21, 23, 25, 19, 16, 15, 18, 22, 14, 11,  9, 13, 17, 10,  8,\n",
       "         5,  6, 12,  7,  3,  1,  2,  4]),\n",
       " 'split0_test_RMSE': array([-110.29148623, -109.54075024, -109.8438929 , -110.55676135,\n",
       "        -110.65485802, -107.38788934, -102.66693426, -104.02872861,\n",
       "        -109.60427827, -110.55423887,  -99.85160976,  -92.70307661,\n",
       "         -87.6647217 , -101.78678338, -109.57721807,  -91.83358984,\n",
       "         -83.15088828,  -79.66737589,  -83.29263122, -101.51994241,\n",
       "         -98.15785434,  -71.39688191,  -75.78598499,  -80.1114474 ,\n",
       "         -82.96000564]),\n",
       " 'split1_test_RMSE': array([-105.79380734, -105.00326467, -105.32111409, -106.02164149,\n",
       "        -106.11364745, -103.13191373,  -98.29402097,  -99.60487741,\n",
       "        -105.10796166, -106.01791976,  -95.22212538,  -90.23415857,\n",
       "         -85.89444568,  -97.63185612, -105.07959911,  -91.01217117,\n",
       "         -86.96696792,  -83.68968519,  -82.38179668,  -97.18130918,\n",
       "         -93.01171729,  -90.11438594,  -85.59615696,  -84.58810436,\n",
       "         -81.14734408]),\n",
       " 'split2_test_RMSE': array([-212.74971519, -211.87923119, -212.23971339, -212.98332114,\n",
       "        -213.08277709, -210.17796905, -205.27598508, -206.18880071,\n",
       "        -212.02319839, -212.98053258, -203.60876287, -197.79785625,\n",
       "        -190.86845692, -203.85189015, -211.99464715, -199.23878828,\n",
       "        -187.41324948, -181.7018723 , -184.48417939, -203.5157866 ,\n",
       "        -202.53464427, -174.28010875, -163.21834141, -177.64761179,\n",
       "        -183.11262869]),\n",
       " 'split3_test_RMSE': array([-105.42446147, -104.6760141 , -105.00009687, -105.63284604,\n",
       "        -105.71818108, -102.75579048,  -98.62969419, -100.0031256 ,\n",
       "        -104.80107212, -105.63123813,  -96.01036366,  -91.91787774,\n",
       "         -87.84389796,  -98.17360467, -104.7751588 ,  -92.04633545,\n",
       "         -86.51552069,  -82.38702001,  -84.20123203,  -97.87349647,\n",
       "         -98.90359739,  -82.70019251,  -79.87122943,  -80.53356031,\n",
       "         -84.00365618]),\n",
       " 'split4_test_RMSE': array([-206.827683  , -205.83129715, -206.23958574, -207.0811933 ,\n",
       "        -207.1919923 , -203.94404682, -198.52890238, -199.6575729 ,\n",
       "        -205.99796754, -207.07831264, -195.89745655, -186.64699148,\n",
       "        -179.99847539, -197.03379545, -205.9677711 , -185.14985963,\n",
       "        -172.03504278, -170.33763331, -171.98544518, -196.65257636,\n",
       "        -179.57862036, -161.06766591, -156.23075793, -164.63728085,\n",
       "        -170.67202408]),\n",
       " 'mean_test_RMSE': array([-148.21743064, -147.38611147, -147.7288806 , -148.45515267,\n",
       "        -148.55229119, -145.47952189, -140.67910738, -141.89662105,\n",
       "        -147.5068956 , -148.4524484 , -138.11806364, -131.85999213,\n",
       "        -126.45399953, -139.69558595, -147.47887885, -131.85614887,\n",
       "        -123.21633383, -119.55671734, -121.2690569 , -139.3486222 ,\n",
       "        -134.43728673, -115.911847  , -112.14049414, -117.50360094,\n",
       "        -120.37913173]),\n",
       " 'std_test_RMSE': array([50.33677923, 50.25521208, 50.2883487 , 50.34190709, 50.34841223,\n",
       "        50.34600154, 50.05782535, 49.89478077, 50.28245058, 50.34180204,\n",
       "        50.40819644, 49.41814197, 48.28386613, 49.6673157 , 50.28136314,\n",
       "        49.4681649 , 46.41274925, 46.25994308, 46.68352023, 49.6597332 ,\n",
       "        46.83995773, 42.8859116 , 39.03960927, 44.01652596, 46.31925311]),\n",
       " 'rank_test_RMSE': array([22, 18, 21, 24, 25, 17, 15, 16, 20, 23, 12, 10,  8, 14, 19,  9,  7,\n",
       "         4,  6, 13, 11,  2,  1,  3,  5])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMparams = {\n",
    "    'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']\n",
    "}\n",
    "MySVM = GridSearchCV(SVR(),\n",
    "                        param_grid = SVMparams,\n",
    "                        scoring=scoring,\n",
    "                        refit=False,\n",
    "                        verbose=2,\n",
    "                        cv=CV)\n",
    "\n",
    "MySVM.fit(X_train_std, y_train)\n",
    "MySVM.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038650</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.114879</td>\n",
       "      <td>-0.165413</td>\n",
       "      <td>...</td>\n",
       "      <td>430451.702800</td>\n",
       "      <td>24</td>\n",
       "      <td>-110.291486</td>\n",
       "      <td>-105.793807</td>\n",
       "      <td>-212.749715</td>\n",
       "      <td>-105.424461</td>\n",
       "      <td>-206.827683</td>\n",
       "      <td>-148.217431</td>\n",
       "      <td>50.336779</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038336</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.020526</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.107186</td>\n",
       "      <td>-0.156006</td>\n",
       "      <td>...</td>\n",
       "      <td>430041.870067</td>\n",
       "      <td>20</td>\n",
       "      <td>-109.540750</td>\n",
       "      <td>-105.003265</td>\n",
       "      <td>-211.879231</td>\n",
       "      <td>-104.676014</td>\n",
       "      <td>-205.831297</td>\n",
       "      <td>-147.386111</td>\n",
       "      <td>50.255212</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.108303</td>\n",
       "      <td>-0.156222</td>\n",
       "      <td>...</td>\n",
       "      <td>430008.956129</td>\n",
       "      <td>21</td>\n",
       "      <td>-109.843893</td>\n",
       "      <td>-105.321114</td>\n",
       "      <td>-212.239713</td>\n",
       "      <td>-105.000097</td>\n",
       "      <td>-206.239586</td>\n",
       "      <td>-147.728881</td>\n",
       "      <td>50.288349</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.020396</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.116087</td>\n",
       "      <td>-0.166075</td>\n",
       "      <td>...</td>\n",
       "      <td>430370.206482</td>\n",
       "      <td>23</td>\n",
       "      <td>-110.556761</td>\n",
       "      <td>-106.021641</td>\n",
       "      <td>-212.983321</td>\n",
       "      <td>-105.632846</td>\n",
       "      <td>-207.081193</td>\n",
       "      <td>-148.455153</td>\n",
       "      <td>50.341907</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>0.019622</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.117070</td>\n",
       "      <td>-0.167555</td>\n",
       "      <td>...</td>\n",
       "      <td>430456.981848</td>\n",
       "      <td>25</td>\n",
       "      <td>-110.654858</td>\n",
       "      <td>-106.113647</td>\n",
       "      <td>-213.082777</td>\n",
       "      <td>-105.718181</td>\n",
       "      <td>-207.191992</td>\n",
       "      <td>-148.552291</td>\n",
       "      <td>50.348412</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.034551</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.099695</td>\n",
       "      <td>-0.146750</td>\n",
       "      <td>...</td>\n",
       "      <td>430073.173873</td>\n",
       "      <td>19</td>\n",
       "      <td>-107.387889</td>\n",
       "      <td>-103.131914</td>\n",
       "      <td>-210.177969</td>\n",
       "      <td>-102.755790</td>\n",
       "      <td>-203.944047</td>\n",
       "      <td>-145.479522</td>\n",
       "      <td>50.346002</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.033711</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.018014</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.050985</td>\n",
       "      <td>-0.081246</td>\n",
       "      <td>...</td>\n",
       "      <td>428069.496064</td>\n",
       "      <td>16</td>\n",
       "      <td>-102.666934</td>\n",
       "      <td>-98.294021</td>\n",
       "      <td>-205.275985</td>\n",
       "      <td>-98.629694</td>\n",
       "      <td>-198.528902</td>\n",
       "      <td>-140.679107</td>\n",
       "      <td>50.057825</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.036652</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.043518</td>\n",
       "      <td>-0.069866</td>\n",
       "      <td>...</td>\n",
       "      <td>426724.975178</td>\n",
       "      <td>15</td>\n",
       "      <td>-104.028729</td>\n",
       "      <td>-99.604877</td>\n",
       "      <td>-206.188801</td>\n",
       "      <td>-100.003126</td>\n",
       "      <td>-199.657573</td>\n",
       "      <td>-141.896621</td>\n",
       "      <td>49.894781</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.036181</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.105213</td>\n",
       "      <td>-0.151156</td>\n",
       "      <td>...</td>\n",
       "      <td>429544.435390</td>\n",
       "      <td>18</td>\n",
       "      <td>-109.604278</td>\n",
       "      <td>-105.107962</td>\n",
       "      <td>-212.023198</td>\n",
       "      <td>-104.801072</td>\n",
       "      <td>-205.997968</td>\n",
       "      <td>-147.506896</td>\n",
       "      <td>50.282451</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.116067</td>\n",
       "      <td>-0.166014</td>\n",
       "      <td>...</td>\n",
       "      <td>430360.548514</td>\n",
       "      <td>22</td>\n",
       "      <td>-110.554239</td>\n",
       "      <td>-106.017920</td>\n",
       "      <td>-212.980533</td>\n",
       "      <td>-105.631238</td>\n",
       "      <td>-207.078313</td>\n",
       "      <td>-148.452448</td>\n",
       "      <td>50.341802</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.038894</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.018804</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.025962</td>\n",
       "      <td>-0.039749</td>\n",
       "      <td>...</td>\n",
       "      <td>427547.115339</td>\n",
       "      <td>14</td>\n",
       "      <td>-99.851610</td>\n",
       "      <td>-95.222125</td>\n",
       "      <td>-203.608763</td>\n",
       "      <td>-96.010364</td>\n",
       "      <td>-195.897457</td>\n",
       "      <td>-138.118064</td>\n",
       "      <td>50.408196</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.040011</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.018305</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.069847</td>\n",
       "      <td>0.104782</td>\n",
       "      <td>...</td>\n",
       "      <td>423228.925809</td>\n",
       "      <td>11</td>\n",
       "      <td>-92.703077</td>\n",
       "      <td>-90.234159</td>\n",
       "      <td>-197.797856</td>\n",
       "      <td>-91.917878</td>\n",
       "      <td>-186.646991</td>\n",
       "      <td>-131.859992</td>\n",
       "      <td>49.418142</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.039630</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.020125</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.165076</td>\n",
       "      <td>0.186799</td>\n",
       "      <td>...</td>\n",
       "      <td>415845.468010</td>\n",
       "      <td>9</td>\n",
       "      <td>-87.664722</td>\n",
       "      <td>-85.894446</td>\n",
       "      <td>-190.868457</td>\n",
       "      <td>-87.843898</td>\n",
       "      <td>-179.998475</td>\n",
       "      <td>-126.454000</td>\n",
       "      <td>48.283866</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.036209</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>0.019105</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.015302</td>\n",
       "      <td>-0.032057</td>\n",
       "      <td>...</td>\n",
       "      <td>422113.265269</td>\n",
       "      <td>13</td>\n",
       "      <td>-101.786783</td>\n",
       "      <td>-97.631856</td>\n",
       "      <td>-203.851890</td>\n",
       "      <td>-98.173605</td>\n",
       "      <td>-197.033795</td>\n",
       "      <td>-139.695586</td>\n",
       "      <td>49.667316</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.038033</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.104795</td>\n",
       "      <td>-0.150781</td>\n",
       "      <td>...</td>\n",
       "      <td>429428.716121</td>\n",
       "      <td>17</td>\n",
       "      <td>-109.577218</td>\n",
       "      <td>-105.079599</td>\n",
       "      <td>-211.994647</td>\n",
       "      <td>-104.775159</td>\n",
       "      <td>-205.967771</td>\n",
       "      <td>-147.478879</td>\n",
       "      <td>50.281363</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.052563</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.020674</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.083739</td>\n",
       "      <td>0.131634</td>\n",
       "      <td>...</td>\n",
       "      <td>422168.381850</td>\n",
       "      <td>10</td>\n",
       "      <td>-91.833590</td>\n",
       "      <td>-91.012171</td>\n",
       "      <td>-199.238788</td>\n",
       "      <td>-92.046335</td>\n",
       "      <td>-185.149860</td>\n",
       "      <td>-131.856149</td>\n",
       "      <td>49.468165</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.045665</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.021106</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.242821</td>\n",
       "      <td>0.319069</td>\n",
       "      <td>...</td>\n",
       "      <td>410947.325842</td>\n",
       "      <td>8</td>\n",
       "      <td>-83.150888</td>\n",
       "      <td>-86.966968</td>\n",
       "      <td>-187.413249</td>\n",
       "      <td>-86.515521</td>\n",
       "      <td>-172.035043</td>\n",
       "      <td>-123.216334</td>\n",
       "      <td>46.412749</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.043190</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.021007</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.305218</td>\n",
       "      <td>0.355021</td>\n",
       "      <td>...</td>\n",
       "      <td>396701.906970</td>\n",
       "      <td>5</td>\n",
       "      <td>-79.667376</td>\n",
       "      <td>-83.689685</td>\n",
       "      <td>-181.701872</td>\n",
       "      <td>-82.387020</td>\n",
       "      <td>-170.337633</td>\n",
       "      <td>-119.556717</td>\n",
       "      <td>46.259943</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.239260</td>\n",
       "      <td>0.271531</td>\n",
       "      <td>...</td>\n",
       "      <td>394075.393308</td>\n",
       "      <td>6</td>\n",
       "      <td>-83.292631</td>\n",
       "      <td>-82.381797</td>\n",
       "      <td>-184.484179</td>\n",
       "      <td>-84.201232</td>\n",
       "      <td>-171.985445</td>\n",
       "      <td>-121.269057</td>\n",
       "      <td>46.683520</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.038134</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>-0.012395</td>\n",
       "      <td>-0.027040</td>\n",
       "      <td>...</td>\n",
       "      <td>420990.416601</td>\n",
       "      <td>12</td>\n",
       "      <td>-101.519942</td>\n",
       "      <td>-97.181309</td>\n",
       "      <td>-203.515787</td>\n",
       "      <td>-97.873496</td>\n",
       "      <td>-196.652576</td>\n",
       "      <td>-139.348622</td>\n",
       "      <td>49.659733</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.138570</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>0.020051</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.225217</td>\n",
       "      <td>0.262840</td>\n",
       "      <td>...</td>\n",
       "      <td>408552.088014</td>\n",
       "      <td>7</td>\n",
       "      <td>-98.157854</td>\n",
       "      <td>-93.011717</td>\n",
       "      <td>-202.534644</td>\n",
       "      <td>-98.903597</td>\n",
       "      <td>-179.578620</td>\n",
       "      <td>-134.437287</td>\n",
       "      <td>46.839958</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.082999</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.540389</td>\n",
       "      <td>0.323371</td>\n",
       "      <td>...</td>\n",
       "      <td>382086.767409</td>\n",
       "      <td>3</td>\n",
       "      <td>-71.396882</td>\n",
       "      <td>-90.114386</td>\n",
       "      <td>-174.280109</td>\n",
       "      <td>-82.700193</td>\n",
       "      <td>-161.067666</td>\n",
       "      <td>-115.911847</td>\n",
       "      <td>42.885912</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050942</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.433401</td>\n",
       "      <td>0.346227</td>\n",
       "      <td>...</td>\n",
       "      <td>316828.773714</td>\n",
       "      <td>1</td>\n",
       "      <td>-75.785985</td>\n",
       "      <td>-85.596157</td>\n",
       "      <td>-163.218341</td>\n",
       "      <td>-79.871229</td>\n",
       "      <td>-156.230758</td>\n",
       "      <td>-112.140494</td>\n",
       "      <td>39.039609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.040777</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.018094</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.372092</td>\n",
       "      <td>0.332223</td>\n",
       "      <td>...</td>\n",
       "      <td>356336.719825</td>\n",
       "      <td>2</td>\n",
       "      <td>-80.111447</td>\n",
       "      <td>-84.588104</td>\n",
       "      <td>-177.647612</td>\n",
       "      <td>-80.533560</td>\n",
       "      <td>-164.637281</td>\n",
       "      <td>-117.503601</td>\n",
       "      <td>44.016526</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.037382</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.247460</td>\n",
       "      <td>0.279605</td>\n",
       "      <td>...</td>\n",
       "      <td>388515.186103</td>\n",
       "      <td>4</td>\n",
       "      <td>-82.960006</td>\n",
       "      <td>-81.147344</td>\n",
       "      <td>-183.112629</td>\n",
       "      <td>-84.003656</td>\n",
       "      <td>-170.672024</td>\n",
       "      <td>-120.379132</td>\n",
       "      <td>46.319253</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.038650      0.001670         0.019102        0.002361     0.1   \n",
       "1        0.038336      0.001807         0.020526        0.002390     0.1   \n",
       "2        0.039223      0.001739         0.018719        0.002943     0.1   \n",
       "3        0.040140      0.003246         0.020396        0.001448     0.1   \n",
       "4        0.036900      0.005497         0.019622        0.001425     0.1   \n",
       "5        0.034551      0.002785         0.015789        0.001491       1   \n",
       "6        0.033711      0.003129         0.018014        0.002074       1   \n",
       "7        0.036652      0.003050         0.019635        0.001844       1   \n",
       "8        0.036181      0.004269         0.016895        0.000209       1   \n",
       "9        0.037356      0.001495         0.018919        0.001363       1   \n",
       "10       0.038894      0.002337         0.018804        0.003188      10   \n",
       "11       0.040011      0.002548         0.018305        0.002443      10   \n",
       "12       0.039630      0.002046         0.020125        0.002462      10   \n",
       "13       0.036209      0.003414         0.019105        0.003139      10   \n",
       "14       0.038033      0.002445         0.018344        0.002178      10   \n",
       "15       0.052563      0.002906         0.020674        0.002500     100   \n",
       "16       0.045665      0.002427         0.021106        0.002289     100   \n",
       "17       0.043190      0.003041         0.021007        0.001226     100   \n",
       "18       0.040001      0.002604         0.018408        0.001743     100   \n",
       "19       0.038134      0.002448         0.018212        0.001935     100   \n",
       "20       0.138570      0.014401         0.020051        0.002366    1000   \n",
       "21       0.082999      0.004883         0.017404        0.002060    1000   \n",
       "22       0.050942      0.007307         0.018833        0.002617    1000   \n",
       "23       0.040777      0.001105         0.018094        0.001395    1000   \n",
       "24       0.037382      0.001665         0.017500        0.002093    1000   \n",
       "\n",
       "   param_gamma param_kernel                                         params  \\\n",
       "0            1          rbf        {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "1          0.1          rbf      {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "2         0.01          rbf     {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "3        0.001          rbf    {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "4       0.0001          rbf   {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "5            1          rbf          {'C': 1, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "6          0.1          rbf        {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "7         0.01          rbf       {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "8        0.001          rbf      {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "9       0.0001          rbf     {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "10           1          rbf         {'C': 10, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "11         0.1          rbf       {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "12        0.01          rbf      {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "13       0.001          rbf     {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "14      0.0001          rbf    {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "15           1          rbf        {'C': 100, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "16         0.1          rbf      {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "17        0.01          rbf     {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "18       0.001          rbf    {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "19      0.0001          rbf   {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "20           1          rbf       {'C': 1000, 'gamma': 1, 'kernel': 'rbf'}   \n",
       "21         0.1          rbf     {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}   \n",
       "22        0.01          rbf    {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}   \n",
       "23       0.001          rbf   {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "24      0.0001          rbf  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
       "\n",
       "    split0_test_R2  split1_test_R2  ...   std_test_MAE  rank_test_MAE  \\\n",
       "0        -0.114879       -0.165413  ...  430451.702800             24   \n",
       "1        -0.107186       -0.156006  ...  430041.870067             20   \n",
       "2        -0.108303       -0.156222  ...  430008.956129             21   \n",
       "3        -0.116087       -0.166075  ...  430370.206482             23   \n",
       "4        -0.117070       -0.167555  ...  430456.981848             25   \n",
       "5        -0.099695       -0.146750  ...  430073.173873             19   \n",
       "6        -0.050985       -0.081246  ...  428069.496064             16   \n",
       "7        -0.043518       -0.069866  ...  426724.975178             15   \n",
       "8        -0.105213       -0.151156  ...  429544.435390             18   \n",
       "9        -0.116067       -0.166014  ...  430360.548514             22   \n",
       "10       -0.025962       -0.039749  ...  427547.115339             14   \n",
       "11        0.069847        0.104782  ...  423228.925809             11   \n",
       "12        0.165076        0.186799  ...  415845.468010              9   \n",
       "13       -0.015302       -0.032057  ...  422113.265269             13   \n",
       "14       -0.104795       -0.150781  ...  429428.716121             17   \n",
       "15        0.083739        0.131634  ...  422168.381850             10   \n",
       "16        0.242821        0.319069  ...  410947.325842              8   \n",
       "17        0.305218        0.355021  ...  396701.906970              5   \n",
       "18        0.239260        0.271531  ...  394075.393308              6   \n",
       "19       -0.012395       -0.027040  ...  420990.416601             12   \n",
       "20        0.225217        0.262840  ...  408552.088014              7   \n",
       "21        0.540389        0.323371  ...  382086.767409              3   \n",
       "22        0.433401        0.346227  ...  316828.773714              1   \n",
       "23        0.372092        0.332223  ...  356336.719825              2   \n",
       "24        0.247460        0.279605  ...  388515.186103              4   \n",
       "\n",
       "    split0_test_RMSE  split1_test_RMSE  split2_test_RMSE  split3_test_RMSE  \\\n",
       "0        -110.291486       -105.793807       -212.749715       -105.424461   \n",
       "1        -109.540750       -105.003265       -211.879231       -104.676014   \n",
       "2        -109.843893       -105.321114       -212.239713       -105.000097   \n",
       "3        -110.556761       -106.021641       -212.983321       -105.632846   \n",
       "4        -110.654858       -106.113647       -213.082777       -105.718181   \n",
       "5        -107.387889       -103.131914       -210.177969       -102.755790   \n",
       "6        -102.666934        -98.294021       -205.275985        -98.629694   \n",
       "7        -104.028729        -99.604877       -206.188801       -100.003126   \n",
       "8        -109.604278       -105.107962       -212.023198       -104.801072   \n",
       "9        -110.554239       -106.017920       -212.980533       -105.631238   \n",
       "10        -99.851610        -95.222125       -203.608763        -96.010364   \n",
       "11        -92.703077        -90.234159       -197.797856        -91.917878   \n",
       "12        -87.664722        -85.894446       -190.868457        -87.843898   \n",
       "13       -101.786783        -97.631856       -203.851890        -98.173605   \n",
       "14       -109.577218       -105.079599       -211.994647       -104.775159   \n",
       "15        -91.833590        -91.012171       -199.238788        -92.046335   \n",
       "16        -83.150888        -86.966968       -187.413249        -86.515521   \n",
       "17        -79.667376        -83.689685       -181.701872        -82.387020   \n",
       "18        -83.292631        -82.381797       -184.484179        -84.201232   \n",
       "19       -101.519942        -97.181309       -203.515787        -97.873496   \n",
       "20        -98.157854        -93.011717       -202.534644        -98.903597   \n",
       "21        -71.396882        -90.114386       -174.280109        -82.700193   \n",
       "22        -75.785985        -85.596157       -163.218341        -79.871229   \n",
       "23        -80.111447        -84.588104       -177.647612        -80.533560   \n",
       "24        -82.960006        -81.147344       -183.112629        -84.003656   \n",
       "\n",
       "    split4_test_RMSE  mean_test_RMSE  std_test_RMSE  rank_test_RMSE  \n",
       "0        -206.827683     -148.217431      50.336779              22  \n",
       "1        -205.831297     -147.386111      50.255212              18  \n",
       "2        -206.239586     -147.728881      50.288349              21  \n",
       "3        -207.081193     -148.455153      50.341907              24  \n",
       "4        -207.191992     -148.552291      50.348412              25  \n",
       "5        -203.944047     -145.479522      50.346002              17  \n",
       "6        -198.528902     -140.679107      50.057825              15  \n",
       "7        -199.657573     -141.896621      49.894781              16  \n",
       "8        -205.997968     -147.506896      50.282451              20  \n",
       "9        -207.078313     -148.452448      50.341802              23  \n",
       "10       -195.897457     -138.118064      50.408196              12  \n",
       "11       -186.646991     -131.859992      49.418142              10  \n",
       "12       -179.998475     -126.454000      48.283866               8  \n",
       "13       -197.033795     -139.695586      49.667316              14  \n",
       "14       -205.967771     -147.478879      50.281363              19  \n",
       "15       -185.149860     -131.856149      49.468165               9  \n",
       "16       -172.035043     -123.216334      46.412749               7  \n",
       "17       -170.337633     -119.556717      46.259943               4  \n",
       "18       -171.985445     -121.269057      46.683520               6  \n",
       "19       -196.652576     -139.348622      49.659733              13  \n",
       "20       -179.578620     -134.437287      46.839958              11  \n",
       "21       -161.067666     -115.911847      42.885912               2  \n",
       "22       -156.230758     -112.140494      39.039609               1  \n",
       "23       -164.637281     -117.503601      44.016526               3  \n",
       "24       -170.672024     -120.379132      46.319253               5  \n",
       "\n",
       "[25 rows x 32 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MySVMbest=pd.concat([pd.DataFrame(MySVM.cv_results_)])\n",
    "MySVMbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22    0.35161\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MySVMbestR2=MySVMbest[MySVMbest['rank_test_R2'].isin([1])]\n",
    "print(MySVMbestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[11:27:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:39] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:40] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.2s\n",
      "[11:27:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:41] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:43] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:44] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.2s\n",
      "[11:27:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.2s\n",
      "[11:27:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:45] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=5, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:46] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=6, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:47] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n",
      "[11:27:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:27:48] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.07, max_depth=7, min_child_weight=4, n_estimators=500, nthread=4, objective=reg:linear, silent=1, subsample=0.7; total time=   0.1s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MyXGBBoost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_81964\\1931691689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mMyXGBoost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mMyXGBBoost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'MyXGBBoost' is not defined"
     ]
    }
   ],
   "source": [
    "MyXGB = xg.XGBRegressor(objective ='reg:squarederror',\n",
    "                  n_estimators = 10, seed = 123)\n",
    "XGBparams = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "  \n",
    "# Fitting the model\n",
    "MyXGB.fit(X_train_std, y_train)\n",
    "  \n",
    "# Predict the model\n",
    "\n",
    "\n",
    "MyXGBoost = GridSearchCV(MyXGB,\n",
    "                        XGBparams,\n",
    "                          scoring=scoring,\n",
    "                        refit=False,\n",
    "                        cv = CV,\n",
    "                        \n",
    "                        verbose=2)\n",
    "\n",
    "MyXGBoost.fit(X_train_std,y_train)\n",
    "MyXGBBoost.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_nthread</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_MAE</th>\n",
       "      <th>rank_test_MAE</th>\n",
       "      <th>split0_test_RMSE</th>\n",
       "      <th>split1_test_RMSE</th>\n",
       "      <th>split2_test_RMSE</th>\n",
       "      <th>split3_test_RMSE</th>\n",
       "      <th>split4_test_RMSE</th>\n",
       "      <th>mean_test_RMSE</th>\n",
       "      <th>std_test_RMSE</th>\n",
       "      <th>rank_test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.180251</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>97930.174993</td>\n",
       "      <td>7</td>\n",
       "      <td>-120.947956</td>\n",
       "      <td>-102.895399</td>\n",
       "      <td>-147.279376</td>\n",
       "      <td>-96.567335</td>\n",
       "      <td>-125.848287</td>\n",
       "      <td>-118.707671</td>\n",
       "      <td>17.958686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.207161</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>101310.791983</td>\n",
       "      <td>9</td>\n",
       "      <td>-122.540755</td>\n",
       "      <td>-100.749995</td>\n",
       "      <td>-148.707301</td>\n",
       "      <td>-99.285887</td>\n",
       "      <td>-125.809011</td>\n",
       "      <td>-119.418590</td>\n",
       "      <td>18.233245</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237962</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>99286.037338</td>\n",
       "      <td>8</td>\n",
       "      <td>-122.969813</td>\n",
       "      <td>-98.857935</td>\n",
       "      <td>-147.044594</td>\n",
       "      <td>-100.872153</td>\n",
       "      <td>-127.109771</td>\n",
       "      <td>-119.370853</td>\n",
       "      <td>17.897827</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.188592</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>81788.474155</td>\n",
       "      <td>4</td>\n",
       "      <td>-119.423260</td>\n",
       "      <td>-104.276774</td>\n",
       "      <td>-143.011182</td>\n",
       "      <td>-99.914364</td>\n",
       "      <td>-131.481749</td>\n",
       "      <td>-119.621466</td>\n",
       "      <td>16.196382</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.208415</td>\n",
       "      <td>0.007717</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>79691.576906</td>\n",
       "      <td>5</td>\n",
       "      <td>-123.253053</td>\n",
       "      <td>-102.567851</td>\n",
       "      <td>-143.870143</td>\n",
       "      <td>-99.680475</td>\n",
       "      <td>-137.376807</td>\n",
       "      <td>-121.349666</td>\n",
       "      <td>17.832411</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.240299</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>79659.991741</td>\n",
       "      <td>6</td>\n",
       "      <td>-127.247414</td>\n",
       "      <td>-102.444674</td>\n",
       "      <td>-144.325529</td>\n",
       "      <td>-102.376150</td>\n",
       "      <td>-136.509185</td>\n",
       "      <td>-122.580590</td>\n",
       "      <td>17.333793</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.187018</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>73677.944227</td>\n",
       "      <td>2</td>\n",
       "      <td>-125.702897</td>\n",
       "      <td>-105.314471</td>\n",
       "      <td>-140.024831</td>\n",
       "      <td>-103.003759</td>\n",
       "      <td>-133.164699</td>\n",
       "      <td>-121.442131</td>\n",
       "      <td>14.838898</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.210019</td>\n",
       "      <td>0.010449</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>73021.913309</td>\n",
       "      <td>1</td>\n",
       "      <td>-126.978439</td>\n",
       "      <td>-105.321432</td>\n",
       "      <td>-141.740284</td>\n",
       "      <td>-102.676792</td>\n",
       "      <td>-134.728024</td>\n",
       "      <td>-122.288994</td>\n",
       "      <td>15.669139</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235122</td>\n",
       "      <td>0.007091</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>74353.085248</td>\n",
       "      <td>3</td>\n",
       "      <td>-131.557249</td>\n",
       "      <td>-105.943636</td>\n",
       "      <td>-142.524267</td>\n",
       "      <td>-104.329094</td>\n",
       "      <td>-135.963678</td>\n",
       "      <td>-124.063585</td>\n",
       "      <td>15.851477</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.180251      0.002093         0.005029        0.001537   \n",
       "1       0.207161      0.005790         0.004855        0.000523   \n",
       "2       0.237962      0.008281         0.004718        0.000647   \n",
       "3       0.188592      0.006908         0.004601        0.000800   \n",
       "4       0.208415      0.007717         0.004952        0.000258   \n",
       "5       0.240299      0.012572         0.005026        0.000595   \n",
       "6       0.187018      0.007596         0.004684        0.000735   \n",
       "7       0.210019      0.010449         0.005033        0.000607   \n",
       "8       0.235122      0.007091         0.004652        0.000443   \n",
       "\n",
       "  param_colsample_bytree param_learning_rate param_max_depth  \\\n",
       "0                    0.7                0.03               5   \n",
       "1                    0.7                0.03               6   \n",
       "2                    0.7                0.03               7   \n",
       "3                    0.7                0.05               5   \n",
       "4                    0.7                0.05               6   \n",
       "5                    0.7                0.05               7   \n",
       "6                    0.7                0.07               5   \n",
       "7                    0.7                0.07               6   \n",
       "8                    0.7                0.07               7   \n",
       "\n",
       "  param_min_child_weight param_n_estimators param_nthread  ...   std_test_MAE  \\\n",
       "0                      4                500             4  ...   97930.174993   \n",
       "1                      4                500             4  ...  101310.791983   \n",
       "2                      4                500             4  ...   99286.037338   \n",
       "3                      4                500             4  ...   81788.474155   \n",
       "4                      4                500             4  ...   79691.576906   \n",
       "5                      4                500             4  ...   79659.991741   \n",
       "6                      4                500             4  ...   73677.944227   \n",
       "7                      4                500             4  ...   73021.913309   \n",
       "8                      4                500             4  ...   74353.085248   \n",
       "\n",
       "  rank_test_MAE split0_test_RMSE split1_test_RMSE  split2_test_RMSE  \\\n",
       "0             7      -120.947956      -102.895399       -147.279376   \n",
       "1             9      -122.540755      -100.749995       -148.707301   \n",
       "2             8      -122.969813       -98.857935       -147.044594   \n",
       "3             4      -119.423260      -104.276774       -143.011182   \n",
       "4             5      -123.253053      -102.567851       -143.870143   \n",
       "5             6      -127.247414      -102.444674       -144.325529   \n",
       "6             2      -125.702897      -105.314471       -140.024831   \n",
       "7             1      -126.978439      -105.321432       -141.740284   \n",
       "8             3      -131.557249      -105.943636       -142.524267   \n",
       "\n",
       "   split3_test_RMSE  split4_test_RMSE  mean_test_RMSE  std_test_RMSE  \\\n",
       "0        -96.567335       -125.848287     -118.707671      17.958686   \n",
       "1        -99.285887       -125.809011     -119.418590      18.233245   \n",
       "2       -100.872153       -127.109771     -119.370853      17.897827   \n",
       "3        -99.914364       -131.481749     -119.621466      16.196382   \n",
       "4        -99.680475       -137.376807     -121.349666      17.832411   \n",
       "5       -102.376150       -136.509185     -122.580590      17.333793   \n",
       "6       -103.003759       -133.164699     -121.442131      14.838898   \n",
       "7       -102.676792       -134.728024     -122.288994      15.669139   \n",
       "8       -104.329094       -135.963678     -124.063585      15.851477   \n",
       "\n",
       "   rank_test_RMSE  \n",
       "0               1  \n",
       "1               3  \n",
       "2               2  \n",
       "3               4  \n",
       "4               5  \n",
       "5               8  \n",
       "6               6  \n",
       "7               7  \n",
       "8               9  \n",
       "\n",
       "[9 rows x 38 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyXGBoostbest=pd.concat([pd.DataFrame(MyXGBoost.cv_results_)])\n",
    "MyXGBoostbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    0.086477\n",
      "Name: mean_test_R2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MyXGBoostbestR2=MyXGBoostbest[MyXGBoostbest['rank_test_R2'].isin([1])]\n",
    "print(MyXGBoostbestR2['mean_test_R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLEAU DES RESULTATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_features_to_select</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_R2</th>\n",
       "      <th>split1_test_R2</th>\n",
       "      <th>split2_test_R2</th>\n",
       "      <th>split3_test_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_nthread</th>\n",
       "      <th>param_objective</th>\n",
       "      <th>param_silent</th>\n",
       "      <th>param_subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013173</td>\n",
       "      <td>1.323881e-03</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>4.898040e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_features_to_select': 1}</td>\n",
       "      <td>-0.332148</td>\n",
       "      <td>-1.579617</td>\n",
       "      <td>0.268301</td>\n",
       "      <td>0.265267</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.431402e-07</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.168008e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.6000000000000001, ...</td>\n",
       "      <td>0.332023</td>\n",
       "      <td>0.066876</td>\n",
       "      <td>0.189315</td>\n",
       "      <td>0.331174</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001827</td>\n",
       "      <td>4.140824e-04</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>5.015850e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>-0.632771</td>\n",
       "      <td>-2.089992</td>\n",
       "      <td>0.510423</td>\n",
       "      <td>-0.787396</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>1.364709e-04</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>4.852514e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>-0.315227</td>\n",
       "      <td>-0.813688</td>\n",
       "      <td>0.277667</td>\n",
       "      <td>-0.279276</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.062567</td>\n",
       "      <td>7.300494e-04</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>4.021222e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.667255</td>\n",
       "      <td>0.163272</td>\n",
       "      <td>0.474348</td>\n",
       "      <td>0.193593</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050942</td>\n",
       "      <td>7.307321e-03</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>2.616927e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.433401</td>\n",
       "      <td>0.346227</td>\n",
       "      <td>0.253816</td>\n",
       "      <td>0.476430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.210019</td>\n",
       "      <td>1.044898e-02</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>6.070893e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'colsample_bytree': 0.7, 'learning_rate': 0.0...</td>\n",
       "      <td>-1.298538</td>\n",
       "      <td>-0.005554</td>\n",
       "      <td>0.752974</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>reg:linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.013173  1.323881e-03         0.002400    4.898040e-04   \n",
       "227       0.001000  2.431402e-07         0.002000    1.168008e-07   \n",
       "6         0.001827  4.140824e-04         0.001707    5.015850e-04   \n",
       "6         0.001073  1.364709e-04         0.001413    4.852514e-04   \n",
       "21        0.062567  7.300494e-04         0.005705    4.021222e-04   \n",
       "22        0.050942  7.307321e-03         0.018833    2.616927e-03   \n",
       "7         0.210019  1.044898e-02         0.005033    6.070893e-04   \n",
       "\n",
       "    param_n_features_to_select  \\\n",
       "0                            1   \n",
       "227                        NaN   \n",
       "6                          NaN   \n",
       "6                          NaN   \n",
       "21                         NaN   \n",
       "22                         NaN   \n",
       "7                          NaN   \n",
       "\n",
       "                                                params  split0_test_R2  \\\n",
       "0                          {'n_features_to_select': 1}       -0.332148   \n",
       "227  {'alpha': 10, 'l1_ratio': 0.6000000000000001, ...        0.332023   \n",
       "6                                       {'alpha': 100}       -0.632771   \n",
       "6                                       {'alpha': 100}       -0.315227   \n",
       "21   {'max_features': 'sqrt', 'min_samples_leaf': 1...        0.667255   \n",
       "22         {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}        0.433401   \n",
       "7    {'colsample_bytree': 0.7, 'learning_rate': 0.0...       -1.298538   \n",
       "\n",
       "     split1_test_R2  split2_test_R2  split3_test_R2  ...  param_gamma  \\\n",
       "0         -1.579617        0.268301        0.265267  ...          NaN   \n",
       "227        0.066876        0.189315        0.331174  ...          NaN   \n",
       "6         -2.089992        0.510423       -0.787396  ...          NaN   \n",
       "6         -0.813688        0.277667       -0.279276  ...          NaN   \n",
       "21         0.163272        0.474348        0.193593  ...          NaN   \n",
       "22         0.346227        0.253816        0.476430  ...         0.01   \n",
       "7         -0.005554        0.752974        0.112676  ...          NaN   \n",
       "\n",
       "     param_kernel  param_colsample_bytree  param_learning_rate  \\\n",
       "0             NaN                     NaN                  NaN   \n",
       "227           NaN                     NaN                  NaN   \n",
       "6             NaN                     NaN                  NaN   \n",
       "6             NaN                     NaN                  NaN   \n",
       "21            NaN                     NaN                  NaN   \n",
       "22            rbf                     NaN                  NaN   \n",
       "7             NaN                     0.7                 0.07   \n",
       "\n",
       "     param_max_depth  param_min_child_weight  param_nthread  param_objective  \\\n",
       "0                NaN                     NaN            NaN              NaN   \n",
       "227              NaN                     NaN            NaN              NaN   \n",
       "6                NaN                     NaN            NaN              NaN   \n",
       "6                NaN                     NaN            NaN              NaN   \n",
       "21               NaN                     NaN            NaN              NaN   \n",
       "22               NaN                     NaN            NaN              NaN   \n",
       "7                  6                       4              4       reg:linear   \n",
       "\n",
       "     param_silent  param_subsample  \n",
       "0             NaN              NaN  \n",
       "227           NaN              NaN  \n",
       "6             NaN              NaN  \n",
       "6             NaN              NaN  \n",
       "21            NaN              NaN  \n",
       "22            NaN              NaN  \n",
       "7               1              0.7  \n",
       "\n",
       "[7 rows x 68 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_concat = [MyDummybestR2,MyElasticbestR2,MyRidgebestR2,MyLassobestR2,MyRandombestR2, MySVMbestR2, MyXGBoostbestR2]\n",
    "tab_result=pd.concat(liste_concat)\n",
    "tab_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST SANS CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5912571523064641\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MyRandomtest = RandomForestRegressor(n_estimators = 500, random_state = 42)\n",
    "\n",
    "MyRandomtest.fit(X_train_std, y_train)\n",
    "MyRandomtest_predict = MyRandomtest.predict(X_test_std)\n",
    "\n",
    "\n",
    "mse_MyRandomtest_predict = mean_squared_error(y_test, MyRandomtest_predict)\n",
    "mae_MyRandomtest_predict = mean_absolute_error(y_test, MyRandomtest_predict)\n",
    "rmse_MyRandomtest_predict= mse_MyRandomtest_predict**.5\n",
    "r2_MyRandomtest_predict = r2_score(y_test.values.ravel(), MyRandomtest_predict)\n",
    "print(r2_MyRandomtest_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST SANS CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5247594603109658\n"
     ]
    }
   ],
   "source": [
    "MyXGBtest = xg.XGBRegressor(objective ='reg:squarederror',\n",
    "                  n_estimators = 10, seed = 123)\n",
    "XGBparams = {'nthread':[4], \n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03], \n",
    "              'max_depth': [5],\n",
    "              'min_child_weight': [4],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "  \n",
    "# Fitting the model\n",
    "MyXGBtest.fit(X_train_std, y_train)\n",
    "\n",
    "MyXGBtest_predict = MyXGBtest.predict(X_test_std)\n",
    "\n",
    "mse_MyXGBtest_predict = mean_squared_error(y_test, MyXGBtest_predict)\n",
    "mae_MyXGBtest_predict = mean_absolute_error(y_test, MyXGBtest_predict)\n",
    "rmse_MyXGBtest_predict= mse_MyXGBtest_predict**.5\n",
    "r2_MyXGBtest_predict = r2_score(y_test.values.ravel(), MyXGBtest_predict)\n",
    "print(r2_MyXGBtest_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST AVEC ENERGY SCORE LE MEILLEUR MODELE RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNRJ2[\"ENERGYSTARScore\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>SteamUse_Part</th>\n",
       "      <th>NaturalGas_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>LargestPropertyUseType_Distribution</th>\n",
       "      <th>LargestPropertyUseType_Food</th>\n",
       "      <th>LargestPropertyUseType_Hotel</th>\n",
       "      <th>LargestPropertyUseType_Legal</th>\n",
       "      <th>LargestPropertyUseType_Medical</th>\n",
       "      <th>LargestPropertyUseType_Office</th>\n",
       "      <th>LargestPropertyUseType_Other</th>\n",
       "      <th>LargestPropertyUseType_Parking</th>\n",
       "      <th>LargestPropertyUseType_School</th>\n",
       "      <th>LargestPropertyUseType_Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7.456910e+06</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277302</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.664479e+06</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7.393711e+07</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.946800e+06</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.465650e+07</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>18261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.025432e+06</td>\n",
       "      <td>20.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.053706e+06</td>\n",
       "      <td>32.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>13157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.053764e+06</td>\n",
       "      <td>223.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310820</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>14101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.828413e+05</td>\n",
       "      <td>22.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>18258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.293722e+06</td>\n",
       "      <td>41.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375189</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PropertyGFATotal  NumberofBuildings  NumberofFloors  \\\n",
       "0                88434                1.0              12   \n",
       "1               103566                1.0              11   \n",
       "2               956110                1.0              41   \n",
       "3                61320                1.0              10   \n",
       "4               175580                1.0              18   \n",
       "...                ...                ...             ...   \n",
       "1509             18261                1.0               1   \n",
       "1510             16000                1.0               1   \n",
       "1511             13157                1.0               1   \n",
       "1512             14101                1.0               1   \n",
       "1513             18258                1.0               1   \n",
       "\n",
       "      SiteEnergyUseWN(kBtu)  TotalGHGEmissions  Electricity_Use  \\\n",
       "0              7.456910e+06             249.98                1   \n",
       "1              8.664479e+06             295.86                1   \n",
       "2              7.393711e+07            2089.28                1   \n",
       "3              6.946800e+06             286.43                1   \n",
       "4              1.465650e+07             505.01                1   \n",
       "...                     ...                ...              ...   \n",
       "1509           1.025432e+06              20.33                1   \n",
       "1510           1.053706e+06              32.17                1   \n",
       "1511           6.053764e+06             223.54                1   \n",
       "1512           7.828413e+05              22.11                1   \n",
       "1513           1.293722e+06              41.27                1   \n",
       "\n",
       "      Electricity_Part  SteamUse_Use  SteamUse_Part  NaturalGas_Use  ...  \\\n",
       "0             0.546060             1       0.277302               1  ...   \n",
       "1             0.386609             0       0.000000               1  ...   \n",
       "2             0.682307             1       0.297113               1  ...   \n",
       "3             0.407519             1       0.325913               1  ...   \n",
       "4             0.378802             0       0.000000               1  ...   \n",
       "...                ...           ...            ...             ...  ...   \n",
       "1509          0.678440             0       0.000000               1  ...   \n",
       "1510          0.417296             0       0.000000               1  ...   \n",
       "1511          0.310820             0       0.000000               1  ...   \n",
       "1512          0.484898             0       0.000000               1  ...   \n",
       "1513          0.375189             0       0.000000               1  ...   \n",
       "\n",
       "      LargestPropertyUseType_Distribution  LargestPropertyUseType_Food  \\\n",
       "0                                       0                            0   \n",
       "1                                       0                            0   \n",
       "2                                       0                            0   \n",
       "3                                       0                            0   \n",
       "4                                       0                            0   \n",
       "...                                   ...                          ...   \n",
       "1509                                    0                            0   \n",
       "1510                                    0                            0   \n",
       "1511                                    0                            0   \n",
       "1512                                    0                            0   \n",
       "1513                                    0                            0   \n",
       "\n",
       "      LargestPropertyUseType_Hotel  LargestPropertyUseType_Legal  \\\n",
       "0                                1                             0   \n",
       "1                                1                             0   \n",
       "2                                1                             0   \n",
       "3                                1                             0   \n",
       "4                                1                             0   \n",
       "...                            ...                           ...   \n",
       "1509                             0                             0   \n",
       "1510                             0                             0   \n",
       "1511                             0                             0   \n",
       "1512                             0                             0   \n",
       "1513                             0                             0   \n",
       "\n",
       "      LargestPropertyUseType_Medical  LargestPropertyUseType_Office  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "...                              ...                            ...   \n",
       "1509                               0                              0   \n",
       "1510                               0                              0   \n",
       "1511                               0                              0   \n",
       "1512                               0                              0   \n",
       "1513                               0                              0   \n",
       "\n",
       "      LargestPropertyUseType_Other  LargestPropertyUseType_Parking  \\\n",
       "0                                0                               0   \n",
       "1                                0                               0   \n",
       "2                                0                               0   \n",
       "3                                0                               0   \n",
       "4                                0                               0   \n",
       "...                            ...                             ...   \n",
       "1509                             0                               0   \n",
       "1510                             0                               0   \n",
       "1511                             0                               0   \n",
       "1512                             0                               0   \n",
       "1513                             0                               0   \n",
       "\n",
       "      LargestPropertyUseType_School  LargestPropertyUseType_Sport  \n",
       "0                                 0                             0  \n",
       "1                                 0                             0  \n",
       "2                                 0                             0  \n",
       "3                                 0                             0  \n",
       "4                                 0                             0  \n",
       "...                             ...                           ...  \n",
       "1509                              0                             0  \n",
       "1510                              0                             0  \n",
       "1511                              0                             0  \n",
       "1512                              0                             0  \n",
       "1513                              0                             0  \n",
       "\n",
       "[1514 rows x 37 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNRJ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNRJ2.dropna(subset=\"ENERGYSTARScore\", inplace=True)\n",
    "dfNRJ2.dropna(subset=\"SiteEUIWN(kBtu/sf)\", inplace=True)\n",
    "dfNRJ2.dropna(subset=\"SiteEnergyUseWN(kBtu)\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropertyGFATotal                       0\n",
       "NumberofBuildings                      0\n",
       "NumberofFloors                         0\n",
       "SiteEnergyUseWN(kBtu)                  0\n",
       "TotalGHGEmissions                      0\n",
       "Electricity_Use                        0\n",
       "Electricity_Part                       0\n",
       "SteamUse_Use                           0\n",
       "SteamUse_Part                          0\n",
       "NaturalGas_Use                         0\n",
       "NaturalGas_Part                        0\n",
       "ENERGYSTARScore                        0\n",
       "age_building                           0\n",
       "part_park                              0\n",
       "SiteEUI(kBtu/sf)                       0\n",
       "SiteEUIWN(kBtu/sf)                     0\n",
       "SourceEUI(kBtu/sf)                     0\n",
       "SourceEUIWN(kBtu/sf)                   0\n",
       "SiteEnergyUse(kBtu)                    0\n",
       "PropertyGFABuilding(s)                 0\n",
       "GHGEmissionsIntensity                  0\n",
       "PrimaryPropertyType_Hotel              0\n",
       "PrimaryPropertyType_Medical            0\n",
       "PrimaryPropertyType_Office             0\n",
       "PrimaryPropertyType_Other              0\n",
       "PrimaryPropertyType_School             0\n",
       "LargestPropertyUseType_Culture         0\n",
       "LargestPropertyUseType_Distribution    0\n",
       "LargestPropertyUseType_Food            0\n",
       "LargestPropertyUseType_Hotel           0\n",
       "LargestPropertyUseType_Legal           0\n",
       "LargestPropertyUseType_Medical         0\n",
       "LargestPropertyUseType_Office          0\n",
       "LargestPropertyUseType_Other           0\n",
       "LargestPropertyUseType_Parking         0\n",
       "LargestPropertyUseType_School          0\n",
       "LargestPropertyUseType_Sport           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNRJ2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>SiteEnergyUseWN(kBtu)</th>\n",
       "      <th>TotalGHGEmissions</th>\n",
       "      <th>Electricity_Use</th>\n",
       "      <th>Electricity_Part</th>\n",
       "      <th>SteamUse_Use</th>\n",
       "      <th>SteamUse_Part</th>\n",
       "      <th>NaturalGas_Use</th>\n",
       "      <th>...</th>\n",
       "      <th>LargestPropertyUseType_Distribution</th>\n",
       "      <th>LargestPropertyUseType_Food</th>\n",
       "      <th>LargestPropertyUseType_Hotel</th>\n",
       "      <th>LargestPropertyUseType_Legal</th>\n",
       "      <th>LargestPropertyUseType_Medical</th>\n",
       "      <th>LargestPropertyUseType_Office</th>\n",
       "      <th>LargestPropertyUseType_Other</th>\n",
       "      <th>LargestPropertyUseType_Parking</th>\n",
       "      <th>LargestPropertyUseType_School</th>\n",
       "      <th>LargestPropertyUseType_Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7.456910e+06</td>\n",
       "      <td>249.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277302</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.664479e+06</td>\n",
       "      <td>295.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7.393711e+07</td>\n",
       "      <td>2089.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297113</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.946800e+06</td>\n",
       "      <td>286.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325913</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.465650e+07</td>\n",
       "      <td>505.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>536697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.403717e+07</td>\n",
       "      <td>245.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.749734</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>126823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.042400e+06</td>\n",
       "      <td>131.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.681123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>52085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.182622e+06</td>\n",
       "      <td>157.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203226</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>24990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.731814e+06</td>\n",
       "      <td>134.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490206</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>45000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.397742e+06</td>\n",
       "      <td>9.24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>983 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PropertyGFATotal  NumberofBuildings  NumberofFloors  \\\n",
       "0                88434                1.0              12   \n",
       "1               103566                1.0              11   \n",
       "2               956110                1.0              41   \n",
       "3                61320                1.0              10   \n",
       "4               175580                1.0              18   \n",
       "...                ...                ...             ...   \n",
       "1493            536697                1.0              13   \n",
       "1494            126823                1.0               4   \n",
       "1495             52085                1.0               1   \n",
       "1496             24990                1.0               2   \n",
       "1498             45000                1.0               3   \n",
       "\n",
       "      SiteEnergyUseWN(kBtu)  TotalGHGEmissions  Electricity_Use  \\\n",
       "0              7.456910e+06             249.98                1   \n",
       "1              8.664479e+06             295.86                1   \n",
       "2              7.393711e+07            2089.28                1   \n",
       "3              6.946800e+06             286.43                1   \n",
       "4              1.465650e+07             505.01                1   \n",
       "...                     ...                ...              ...   \n",
       "1493           1.403717e+07             245.16                1   \n",
       "1494           6.042400e+06             131.02                1   \n",
       "1495           4.182622e+06             157.70                1   \n",
       "1496           4.731814e+06             134.80                1   \n",
       "1498           1.397742e+06               9.24                1   \n",
       "\n",
       "      Electricity_Part  SteamUse_Use  SteamUse_Part  NaturalGas_Use  ...  \\\n",
       "0             0.546060             1       0.277302               1  ...   \n",
       "1             0.386609             0       0.000000               1  ...   \n",
       "2             0.682307             1       0.297113               1  ...   \n",
       "3             0.407519             1       0.325913               1  ...   \n",
       "4             0.378802             0       0.000000               1  ...   \n",
       "...                ...           ...            ...             ...  ...   \n",
       "1493          0.749734             0       0.000000               1  ...   \n",
       "1494          0.681123             0       0.000000               1  ...   \n",
       "1495          0.203226             0       0.000000               1  ...   \n",
       "1496          0.490206             0       0.000000               1  ...   \n",
       "1498          1.000000             0       0.000000               0  ...   \n",
       "\n",
       "      LargestPropertyUseType_Distribution  LargestPropertyUseType_Food  \\\n",
       "0                                       0                            0   \n",
       "1                                       0                            0   \n",
       "2                                       0                            0   \n",
       "3                                       0                            0   \n",
       "4                                       0                            0   \n",
       "...                                   ...                          ...   \n",
       "1493                                    0                            0   \n",
       "1494                                    0                            0   \n",
       "1495                                    1                            0   \n",
       "1496                                    0                            0   \n",
       "1498                                    0                            0   \n",
       "\n",
       "      LargestPropertyUseType_Hotel  LargestPropertyUseType_Legal  \\\n",
       "0                                1                             0   \n",
       "1                                1                             0   \n",
       "2                                1                             0   \n",
       "3                                1                             0   \n",
       "4                                1                             0   \n",
       "...                            ...                           ...   \n",
       "1493                             0                             0   \n",
       "1494                             1                             0   \n",
       "1495                             0                             0   \n",
       "1496                             0                             0   \n",
       "1498                             0                             0   \n",
       "\n",
       "      LargestPropertyUseType_Medical  LargestPropertyUseType_Office  \\\n",
       "0                                  0                              0   \n",
       "1                                  0                              0   \n",
       "2                                  0                              0   \n",
       "3                                  0                              0   \n",
       "4                                  0                              0   \n",
       "...                              ...                            ...   \n",
       "1493                               0                              1   \n",
       "1494                               0                              0   \n",
       "1495                               0                              0   \n",
       "1496                               0                              1   \n",
       "1498                               0                              0   \n",
       "\n",
       "      LargestPropertyUseType_Other  LargestPropertyUseType_Parking  \\\n",
       "0                                0                               0   \n",
       "1                                0                               0   \n",
       "2                                0                               0   \n",
       "3                                0                               0   \n",
       "4                                0                               0   \n",
       "...                            ...                             ...   \n",
       "1493                             0                               0   \n",
       "1494                             0                               0   \n",
       "1495                             0                               0   \n",
       "1496                             0                               0   \n",
       "1498                             0                               0   \n",
       "\n",
       "      LargestPropertyUseType_School  LargestPropertyUseType_Sport  \n",
       "0                                 0                             0  \n",
       "1                                 0                             0  \n",
       "2                                 0                             0  \n",
       "3                                 0                             0  \n",
       "4                                 0                             0  \n",
       "...                             ...                           ...  \n",
       "1493                              0                             0  \n",
       "1494                              0                             0  \n",
       "1495                              0                             0  \n",
       "1496                              0                             0  \n",
       "1498                              1                             0  \n",
       "\n",
       "[983 rows x 37 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNRJ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfNRJ2[[\"ENERGYSTARScore\",'NumberofBuildings', 'NumberofFloors', \n",
    "       'age_building', 'part_park', \n",
    "       'PropertyGFABuilding(s)','PropertyGFATotal',\n",
    "        'PrimaryPropertyType_Hotel', 'PrimaryPropertyType_Medical', 'PrimaryPropertyType_Office', 'PrimaryPropertyType_Other', 'PrimaryPropertyType_School',\n",
    "        'LargestPropertyUseType_Culture', 'LargestPropertyUseType_Distribution',   'LargestPropertyUseType_Food', 'LargestPropertyUseType_Hotel', 'LargestPropertyUseType_Legal', 'LargestPropertyUseType_Medical', 'LargestPropertyUseType_Office', 'LargestPropertyUseType_Other', 'LargestPropertyUseType_Parking', 'LargestPropertyUseType_School', 'LargestPropertyUseType_Sport']]\n",
    "\n",
    "y = dfNRJ2[['TotalGHGEmissions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "std_scale = StandardScaler().fit(X_train)\n",
    "X_train_std =  std_scale.transform(X_train)\n",
    "X_test_std =  std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31757685653214995\n"
     ]
    }
   ],
   "source": [
    "MyRandomtest_NRJ = RandomForestRegressor(n_estimators = 500, random_state = 42)\n",
    "\n",
    "MyRandomtest_NRJ.fit(X_train_std, y_train)\n",
    "MyRandomtest_NRJ_predict = MyRandomtest_NRJ.predict(X_test_std)\n",
    "\n",
    "\n",
    "mse_MyRandomtest_NRJ_predict = mean_squared_error(y_test, MyRandomtest_NRJ_predict)\n",
    "mae_MyRandomtest_NRJ_predict = mean_absolute_error(y_test, MyRandomtest_NRJ_predict)\n",
    "rmse_MyRandomtest_NRJ_predict= mse_MyRandomtest_NRJ_predict**.5\n",
    "r2_MyRandomtest_NRJ_predict = r2_score(y_test.values.ravel(), MyRandomtest_NRJ_predict)\n",
    "print(r2_MyRandomtest_NRJ_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES IMPORTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "X has feature names, but RandomForestRegressor was fitted without feature names\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(n_estimators = 500, random_state = 42)\n",
    "random_forest.fit(X_train_std, y_train)\n",
    "random_forest_preds = random_forest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x950 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>feature_importance_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PropertyGFABuilding(s)</td>\n",
       "      <td>101.789322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NumberofBuildings</td>\n",
       "      <td>43.574566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENERGYSTARScore</td>\n",
       "      <td>38.734032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PropertyGFATotal</td>\n",
       "      <td>15.693973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LargestPropertyUseType_Office</td>\n",
       "      <td>13.306266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         col_name  feature_importance_vals\n",
       "5          PropertyGFABuilding(s)               101.789322\n",
       "1               NumberofBuildings                43.574566\n",
       "0                 ENERGYSTARScore                38.734032\n",
       "6                PropertyGFATotal                15.693973\n",
       "18  LargestPropertyUseType_Office                13.306266"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = shap.TreeExplainer(random_forest)\n",
    "shap_values = explainer.shap_values(X_test_std)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "\n",
    "random_forest_resultX = pd.DataFrame(shap_values, columns = feature_names)\n",
    "\n",
    "vals = np.abs(random_forest_resultX.values).mean(0)\n",
    "\n",
    "shap_importance = pd.DataFrame(list(zip(feature_names, vals)),\n",
    "                                  columns=['col_name','feature_importance_vals'])\n",
    "shap_importance.sort_values(by=['feature_importance_vals'],\n",
    "                               ascending=False, inplace=True)\n",
    "shap_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
